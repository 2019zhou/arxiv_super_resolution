{"2024-03-27T00:00:00Z":{"Computer Vision and Pattern Recognition":[{"id":"http://arxiv.org/abs/2403.18821v1","updated":"2024-03-27T17:59:56Z","published":"2024-03-27T17:59:56Z","title":"Real Acoustic Fields: An Audio-Visual Room Acoustics Dataset and\n  Benchmark","summary":"  We present a new dataset called Real Acoustic Fields (RAF) that captures real\nacoustic room data from multiple modalities. The dataset includes high-quality\nand densely captured room impulse response data paired with multi-view images,\nand precise 6DoF pose tracking data for sound emitters and listeners in the\nrooms. We used this dataset to evaluate existing methods for novel-view\nacoustic synthesis and impulse response generation which previously relied on\nsynthetic data. In our evaluation, we thoroughly assessed existing audio and\naudio-visual models against multiple criteria and proposed settings to enhance\ntheir performance on real-world data. We also conducted experiments to\ninvestigate the impact of incorporating visual data (i.e., images and depth)\ninto neural acoustic field models. Additionally, we demonstrated the\neffectiveness of a simple sim2real approach, where a model is pre-trained with\nsimulated data and fine-tuned with sparse real-world data, resulting in\nsignificant improvements in the few-shot learning approach. RAF is the first\ndataset to provide densely captured room acoustic data, making it an ideal\nresource for researchers working on audio and audio-visual neural acoustic\nfield modeling techniques. Demos and datasets are available on our project\npage: https://facebookresearch.github.io/real-acoustic-fields/\n","authors":["Ziyang Chen","Israel D. Gebru","Christian Richardt","Anurag Kumar","William Laney","Andrew Owens","Alexander Richard"],"pdf_url":"https://arxiv.org/pdf/2403.18821v1.pdf","comment":"Accepted to CVPR 2024. Project site:\n  https://facebookresearch.github.io/real-acoustic-fields/"},{"id":"http://arxiv.org/abs/2403.18820v1","updated":"2024-03-27T17:59:54Z","published":"2024-03-27T17:59:54Z","title":"MetaCap: Meta-learning Priors from Multi-View Imagery for Sparse-view\n  Human Performance Capture and Rendering","summary":"  Faithful human performance capture and free-view rendering from sparse RGB\nobservations is a long-standing problem in Vision and Graphics. The main\nchallenges are the lack of observations and the inherent ambiguities of the\nsetting, e.g. occlusions and depth ambiguity. As a result, radiance fields,\nwhich have shown great promise in capturing high-frequency appearance and\ngeometry details in dense setups, perform poorly when na\\\"ively supervising\nthem on sparse camera views, as the field simply overfits to the sparse-view\ninputs. To address this, we propose MetaCap, a method for efficient and\nhigh-quality geometry recovery and novel view synthesis given very sparse or\neven a single view of the human. Our key idea is to meta-learn the radiance\nfield weights solely from potentially sparse multi-view videos, which can serve\nas a prior when fine-tuning them on sparse imagery depicting the human. This\nprior provides a good network weight initialization, thereby effectively\naddressing ambiguities in sparse-view capture. Due to the articulated structure\nof the human body and motion-induced surface deformations, learning such a\nprior is non-trivial. Therefore, we propose to meta-learn the field weights in\na pose-canonicalized space, which reduces the spatial feature range and makes\nfeature learning more effective. Consequently, one can fine-tune our field\nparameters to quickly generalize to unseen poses, novel illumination conditions\nas well as novel and sparse (even monocular) camera views. For evaluating our\nmethod under different scenarios, we collect a new dataset, WildDynaCap, which\ncontains subjects captured in, both, a dense camera dome and in-the-wild sparse\ncamera rigs, and demonstrate superior results compared to recent\nstate-of-the-art methods on both public and WildDynaCap dataset.\n","authors":["Guoxing Sun","Rishabh Dabral","Pascal Fua","Christian Theobalt","Marc Habermann"],"pdf_url":"https://arxiv.org/pdf/2403.18820v1.pdf","comment":"Project page: https://vcai.mpi-inf.mpg.de/projects/MetaCap/"},{"id":"http://arxiv.org/abs/2403.18819v1","updated":"2024-03-27T17:59:53Z","published":"2024-03-27T17:59:53Z","title":"Benchmarking Object Detectors with COCO: A New Path Forward","summary":"  The Common Objects in Context (COCO) dataset has been instrumental in\nbenchmarking object detectors over the past decade. Like every dataset, COCO\ncontains subtle errors and imperfections stemming from its annotation\nprocedure. With the advent of high-performing models, we ask whether these\nerrors of COCO are hindering its utility in reliably benchmarking further\nprogress. In search for an answer, we inspect thousands of masks from COCO\n(2017 version) and uncover different types of errors such as imprecise mask\nboundaries, non-exhaustively annotated instances, and mislabeled masks. Due to\nthe prevalence of COCO, we choose to correct these errors to maintain\ncontinuity with prior research. We develop COCO-ReM (Refined Masks), a cleaner\nset of annotations with visibly better mask quality than COCO-2017. We evaluate\nfifty object detectors and find that models that predict visually sharper masks\nscore higher on COCO-ReM, affirming that they were being incorrectly penalized\ndue to errors in COCO-2017. Moreover, our models trained using COCO-ReM\nconverge faster and score higher than their larger variants trained using\nCOCO-2017, highlighting the importance of data quality in improving object\ndetectors. With these findings, we advocate using COCO-ReM for future object\ndetection research. Our dataset is available at https://cocorem.xyz\n","authors":["Shweta Singh","Aayan Yadav","Jitesh Jain","Humphrey Shi","Justin Johnson","Karan Desai"],"pdf_url":"https://arxiv.org/pdf/2403.18819v1.pdf","comment":"Technical report. Dataset website: https://cocorem.xyz and code:\n  https://github.com/kdexd/coco-rem"},{"id":"http://arxiv.org/abs/2403.18818v1","updated":"2024-03-27T17:59:52Z","published":"2024-03-27T17:59:52Z","title":"ObjectDrop: Bootstrapping Counterfactuals for Photorealistic Object\n  Removal and Insertion","summary":"  Diffusion models have revolutionized image editing but often generate images\nthat violate physical laws, particularly the effects of objects on the scene,\ne.g., occlusions, shadows, and reflections. By analyzing the limitations of\nself-supervised approaches, we propose a practical solution centered on a\n\\q{counterfactual} dataset. Our method involves capturing a scene before and\nafter removing a single object, while minimizing other changes. By fine-tuning\na diffusion model on this dataset, we are able to not only remove objects but\nalso their effects on the scene. However, we find that applying this approach\nfor photorealistic object insertion requires an impractically large dataset. To\ntackle this challenge, we propose bootstrap supervision; leveraging our object\nremoval model trained on a small counterfactual dataset, we synthetically\nexpand this dataset considerably. Our approach significantly outperforms prior\nmethods in photorealistic object removal and insertion, particularly at\nmodeling the effects of objects on the scene.\n","authors":["Daniel Winter","Matan Cohen","Shlomi Fruchter","Yael Pritch","Alex Rav-Acha","Yedid Hoshen"],"pdf_url":"https://arxiv.org/pdf/2403.18818v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.18816v1","updated":"2024-03-27T17:59:33Z","published":"2024-03-27T17:59:33Z","title":"Garment3DGen: 3D Garment Stylization and Texture Generation","summary":"  We introduce Garment3DGen a new method to synthesize 3D garment assets from a\nbase mesh given a single input image as guidance. Our proposed approach allows\nusers to generate 3D textured clothes based on both real and synthetic images,\nsuch as those generated by text prompts. The generated assets can be directly\ndraped and simulated on human bodies. First, we leverage the recent progress of\nimage to 3D diffusion methods to generate 3D garment geometries. However, since\nthese geometries cannot be utilized directly for downstream tasks, we propose\nto use them as pseudo ground-truth and set up a mesh deformation optimization\nprocedure that deforms a base template mesh to match the generated 3D target.\nSecond, we introduce carefully designed losses that allow the input base mesh\nto freely deform towards the desired target, yet preserve mesh quality and\ntopology such that they can be simulated. Finally, a texture estimation module\ngenerates high-fidelity texture maps that are globally and locally consistent\nand faithfully capture the input guidance, allowing us to render the generated\n3D assets. With Garment3DGen users can generate the textured 3D garment of\ntheir choice without the need of artist intervention. One can provide a textual\nprompt describing the garment they desire to generate a simulation-ready 3D\nasset. We present a plethora of quantitative and qualitative comparisons on\nvarious assets both real and generated and provide use-cases of how one can\ngenerate simulation-ready 3D garments.\n","authors":["Nikolaos Sarafianos","Tuur Stuyck","Xiaoyu Xiang","Yilei Li","Jovan Popovic","Rakesh Ranjan"],"pdf_url":"https://arxiv.org/pdf/2403.18816v1.pdf","comment":"Project Page: https://nsarafianos.github.io/garment3dgen"},{"id":"http://arxiv.org/abs/2403.18814v1","updated":"2024-03-27T17:59:04Z","published":"2024-03-27T17:59:04Z","title":"Mini-Gemini: Mining the Potential of Multi-modality Vision Language\n  Models","summary":"  In this work, we introduce Mini-Gemini, a simple and effective framework\nenhancing multi-modality Vision Language Models (VLMs). Despite the\nadvancements in VLMs facilitating basic visual dialog and reasoning, a\nperformance gap persists compared to advanced models like GPT-4 and Gemini. We\ntry to narrow the gap by mining the potential of VLMs for better performance\nand any-to-any workflow from three aspects, i.e., high-resolution visual\ntokens, high-quality data, and VLM-guided generation. To enhance visual tokens,\nwe propose to utilize an additional visual encoder for high-resolution\nrefinement without increasing the visual token count. We further construct a\nhigh-quality dataset that promotes precise image comprehension and\nreasoning-based generation, expanding the operational scope of current VLMs. In\ngeneral, Mini-Gemini further mines the potential of VLMs and empowers current\nframeworks with image understanding, reasoning, and generation simultaneously.\nMini-Gemini supports a series of dense and MoE Large Language Models (LLMs)\nfrom 2B to 34B. It is demonstrated to achieve leading performance in several\nzero-shot benchmarks and even surpasses the developed private models. Code and\nmodels are available at https://github.com/dvlab-research/MiniGemini.\n","authors":["Yanwei Li","Yuechen Zhang","Chengyao Wang","Zhisheng Zhong","Yixin Chen","Ruihang Chu","Shaoteng Liu","Jiaya Jia"],"pdf_url":"https://arxiv.org/pdf/2403.18814v1.pdf","comment":"Code and models are available at\n  https://github.com/dvlab-research/MiniGemini"},{"id":"http://arxiv.org/abs/2403.18811v1","updated":"2024-03-27T17:57:02Z","published":"2024-03-27T17:57:02Z","title":"Duolando: Follower GPT with Off-Policy Reinforcement Learning for Dance\n  Accompaniment","summary":"  We introduce a novel task within the field of 3D dance generation, termed\ndance accompaniment, which necessitates the generation of responsive movements\nfrom a dance partner, the \"follower\", synchronized with the lead dancer's\nmovements and the underlying musical rhythm. Unlike existing solo or group\ndance generation tasks, a duet dance scenario entails a heightened degree of\ninteraction between the two participants, requiring delicate coordination in\nboth pose and position. To support this task, we first build a large-scale and\ndiverse duet interactive dance dataset, DD100, by recording about 117 minutes\nof professional dancers' performances. To address the challenges inherent in\nthis task, we propose a GPT-based model, Duolando, which autoregressively\npredicts the subsequent tokenized motion conditioned on the coordinated\ninformation of the music, the leader's and the follower's movements. To further\nenhance the GPT's capabilities of generating stable results on unseen\nconditions (music and leader motions), we devise an off-policy reinforcement\nlearning strategy that allows the model to explore viable trajectories from\nout-of-distribution samplings, guided by human-defined rewards. Based on the\ncollected dataset and proposed method, we establish a benchmark with several\ncarefully designed metrics.\n","authors":["Li Siyao","Tianpei Gu","Zhitao Yang","Zhengyu Lin","Ziwei Liu","Henghui Ding","Lei Yang","Chen Change Loy"],"pdf_url":"https://arxiv.org/pdf/2403.18811v1.pdf","comment":"ICLR 2024"},{"id":"http://arxiv.org/abs/2403.18807v1","updated":"2024-03-27T17:53:30Z","published":"2024-03-27T17:53:30Z","title":"ECoDepth: Effective Conditioning of Diffusion Models for Monocular Depth\n  Estimation","summary":"  In the absence of parallax cues, a learning-based single image depth\nestimation (SIDE) model relies heavily on shading and contextual cues in the\nimage. While this simplicity is attractive, it is necessary to train such\nmodels on large and varied datasets, which are difficult to capture. It has\nbeen shown that using embeddings from pre-trained foundational models, such as\nCLIP, improves zero shot transfer in several applications. Taking inspiration\nfrom this, in our paper we explore the use of global image priors generated\nfrom a pre-trained ViT model to provide more detailed contextual information.\nWe argue that the embedding vector from a ViT model, pre-trained on a large\ndataset, captures greater relevant information for SIDE than the usual route of\ngenerating pseudo image captions, followed by CLIP based text embeddings. Based\non this idea, we propose a new SIDE model using a diffusion backbone which is\nconditioned on ViT embeddings. Our proposed design establishes a new\nstate-of-the-art (SOTA) for SIDE on NYUv2 dataset, achieving Abs Rel error of\n0.059(14% improvement) compared to 0.069 by the current SOTA (VPD). And on\nKITTI dataset, achieving Sq Rel error of 0.139 (2% improvement) compared to\n0.142 by the current SOTA (GEDepth). For zero-shot transfer with a model\ntrained on NYUv2, we report mean relative improvement of (20%, 23%, 81%, 25%)\nover NeWCRFs on (Sun-RGBD, iBims1, DIODE, HyperSim) datasets, compared to (16%,\n18%, 45%, 9%) by ZoeDepth. The code is available at\nhttps://github.com/Aradhye2002/EcoDepth.\n","authors":["Suraj Patni","Aradhye Agarwal","Chetan Arora"],"pdf_url":"https://arxiv.org/pdf/2403.18807v1.pdf","comment":"Accepted at IEEE/CVF Conference on Computer Vision and Pattern\n  Recognition (CVPR) 2024"},{"id":"http://arxiv.org/abs/2311.10319v4","updated":"2024-03-27T17:41:50Z","published":"2023-11-17T04:04:29Z","title":"Shifting to Machine Supervision: Annotation-Efficient Semi and\n  Self-Supervised Learning for Automatic Medical Image Segmentation and\n  Classification","summary":"  Advancements in clinical treatment are increasingly constrained by the\nlimitations of supervised learning techniques, which depend heavily on large\nvolumes of annotated data. The annotation process is not only costly but also\ndemands substantial time from clinical specialists. Addressing this issue, we\nintroduce the S4MI (Self-Supervision and Semi-Supervision for Medical Imaging)\npipeline, a novel approach that leverages advancements in self-supervised and\nsemi-supervised learning. These techniques engage in auxiliary tasks that do\nnot require labeling, thus simplifying the scaling of machine supervision\ncompared to fully-supervised methods. Our study benchmarks these techniques on\nthree distinct medical imaging datasets to evaluate their effectiveness in\nclassification and segmentation tasks. Notably, we observed that self\nsupervised learning significantly surpassed the performance of supervised\nmethods in the classification of all evaluated datasets. Remarkably, the\nsemi-supervised approach demonstrated superior outcomes in segmentation,\noutperforming fully-supervised methods while using 50% fewer labels across all\ndatasets. In line with our commitment to contributing to the scientific\ncommunity, we have made the S4MI code openly accessible, allowing for broader\napplication and further development of these methods.\n","authors":["Pranav Singh","Raviteja Chukkapalli","Shravan Chaudhari","Luoyao Chen","Mei Chen","Jinqian Pan","Craig Smuda","Jacopo Cirrone"],"pdf_url":"https://arxiv.org/pdf/2311.10319v4.pdf","comment":"Seventeen pages (incl. references), five figures, and one table.\n  (Under Review)"},{"id":"http://arxiv.org/abs/2403.18795v1","updated":"2024-03-27T17:40:14Z","published":"2024-03-27T17:40:14Z","title":"Gamba: Marry Gaussian Splatting with Mamba for single view 3D\n  reconstruction","summary":"  We tackle the challenge of efficiently reconstructing a 3D asset from a\nsingle image with growing demands for automated 3D content creation pipelines.\nPrevious methods primarily rely on Score Distillation Sampling (SDS) and Neural\nRadiance Fields (NeRF). Despite their significant success, these approaches\nencounter practical limitations due to lengthy optimization and considerable\nmemory usage. In this report, we introduce Gamba, an end-to-end amortized 3D\nreconstruction model from single-view images, emphasizing two main insights:\n(1) 3D representation: leveraging a large number of 3D Gaussians for an\nefficient 3D Gaussian splatting process; (2) Backbone design: introducing a\nMamba-based sequential network that facilitates context-dependent reasoning and\nlinear scalability with the sequence (token) length, accommodating a\nsubstantial number of Gaussians. Gamba incorporates significant advancements in\ndata preprocessing, regularization design, and training methodologies. We\nassessed Gamba against existing optimization-based and feed-forward 3D\ngeneration approaches using the real-world scanned OmniObject3D dataset. Here,\nGamba demonstrates competitive generation capabilities, both qualitatively and\nquantitatively, while achieving remarkable speed, approximately 0.6 second on a\nsingle NVIDIA A100 GPU.\n","authors":["Qiuhong Shen","Xuanyu Yi","Zike Wu","Pan Zhou","Hanwang Zhang","Shuicheng Yan","Xinchao Wang"],"pdf_url":"https://arxiv.org/pdf/2403.18795v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.18791v1","updated":"2024-03-27T17:35:24Z","published":"2024-03-27T17:35:24Z","title":"Object Pose Estimation via the Aggregation of Diffusion Features","summary":"  Estimating the pose of objects from images is a crucial task of 3D scene\nunderstanding, and recent approaches have shown promising results on very large\nbenchmarks. However, these methods experience a significant performance drop\nwhen dealing with unseen objects. We believe that it results from the limited\ngeneralizability of image features. To address this problem, we have an\nin-depth analysis on the features of diffusion models, e.g. Stable Diffusion,\nwhich hold substantial potential for modeling unseen objects. Based on this\nanalysis, we then innovatively introduce these diffusion features for object\npose estimation. To achieve this, we propose three distinct architectures that\ncan effectively capture and aggregate diffusion features of different\ngranularity, greatly improving the generalizability of object pose estimation.\nOur approach outperforms the state-of-the-art methods by a considerable margin\non three popular benchmark datasets, LM, O-LM, and T-LESS. In particular, our\nmethod achieves higher accuracy than the previous best arts on unseen objects:\n98.2% vs. 93.5% on Unseen LM, 85.9% vs. 76.3% on Unseen O-LM, showing the\nstrong generalizability of our method. Our code is released at\nhttps://github.com/Tianfu18/diff-feats-pose.\n","authors":["Tianfu Wang","Guosheng Hu","Hongguang Wang"],"pdf_url":"https://arxiv.org/pdf/2403.18791v1.pdf","comment":"Accepted to CVPR2024"},{"id":"http://arxiv.org/abs/2403.18784v1","updated":"2024-03-27T17:32:04Z","published":"2024-03-27T17:32:04Z","title":"SplatFace: Gaussian Splat Face Reconstruction Leveraging an Optimizable\n  Surface","summary":"  We present SplatFace, a novel Gaussian splatting framework designed for 3D\nhuman face reconstruction without reliance on accurate pre-determined geometry.\nOur method is designed to simultaneously deliver both high-quality novel view\nrendering and accurate 3D mesh reconstructions. We incorporate a generic 3D\nMorphable Model (3DMM) to provide a surface geometric structure, making it\npossible to reconstruct faces with a limited set of input images. We introduce\na joint optimization strategy that refines both the Gaussians and the morphable\nsurface through a synergistic non-rigid alignment process. A novel distance\nmetric, splat-to-surface, is proposed to improve alignment by considering both\nthe Gaussian position and covariance. The surface information is also utilized\nto incorporate a world-space densification process, resulting in superior\nreconstruction quality. Our experimental analysis demonstrates that the\nproposed method is competitive with both other Gaussian splatting techniques in\nnovel view synthesis and other 3D reconstruction methods in producing 3D face\nmeshes with high geometric precision.\n","authors":["Jiahao Luo","Jing Liu","James Davis"],"pdf_url":"https://arxiv.org/pdf/2403.18784v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.18775v1","updated":"2024-03-27T17:23:39Z","published":"2024-03-27T17:23:39Z","title":"ImageNet-D: Benchmarking Neural Network Robustness on Diffusion\n  Synthetic Object","summary":"  We establish rigorous benchmarks for visual perception robustness. Synthetic\nimages such as ImageNet-C, ImageNet-9, and Stylized ImageNet provide specific\ntype of evaluation over synthetic corruptions, backgrounds, and textures, yet\nthose robustness benchmarks are restricted in specified variations and have low\nsynthetic quality. In this work, we introduce generative model as a data source\nfor synthesizing hard images that benchmark deep models' robustness. Leveraging\ndiffusion models, we are able to generate images with more diversified\nbackgrounds, textures, and materials than any prior work, where we term this\nbenchmark as ImageNet-D. Experimental results show that ImageNet-D results in a\nsignificant accuracy drop to a range of vision models, from the standard ResNet\nvisual classifier to the latest foundation models like CLIP and MiniGPT-4,\nsignificantly reducing their accuracy by up to 60\\%. Our work suggests that\ndiffusion models can be an effective source to test vision models. The code and\ndataset are available at https://github.com/chenshuang-zhang/imagenet_d.\n","authors":["Chenshuang Zhang","Fei Pan","Junmo Kim","In So Kweon","Chengzhi Mao"],"pdf_url":"https://arxiv.org/pdf/2403.18775v1.pdf","comment":"Accepted at CVPR 2024"},{"id":"http://arxiv.org/abs/2312.01220v2","updated":"2024-03-27T17:23:16Z","published":"2023-12-02T20:11:48Z","title":"Boosting Object Detection with Zero-Shot Day-Night Domain Adaptation","summary":"  Detecting objects in low-light scenarios presents a persistent challenge, as\ndetectors trained on well-lit data exhibit significant performance degradation\non low-light data due to low visibility. Previous methods mitigate this issue\nby exploring image enhancement or object detection techniques with real\nlow-light image datasets. However, the progress is impeded by the inherent\ndifficulties about collecting and annotating low-light images. To address this\nchallenge, we propose to boost low-light object detection with zero-shot\nday-night domain adaptation, which aims to generalize a detector from well-lit\nscenarios to low-light ones without requiring real low-light data. Revisiting\nRetinex theory in the low-level vision, we first design a reflectance\nrepresentation learning module to learn Retinex-based illumination invariance\nin images with a carefully designed illumination invariance reinforcement\nstrategy. Next, an interchange-redecomposition-coherence procedure is\nintroduced to improve over the vanilla Retinex image decomposition process by\nperforming two sequential image decompositions and introducing a\nredecomposition cohering loss. Extensive experiments on ExDark, DARK FACE, and\nCODaN datasets show strong low-light generalizability of our method. Our code\nis available at https://github.com/ZPDu/DAI-Net.\n","authors":["Zhipeng Du","Miaojing Shi","Jiankang Deng"],"pdf_url":"https://arxiv.org/pdf/2312.01220v2.pdf","comment":"Accepted to CVPR 2024"},{"id":"http://arxiv.org/abs/2403.06054v4","updated":"2024-03-27T17:06:10Z","published":"2024-03-10T00:47:05Z","title":"Decoupled Data Consistency with Diffusion Purification for Image\n  Restoration","summary":"  Diffusion models have recently gained traction as a powerful class of deep\ngenerative priors, excelling in a wide range of image restoration tasks due to\ntheir exceptional ability to model data distributions. To solve image\nrestoration problems, many existing techniques achieve data consistency by\nincorporating additional likelihood gradient steps into the reverse sampling\nprocess of diffusion models. However, the additional gradient steps pose a\nchallenge for real-world practical applications as they incur a large\ncomputational overhead, thereby increasing inference time. They also present\nadditional difficulties when using accelerated diffusion model samplers, as the\nnumber of data consistency steps is limited by the number of reverse sampling\nsteps. In this work, we propose a novel diffusion-based image restoration\nsolver that addresses these issues by decoupling the reverse process from the\ndata consistency steps. Our method involves alternating between a\nreconstruction phase to maintain data consistency and a refinement phase that\nenforces the prior via diffusion purification. Our approach demonstrates\nversatility, making it highly adaptable for efficient problem-solving in latent\nspace. Additionally, it reduces the necessity for numerous sampling steps\nthrough the integration of consistency models. The efficacy of our approach is\nvalidated through comprehensive experiments across various image restoration\ntasks, including image denoising, deblurring, inpainting, and super-resolution.\n","authors":["Xiang Li","Soo Min Kwon","Ismail R. Alkhouri","Saiprasad Ravishankar","Qing Qu"],"pdf_url":"https://arxiv.org/pdf/2403.06054v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.18762v1","updated":"2024-03-27T17:01:10Z","published":"2024-03-27T17:01:10Z","title":"ModaLink: Unifying Modalities for Efficient Image-to-PointCloud Place\n  Recognition","summary":"  Place recognition is an important task for robots and autonomous cars to\nlocalize themselves and close loops in pre-built maps. While single-modal\nsensor-based methods have shown satisfactory performance, cross-modal place\nrecognition that retrieving images from a point-cloud database remains a\nchallenging problem. Current cross-modal methods transform images into 3D\npoints using depth estimation for modality conversion, which are usually\ncomputationally intensive and need expensive labeled data for depth\nsupervision. In this work, we introduce a fast and lightweight framework to\nencode images and point clouds into place-distinctive descriptors. We propose\nan effective Field of View (FoV) transformation module to convert point clouds\ninto an analogous modality as images. This module eliminates the necessity for\ndepth estimation and helps subsequent modules achieve real-time performance. We\nfurther design a non-negative factorization-based encoder to extract mutually\nconsistent semantic features between point clouds and images. This encoder\nyields more distinctive global descriptors for retrieval. Experimental results\non the KITTI dataset show that our proposed methods achieve state-of-the-art\nperformance while running in real time. Additional evaluation on the HAOMO\ndataset covering a 17 km trajectory further shows the practical generalization\ncapabilities. We have released the implementation of our methods as open source\nat: https://github.com/haomo-ai/ModaLink.git.\n","authors":["Weidong Xie","Lun Luo","Nanfei Ye","Yi Ren","Shaoyi Du","Minhang Wang","Jintao Xu","Rui Ai","Weihao Gu","Xieyuanli Chen"],"pdf_url":"https://arxiv.org/pdf/2403.18762v1.pdf","comment":"8 pages, 11 figures, conference"},{"id":"http://arxiv.org/abs/2403.18756v1","updated":"2024-03-27T16:56:14Z","published":"2024-03-27T16:56:14Z","title":"Detection of subclinical atherosclerosis by image-based deep learning on\n  chest x-ray","summary":"  Aims. To develop a deep-learning based system for recognition of subclinical\natherosclerosis on a plain frontal chest x-ray. Methods and Results. A\ndeep-learning algorithm to predict coronary artery calcium (CAC) score (the\nAI-CAC model) was developed on 460 chest x-ray (80% training cohort, 20%\ninternal validation cohort) of primary prevention patients (58.4% male, median\nage 63 [51-74] years) with available paired chest x-ray and chest computed\ntomography (CT) indicated for any clinical reason and performed within 3\nmonths. The CAC score calculated on chest CT was used as ground truth. The\nmodel was validated on an temporally-independent cohort of 90 patients from the\nsame institution (external validation). The diagnostic accuracy of the AI-CAC\nmodel assessed by the area under the curve (AUC) was the primary outcome.\nOverall, median AI-CAC score was 35 (0-388) and 28.9% patients had no AI-CAC.\nAUC of the AI-CAC model to identify a CAC>0 was 0.90 in the internal validation\ncohort and 0.77 in the external validation cohort. Sensitivity was consistently\nabove 92% in both cohorts. In the overall cohort (n=540), among patients with\nAI-CAC=0, a single ASCVD event occurred, after 4.3 years. Patients with\nAI-CAC>0 had significantly higher Kaplan Meier estimates for ASCVD events\n(13.5% vs. 3.4%, log-rank=0.013). Conclusion. The AI-CAC model seems to\naccurately detect subclinical atherosclerosis on chest x-ray with elevated\nsensitivity, and to predict ASCVD events with elevated negative predictive\nvalue. Adoption of the AI-CAC model to refine CV risk stratification or as an\nopportunistic screening tool requires prospective evaluation.\n","authors":["Guglielmo Gallone","Francesco Iodice","Alberto Presta","Davide Tore","Ovidio de Filippo","Michele Visciano","Carlo Alberto Barbano","Alessandro Serafini","Paola Gorrini","Alessandro Bruno","Walter Grosso Marra","James Hughes","Mario Iannaccone","Paolo Fonio","Attilio Fiandrotti","Alessandro Depaoli","Marco Grangetto","Gaetano Maria de Ferrari","Fabrizio D'Ascenzo"],"pdf_url":"https://arxiv.org/pdf/2403.18756v1.pdf","comment":"Submitted to European Heart Journal - Cardiovascular Imaging Added\n  also the additional material 44 pages (30 main paper, 14 additional\n  material), 14 figures (5 main manuscript, 9 additional material)"},{"id":"http://arxiv.org/abs/2303.09817v2","updated":"2024-03-27T16:52:59Z","published":"2023-03-17T07:53:18Z","title":"Interpretable machine learning for time-to-event prediction in medicine\n  and healthcare","summary":"  Time-to-event prediction, e.g. cancer survival analysis or hospital length of\nstay, is a highly prominent machine learning task in medical and healthcare\napplications. However, only a few interpretable machine learning methods comply\nwith its challenges. To facilitate a comprehensive explanatory analysis of\nsurvival models, we formally introduce time-dependent feature effects and\nglobal feature importance explanations. We show how post-hoc interpretation\nmethods allow for finding biases in AI systems predicting length of stay using\na novel multi-modal dataset created from 1235 X-ray images with textual\nradiology reports annotated by human experts. Moreover, we evaluate cancer\nsurvival models beyond predictive performance to include the importance of\nmulti-omics feature groups based on a large-scale benchmark comprising 11\ndatasets from The Cancer Genome Atlas (TCGA). Model developers can use the\nproposed methods to debug and improve machine learning algorithms, while\nphysicians can discover disease biomarkers and assess their significance. We\nhope the contributed open data and code resources facilitate future work in the\nemerging research direction of explainable survival analysis.\n","authors":["Hubert Baniecki","Bartlomiej Sobieski","Patryk Szatkowski","Przemyslaw Bombinski","Przemyslaw Biecek"],"pdf_url":"https://arxiv.org/pdf/2303.09817v2.pdf","comment":"An extended version of an AIME 2023 paper submitted to Artificial\n  Intelligence in Medicine"},{"id":"http://arxiv.org/abs/2403.14623v2","updated":"2024-03-27T16:49:35Z","published":"2024-03-21T17:59:41Z","title":"Simplified Diffusion Schr√∂dinger Bridge","summary":"  This paper introduces a novel theoretical simplification of the Diffusion\nSchr\\\"odinger Bridge (DSB) that facilitates its unification with Score-based\nGenerative Models (SGMs), addressing the limitations of DSB in complex data\ngeneration and enabling faster convergence and enhanced performance. By\nemploying SGMs as an initial solution for DSB, our approach capitalizes on the\nstrengths of both frameworks, ensuring a more efficient training process and\nimproving the performance of SGM. We also propose a reparameterization\ntechnique that, despite theoretical approximations, practically improves the\nnetwork's fitting capabilities. Our extensive experimental evaluations confirm\nthe effectiveness of the simplified DSB, demonstrating its significant\nimprovements. We believe the contributions of this work pave the way for\nadvanced generative modeling. The code is available at\nhttps://github.com/checkcrab/SDSB.\n","authors":["Zhicong Tang","Tiankai Hang","Shuyang Gu","Dong Chen","Baining Guo"],"pdf_url":"https://arxiv.org/pdf/2403.14623v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.11107v2","updated":"2024-03-27T16:48:34Z","published":"2024-03-17T06:21:21Z","title":"Self-supervised co-salient object detection via feature correspondence\n  at multiple scales","summary":"  Our paper introduces a novel two-stage self-supervised approach for detecting\nco-occurring salient objects (CoSOD) in image groups without requiring\nsegmentation annotations. Unlike existing unsupervised methods that rely solely\non patch-level information (e.g. clustering patch descriptors) or on\ncomputation heavy off-the-shelf components for CoSOD, our lightweight model\nleverages feature correspondences at both patch and region levels,\nsignificantly improving prediction performance. In the first stage, we train a\nself-supervised network that detects co-salient regions by computing local\npatch-level feature correspondences across images. We obtain the segmentation\npredictions using confidence-based adaptive thresholding. In the next stage, we\nrefine these intermediate segmentations by eliminating the detected regions\n(within each image) whose averaged feature representations are dissimilar to\nthe foreground feature representation averaged across all the cross-attention\nmaps (from the previous stage). Extensive experiments on three CoSOD benchmark\ndatasets show that our self-supervised model outperforms the corresponding\nstate-of-the-art models by a huge margin (e.g. on the CoCA dataset, our model\nhas a 13.7% F-measure gain over the SOTA unsupervised CoSOD model). Notably,\nour self-supervised model also outperforms several recent fully supervised\nCoSOD models on the three test datasets (e.g., on the CoCA dataset, our model\nhas a 4.6% F-measure gain over a recent supervised CoSOD model).\n","authors":["Souradeep Chakraborty","Dimitris Samaras"],"pdf_url":"https://arxiv.org/pdf/2403.11107v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.18734v1","updated":"2024-03-27T16:22:45Z","published":"2024-03-27T16:22:45Z","title":"A vascular synthetic model for improved aneurysm segmentation and\n  detection via Deep Neural Networks","summary":"  We hereby present a full synthetic model, able to mimic the various\nconstituents of the cerebral vascular tree: the cerebral arteries, the\nbifurcations and the intracranial aneurysms. By building this model, our goal\nwas to provide a substantial dataset of brain arteries which could be used by a\n3D Convolutional Neural Network (CNN) to either segment or detect/recognize\nvarious vascular diseases (such as artery dissection/thrombosis) or even some\nportions of the cerebral vasculature, such as the bifurcations or aneurysms. In\nthis study, we will particularly focus on Intra-Cranial Aneurysm (ICA)\ndetection and segmentation. The cerebral aneurysms most often occur on a\nparticular structure of the vascular tree named the Circle of Willis. Various\nstudies have been conducted to detect and monitor the ICAs and those based on\nDeep Learning (DL) achieve the best performances. Specifically, in this work,\nwe propose a full synthetic 3D model able to mimic the brain vasculature as\nacquired by Magnetic Resonance Angiography (MRA), and more particularly the\nTime Of Flight (TOF) principle. Among the various MRI modalities, the MRA-TOF\nallows to have a relatively good rendering of the blood vessels and is\nnon-invasive (no contrast liquid injection). Our model has been designed to\nsimultaneously mimic the arteries geometry, the ICA shape and the background\nnoise. The geometry of the vascular tree is modeled thanks to an interpolation\nwith 3D Spline functions, and the statistical properties of the background MRI\nnoise is collected from MRA acquisitions and reproduced within the model. In\nthis work, we thoroughly describe the synthetic vasculature model, we build up\na neural network designed for ICA segmentation and detection, and finally, we\ncarry out an in-depth evaluation of the performance gap gained thanks to the\nsynthetic model data augmentation.\n","authors":["Rafic Nader","Florent Autrusseau","Vincent L'Allinec","Romain Bourcier"],"pdf_url":"https://arxiv.org/pdf/2403.18734v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.18731v1","updated":"2024-03-27T16:21:24Z","published":"2024-03-27T16:21:24Z","title":"Enhancing Manufacturing Quality Prediction Models through the\n  Integration of Explainability Methods","summary":"  This research presents a method that utilizes explainability techniques to\namplify the performance of machine learning (ML) models in forecasting the\nquality of milling processes, as demonstrated in this paper through a\nmanufacturing use case. The methodology entails the initial training of ML\nmodels, followed by a fine-tuning phase where irrelevant features identified\nthrough explainability methods are eliminated. This procedural refinement\nresults in performance enhancements, paving the way for potential reductions in\nmanufacturing costs and a better understanding of the trained ML models. This\nstudy highlights the usefulness of explainability techniques in both explaining\nand optimizing predictive models in the manufacturing realm.\n","authors":["Dennis Gross","Helge Spieker","Arnaud Gotlieb","Ricardo Knoblauch"],"pdf_url":"https://arxiv.org/pdf/2403.18731v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.18730v1","updated":"2024-03-27T16:20:55Z","published":"2024-03-27T16:20:55Z","title":"Towards Image Ambient Lighting Normalization","summary":"  Lighting normalization is a crucial but underexplored restoration task with\nbroad applications. However, existing works often simplify this task within the\ncontext of shadow removal, limiting the light sources to one and\noversimplifying the scene, thus excluding complex self-shadows and restricting\nsurface classes to smooth ones. Although promising, such simplifications hinder\ngeneralizability to more realistic settings encountered in daily use. In this\npaper, we propose a new challenging task termed Ambient Lighting Normalization\n(ALN), which enables the study of interactions between shadows, unifying image\nrestoration and shadow removal in a broader context. To address the lack of\nappropriate datasets for ALN, we introduce the large-scale high-resolution\ndataset Ambient6K, comprising samples obtained from multiple light sources and\nincluding self-shadows resulting from complex geometries, which is the first of\nits kind. For benchmarking, we select various mainstream methods and rigorously\nevaluate them on Ambient6K. Additionally, we propose IFBlend, a novel strong\nbaseline that maximizes Image-Frequency joint entropy to selectively restore\nlocal areas under different lighting conditions, without relying on shadow\nlocalization priors. Experiments show that IFBlend achieves SOTA scores on\nAmbient6K and exhibits competitive performance on conventional shadow removal\nbenchmarks compared to shadow-specific models with mask priors. The dataset,\nbenchmark, and code are available at https://github.com/fvasluianu97/IFBlend.\n","authors":["Florin-Alexandru Vasluianu","Tim Seizinger","Zongwei Wu","Rakesh Ranjan","Radu Timofte"],"pdf_url":"https://arxiv.org/pdf/2403.18730v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.09992v3","updated":"2024-03-27T16:20:52Z","published":"2023-03-17T14:07:55Z","title":"LION: Implicit Vision Prompt Tuning","summary":"  Despite recent competitive performance across a range of vision tasks, vision\nTransformers still have an issue of heavy computational costs. Recently, vision\nprompt learning has provided an economic solution to this problem without\nfine-tuning the whole large-scale models. However, the efficiency of existing\nmodels are still far from satisfactory due to insertion of extensive prompts\nblocks and trick prompt designs. In this paper, we propose an efficient vision\nmodel named impLicit vIsion prOmpt tuNing (LION), which is motivated by deep\nimplicit models with stable memory costs for various complex tasks. In\nparticular, we merely insect two equilibrium implicit layers in two ends of the\npre-trained main backbone with parameters in the backbone frozen. Moreover, we\nprune the parameters in these two layers according to lottery hypothesis. The\nperformance obtained by our LION are promising on a wide range of datasets. In\nparticular, our LION reduces up to 11.5% of training parameter numbers while\nobtaining higher performance compared with the state-of-the-art baseline VPT,\nespecially under challenging scenes. Furthermore, we find that our proposed\nLION had a good generalization performance, making it an easy way to boost\ntransfer learning in the future.\n","authors":["Haixin Wang","Jianlong Chang","Xiao Luo","Jinan Sun","Zhouchen Lin","Qi Tian"],"pdf_url":"https://arxiv.org/pdf/2303.09992v3.pdf","comment":"Accepted by AAAI2024; 9 pages, 3 figures, 4 tables"},{"id":"http://arxiv.org/abs/2403.18717v1","updated":"2024-03-27T16:06:37Z","published":"2024-03-27T16:06:37Z","title":"Semi-Supervised Learning for Deep Causal Generative Models","summary":"  Developing models that can answer questions of the form \"How would $x$ change\nif $y$ had been $z$?\" is fundamental for advancing medical image analysis.\nTraining causal generative models that address such counterfactual questions,\nthough, currently requires that all relevant variables have been observed and\nthat corresponding labels are available in training data. However, clinical\ndata may not have complete records for all patients and state of the art causal\ngenerative models are unable to take full advantage of this. We thus develop,\nfor the first time, a semi-supervised deep causal generative model that\nexploits the causal relationships between variables to maximise the use of all\navailable data. We explore this in the setting where each sample is either\nfully labelled or fully unlabelled, as well as the more clinically realistic\ncase of having different labels missing for each sample. We leverage techniques\nfrom causal inference to infer missing values and subsequently generate\nrealistic counterfactuals, even for samples with incomplete labels.\n","authors":["Yasin Ibrahim","Hermione Warr","Konstantinos Kamnitsas"],"pdf_url":"https://arxiv.org/pdf/2403.18717v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.18715v1","updated":"2024-03-27T16:04:47Z","published":"2024-03-27T16:04:47Z","title":"Mitigating Hallucinations in Large Vision-Language Models with\n  Instruction Contrastive Decoding","summary":"  Large Vision-Language Models (LVLMs) are increasingly adept at generating\ncontextually detailed and coherent responses from visual inputs. However, their\napplication in multimodal decision-making and open-ended generation is hindered\nby a notable rate of hallucinations, where generated text inaccurately\nrepresents the visual contents. To address this issue, this paper introduces\nthe Instruction Contrastive Decoding (ICD) method, a novel approach designed to\nreduce hallucinations during LVLM inference. Our method is inspired by our\nobservation that what we call disturbance instructions significantly exacerbate\nhallucinations in multimodal fusion modules. ICD contrasts distributions from\nstandard and instruction disturbance, thereby increasing alignment uncertainty\nand effectively subtracting hallucinated concepts from the original\ndistribution. Through comprehensive experiments on discriminative benchmarks\n(POPE and MME) and a generative benchmark (LLaVa-Bench), we demonstrate that\nICD significantly mitigates both object-level and attribute-level\nhallucinations. Moreover, our method not only addresses hallucinations but also\nsignificantly enhances the general perception and recognition capabilities of\nLVLMs.\n","authors":["Xintong Wang","Jingheng Pan","Liang Ding","Chris Biemann"],"pdf_url":"https://arxiv.org/pdf/2403.18715v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.18714v1","updated":"2024-03-27T16:02:00Z","published":"2024-03-27T16:02:00Z","title":"Bringing Textual Prompt to AI-Generated Image Quality Assessment","summary":"  AI-Generated Images (AGIs) have inherent multimodal nature. Unlike\ntraditional image quality assessment (IQA) on natural scenarios, AGIs quality\nassessment (AGIQA) takes the correspondence of image and its textual prompt\ninto consideration. This is coupled in the ground truth score, which confuses\nthe unimodal IQA methods. To solve this problem, we introduce IP-IQA (AGIs\nQuality Assessment via Image and Prompt), a multimodal framework for AGIQA via\ncorresponding image and prompt incorporation. Specifically, we propose a novel\nincremental pretraining task named Image2Prompt for better understanding of\nAGIs and their corresponding textual prompts. An effective and efficient\nimage-prompt fusion module, along with a novel special [QA] token, are also\napplied. Both are plug-and-play and beneficial for the cooperation of image and\nits corresponding prompt. Experiments demonstrate that our IP-IQA achieves the\nstate-of-the-art on AGIQA-1k and AGIQA-3k datasets. Code will be available.\n","authors":["Bowen Qu","Haohui Li","Wei Gao"],"pdf_url":"https://arxiv.org/pdf/2403.18714v1.pdf","comment":"6 pages, 3 figures, accepted by ICME2024"},{"id":"http://arxiv.org/abs/2403.18711v1","updated":"2024-03-27T15:58:25Z","published":"2024-03-27T15:58:25Z","title":"SAT-NGP : Unleashing Neural Graphics Primitives for Fast Relightable\n  Transient-Free 3D reconstruction from Satellite Imagery","summary":"  Current stereo-vision pipelines produce high accuracy 3D reconstruction when\nusing multiple pairs or triplets of satellite images. However, these pipelines\nare sensitive to the changes between images that can occur as a result of\nmulti-date acquisitions. Such variations are mainly due to variable shadows,\nreflexions and transient objects (cars, vegetation). To take such changes into\naccount, Neural Radiance Fields (NeRF) have recently been applied to multi-date\nsatellite imagery. However, Neural methods are very compute-intensive, taking\ndozens of hours to learn, compared with minutes for standard stereo-vision\npipelines. Following the ideas of Instant Neural Graphics Primitives we propose\nto use an efficient sampling strategy and multi-resolution hash encoding to\naccelerate the learning. Our model, Satellite Neural Graphics Primitives\n(SAT-NGP) decreases the learning time to 15 minutes while maintaining the\nquality of the 3D reconstruction.\n","authors":["Camille Billouard","Dawa Derksen","Emmanuelle Sarrazin","Bruno Vallet"],"pdf_url":"https://arxiv.org/pdf/2403.18711v1.pdf","comment":"5 pages, 3 figures, 1 table; Accepted to International Geoscience and\n  Remote Sensing Symposium (IGARSS) 2024; Code available at\n  https://github.com/Ellimac0/SAT-NGP"},{"id":"http://arxiv.org/abs/2403.18708v1","updated":"2024-03-27T15:56:42Z","published":"2024-03-27T15:56:42Z","title":"Dense Vision Transformer Compression with Few Samples","summary":"  Few-shot model compression aims to compress a large model into a more compact\none with only a tiny training set (even without labels). Block-level pruning\nhas recently emerged as a leading technique in achieving high accuracy and low\nlatency in few-shot CNN compression. But, few-shot compression for Vision\nTransformers (ViT) remains largely unexplored, which presents a new challenge.\nIn particular, the issue of sparse compression exists in traditional CNN\nfew-shot methods, which can only produce very few compressed models of\ndifferent model sizes. This paper proposes a novel framework for few-shot ViT\ncompression named DC-ViT. Instead of dropping the entire block, DC-ViT\nselectively eliminates the attention module while retaining and reusing\nportions of the MLP module. DC-ViT enables dense compression, which outputs\nnumerous compressed models that densely populate the range of model complexity.\nDC-ViT outperforms state-of-the-art few-shot compression methods by a\nsignificant margin of 10 percentage points, along with lower latency in the\ncompression of ViT and its variants.\n","authors":["Hanxiao Zhang","Yifan Zhou","Guo-Hua Wang","Jianxin Wu"],"pdf_url":"https://arxiv.org/pdf/2403.18708v1.pdf","comment":"Accepted to CVPR 2024. Note: Jianxin Wu is a contributing author for\n  the arXiv version of this paper but is not listed as an author in the CVPR\n  version due to his role as Program Chair"},{"id":"http://arxiv.org/abs/2401.15120v2","updated":"2024-03-27T15:49:52Z","published":"2024-01-26T03:44:58Z","title":"Incorporating simulated spatial context information improves the\n  effectiveness of contrastive learning models","summary":"  Visual learning often occurs in a specific context, where an agent acquires\nskills through exploration and tracking of its location in a consistent\nenvironment. The historical spatial context of the agent provides a similarity\nsignal for self-supervised contrastive learning. We present a unique approach,\ntermed Environmental Spatial Similarity (ESS), that complements existing\ncontrastive learning methods. Using images from simulated, photorealistic\nenvironments as an experimental setting, we demonstrate that ESS outperforms\ntraditional instance discrimination approaches. Moreover, sampling additional\ndata from the same environment substantially improves accuracy and provides new\naugmentations. ESS allows remarkable proficiency in room classification and\nspatial prediction tasks, especially in unfamiliar environments. This learning\nparadigm has the potential to enable rapid visual learning in agents operating\nin new environments with unique visual characteristics. Potentially\ntransformative applications span from robotics to space exploration. Our proof\nof concept demonstrates improved efficiency over methods that rely on\nextensive, disconnected datasets.\n","authors":["Lizhen Zhu","James Z. Wang","Wonseuk Lee","Brad Wyble"],"pdf_url":"https://arxiv.org/pdf/2401.15120v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.12091v3","updated":"2024-03-27T15:44:25Z","published":"2023-03-21T09:07:15Z","title":"Adaptive Negative Evidential Deep Learning for Open-set Semi-supervised\n  Learning","summary":"  Semi-supervised learning (SSL) methods assume that labeled data, unlabeled\ndata and test data are from the same distribution. Open-set semi-supervised\nlearning (Open-set SSL) considers a more practical scenario, where unlabeled\ndata and test data contain new categories (outliers) not observed in labeled\ndata (inliers). Most previous works focused on outlier detection via binary\nclassifiers, which suffer from insufficient scalability and inability to\ndistinguish different types of uncertainty. In this paper, we propose a novel\nframework, Adaptive Negative Evidential Deep Learning (ANEDL) to tackle these\nlimitations. Concretely, we first introduce evidential deep learning (EDL) as\nan outlier detector to quantify different types of uncertainty, and design\ndifferent uncertainty metrics for self-training and inference. Furthermore, we\npropose a novel adaptive negative optimization strategy, making EDL more\ntailored to the unlabeled dataset containing both inliers and outliers. As\ndemonstrated empirically, our proposed method outperforms existing\nstate-of-the-art methods across four datasets.\n","authors":["Yang Yu","Danruo Deng","Furui Liu","Yueming Jin","Qi Dou","Guangyong Chen","Pheng-Ann Heng"],"pdf_url":"https://arxiv.org/pdf/2303.12091v3.pdf","comment":"Accepted by AAAI2024"},{"id":"http://arxiv.org/abs/2403.18690v1","updated":"2024-03-27T15:41:23Z","published":"2024-03-27T15:41:23Z","title":"Annolid: Annotate, Segment, and Track Anything You Need","summary":"  Annolid is a deep learning-based software package designed for the\nsegmentation, labeling, and tracking of research targets within video files,\nfocusing primarily on animal behavior analysis. Based on state-of-the-art\ninstance segmentation methods, Annolid now harnesses the Cutie video object\nsegmentation model to achieve resilient, markerless tracking of multiple\nanimals from single annotated frames, even in environments in which they may be\npartially or entirely concealed by environmental features or by one another.\nOur integration of Segment Anything and Grounding-DINO strategies additionally\nenables the automatic masking and segmentation of recognizable animals and\nobjects by text command, removing the need for manual annotation. Annolid's\ncomprehensive approach to object segmentation flexibly accommodates a broad\nspectrum of behavior analysis applications, enabling the classification of\ndiverse behavioral states such as freezing, digging, pup huddling, and social\ninteractions in addition to the tracking of animals and their body parts.\n","authors":["Chen Yang","Thomas A. Cleland"],"pdf_url":"https://arxiv.org/pdf/2403.18690v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2312.08479v2","updated":"2024-03-27T15:38:27Z","published":"2023-12-13T19:38:50Z","title":"Vision Transformer-Based Deep Learning for Histologic Classification of\n  Endometrial Cancer","summary":"  Endometrial cancer, the fourth most common cancer in females in the United\nStates, with the lifetime risk for developing this disease is approximately\n2.8% in women. Precise histologic evaluation and molecular classification of\nendometrial cancer is important for effective patient management and\ndetermining the best treatment modalities. This study introduces EndoNet, which\nuses convolutional neural networks for extracting histologic features and a\nvision transformer for aggregating these features and classifying slides based\non their visual characteristics into high- and low- grade. The model was\ntrained on 929 digitized hematoxylin and eosin-stained whole-slide images of\nendometrial cancer from hysterectomy cases at Dartmouth-Health. It classifies\nthese slides into low-grade (Endometroid Grades 1 and 2) and high-grade\n(endometroid carcinoma FIGO grade 3, uterine serous carcinoma, carcinosarcoma)\ncategories. EndoNet was evaluated on an internal test set of 110 patients and\nan external test set of 100 patients from the public TCGA database. The model\nachieved a weighted average F1-score of 0.91 (95% CI: 0.86-0.95) and an AUC of\n0.95 (95% CI: 0.89-0.99) on the internal test, and 0.86 (95% CI: 0.80-0.94) for\nF1-score and 0.86 (95% CI: 0.75-0.93) for AUC on the external test. Pending\nfurther validation, EndoNet has the potential to support pathologists without\nthe need of manual annotations in classifying the grades of gynecologic\npathology tumors.\n","authors":["Manu Goyal","Laura J. Tafe","James X. Feng","Kristen E. Muller","Liesbeth Hondelink","Jessica L. Bentz","Saeed Hassanpour"],"pdf_url":"https://arxiv.org/pdf/2312.08479v2.pdf","comment":"4 Tables and 3 Figures"},{"id":"http://arxiv.org/abs/2308.06098v2","updated":"2024-03-27T15:26:44Z","published":"2023-08-11T12:18:53Z","title":"Automated Construction of Time-Space Diagrams for Traffic Analysis Using\n  Street-View Video Sequence","summary":"  Time-space diagrams are essential tools for analyzing traffic patterns and\noptimizing transportation infrastructure and traffic management strategies.\nTraditional data collection methods for these diagrams have limitations in\nterms of temporal and spatial coverage. Recent advancements in camera\ntechnology have overcome these limitations and provided extensive urban data.\nIn this study, we propose an innovative approach to constructing time-space\ndiagrams by utilizing street-view video sequences captured by cameras mounted\non moving vehicles. Using the state-of-the-art YOLOv5, StrongSORT, and\nphotogrammetry techniques for distance calculation, we can infer vehicle\ntrajectories from the video data and generate time-space diagrams. To evaluate\nthe effectiveness of our proposed method, we utilized datasets from the KITTI\ncomputer vision benchmark suite. The evaluation results demonstrate that our\napproach can generate trajectories from video data, although there are some\nerrors that can be mitigated by improving the performance of the detector,\ntracker, and distance calculation components. In conclusion, the utilization of\nstreet-view video sequences captured by cameras mounted on moving vehicles,\ncombined with state-of-the-art computer vision techniques, has immense\npotential for constructing comprehensive time-space diagrams. These diagrams\noffer valuable insights into traffic patterns and contribute to the design of\ntransportation infrastructure and traffic management strategies.\n","authors":["Tanay Rastogi","M√•rten Bj√∂rkman"],"pdf_url":"https://arxiv.org/pdf/2308.06098v2.pdf","comment":"The paper is published in 2023 IEEE 26th International Conference on\n  Intelligent Transportation Systems (ITSC)"},{"id":"http://arxiv.org/abs/2403.18674v1","updated":"2024-03-27T15:17:10Z","published":"2024-03-27T15:17:10Z","title":"Deep Learning for Robust and Explainable Models in Computer Vision","summary":"  Recent breakthroughs in machine and deep learning (ML and DL) research have\nprovided excellent tools for leveraging enormous amounts of data and optimizing\nhuge models with millions of parameters to obtain accurate networks for image\nprocessing. These developments open up tremendous opportunities for using\nartificial intelligence (AI) in the automation and human assisted AI industry.\nHowever, as more and more models are deployed and used in practice, many\nchallenges have emerged. This thesis presents various approaches that address\nrobustness and explainability challenges for using ML and DL in practice.\n  Robustness and reliability are the critical components of any model before\ncertification and deployment in practice. Deep convolutional neural networks\n(CNNs) exhibit vulnerability to transformations of their inputs, such as\nrotation and scaling, or intentional manipulations as described in the\nadversarial attack literature. In addition, building trust in AI-based models\nrequires a better understanding of current models and developing methods that\nare more explainable and interpretable a priori.\n  This thesis presents developments in computer vision models' robustness and\nexplainability. Furthermore, this thesis offers an example of using vision\nmodels' feature response visualization (models' interpretations) to improve\nrobustness despite interpretability and robustness being seemingly unrelated in\nthe related research. Besides methodological developments for robust and\nexplainable vision models, a key message of this thesis is introducing model\ninterpretation techniques as a tool for understanding vision models and\nimproving their design and robustness. In addition to the theoretical\ndevelopments, this thesis demonstrates several applications of ML and DL in\ndifferent contexts, such as medical imaging and affective computing.\n","authors":["Mohammadreza Amirian"],"pdf_url":"https://arxiv.org/pdf/2403.18674v1.pdf","comment":"150 pages, 37 figures, 12 tables"},{"id":"http://arxiv.org/abs/2311.15803v3","updated":"2024-03-27T15:05:19Z","published":"2023-11-27T13:25:47Z","title":"SOAC: Spatio-Temporal Overlap-Aware Multi-Sensor Calibration using\n  Neural Radiance Fields","summary":"  In rapidly-evolving domains such as autonomous driving, the use of multiple\nsensors with different modalities is crucial to ensure high operational\nprecision and stability. To correctly exploit the provided information by each\nsensor in a single common frame, it is essential for these sensors to be\naccurately calibrated. In this paper, we leverage the ability of Neural\nRadiance Fields (NeRF) to represent different sensors modalities in a common\nvolumetric representation to achieve robust and accurate spatio-temporal sensor\ncalibration. By designing a partitioning approach based on the visible part of\nthe scene for each sensor, we formulate the calibration problem using only the\noverlapping areas. This strategy results in a more robust and accurate\ncalibration that is less prone to failure. We demonstrate that our approach\nworks on outdoor urban scenes by validating it on multiple established driving\ndatasets. Results show that our method is able to get better accuracy and\nrobustness compared to existing methods.\n","authors":["Quentin Herau","Nathan Piasco","Moussab Bennehar","Luis Rold√£o","Dzmitry Tsishkou","Cyrille Migniot","Pascal Vasseur","C√©dric Demonceaux"],"pdf_url":"https://arxiv.org/pdf/2311.15803v3.pdf","comment":"Accepted at CVPR 2024. Project page: https://qherau.github.io/SOAC/"},{"id":"http://arxiv.org/abs/2403.18660v1","updated":"2024-03-27T15:03:38Z","published":"2024-03-27T15:03:38Z","title":"InstructBrush: Learning Attention-based Instruction Optimization for\n  Image Editing","summary":"  In recent years, instruction-based image editing methods have garnered\nsignificant attention in image editing. However, despite encompassing a wide\nrange of editing priors, these methods are helpless when handling editing tasks\nthat are challenging to accurately describe through language. We propose\nInstructBrush, an inversion method for instruction-based image editing methods\nto bridge this gap. It extracts editing effects from exemplar image pairs as\nediting instructions, which are further applied for image editing. Two key\ntechniques are introduced into InstructBrush, Attention-based Instruction\nOptimization and Transformation-oriented Instruction Initialization, to address\nthe limitations of the previous method in terms of inversion effects and\ninstruction generalization. To explore the ability of instruction inversion\nmethods to guide image editing in open scenarios, we establish a\nTransformationOriented Paired Benchmark (TOP-Bench), which contains a rich set\nof scenes and editing types. The creation of this benchmark paves the way for\nfurther exploration of instruction inversion. Quantitatively and qualitatively,\nour approach achieves superior performance in editing and is more semantically\nconsistent with the target editing effects.\n","authors":["Ruoyu Zhao","Qingnan Fan","Fei Kou","Shuai Qin","Hong Gu","Wei Wu","Pengcheng Xu","Mingrui Zhu","Nannan Wang","Xinbo Gao"],"pdf_url":"https://arxiv.org/pdf/2403.18660v1.pdf","comment":"Project Page: https://royzhao926.github.io/InstructBrush/"},{"id":"http://arxiv.org/abs/2311.12386v3","updated":"2024-03-27T15:01:44Z","published":"2023-11-21T06:55:21Z","title":"Point, Segment and Count: A Generalized Framework for Object Counting","summary":"  Class-agnostic object counting aims to count all objects in an image with\nrespect to example boxes or class names, \\emph{a.k.a} few-shot and zero-shot\ncounting. In this paper, we propose a generalized framework for both few-shot\nand zero-shot object counting based on detection. Our framework combines the\nsuperior advantages of two foundation models without compromising their\nzero-shot capability: (\\textbf{i}) SAM to segment all possible objects as mask\nproposals, and (\\textbf{ii}) CLIP to classify proposals to obtain accurate\nobject counts. However, this strategy meets the obstacles of efficiency\noverhead and the small crowded objects that cannot be localized and\ndistinguished. To address these issues, our framework, termed PseCo, follows\nthree steps: point, segment, and count. Specifically, we first propose a\nclass-agnostic object localization to provide accurate but least point prompts\nfor SAM, which consequently not only reduces computation costs but also avoids\nmissing small objects. Furthermore, we propose a generalized object\nclassification that leverages CLIP image/text embeddings as the classifier,\nfollowing a hierarchical knowledge distillation to obtain discriminative\nclassifications among hierarchical mask proposals. Extensive experimental\nresults on FSC-147, COCO, and LVIS demonstrate that PseCo achieves\nstate-of-the-art performance in both few-shot/zero-shot object\ncounting/detection. Code: https://github.com/Hzzone/PseCo\n","authors":["Zhizhong Huang","Mingliang Dai","Yi Zhang","Junping Zhang","Hongming Shan"],"pdf_url":"https://arxiv.org/pdf/2311.12386v3.pdf","comment":"Accepted by CVPR 2024. Camera ready"},{"id":"http://arxiv.org/abs/2311.17532v3","updated":"2024-03-27T15:01:22Z","published":"2023-11-29T11:10:40Z","title":"Weakly-Supervised Emotion Transition Learning for Diverse 3D Co-speech\n  Gesture Generation","summary":"  Generating vivid and emotional 3D co-speech gestures is crucial for virtual\navatar animation in human-machine interaction applications. While the existing\nmethods enable generating the gestures to follow a single emotion label, they\noverlook that long gesture sequence modeling with emotion transition is more\npractical in real scenes. In addition, the lack of large-scale available\ndatasets with emotional transition speech and corresponding 3D human gestures\nalso limits the addressing of this task. To fulfill this goal, we first\nincorporate the ChatGPT-4 and an audio inpainting approach to construct the\nhigh-fidelity emotion transition human speeches. Considering obtaining the\nrealistic 3D pose annotations corresponding to the dynamically inpainted\nemotion transition audio is extremely difficult, we propose a novel weakly\nsupervised training strategy to encourage authority gesture transitions.\nSpecifically, to enhance the coordination of transition gestures w.r.t\ndifferent emotional ones, we model the temporal association representation\nbetween two different emotional gesture sequences as style guidance and infuse\nit into the transition generation. We further devise an emotion mixture\nmechanism that provides weak supervision based on a learnable mixed emotion\nlabel for transition gestures. Last, we present a keyframe sampler to supply\neffective initial posture cues in long sequences, enabling us to generate\ndiverse gestures. Extensive experiments demonstrate that our method outperforms\nthe state-of-the-art models constructed by adapting single emotion-conditioned\ncounterparts on our newly defined emotion transition task and datasets. Our\ncode and dataset will be released on the project page:\nhttps://xingqunqi-lab.github.io/Emo-Transition-Gesture/.\n","authors":["Xingqun Qi","Jiahao Pan","Peng Li","Ruibin Yuan","Xiaowei Chi","Mengfei Li","Wenhan Luo","Wei Xue","Shanghang Zhang","Qifeng Liu","Yike Guo"],"pdf_url":"https://arxiv.org/pdf/2311.17532v3.pdf","comment":"Accepted by CVPR 2024"},{"id":"http://arxiv.org/abs/2403.18649v1","updated":"2024-03-27T14:56:44Z","published":"2024-03-27T14:56:44Z","title":"Addressing Data Annotation Challenges in Multiple Sensors: A Solution\n  for Scania Collected Datasets","summary":"  Data annotation in autonomous vehicles is a critical step in the development\nof Deep Neural Network (DNN) based models or the performance evaluation of the\nperception system. This often takes the form of adding 3D bounding boxes on\ntime-sequential and registered series of point-sets captured from active\nsensors like Light Detection and Ranging (LiDAR) and Radio Detection and\nRanging (RADAR). When annotating multiple active sensors, there is a need to\nmotion compensate and translate the points to a consistent coordinate frame and\ntimestamp respectively. However, highly dynamic objects pose a unique\nchallenge, as they can appear at different timestamps in each sensor's data.\nWithout knowing the speed of the objects, their position appears to be\ndifferent in different sensor outputs. Thus, even after motion compensation,\nhighly dynamic objects are not matched from multiple sensors in the same frame,\nand human annotators struggle to add unique bounding boxes that capture all\nobjects. This article focuses on addressing this challenge, primarily within\nthe context of Scania collected datasets. The proposed solution takes a track\nof an annotated object as input and uses the Moving Horizon Estimation (MHE) to\nrobustly estimate its speed. The estimated speed profile is utilized to correct\nthe position of the annotated box and add boxes to object clusters missed by\nthe original annotation.\n","authors":["Ajinkya Khoche","Aron Asefaw","Alejandro Gonzalez","Bogdan Timus","Sina Sharif Mansouri","Patric Jensfelt"],"pdf_url":"https://arxiv.org/pdf/2403.18649v1.pdf","comment":"Accepted to European Control Conference 2024"},{"id":"http://arxiv.org/abs/2403.18637v1","updated":"2024-03-27T14:42:08Z","published":"2024-03-27T14:42:08Z","title":"Transformers-based architectures for stroke segmentation: A review","summary":"  Stroke remains a significant global health concern, necessitating precise and\nefficient diagnostic tools for timely intervention and improved patient\noutcomes. The emergence of deep learning methodologies has transformed the\nlandscape of medical image analysis. Recently, Transformers, initially designed\nfor natural language processing, have exhibited remarkable capabilities in\nvarious computer vision applications, including medical image analysis. This\ncomprehensive review aims to provide an in-depth exploration of the\ncutting-edge Transformer-based architectures applied in the context of stroke\nsegmentation. It commences with an exploration of stroke pathology, imaging\nmodalities, and the challenges associated with accurate diagnosis and\nsegmentation. Subsequently, the review delves into the fundamental ideas of\nTransformers, offering detailed insights into their architectural intricacies\nand the underlying mechanisms that empower them to effectively capture complex\nspatial information within medical images. The existing literature is\nsystematically categorized and analyzed, discussing various approaches that\nleverage Transformers for stroke segmentation. A critical assessment is\nprovided, highlighting the strengths and limitations of these methods,\nincluding considerations of performance and computational efficiency.\nAdditionally, this review explores potential avenues for future research and\ndevelopment\n","authors":["Yalda Zafari-Ghadim","Essam A. Rashed","Mohamed Mabrok"],"pdf_url":"https://arxiv.org/pdf/2403.18637v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2204.11041v3","updated":"2024-03-27T14:29:27Z","published":"2022-04-23T10:19:58Z","title":"Learning by Erasing: Conditional Entropy based Transferable\n  Out-Of-Distribution Detection","summary":"  Out-of-distribution (OOD) detection is essential to handle the distribution\nshifts between training and test scenarios. For a new in-distribution (ID)\ndataset, existing methods require retraining to capture the dataset-specific\nfeature representation or data distribution. In this paper, we propose a deep\ngenerative models (DGM) based transferable OOD detection method, which is\nunnecessary to retrain on a new ID dataset. We design an image erasing strategy\nto equip exclusive conditional entropy distribution for each ID dataset, which\ndetermines the discrepancy of DGM's posteriori ucertainty distribution on\ndifferent ID datasets. Owing to the powerful representation capacity of\nconvolutional neural networks, the proposed model trained on complex dataset\ncan capture the above discrepancy between ID datasets without retraining and\nthus achieve transferable OOD detection. We validate the proposed method on\nfive datasets and verity that ours achieves comparable performance to the\nstate-of-the-art group based OOD detection methods that need to be retrained to\ndeploy on new ID datasets. Our code is available at\nhttps://github.com/oOHCIOo/CETOOD.\n","authors":["Meng Xing","Zhiyong Feng","Yong Su","Changjae Oh"],"pdf_url":"https://arxiv.org/pdf/2204.11041v3.pdf","comment":"update new experimental results"},{"id":"http://arxiv.org/abs/2403.18605v1","updated":"2024-03-27T14:24:30Z","published":"2024-03-27T14:24:30Z","title":"FlexEdit: Flexible and Controllable Diffusion-based Object-centric Image\n  Editing","summary":"  Our work addresses limitations seen in previous approaches for object-centric\nediting problems, such as unrealistic results due to shape discrepancies and\nlimited control in object replacement or insertion. To this end, we introduce\nFlexEdit, a flexible and controllable editing framework for objects where we\niteratively adjust latents at each denoising step using our FlexEdit block.\nInitially, we optimize latents at test time to align with specified object\nconstraints. Then, our framework employs an adaptive mask, automatically\nextracted during denoising, to protect the background while seamlessly blending\nnew content into the target image. We demonstrate the versatility of FlexEdit\nin various object editing tasks and curate an evaluation test suite with\nsamples from both real and synthetic images, along with novel evaluation\nmetrics designed for object-centric editing. We conduct extensive experiments\non different editing scenarios, demonstrating the superiority of our editing\nframework over recent advanced text-guided image editing methods. Our project\npage is published at https://flex-edit.github.io/.\n","authors":["Trong-Tung Nguyen","Duc-Anh Nguyen","Anh Tran","Cuong Pham"],"pdf_url":"https://arxiv.org/pdf/2403.18605v1.pdf","comment":"Our project page: https://flex-edit.github.io/"},{"id":"http://arxiv.org/abs/2403.18600v1","updated":"2024-03-27T14:22:40Z","published":"2024-03-27T14:22:40Z","title":"RAP: Retrieval-Augmented Planner for Adaptive Procedure Planning in\n  Instructional Videos","summary":"  Procedure Planning in instructional videos entails generating a sequence of\naction steps based on visual observations of the initial and target states.\nDespite the rapid progress in this task, there remain several critical\nchallenges to be solved: (1) Adaptive procedures: Prior works hold an\nunrealistic assumption that the number of action steps is known and fixed,\nleading to non-generalizable models in real-world scenarios where the sequence\nlength varies. (2) Temporal relation: Understanding the step temporal relation\nknowledge is essential in producing reasonable and executable plans. (3)\nAnnotation cost: Annotating instructional videos with step-level labels (i.e.,\ntimestamp) or sequence-level labels (i.e., action category) is demanding and\nlabor-intensive, limiting its generalizability to large-scale datasets.In this\nwork, we propose a new and practical setting, called adaptive procedure\nplanning in instructional videos, where the procedure length is not fixed or\npre-determined. To address these challenges we introduce Retrieval-Augmented\nPlanner (RAP) model. Specifically, for adaptive procedures, RAP adaptively\ndetermines the conclusion of actions using an auto-regressive model\narchitecture. For temporal relation, RAP establishes an external memory module\nto explicitly retrieve the most relevant state-action pairs from the training\nvideos and revises the generated procedures. To tackle high annotation cost,\nRAP utilizes a weakly-supervised learning manner to expand the training dataset\nto other task-relevant, unannotated videos by generating pseudo labels for\naction steps. Experiments on CrossTask and COIN benchmarks show the superiority\nof RAP over traditional fixed-length models, establishing it as a strong\nbaseline solution for adaptive procedure planning.\n","authors":["Ali Zare","Yulei Niu","Hammad Ayyubi","Shih-fu Chang"],"pdf_url":"https://arxiv.org/pdf/2403.18600v1.pdf","comment":"23 pages, 6 figures, 12 tables"},{"id":"http://arxiv.org/abs/2403.18593v1","updated":"2024-03-27T14:18:09Z","published":"2024-03-27T14:18:09Z","title":"Homogeneous Tokenizer Matters: Homogeneous Visual Tokenizer for Remote\n  Sensing Image Understanding","summary":"  The tokenizer, as one of the fundamental components of large models, has long\nbeen overlooked or even misunderstood in visual tasks. One key factor of the\ngreat comprehension power of the large language model is that natural language\ntokenizers utilize meaningful words or subwords as the basic elements of\nlanguage. In contrast, mainstream visual tokenizers, represented by patch-based\nmethods such as Patch Embed, rely on meaningless rectangular patches as basic\nelements of vision, which cannot serve as effectively as words or subwords in\nlanguage. Starting from the essence of the tokenizer, we defined semantically\nindependent regions (SIRs) for vision. We designed a simple HOmogeneous visual\ntOKenizer: HOOK. HOOK mainly consists of two modules: the Object Perception\nModule (OPM) and the Object Vectorization Module (OVM). To achieve homogeneity,\nthe OPM splits the image into 4*4 pixel seeds and then utilizes the attention\nmechanism to perceive SIRs. The OVM employs cross-attention to merge seeds\nwithin the same SIR. To achieve adaptability, the OVM defines a variable number\nof learnable vectors as cross-attention queries, allowing for the adjustment of\ntoken quantity. We conducted experiments on the NWPU-RESISC45, WHU-RS19\nclassification dataset, and GID5 segmentation dataset for sparse and dense\ntasks. The results demonstrate that the visual tokens obtained by HOOK\ncorrespond to individual objects, which demonstrates homogeneity. HOOK\noutperformed Patch Embed by 6\\% and 10\\% in the two tasks and achieved\nstate-of-the-art performance compared to the baselines used for comparison.\nCompared to Patch Embed, which requires more than one hundred tokens for one\nimage, HOOK requires only 6 and 8 tokens for sparse and dense tasks,\nrespectively, resulting in efficiency improvements of 1.5 to 2.8 times. The\ncode is available at https://github.com/GeoX-Lab/Hook.\n","authors":["Run Shao","Zhaoyang Zhang","Chao Tao","Yunsheng Zhang","Chengli Peng","Haifeng Li"],"pdf_url":"https://arxiv.org/pdf/2403.18593v1.pdf","comment":"20 pages, 8 figures, 6 tables"},{"id":"http://arxiv.org/abs/2403.18589v1","updated":"2024-03-27T14:12:56Z","published":"2024-03-27T14:12:56Z","title":"Users prefer Jpegli over same-sized libjpeg-turbo or MozJPEG","summary":"  We performed pairwise comparisons by human raters of JPEG images from\nMozJPEG, libjpeg-turbo and our new Jpegli encoder. When compressing images at a\nquality similar to libjpeg-turbo quality 95, the Jpegli images were 54% likely\nto be preferred over both libjpeg-turbo and MozJPEG images, but used only 2.8\nbits per pixel compared to libjpeg-turbo and MozJPEG that used 3.8 and 3.5 bits\nper pixel respectively. The raw ratings and source images are publicly\navailable for further analysis and study.\n","authors":["Martin Bruse","Luca Versari","Zoltan Szabadka","Jyrki Alakuijala"],"pdf_url":"https://arxiv.org/pdf/2403.18589v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.18587v1","updated":"2024-03-27T14:11:23Z","published":"2024-03-27T14:11:23Z","title":"The Impact of Uniform Inputs on Activation Sparsity and Energy-Latency\n  Attacks in Computer Vision","summary":"  Resource efficiency plays an important role for machine learning nowadays.\nThe energy and decision latency are two critical aspects to ensure a\nsustainable and practical application. Unfortunately, the energy consumption\nand decision latency are not robust against adversaries. Researchers have\nrecently demonstrated that attackers can compute and submit so-called sponge\nexamples at inference time to increase the energy consumption and decision\nlatency of neural networks. In computer vision, the proposed strategy crafts\ninputs with less activation sparsity which could otherwise be used to\naccelerate the computation. In this paper, we analyze the mechanism how these\nenergy-latency attacks reduce activation sparsity. In particular, we find that\ninput uniformity is a key enabler. A uniform image, that is, an image with\nmostly flat, uniformly colored surfaces, triggers more activations due to a\nspecific interplay of convolution, batch normalization, and ReLU activation.\nBased on these insights, we propose two new simple, yet effective strategies\nfor crafting sponge examples: sampling images from a probability distribution\nand identifying dense, yet inconspicuous inputs in natural datasets. We\nempirically examine our findings in a comprehensive evaluation with multiple\nimage classification models and show that our attack achieves the same sparsity\neffect as prior sponge-example methods, but at a fraction of computation\neffort. We also show that our sponge examples transfer between different neural\nnetworks. Finally, we discuss applications of our findings for the good by\nimproving efficiency by increasing sparsity.\n","authors":["Andreas M√ºller","Erwin Quiring"],"pdf_url":"https://arxiv.org/pdf/2403.18587v1.pdf","comment":"Accepted at the DLSP 2024"},{"id":"http://arxiv.org/abs/2312.07264v2","updated":"2024-03-27T14:09:10Z","published":"2023-12-12T13:44:53Z","title":"Dual Structure-Aware Image Filterings for Semi-supervised Medical Image\n  Segmentation","summary":"  Semi-supervised image segmentation has attracted great attention recently.\nThe key is how to leverage unlabeled images in the training process. Most\nmethods maintain consistent predictions of the unlabeled images under\nvariations (e.g., adding noise/perturbations, or creating alternative versions)\nin the image and/or model level. In most image-level variation, medical images\noften have prior structure information, which has not been well explored. In\nthis paper, we propose novel dual structure-aware image filterings (DSAIF) as\nthe image-level variations for semi-supervised medical image segmentation.\nMotivated by connected filtering that simplifies image via filtering in\nstructure-aware tree-based image representation, we resort to the dual contrast\ninvariant Max-tree and Min-tree representation. Specifically, we propose a\nnovel connected filtering that removes topologically equivalent nodes (i.e.\nconnected components) having no siblings in the Max/Min-tree. This results in\ntwo filtered images preserving topologically critical structure. Applying the\nproposed DSAIF to mutually supervised networks decreases the consensus of their\nerroneous predictions on unlabeled images. This helps to alleviate the\nconfirmation bias issue of overfitting to noisy pseudo labels of unlabeled\nimages, and thus effectively improves the segmentation performance. Extensive\nexperimental results on three benchmark datasets demonstrate that the proposed\nmethod significantly/consistently outperforms some state-of-the-art methods.\nThe source codes will be publicly available.\n","authors":["Yuliang Gu","Zhichao Sun","Tian Chen","Xin Xiao","Yepeng Liu","Yongchao Xu","Laurent Najman"],"pdf_url":"https://arxiv.org/pdf/2312.07264v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.18575v1","updated":"2024-03-27T13:56:08Z","published":"2024-03-27T13:56:08Z","title":"HandBooster: Boosting 3D Hand-Mesh Reconstruction by Conditional\n  Synthesis and Sampling of Hand-Object Interactions","summary":"  Reconstructing 3D hand mesh robustly from a single image is very challenging,\ndue to the lack of diversity in existing real-world datasets. While data\nsynthesis helps relieve the issue, the syn-to-real gap still hinders its usage.\nIn this work, we present HandBooster, a new approach to uplift the data\ndiversity and boost the 3D hand-mesh reconstruction performance by training a\nconditional generative space on hand-object interactions and purposely sampling\nthe space to synthesize effective data samples. First, we construct versatile\ncontent-aware conditions to guide a diffusion model to produce realistic images\nwith diverse hand appearances, poses, views, and backgrounds; favorably,\naccurate 3D annotations are obtained for free. Then, we design a novel\ncondition creator based on our similarity-aware distribution sampling\nstrategies to deliberately find novel and realistic interaction poses that are\ndistinctive from the training set. Equipped with our method, several baselines\ncan be significantly improved beyond the SOTA on the HO3D and DexYCB\nbenchmarks. Our code will be released on\nhttps://github.com/hxwork/HandBooster_Pytorch.\n","authors":["Hao Xu","Haipeng Li","Yinqiao Wang","Shuaicheng Liu","Chi-Wing Fu"],"pdf_url":"https://arxiv.org/pdf/2403.18575v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.07636v3","updated":"2024-03-27T13:51:59Z","published":"2024-03-12T13:18:22Z","title":"Decomposing Disease Descriptions for Enhanced Pathology Detection: A\n  Multi-Aspect Vision-Language Pre-training Framework","summary":"  Medical vision language pre-training (VLP) has emerged as a frontier of\nresearch, enabling zero-shot pathological recognition by comparing the query\nimage with the textual descriptions for each disease. Due to the complex\nsemantics of biomedical texts, current methods struggle to align medical images\nwith key pathological findings in unstructured reports. This leads to the\nmisalignment with the target disease's textual representation. In this paper,\nwe introduce a novel VLP framework designed to dissect disease descriptions\ninto their fundamental aspects, leveraging prior knowledge about the visual\nmanifestations of pathologies. This is achieved by consulting a large language\nmodel and medical experts. Integrating a Transformer module, our approach\naligns an input image with the diverse elements of a disease, generating\naspect-centric image representations. By consolidating the matches from each\naspect, we improve the compatibility between an image and its associated\ndisease. Additionally, capitalizing on the aspect-oriented representations, we\npresent a dual-head Transformer tailored to process known and unknown diseases,\noptimizing the comprehensive detection efficacy. Conducting experiments on\nseven downstream datasets, ours improves the accuracy of recent methods by up\nto 8.56% and 17.0% for seen and unseen categories, respectively. Our code is\nreleased at https://github.com/HieuPhan33/MAVL.\n","authors":["Vu Minh Hieu Phan","Yutong Xie","Yuankai Qi","Lingqiao Liu","Liyang Liu","Bowen Zhang","Zhibin Liao","Qi Wu","Minh-Son To","Johan W. Verjans"],"pdf_url":"https://arxiv.org/pdf/2403.07636v3.pdf","comment":"Accepted at CVPR2024. Pre-print before final camera-ready version"},{"id":"http://arxiv.org/abs/2403.18565v1","updated":"2024-03-27T13:46:01Z","published":"2024-03-27T13:46:01Z","title":"Artifact Reduction in 3D and 4D Cone-beam Computed Tomography Images\n  with Deep Learning -- A Review","summary":"  Deep learning based approaches have been used to improve image quality in\ncone-beam computed tomography (CBCT), a medical imaging technique often used in\napplications such as image-guided radiation therapy, implant dentistry or\northopaedics. In particular, while deep learning methods have been applied to\nreduce various types of CBCT image artifacts arising from motion, metal\nobjects, or low-dose acquisition, a comprehensive review summarizing the\nsuccesses and shortcomings of these approaches, with a primary focus on the\ntype of artifacts rather than the architecture of neural networks, is lacking\nin the literature. In this review, the data generation and simulation\npipelines, and artifact reduction techniques are specifically investigated for\neach type of artifact. We provide an overview of deep learning techniques that\nhave successfully been shown to reduce artifacts in 3D, as well as in\ntime-resolved (4D) CBCT through the use of projection- and/or volume-domain\noptimizations, or by introducing neural networks directly within the CBCT\nreconstruction algorithms. Research gaps are identified to suggest avenues for\nfuture exploration. One of the key findings of this work is an observed trend\ntowards the use of generative models including GANs and score-based or\ndiffusion models, accompanied with the need for more diverse and open training\ndatasets and simulations.\n","authors":["Mohammadreza Amirian","Daniel Barco","Ivo Herzig","Frank-Peter Schilling"],"pdf_url":"https://arxiv.org/pdf/2403.18565v1.pdf","comment":"16 pages, 4 figures, 1 Table, published in IEEE Access Journal"},{"id":"http://arxiv.org/abs/2403.09700v2","updated":"2024-03-27T13:42:25Z","published":"2024-03-05T22:19:21Z","title":"Shapley Values-Powered Framework for Fair Reward Split in Content\n  Produced by GenAI","summary":"  It is evident that, currently, generative models are surpassed in quality by\nhuman professionals. However, with the advancements in Artificial Intelligence,\nthis gap will narrow, leading to scenarios where individuals who have dedicated\nyears of their lives to mastering a skill become obsolete due to their high\ncosts, which are inherently linked to the time they require to complete a task\n-- a task that AI could accomplish in minutes or seconds. To avoid future\nsocial upheavals, we must, even now, contemplate how to fairly assess the\ncontributions of such individuals in training generative models and how to\ncompensate them for the reduction or complete loss of their incomes. In this\nwork, we propose a method to structure collaboration between model developers\nand data providers. To achieve this, we employ Shapley Values to quantify the\ncontribution of artist(s) in an image generated by the Stable Diffusion-v1.5\nmodel and to equitably allocate the reward among them.\n","authors":["Alex Glinsky","Alexey Sokolsky"],"pdf_url":"https://arxiv.org/pdf/2403.09700v2.pdf","comment":"36 pages, 32 figures"},{"id":"http://arxiv.org/abs/2403.18554v1","updated":"2024-03-27T13:33:14Z","published":"2024-03-27T13:33:14Z","title":"CosalPure: Learning Concept from Group Images for Robust Co-Saliency\n  Detection","summary":"  Co-salient object detection (CoSOD) aims to identify the common and salient\n(usually in the foreground) regions across a given group of images. Although\nachieving significant progress, state-of-the-art CoSODs could be easily\naffected by some adversarial perturbations, leading to substantial accuracy\nreduction. The adversarial perturbations can mislead CoSODs but do not change\nthe high-level semantic information (e.g., concept) of the co-salient objects.\nIn this paper, we propose a novel robustness enhancement framework by first\nlearning the concept of the co-salient objects based on the input group images\nand then leveraging this concept to purify adversarial perturbations, which are\nsubsequently fed to CoSODs for robustness enhancement. Specifically, we propose\nCosalPure containing two modules, i.e., group-image concept learning and\nconcept-guided diffusion purification. For the first module, we adopt a\npre-trained text-to-image diffusion model to learn the concept of co-salient\nobjects within group images where the learned concept is robust to adversarial\nexamples. For the second module, we map the adversarial image to the latent\nspace and then perform diffusion generation by embedding the learned concept\ninto the noise prediction function as an extra condition. Our method can\neffectively alleviate the influence of the SOTA adversarial attack containing\ndifferent adversarial patterns, including exposure and noise. The extensive\nresults demonstrate that our method could enhance the robustness of CoSODs\nsignificantly.\n","authors":["Jiayi Zhu","Qing Guo","Felix Juefei-Xu","Yihao Huang","Yang Liu","Geguang Pu"],"pdf_url":"https://arxiv.org/pdf/2403.18554v1.pdf","comment":"8 pages"},{"id":"http://arxiv.org/abs/2403.18551v1","updated":"2024-03-27T13:31:39Z","published":"2024-03-27T13:31:39Z","title":"Attention Calibration for Disentangled Text-to-Image Personalization","summary":"  Recent thrilling progress in large-scale text-to-image (T2I) models has\nunlocked unprecedented synthesis quality of AI-generated content (AIGC)\nincluding image generation, 3D and video composition. Further, personalized\ntechniques enable appealing customized production of a novel concept given only\nseveral images as reference. However, an intriguing problem persists: Is it\npossible to capture multiple, novel concepts from one single reference image?\nIn this paper, we identify that existing approaches fail to preserve visual\nconsistency with the reference image and eliminate cross-influence from\nconcepts. To alleviate this, we propose an attention calibration mechanism to\nimprove the concept-level understanding of the T2I model. Specifically, we\nfirst introduce new learnable modifiers bound with classes to capture\nattributes of multiple concepts. Then, the classes are separated and\nstrengthened following the activation of the cross-attention operation,\nensuring comprehensive and self-contained concepts. Additionally, we suppress\nthe attention activation of different classes to mitigate mutual influence\namong concepts. Together, our proposed method, dubbed DisenDiff, can learn\ndisentangled multiple concepts from one single image and produce novel\ncustomized images with learned concepts. We demonstrate that our method\noutperforms the current state of the art in both qualitative and quantitative\nevaluations. More importantly, our proposed techniques are compatible with LoRA\nand inpainting pipelines, enabling more interactive experiences.\n","authors":["Yanbing Zhang","Mengping Yang","Qin Zhou","Zhe Wang"],"pdf_url":"https://arxiv.org/pdf/2403.18551v1.pdf","comment":"Accepted to CVPR 2024"},{"id":"http://arxiv.org/abs/2403.18550v1","updated":"2024-03-27T13:30:48Z","published":"2024-03-27T13:30:48Z","title":"OrCo: Towards Better Generalization via Orthogonality and Contrast for\n  Few-Shot Class-Incremental Learning","summary":"  Few-Shot Class-Incremental Learning (FSCIL) introduces a paradigm in which\nthe problem space expands with limited data. FSCIL methods inherently face the\nchallenge of catastrophic forgetting as data arrives incrementally, making\nmodels susceptible to overwriting previously acquired knowledge. Moreover,\ngiven the scarcity of labeled samples available at any given time, models may\nbe prone to overfitting and find it challenging to strike a balance between\nextensive pretraining and the limited incremental data. To address these\nchallenges, we propose the OrCo framework built on two core principles:\nfeatures' orthogonality in the representation space, and contrastive learning.\nIn particular, we improve the generalization of the embedding space by\nemploying a combination of supervised and self-supervised contrastive losses\nduring the pretraining phase. Additionally, we introduce OrCo loss to address\nchallenges arising from data limitations during incremental sessions. Through\nfeature space perturbations and orthogonality between classes, the OrCo loss\nmaximizes margins and reserves space for the following incremental data. This,\nin turn, ensures the accommodation of incoming classes in the feature space\nwithout compromising previously acquired knowledge. Our experimental results\nshowcase state-of-the-art performance across three benchmark datasets,\nincluding mini-ImageNet, CIFAR100, and CUB datasets. Code is available at\nhttps://github.com/noorahmedds/OrCo\n","authors":["Noor Ahmed","Anna Kukleva","Bernt Schiele"],"pdf_url":"https://arxiv.org/pdf/2403.18550v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.18548v1","updated":"2024-03-27T13:27:02Z","published":"2024-03-27T13:27:02Z","title":"A Semi-supervised Nighttime Dehazing Baseline with Spatial-Frequency\n  Aware and Realistic Brightness Constraint","summary":"  Existing research based on deep learning has extensively explored the problem\nof daytime image dehazing. However, few studies have considered the\ncharacteristics of nighttime hazy scenes. There are two distinctions between\nnighttime and daytime haze. First, there may be multiple active colored light\nsources with lower illumination intensity in nighttime scenes, which may cause\nhaze, glow and noise with localized, coupled and frequency inconsistent\ncharacteristics. Second, due to the domain discrepancy between simulated and\nreal-world data, unrealistic brightness may occur when applying a dehazing\nmodel trained on simulated data to real-world data. To address the above two\nissues, we propose a semi-supervised model for real-world nighttime dehazing.\nFirst, the spatial attention and frequency spectrum filtering are implemented\nas a spatial-frequency domain information interaction module to handle the\nfirst issue. Second, a pseudo-label-based retraining strategy and a local\nwindow-based brightness loss for semi-supervised training process is designed\nto suppress haze and glow while achieving realistic brightness. Experiments on\npublic benchmarks validate the effectiveness of the proposed method and its\nsuperiority over state-of-the-art methods. The source code and Supplementary\nMaterials are placed in the https://github.com/Xiaofeng-life/SFSNiD.\n","authors":["Xiaofeng Cong","Jie Gui","Jing Zhang","Junming Hou","Hao Shen"],"pdf_url":"https://arxiv.org/pdf/2403.18548v1.pdf","comment":"This paper is accepted by CVPR2024"},{"id":"http://arxiv.org/abs/2403.18546v1","updated":"2024-03-27T13:24:58Z","published":"2024-03-27T13:24:58Z","title":"Efficient Heatmap-Guided 6-Dof Grasp Detection in Cluttered Scenes","summary":"  Fast and robust object grasping in clutter is a crucial component of\nrobotics. Most current works resort to the whole observed point cloud for 6-Dof\ngrasp generation, ignoring the guidance information excavated from global\nsemantics, thus limiting high-quality grasp generation and real-time\nperformance. In this work, we show that the widely used heatmaps are\nunderestimated in the efficiency of 6-Dof grasp generation. Therefore, we\npropose an effective local grasp generator combined with grasp heatmaps as\nguidance, which infers in a global-to-local semantic-to-point way.\nSpecifically, Gaussian encoding and the grid-based strategy are applied to\npredict grasp heatmaps as guidance to aggregate local points into graspable\nregions and provide global semantic information. Further, a novel non-uniform\nanchor sampling mechanism is designed to improve grasp accuracy and diversity.\nBenefiting from the high-efficiency encoding in the image space and focusing on\npoints in local graspable regions, our framework can perform high-quality grasp\ndetection in real-time and achieve state-of-the-art results. In addition, real\nrobot experiments demonstrate the effectiveness of our method with a success\nrate of 94% and a clutter completion rate of 100%. Our code is available at\nhttps://github.com/THU-VCLab/HGGD.\n","authors":["Siang Chen","Wei Tang","Pengwei Xie","Wenming Yang","Guijin Wang"],"pdf_url":"https://arxiv.org/pdf/2403.18546v1.pdf","comment":"Extensive results on GraspNet-1B dataset"},{"id":"http://arxiv.org/abs/2310.15081v3","updated":"2024-03-27T13:23:28Z","published":"2023-10-23T16:41:13Z","title":"E4S: Fine-grained Face Swapping via Editing With Regional GAN Inversion","summary":"  This paper proposes a novel approach to face swapping from the perspective of\nfine-grained facial editing, dubbed \"editing for swapping\" (E4S). The\ntraditional face swapping methods rely on global feature extraction and fail to\npreserve the detailed source identity. In contrast, we propose a Regional GAN\nInversion (RGI) method, which allows the explicit disentanglement of shape and\ntexture. Specifically, our E4S performs face swapping in the latent space of a\npretrained StyleGAN, where a multi-scale mask-guided encoder is applied to\nproject the texture of each facial component into regional style codes and a\nmask-guided injection module manipulating feature maps with the style codes.\nBased on this disentanglement, face swapping can be simplified as style and\nmask swapping. Besides, due to the large lighting condition gap, transferring\nthe source skin into the target image may lead to disharmony lighting. We\npropose a re-coloring network to make the swapped face maintain the target\nlighting condition while preserving the source skin. Further, to deal with the\npotential mismatch areas during mask exchange, we design a face inpainting\nmodule to refine the face shape. The extensive comparisons with\nstate-of-the-art methods demonstrate that our E4S outperforms existing methods\nin preserving texture, shape, and lighting. Our implementation is available at\nhttps://github.com/e4s2024/E4S2024.\n","authors":["Maomao Li","Ge Yuan","Cairong Wang","Zhian Liu","Yong Zhang","Yongwei Nie","Jue Wang","Dong Xu"],"pdf_url":"https://arxiv.org/pdf/2310.15081v3.pdf","comment":"Project Page: https://e4s2024.github.io/ ;. arXiv admin note: text\n  overlap with arXiv:2211.14068"},{"id":"http://arxiv.org/abs/2403.18525v1","updated":"2024-03-27T12:59:44Z","published":"2024-03-27T12:59:44Z","title":"Language Plays a Pivotal Role in the Object-Attribute Compositional\n  Generalization of CLIP","summary":"  Vision-language models, such as CLIP, have shown promising\nOut-of-Distribution (OoD) generalization under various types of distribution\nshifts. Recent studies attempted to investigate the leading cause of this\ncapability. In this work, we follow the same path, but focus on a specific type\nof OoD data - images with novel compositions of attribute-object pairs - and\nstudy whether such models can successfully classify those images into\ncomposition classes. We carefully designed an authentic image test dataset\ncalled ImageNet-AO, consisting of attributes for objects that are unlikely\nencountered in the CLIP training sets. We found that CLIPs trained with large\ndatasets such as OpenAI CLIP, LAION-400M, and LAION-2B show orders-of-magnitude\nimprovement in effective compositional OoD generalization compared to both\nsupervised models and CLIPs trained with smaller datasets, such as CC-12M and\nYFCC-15M. Our results provide evidence that the scale and diversity of training\ndata and language supervision play a key role in unlocking the compositional\ngeneralization abilities of vision-language models.\n","authors":["Reza Abbasi","Mohammad Samiei","Mohammad Hossein Rohban","Mahdieh Soleymani Baghshah"],"pdf_url":"https://arxiv.org/pdf/2403.18525v1.pdf","comment":"Oral accepted at OODCV 2023(http://www.ood-cv.org)"},{"id":"http://arxiv.org/abs/2403.18514v1","updated":"2024-03-27T12:44:57Z","published":"2024-03-27T12:44:57Z","title":"CT-3DFlow : Leveraging 3D Normalizing Flows for Unsupervised Detection\n  of Pathological Pulmonary CT scans","summary":"  Unsupervised pathology detection can be implemented by training a model on\nhealthy data only and measuring the deviation from the training set upon\ninference, for example with CNN-based feature extraction and one-class\nclassifiers, or reconstruction-score-based methods such as AEs, GANs and\nDiffusion models. Normalizing Flows (NF) have the ability to directly learn the\nprobability distribution of training examples through an invertible\narchitecture. We leverage this property in a novel 3D NF-based model named\nCT-3DFlow, specifically tailored for patient-level pulmonary pathology\ndetection in chest CT data. Our model is trained unsupervised on healthy 3D\npulmonary CT patches, and detects deviations from its log-likelihood\ndistribution as anomalies. We aggregate patches-level likelihood values from a\npatient's CT scan to provide a patient-level 'normal'/'abnormal' prediction.\nOut-of-distribution detection performance is evaluated using expert annotations\non a separate chest CT test dataset, outperforming other state-of-the-art\nmethods.\n","authors":["Aissam Djahnine","Alexandre Popoff","Emilien Jupin-Delevaux","Vincent Cottin","Olivier Nempont","Loic Boussel"],"pdf_url":"https://arxiv.org/pdf/2403.18514v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.04344v3","updated":"2024-03-27T12:44:55Z","published":"2023-06-07T11:18:53Z","title":"ViDA: Homeostatic Visual Domain Adapter for Continual Test Time\n  Adaptation","summary":"  Since real-world machine systems are running in non-stationary environments,\nContinual Test-Time Adaptation (CTTA) task is proposed to adapt the pre-trained\nmodel to continually changing target domains. Recently, existing methods mainly\nfocus on model-based adaptation, which aims to leverage a self-training manner\nto extract the target domain knowledge. However, pseudo labels can be noisy and\nthe updated model parameters are unreliable under dynamic data distributions,\nleading to error accumulation and catastrophic forgetting in the continual\nadaptation process. To tackle these challenges and maintain the model\nplasticity, we design a Visual Domain Adapter (ViDA) for CTTA, explicitly\nhandling both domain-specific and domain-shared knowledge. Specifically, we\nfirst comprehensively explore the different domain representations of the\nadapters with trainable high-rank or low-rank embedding spaces. Then we inject\nViDAs into the pre-trained model, which leverages high-rank and low-rank\nfeatures to adapt the current domain distribution and maintain the continual\ndomain-shared knowledge, respectively. To exploit the low-rank and high-rank\nViDAs more effectively, we further propose a Homeostatic Knowledge Allotment\n(HKA) strategy, which adaptively combines different knowledge from each ViDA.\nExtensive experiments conducted on four widely used benchmarks demonstrate that\nour proposed method achieves state-of-the-art performance in both\nclassification and segmentation CTTA tasks. Note that, our method can be\nregarded as a novel transfer paradigm for large-scale models, delivering\npromising results in adaptation to continually changing distributions. Project\npage: https://sites.google.com/view/iclr2024-vida/home.\n","authors":["Jiaming Liu","Senqiao Yang","Peidong Jia","Renrui Zhang","Ming Lu","Yandong Guo","Wei Xue","Shanghang Zhang"],"pdf_url":"https://arxiv.org/pdf/2306.04344v3.pdf","comment":"Accepted by ICLR2024"},{"id":"http://arxiv.org/abs/2403.18512v1","updated":"2024-03-27T12:41:30Z","published":"2024-03-27T12:41:30Z","title":"ParCo: Part-Coordinating Text-to-Motion Synthesis","summary":"  We study a challenging task: text-to-motion synthesis, aiming to generate\nmotions that align with textual descriptions and exhibit coordinated movements.\nCurrently, the part-based methods introduce part partition into the motion\nsynthesis process to achieve finer-grained generation. However, these methods\nencounter challenges such as the lack of coordination between different part\nmotions and difficulties for networks to understand part concepts. Moreover,\nintroducing finer-grained part concepts poses computational complexity\nchallenges. In this paper, we propose Part-Coordinating Text-to-Motion\nSynthesis (ParCo), endowed with enhanced capabilities for understanding part\nmotions and communication among different part motion generators, ensuring a\ncoordinated and fined-grained motion synthesis. Specifically, we discretize\nwhole-body motion into multiple part motions to establish the prior concept of\ndifferent parts. Afterward, we employ multiple lightweight generators designed\nto synthesize different part motions and coordinate them through our part\ncoordination module. Our approach demonstrates superior performance on common\nbenchmarks with economic computations, including HumanML3D and KIT-ML,\nproviding substantial evidence of its effectiveness. Code is available at\nhttps://github.com/qrzou/ParCo .\n","authors":["Qiran Zou","Shangyuan Yuan","Shian Du","Yu Wang","Chang Liu","Yi Xu","Jie Chen","Xiangyang Ji"],"pdf_url":"https://arxiv.org/pdf/2403.18512v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.16516v2","updated":"2024-03-27T12:32:31Z","published":"2024-03-25T08:00:43Z","title":"Visually Guided Generative Text-Layout Pre-training for Document\n  Intelligence","summary":"  Prior study shows that pre-training techniques can boost the performance of\nvisual document understanding (VDU), which typically requires models to gain\nabilities to perceive and reason both document texts and layouts (e.g.,\nlocations of texts and table-cells). To this end, we propose visually guided\ngenerative text-layout pre-training, named ViTLP. Given a document image, the\nmodel optimizes hierarchical language and layout modeling objectives to\ngenerate the interleaved text and layout sequence. In addition, to address the\nlimitation of processing long documents by Transformers, we introduce a\nstraightforward yet effective multi-segment generative pre-training scheme,\nfacilitating ViTLP to process word-intensive documents of any length. ViTLP can\nfunction as a native OCR model to localize and recognize texts of document\nimages. Besides, ViTLP can be effectively applied to various downstream VDU\ntasks. Extensive experiments show that ViTLP achieves competitive performance\nover existing baselines on benchmark VDU tasks, including information\nextraction, document classification, and document question answering.\n","authors":["Zhiming Mao","Haoli Bai","Lu Hou","Jiansheng Wei","Xin Jiang","Qun Liu","Kam-Fai Wong"],"pdf_url":"https://arxiv.org/pdf/2403.16516v2.pdf","comment":"Accepted to NAACL 2024 main conference. The first version of this\n  paper was submitted to OpenReview\n  (https://openreview.net/forum?id=ARtBIBAmNR) in June 2023"},{"id":"http://arxiv.org/abs/2312.06358v2","updated":"2024-03-27T12:24:29Z","published":"2023-12-11T13:05:54Z","title":"Intraoperative 2D/3D Image Registration via Differentiable X-ray\n  Rendering","summary":"  Surgical decisions are informed by aligning rapid portable 2D intraoperative\nimages (e.g., X-rays) to a high-fidelity 3D preoperative reference scan (e.g.,\nCT). 2D/3D image registration often fails in practice: conventional\noptimization methods are prohibitively slow and susceptible to local minima,\nwhile neural networks trained on small datasets fail on new patients or require\nimpractical landmark supervision. We present DiffPose, a self-supervised\napproach that leverages patient-specific simulation and differentiable\nphysics-based rendering to achieve accurate 2D/3D registration without relying\non manually labeled data. Preoperatively, a CNN is trained to regress the pose\nof a randomly oriented synthetic X-ray rendered from the preoperative CT. The\nCNN then initializes rapid intraoperative test-time optimization that uses the\ndifferentiable X-ray renderer to refine the solution. Our work further proposes\nseveral geometrically principled methods for sampling camera poses from\n$\\mathbf{SE}(3)$, for sparse differentiable rendering, and for driving\nregistration in the tangent space $\\mathfrak{se}(3)$ with geodesic and\nmultiscale locality-sensitive losses. DiffPose achieves sub-millimeter accuracy\nacross surgical datasets at intraoperative speeds, improving upon existing\nunsupervised methods by an order of magnitude and even outperforming supervised\nbaselines. Our code is available at https://github.com/eigenvivek/DiffPose.\n","authors":["Vivek Gopalakrishnan","Neel Dey","Polina Golland"],"pdf_url":"https://arxiv.org/pdf/2312.06358v2.pdf","comment":"CVPR 2024"},{"id":"http://arxiv.org/abs/2403.18501v1","updated":"2024-03-27T12:24:20Z","published":"2024-03-27T12:24:20Z","title":"HEMIT: H&E to Multiplex-immunohistochemistry Image Translation with\n  Dual-Branch Pix2pix Generator","summary":"  Computational analysis of multiplexed immunofluorescence histology data is\nemerging as an important method for understanding the tumour micro-environment\nin cancer. This work presents HEMIT, a dataset designed for translating\nHematoxylin and Eosin (H&E) sections to multiplex-immunohistochemistry (mIHC)\nimages, featuring DAPI, CD3, and panCK markers. Distinctively, HEMIT's mIHC\nimages are multi-component and cellular-level aligned with H&E, enriching\nsupervised stain translation tasks. To our knowledge, HEMIT is the first\npublicly available cellular-level aligned dataset that enables H&E to\nmulti-target mIHC image translation. This dataset provides the computer vision\ncommunity with a valuable resource to develop novel computational methods which\nhave the potential to gain new insights from H&E slide archives.\n  We also propose a new dual-branch generator architecture, using residual\nConvolutional Neural Networks (CNNs) and Swin Transformers which achieves\nbetter translation outcomes than other popular algorithms. When evaluated on\nHEMIT, it outperforms pix2pixHD, pix2pix, U-Net, and ResNet, achieving the\nhighest overall score on key metrics including the Structural Similarity Index\nMeasure (SSIM), Pearson correlation score (R), and Peak signal-to-noise Ratio\n(PSNR). Additionally, downstream analysis has been used to further validate the\nquality of the generated mIHC images. These results set a new benchmark in the\nfield of stain translation tasks.\n","authors":["Chang Bian","Beth Philips","Tim Cootes","Martin Fergie"],"pdf_url":"https://arxiv.org/pdf/2403.18501v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.04698v3","updated":"2024-03-27T12:24:17Z","published":"2023-11-08T14:10:19Z","title":"Challenging Common Paradigms in Multi-Task Learning","summary":"  While multi-task learning (MTL) has gained significant attention in recent\nyears, its underlying mechanisms remain poorly understood. Recent methods did\nnot yield consistent performance improvements over single task learning (STL)\nbaselines, underscoring the importance of gaining more profound insights about\nchallenges specific to MTL. In our study, we challenge paradigms in MTL in the\ncontext of STL: First, the impact of the choice of optimizer has only been\nmildly investigated in MTL. We show the pivotal role of common STL tools such\nas the Adam optimizer in MTL empirically in various experiments. To further\ninvestigate Adam's effectiveness, we theoretical derive a partial loss-scale\ninvariance under mild assumptions. Second, the notion of gradient conflicts has\noften been phrased as a specific problem in MTL. We delve into the role of\ngradient conflicts in MTL and compare it to STL. For angular gradient alignment\nwe find no evidence that this is a unique problem in MTL. We emphasize\ndifferences in gradient magnitude as the main distinguishing factor. Lastly, we\ncompare the transferability of features learned through MTL and STL on common\nimage corruptions, and find light evidence that MTL can lead to superior\ntransferability. Overall, we find surprising similarities between STL and MTL\nsuggesting to consider methods from both fields in a broader context.\n","authors":["Cathrin Elich","Lukas Kirchdorfer","Jan M. K√∂hler","Lukas Schott"],"pdf_url":"https://arxiv.org/pdf/2311.04698v3.pdf","comment":"-"},{"id":"http://arxiv.org/abs/2403.18495v1","updated":"2024-03-27T12:15:22Z","published":"2024-03-27T12:15:22Z","title":"Direct mineral content prediction from drill core images via transfer\n  learning","summary":"  Deep subsurface exploration is important for mining, oil and gas industries,\nas well as in the assessment of geological units for the disposal of chemical\nor nuclear waste, or the viability of geothermal energy systems. Typically,\ndetailed examinations of subsurface formations or units are performed on\ncuttings or core materials extracted during drilling campaigns, as well as on\ngeophysical borehole data, which provide detailed information about the\npetrophysical properties of the rocks. Depending on the volume of rock samples\nand the analytical program, the laboratory analysis and diagnostics can be very\ntime-consuming. This study investigates the potential of utilizing machine\nlearning, specifically convolutional neural networks (CNN), to assess the\nlithology and mineral content solely from analysis of drill core images, aiming\nto support and expedite the subsurface geological exploration. The paper\noutlines a comprehensive methodology, encompassing data preprocessing, machine\nlearning methods, and transfer learning techniques. The outcome reveals a\nremarkable 96.7% accuracy in the classification of drill core segments into\ndistinct formation classes. Furthermore, a CNN model was trained for the\nevaluation of mineral content using a learning data set from multidimensional\nlog analysis data (silicate, total clay, carbonate). When benchmarked against\nlaboratory XRD measurements on samples from the cores, both the advanced\nmultidimensional log analysis model and the neural network approach developed\nhere provide equally good performance. This work demonstrates that deep\nlearning and particularly transfer learning can support extracting\npetrophysical properties, including mineral content and formation\nclassification, from drill core images, thus offering a road map for enhancing\nmodel performance and data set quality in image-based analysis of drill cores.\n","authors":["Romana Boiger","Sergey V. Churakov","Ignacio Ballester Llagaria","Georg Kosakowski","Raphael W√ºst","Nikolaos I. Prasianakis"],"pdf_url":"https://arxiv.org/pdf/2403.18495v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.02203v5","updated":"2024-03-27T12:12:45Z","published":"2023-07-05T10:54:50Z","title":"Neural Fields for Interactive Visualization of Statistical Dependencies\n  in 3D Simulation Ensembles","summary":"  We present the first neural network that has learned to compactly represent\nand can efficiently reconstruct the statistical dependencies between the values\nof physical variables at different spatial locations in large 3D simulation\nensembles. Going beyond linear dependencies, we consider mutual information as\na measure of non-linear dependence. We demonstrate learning and reconstruction\nwith a large weather forecast ensemble comprising 1000 members, each storing\nmultiple physical variables at a 250 x 352 x 20 simulation grid. By\ncircumventing compute-intensive statistical estimators at runtime, we\ndemonstrate significantly reduced memory and computation requirements for\nreconstructing the major dependence structures. This enables embedding the\nestimator into a GPU-accelerated direct volume renderer and interactively\nvisualizing all mutual dependencies for a selected domain point.\n","authors":["Fatemeh Farokhmanesh","Kevin H√∂hlein","Christoph Neuhauser","Tobias Necker","Martin Weissmann","Takemasa Miyoshi","R√ºdiger Westermann"],"pdf_url":"https://arxiv.org/pdf/2307.02203v5.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.18493v1","updated":"2024-03-27T12:08:41Z","published":"2024-03-27T12:08:41Z","title":"VersaT2I: Improving Text-to-Image Models with Versatile Reward","summary":"  Recent text-to-image (T2I) models have benefited from large-scale and\nhigh-quality data, demonstrating impressive performance. However, these T2I\nmodels still struggle to produce images that are aesthetically pleasing,\ngeometrically accurate, faithful to text, and of good low-level quality. We\npresent VersaT2I, a versatile training framework that can boost the performance\nwith multiple rewards of any T2I model. We decompose the quality of the image\ninto several aspects such as aesthetics, text-image alignment, geometry,\nlow-level quality, etc. Then, for every quality aspect, we select high-quality\nimages in this aspect generated by the model as the training set to finetune\nthe T2I model using the Low-Rank Adaptation (LoRA). Furthermore, we introduce a\ngating function to combine multiple quality aspects, which can avoid conflicts\nbetween different quality aspects. Our method is easy to extend and does not\nrequire any manual annotation, reinforcement learning, or model architecture\nchanges. Extensive experiments demonstrate that VersaT2I outperforms the\nbaseline methods across various quality criteria.\n","authors":["Jianshu Guo","Wenhao Chai","Jie Deng","Hsiang-Wei Huang","Tian Ye","Yichen Xu","Jiawei Zhang","Jenq-Neng Hwang","Gaoang Wang"],"pdf_url":"https://arxiv.org/pdf/2403.18493v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.18490v1","updated":"2024-03-27T12:05:22Z","published":"2024-03-27T12:05:22Z","title":"I2CKD : Intra- and Inter-Class Knowledge Distillation for Semantic\n  Segmentation","summary":"  This paper proposes a new knowledge distillation method tailored for image\nsemantic segmentation, termed Intra- and Inter-Class Knowledge Distillation\n(I2CKD). The focus of this method is on capturing and transferring knowledge\nbetween the intermediate layers of teacher (cumbersome model) and student\n(compact model). For knowledge extraction, we exploit class prototypes derived\nfrom feature maps. To facilitate knowledge transfer, we employ a triplet loss\nin order to minimize intra-class variances and maximize inter-class variances\nbetween teacher and student prototypes. Consequently, I2CKD enables the student\nto better mimic the feature representation of the teacher for each class,\nthereby enhancing the segmentation performance of the compact network.\nExtensive experiments on three segmentation datasets, i.e., Cityscapes, Pascal\nVOC and CamVid, using various teacher-student network pairs demonstrate the\neffectiveness of the proposed method.\n","authors":["Ayoub Karine","Thibault Napol√©on","Maher Jridi"],"pdf_url":"https://arxiv.org/pdf/2403.18490v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2312.16943v2","updated":"2024-03-27T11:46:36Z","published":"2023-12-28T10:40:11Z","title":"SAR-Net: Multi-scale Direction-aware SAR Network via Global Information\n  Fusion","summary":"  Deep learning has driven significant progress in object detection using\nSynthetic Aperture Radar (SAR) imagery. Existing methods, while achieving\npromising results, often struggle to effectively integrate local and global\ninformation, particularly direction-aware features. This paper proposes\nSAR-Net, a novel framework specifically designed for global fusion of\ndirection-aware information in SAR object detection. SAR-Net leverages two key\ninnovations: the Unity Compensation Mechanism (UCM) and the Direction-aware\nAttention Module (DAM). UCM facilitates the establishment of complementary\nrelationships among features across different scales, enabling efficient global\ninformation fusion. Among them, Multi-scale Alignment Module (MAM) and distinct\nMulti-level Fusion Module (MFM) enhance feature integration by capturing both\ntexture detail and semantic information. Then, Multi-feature Embedding Module\n(MEM) feeds back global features into the primary branches, further improving\ninformation transmission. Additionally, DAM, through bidirectional attention\npolymerization, captures direction-aware information, effectively eliminating\nbackground interference. Extensive experiments demonstrate the effectiveness of\nSAR-Net, achieving state-of-the-art results on aircraft (SAR-AIRcraft-1.0) and\nship datasets (SSDD, HRSID), confirming its generalization capability and\nrobustness.\n","authors":["Mingxiang Cao","Jie Lei","Weiying Xie","Jiaqing Zhang","Daixun Li","Yunsong Li"],"pdf_url":"https://arxiv.org/pdf/2312.16943v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.18476v1","updated":"2024-03-27T11:45:08Z","published":"2024-03-27T11:45:08Z","title":"Modeling uncertainty for Gaussian Splatting","summary":"  We present Stochastic Gaussian Splatting (SGS): the first framework for\nuncertainty estimation using Gaussian Splatting (GS). GS recently advanced the\nnovel-view synthesis field by achieving impressive reconstruction quality at a\nfraction of the computational cost of Neural Radiance Fields (NeRF). However,\ncontrary to the latter, it still lacks the ability to provide information about\nthe confidence associated with their outputs. To address this limitation, in\nthis paper, we introduce a Variational Inference-based approach that seamlessly\nintegrates uncertainty prediction into the common rendering pipeline of GS.\nAdditionally, we introduce the Area Under Sparsification Error (AUSE) as a new\nterm in the loss function, enabling optimization of uncertainty estimation\nalongside image reconstruction. Experimental results on the LLFF dataset\ndemonstrate that our method outperforms existing approaches in terms of both\nimage rendering quality and uncertainty estimation accuracy. Overall, our\nframework equips practitioners with valuable insights into the reliability of\nsynthesized views, facilitating safer decision-making in real-world\napplications.\n","authors":["Luca Savant","Diego Valsesia","Enrico Magli"],"pdf_url":"https://arxiv.org/pdf/2403.18476v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.12028v2","updated":"2024-03-27T11:43:28Z","published":"2023-11-20T18:59:51Z","title":"Hourglass Tokenizer for Efficient Transformer-Based 3D Human Pose\n  Estimation","summary":"  Transformers have been successfully applied in the field of video-based 3D\nhuman pose estimation. However, the high computational costs of these video\npose transformers (VPTs) make them impractical on resource-constrained devices.\nIn this paper, we present a plug-and-play pruning-and-recovering framework,\ncalled Hourglass Tokenizer (HoT), for efficient transformer-based 3D human pose\nestimation from videos. Our HoT begins with pruning pose tokens of redundant\nframes and ends with recovering full-length tokens, resulting in a few pose\ntokens in the intermediate transformer blocks and thus improving the model\nefficiency. To effectively achieve this, we propose a token pruning cluster\n(TPC) that dynamically selects a few representative tokens with high semantic\ndiversity while eliminating the redundancy of video frames. In addition, we\ndevelop a token recovering attention (TRA) to restore the detailed\nspatio-temporal information based on the selected tokens, thereby expanding the\nnetwork output to the original full-length temporal resolution for fast\ninference. Extensive experiments on two benchmark datasets (i.e., Human3.6M and\nMPI-INF-3DHP) demonstrate that our method can achieve both high efficiency and\nestimation accuracy compared to the original VPT models. For instance, applying\nto MotionBERT and MixSTE on Human3.6M, our HoT can save nearly 50% FLOPs\nwithout sacrificing accuracy and nearly 40% FLOPs with only 0.2% accuracy drop,\nrespectively. Code and models are available at\nhttps://github.com/NationalGAILab/HoT.\n","authors":["Wenhao Li","Mengyuan Liu","Hong Liu","Pichao Wang","Jialun Cai","Nicu Sebe"],"pdf_url":"https://arxiv.org/pdf/2311.12028v2.pdf","comment":"Accepted by CVPR 2024, Open Sourced"},{"id":"http://arxiv.org/abs/2403.18471v1","updated":"2024-03-27T11:32:44Z","published":"2024-03-27T11:32:44Z","title":"DiffusionFace: Towards a Comprehensive Dataset for Diffusion-Based Face\n  Forgery Analysis","summary":"  The rapid progress in deep learning has given rise to hyper-realistic facial\nforgery methods, leading to concerns related to misinformation and security\nrisks. Existing face forgery datasets have limitations in generating\nhigh-quality facial images and addressing the challenges posed by evolving\ngenerative techniques. To combat this, we present DiffusionFace, the first\ndiffusion-based face forgery dataset, covering various forgery categories,\nincluding unconditional and Text Guide facial image generation, Img2Img,\nInpaint, and Diffusion-based facial exchange algorithms. Our DiffusionFace\ndataset stands out with its extensive collection of 11 diffusion models and the\nhigh-quality of the generated images, providing essential metadata and a\nreal-world internet-sourced forgery facial image dataset for evaluation.\nAdditionally, we provide an in-depth analysis of the data and introduce\npractical evaluation protocols to rigorously assess discriminative models'\neffectiveness in detecting counterfeit facial images, aiming to enhance\nsecurity in facial image authentication processes. The dataset is available for\ndownload at \\url{https://github.com/Rapisurazurite/DiffFace}.\n","authors":["Zhongxi Chen","Ke Sun","Ziyin Zhou","Xianming Lin","Xiaoshuai Sun","Liujuan Cao","Rongrong Ji"],"pdf_url":"https://arxiv.org/pdf/2403.18471v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.18469v1","updated":"2024-03-27T11:28:57Z","published":"2024-03-27T11:28:57Z","title":"Density-guided Translator Boosts Synthetic-to-Real Unsupervised Domain\n  Adaptive Segmentation of 3D Point Clouds","summary":"  3D synthetic-to-real unsupervised domain adaptive segmentation is crucial to\nannotating new domains. Self-training is a competitive approach for this task,\nbut its performance is limited by different sensor sampling patterns (i.e.,\nvariations in point density) and incomplete training strategies. In this work,\nwe propose a density-guided translator (DGT), which translates point density\nbetween domains, and integrates it into a two-stage self-training pipeline\nnamed DGT-ST. First, in contrast to existing works that simultaneously conduct\ndata generation and feature/output alignment within unstable adversarial\ntraining, we employ the non-learnable DGT to bridge the domain gap at the input\nlevel. Second, to provide a well-initialized model for self-training, we\npropose a category-level adversarial network in stage one that utilizes the\nprototype to prevent negative transfer. Finally, by leveraging the designs\nabove, a domain-mixed self-training method with source-aware consistency loss\nis proposed in stage two to narrow the domain gap further. Experiments on two\nsynthetic-to-real segmentation tasks (SynLiDAR $\\rightarrow$ semanticKITTI and\nSynLiDAR $\\rightarrow$ semanticPOSS) demonstrate that DGT-ST outperforms\nstate-of-the-art methods, achieving 9.4$\\%$ and 4.3$\\%$ mIoU improvements,\nrespectively. Code is available at \\url{https://github.com/yuan-zm/DGT-ST}.\n","authors":["Zhimin Yuan","Wankang Zeng","Yanfei Su","Weiquan Liu","Ming Cheng","Yulan Guo","Cheng Wang"],"pdf_url":"https://arxiv.org/pdf/2403.18469v1.pdf","comment":"CVPR2024"},{"id":"http://arxiv.org/abs/2403.18468v1","updated":"2024-03-27T11:28:32Z","published":"2024-03-27T11:28:32Z","title":"Deep Learning Segmentation and Classification of Red Blood Cells Using a\n  Large Multi-Scanner Dataset","summary":"  Digital pathology has recently been revolutionized by advancements in\nartificial intelligence, deep learning, and high-performance computing. With\nits advanced tools, digital pathology can help improve and speed up the\ndiagnostic process, reduce human errors, and streamline the reporting step. In\nthis paper, we report a new large red blood cell (RBC) image dataset and\npropose a two-stage deep learning framework for RBC image segmentation and\nclassification. The dataset is a highly diverse dataset of more than 100K RBCs\ncontaining eight different classes. The dataset, which is considerably larger\nthan any publicly available hematopathology dataset, was labeled independently\nby two hematopathologists who also manually created masks for RBC cell\nsegmentation. Subsequently, in the proposed framework, first, a U-Net model was\ntrained to achieve automatic RBC image segmentation. Second, an EfficientNetB0\nmodel was trained to classify RBC images into one of the eight classes using a\ntransfer learning approach with a 5X2 cross-validation scheme. An IoU of 98.03%\nand an average classification accuracy of 96.5% were attained on the test set.\nMoreover, we have performed experimental comparisons against several prominent\nCNN models. These comparisons show the superiority of the proposed model with a\ngood balance between performance and computational cost.\n","authors":["Mohamed Elmanna","Ahmed Elsafty","Yomna Ahmed","Muhammad Rushdi","Ahmed Morsy"],"pdf_url":"https://arxiv.org/pdf/2403.18468v1.pdf","comment":"15 pages, 12 figures, 8 tables"},{"id":"http://arxiv.org/abs/2403.18461v1","updated":"2024-03-27T11:19:34Z","published":"2024-03-27T11:19:34Z","title":"DiffStyler: Diffusion-based Localized Image Style Transfer","summary":"  Image style transfer aims to imbue digital imagery with the distinctive\nattributes of style targets, such as colors, brushstrokes, shapes, whilst\nconcurrently preserving the semantic integrity of the content. Despite the\nadvancements in arbitrary style transfer methods, a prevalent challenge remains\nthe delicate equilibrium between content semantics and style attributes. Recent\ndevelopments in large-scale text-to-image diffusion models have heralded\nunprecedented synthesis capabilities, albeit at the expense of relying on\nextensive and often imprecise textual descriptions to delineate artistic\nstyles. Addressing these limitations, this paper introduces DiffStyler, a novel\napproach that facilitates efficient and precise arbitrary image style transfer.\nDiffStyler lies the utilization of a text-to-image Stable Diffusion model-based\nLoRA to encapsulate the essence of style targets. This approach, coupled with\nstrategic cross-LoRA feature and attention injection, guides the style transfer\nprocess. The foundation of our methodology is rooted in the observation that\nLoRA maintains the spatial feature consistency of UNet, a discovery that\nfurther inspired the development of a mask-wise style transfer technique. This\ntechnique employs masks extracted through a pre-trained FastSAM model,\nutilizing mask prompts to facilitate feature fusion during the denoising\nprocess, thereby enabling localized style transfer that preserves the original\nimage's unaffected regions. Moreover, our approach accommodates multiple style\ntargets through the use of corresponding masks. Through extensive\nexperimentation, we demonstrate that DiffStyler surpasses previous methods in\nachieving a more harmonious balance between content preservation and style\nintegration.\n","authors":["Shaoxu Li"],"pdf_url":"https://arxiv.org/pdf/2403.18461v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.10522v4","updated":"2024-03-27T11:18:51Z","published":"2023-11-17T13:43:43Z","title":"Enhancing Object Coherence in Layout-to-Image Synthesis","summary":"  Layout-to-image synthesis is an emerging technique in conditional image\ngeneration. It aims to generate complex scenes, where users require fine\ncontrol over the layout of the objects in a scene. However, it remains\nchallenging to control the object coherence, including semantic coherence\n(e.g., the cat looks at the flowers or not) and physical coherence (e.g., the\nhand and the racket should not be misaligned). In this paper, we propose a\nnovel diffusion model with effective global semantic fusion (GSF) and\nself-similarity feature enhancement modules to guide the object coherence for\nthis task. For semantic coherence, we argue that the image caption contains\nrich information for defining the semantic relationship within the objects in\nthe images. Instead of simply employing cross-attention between captions and\ngenerated images, which addresses the highly relevant layout restriction and\nsemantic coherence separately and thus leads to unsatisfying results shown in\nour experiments, we develop GSF to fuse the supervision from the layout\nrestriction and semantic coherence requirement and exploit it to guide the\nimage synthesis process. Moreover, to improve the physical coherence, we\ndevelop a Self-similarity Coherence Attention (SCA) module to explicitly\nintegrate local contextual physical coherence into each pixel's generation\nprocess. Specifically, we adopt a self-similarity map to encode the coherence\nrestrictions and employ it to extract coherent features from text embedding.\nThrough visualization of our self-similarity map, we explore the essence of\nSCA, revealing that its effectiveness is not only in capturing reliable\nphysical coherence patterns but also in enhancing complex texture generation.\nExtensive experiments demonstrate the superiority of our proposed method in\nboth image generation quality and controllability.\n","authors":["Yibin Wang","Weizhong Zhang","Jianwei Zheng","Cheng Jin"],"pdf_url":"https://arxiv.org/pdf/2311.10522v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.18454v1","updated":"2024-03-27T11:13:20Z","published":"2024-03-27T11:13:20Z","title":"Scaling Vision-and-Language Navigation With Offline RL","summary":"  The study of vision-and-language navigation (VLN) has typically relied on\nexpert trajectories, which may not always be available in real-world situations\ndue to the significant effort required to collect them. On the other hand,\nexisting approaches to training VLN agents that go beyond available expert data\ninvolve data augmentations or online exploration which can be tedious and\nrisky. In contrast, it is easy to access large repositories of suboptimal\noffline trajectories. Inspired by research in offline reinforcement learning\n(ORL), we introduce a new problem setup of VLN-ORL which studies VLN using\nsuboptimal demonstration data. We introduce a simple and effective\nreward-conditioned approach that can account for dataset suboptimality for\ntraining VLN agents, as well as benchmarks to evaluate progress and promote\nresearch in this area. We empirically study various noise models for\ncharacterizing dataset suboptimality among other unique challenges in VLN-ORL\nand instantiate it for the VLN$\\circlearrowright$BERT and MTVM architectures in\nthe R2R and RxR environments. Our experiments demonstrate that the proposed\nreward-conditioned approach leads to significant performance improvements, even\nin complex and intricate environments.\n","authors":["Valay Bundele","Mahesh Bhupati","Biplab Banerjee","Aditya Grover"],"pdf_url":"https://arxiv.org/pdf/2403.18454v1.pdf","comment":"Published in Transactions on Machine Learning Research (04/2024)"},{"id":"http://arxiv.org/abs/2403.18452v1","updated":"2024-03-27T11:11:08Z","published":"2024-03-27T11:11:08Z","title":"SingularTrajectory: Universal Trajectory Predictor Using Diffusion Model","summary":"  There are five types of trajectory prediction tasks: deterministic,\nstochastic, domain adaptation, momentary observation, and few-shot. These\nassociated tasks are defined by various factors, such as the length of input\npaths, data split and pre-processing methods. Interestingly, even though they\ncommonly take sequential coordinates of observations as input and infer future\npaths in the same coordinates as output, designing specialized architectures\nfor each task is still necessary. For the other task, generality issues can\nlead to sub-optimal performances. In this paper, we propose SingularTrajectory,\na diffusion-based universal trajectory prediction framework to reduce the\nperformance gap across the five tasks. The core of SingularTrajectory is to\nunify a variety of human dynamics representations on the associated tasks. To\ndo this, we first build a Singular space to project all types of motion\npatterns from each task into one embedding space. We next propose an adaptive\nanchor working in the Singular space. Unlike traditional fixed anchor methods\nthat sometimes yield unacceptable paths, our adaptive anchor enables correct\nanchors, which are put into a wrong location, based on a traversability map.\nFinally, we adopt a diffusion-based predictor to further enhance the prototype\npaths using a cascaded denoising process. Our unified framework ensures the\ngenerality across various benchmark settings such as input modality, and\ntrajectory lengths. Extensive experiments on five public benchmarks demonstrate\nthat SingularTrajectory substantially outperforms existing models, highlighting\nits effectiveness in estimating general dynamics of human movements. Code is\npublicly available at https://github.com/inhwanbae/SingularTrajectory .\n","authors":["Inhwan Bae","Young-Jae Park","Hae-Gon Jeon"],"pdf_url":"https://arxiv.org/pdf/2403.18452v1.pdf","comment":"Accepted at CVPR 2024"},{"id":"http://arxiv.org/abs/2403.18447v1","updated":"2024-03-27T11:06:44Z","published":"2024-03-27T11:06:44Z","title":"Can Language Beat Numerical Regression? Language-Based Multimodal\n  Trajectory Prediction","summary":"  Language models have demonstrated impressive ability in context understanding\nand generative performance. Inspired by the recent success of language\nfoundation models, in this paper, we propose LMTraj (Language-based Multimodal\nTrajectory predictor), which recasts the trajectory prediction task into a sort\nof question-answering problem. Departing from traditional numerical regression\nmodels, which treat the trajectory coordinate sequence as continuous signals,\nwe consider them as discrete signals like text prompts. Specially, we first\ntransform an input space for the trajectory coordinate into the natural\nlanguage space. Here, the entire time-series trajectories of pedestrians are\nconverted into a text prompt, and scene images are described as text\ninformation through image captioning. The transformed numerical and image data\nare then wrapped into the question-answering template for use in a language\nmodel. Next, to guide the language model in understanding and reasoning\nhigh-level knowledge, such as scene context and social relationships between\npedestrians, we introduce an auxiliary multi-task question and answering. We\nthen train a numerical tokenizer with the prompt data. We encourage the\ntokenizer to separate the integer and decimal parts well, and leverage it to\ncapture correlations between the consecutive numbers in the language model.\nLastly, we train the language model using the numerical tokenizer and all of\nthe question-answer prompts. Here, we propose a beam-search-based most-likely\nprediction and a temperature-based multimodal prediction to implement both\ndeterministic and stochastic inferences. Applying our LMTraj, we show that the\nlanguage-based model can be a powerful pedestrian trajectory predictor, and\noutperforms existing numerical-based predictor methods. Code is publicly\navailable at https://github.com/inhwanbae/LMTrajectory .\n","authors":["Inhwan Bae","Junoh Lee","Hae-Gon Jeon"],"pdf_url":"https://arxiv.org/pdf/2403.18447v1.pdf","comment":"Accepted at CVPR 2024"},{"id":"http://arxiv.org/abs/2403.18443v1","updated":"2024-03-27T11:00:33Z","published":"2024-03-27T11:00:33Z","title":"$\\mathrm{F^2Depth}$: Self-supervised Indoor Monocular Depth Estimation\n  via Optical Flow Consistency and Feature Map Synthesis","summary":"  Self-supervised monocular depth estimation methods have been increasingly\ngiven much attention due to the benefit of not requiring large, labelled\ndatasets. Such self-supervised methods require high-quality salient features\nand consequently suffer from severe performance drop for indoor scenes, where\nlow-textured regions dominant in the scenes are almost indiscriminative. To\naddress the issue, we propose a self-supervised indoor monocular depth\nestimation framework called $\\mathrm{F^2Depth}$. A self-supervised optical flow\nestimation network is introduced to supervise depth learning. To improve\noptical flow estimation performance in low-textured areas, only some patches of\npoints with more discriminative features are adopted for finetuning based on\nour well-designed patch-based photometric loss. The finetuned optical flow\nestimation network generates high-accuracy optical flow as a supervisory signal\nfor depth estimation. Correspondingly, an optical flow consistency loss is\ndesigned. Multi-scale feature maps produced by finetuned optical flow\nestimation network perform warping to compute feature map synthesis loss as\nanother supervisory signal for depth learning. Experimental results on the NYU\nDepth V2 dataset demonstrate the effectiveness of the framework and our\nproposed losses. To evaluate the generalization ability of our\n$\\mathrm{F^2Depth}$, we collect a Campus Indoor depth dataset composed of\napproximately 1500 points selected from 99 images in 18 scenes. Zero-shot\ngeneralization experiments on 7-Scenes dataset and Campus Indoor achieve\n$\\delta_1$ accuracy of 75.8% and 76.0% respectively. The accuracy results show\nthat our model can generalize well to monocular images captured in unknown\nindoor scenes.\n","authors":["Xiaotong Guo","Huijie Zhao","Shuwei Shao","Xudong Li","Baochang Zhang"],"pdf_url":"https://arxiv.org/pdf/2403.18443v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2211.17126v2","updated":"2024-03-27T10:50:54Z","published":"2022-11-30T16:03:24Z","title":"BEVUDA: Multi-geometric Space Alignments for Domain Adaptive BEV 3D\n  Object Detection","summary":"  Vision-centric bird-eye-view (BEV) perception has shown promising potential\nin autonomous driving. Recent works mainly focus on improving efficiency or\naccuracy but neglect the challenges when facing environment changing, resulting\nin severe degradation of transfer performance. For BEV perception, we figure\nout the significant domain gaps existing in typical real-world cross-domain\nscenarios and comprehensively solve the Domain Adaption (DA) problem for\nmulti-view 3D object detection. Since BEV perception approaches are complicated\nand contain several components, the domain shift accumulation on multiple\ngeometric spaces (i.e., 2D, 3D Voxel, BEV) makes BEV DA even challenging. In\nthis paper, we propose a Multi-space Alignment Teacher-Student (MATS) framework\nto ease the domain shift accumulation, which consists of a Depth-Aware Teacher\n(DAT) and a Geometric-space Aligned Student (GAS) model. DAT tactfully combines\ntarget lidar and reliable depth prediction to construct depth-aware\ninformation, extracting target domain-specific knowledge in Voxel and BEV\nfeature spaces. It then transfers the sufficient domain knowledge of multiple\nspaces to the student model. In order to jointly alleviate the domain shift,\nGAS projects multi-geometric space features to a shared geometric embedding\nspace and decreases data distribution distance between two domains. To verify\nthe effectiveness of our method, we conduct BEV 3D object detection experiments\non three cross-domain scenarios and achieve state-of-the-art performance.\n","authors":["Jiaming Liu","Rongyu Zhang","Xiaoqi Li","Xiaowei Chi","Zehui Chen","Ming Lu","Yandong Guo","Shanghang Zhang"],"pdf_url":"https://arxiv.org/pdf/2211.17126v2.pdf","comment":"Accepted by ICRA2024"},{"id":"http://arxiv.org/abs/2403.18442v1","updated":"2024-03-27T10:50:24Z","published":"2024-03-27T10:50:24Z","title":"Backpropagation-free Network for 3D Test-time Adaptation","summary":"  Real-world systems often encounter new data over time, which leads to\nexperiencing target domain shifts. Existing Test-Time Adaptation (TTA) methods\ntend to apply computationally heavy and memory-intensive backpropagation-based\napproaches to handle this. Here, we propose a novel method that uses a\nbackpropagation-free approach for TTA for the specific case of 3D data. Our\nmodel uses a two-stream architecture to maintain knowledge about the source\ndomain as well as complementary target-domain-specific information. The\nbackpropagation-free property of our model helps address the well-known\nforgetting problem and mitigates the error accumulation issue. The proposed\nmethod also eliminates the need for the usually noisy process of\npseudo-labeling and reliance on costly self-supervised training. Moreover, our\nmethod leverages subspace learning, effectively reducing the distribution\nvariance between the two domains. Furthermore, the source-domain-specific and\nthe target-domain-specific streams are aligned using a novel entropy-based\nadaptive fusion strategy. Extensive experiments on popular benchmarks\ndemonstrate the effectiveness of our method. The code will be available at\nhttps://github.com/abie-e/BFTT3D.\n","authors":["Yanshuo Wang","Ali Cheraghian","Zeeshan Hayder","Jie Hong","Sameera Ramasinghe","Shafin Rahman","David Ahmedt-Aristizabal","Xuesong Li","Lars Petersson","Mehrtash Harandi"],"pdf_url":"https://arxiv.org/pdf/2403.18442v1.pdf","comment":"CVPR 2024"},{"id":"http://arxiv.org/abs/2311.18113v2","updated":"2024-03-27T10:46:59Z","published":"2023-11-29T21:58:41Z","title":"Back to 3D: Few-Shot 3D Keypoint Detection with Back-Projected 2D\n  Features","summary":"  With the immense growth of dataset sizes and computing resources in recent\nyears, so-called foundation models have become popular in NLP and vision tasks.\nIn this work, we propose to explore foundation models for the task of keypoint\ndetection on 3D shapes. A unique characteristic of keypoint detection is that\nit requires semantic and geometric awareness while demanding high localization\naccuracy. To address this problem, we propose, first, to back-project features\nfrom large pre-trained 2D vision models onto 3D shapes and employ them for this\ntask. We show that we obtain robust 3D features that contain rich semantic\ninformation and analyze multiple candidate features stemming from different 2D\nfoundation models. Second, we employ a keypoint candidate optimization module\nwhich aims to match the average observed distribution of keypoints on the shape\nand is guided by the back-projected features. The resulting approach achieves a\nnew state of the art for few-shot keypoint detection on the KeyPointNet\ndataset, almost doubling the performance of the previous best methods.\n","authors":["Thomas Wimmer","Peter Wonka","Maks Ovsjanikov"],"pdf_url":"https://arxiv.org/pdf/2311.18113v2.pdf","comment":"Accepted to CVPR 2024, Project page:\n  https://wimmerth.github.io/back-to-3d.html"},{"id":"http://arxiv.org/abs/2401.08742v2","updated":"2024-03-27T10:33:02Z","published":"2024-01-16T18:58:36Z","title":"Fast Dynamic 3D Object Generation from a Single-view Video","summary":"  Generating dynamic 3D object from a single-view video is challenging due to\nthe lack of 4D labeled data. Extending image-to-3D pipelines by transferring\noff-the-shelf image generation models such as score distillation sampling,\nexisting methods tend to be slow and expensive to scale due to the need for\nback-propagating the information-limited supervision signals through a large\npretrained model. To address this, we propose an efficient video-to-4D object\ngeneration framework called Efficient4D. It generates high-quality\nspacetime-consistent images under different camera views, and then uses them as\nlabeled data to directly train a novel 4D Gaussian splatting model with\nexplicit point cloud geometry, enabling real-time rendering under continuous\ncamera trajectories. Extensive experiments on synthetic and real videos show\nthat Efficient4D offers a remarkable 20-fold increase in speed when compared to\nprior art alternatives while preserving the quality of novel view synthesis.\nFor example, Efficient4D takes only 6 mins to model a dynamic object, vs 120\nmins by Consistent4D.\n","authors":["Zijie Pan","Zeyu Yang","Xiatian Zhu","Li Zhang"],"pdf_url":"https://arxiv.org/pdf/2401.08742v2.pdf","comment":"Technical report"},{"id":"http://arxiv.org/abs/2403.18425v1","updated":"2024-03-27T10:26:42Z","published":"2024-03-27T10:26:42Z","title":"U-Sketch: An Efficient Approach for Sketch to Image Diffusion Models","summary":"  Diffusion models have demonstrated remarkable performance in text-to-image\nsynthesis, producing realistic and high resolution images that faithfully\nadhere to the corresponding text-prompts. Despite their great success, they\nstill fall behind in sketch-to-image synthesis tasks, where in addition to\ntext-prompts, the spatial layout of the generated images has to closely follow\nthe outlines of certain reference sketches. Employing an MLP latent edge\npredictor to guide the spatial layout of the synthesized image by predicting\nedge maps at each denoising step has been recently proposed. Despite yielding\npromising results, the pixel-wise operation of the MLP does not take into\naccount the spatial layout as a whole, and demands numerous denoising\niterations to produce satisfactory images, leading to time inefficiency. To\nthis end, we introduce U-Sketch, a framework featuring a U-Net type latent edge\npredictor, which is capable of efficiently capturing both local and global\nfeatures, as well as spatial correlations between pixels. Moreover, we propose\nthe addition of a sketch simplification network that offers the user the choice\nof preprocessing and simplifying input sketches for enhanced outputs. The\nexperimental results, corroborated by user feedback, demonstrate that our\nproposed U-Net latent edge predictor leads to more realistic results, that are\nbetter aligned with the spatial outlines of the reference sketches, while\ndrastically reducing the number of required denoising steps and, consequently,\nthe overall execution time.\n","authors":["Ilias Mitsouras","Eleftherios Tsonis","Paraskevi Tzouveli","Athanasios Voulodimos"],"pdf_url":"https://arxiv.org/pdf/2403.18425v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.15098v2","updated":"2024-03-27T10:26:23Z","published":"2024-03-22T10:36:50Z","title":"UniTraj: A Unified Framework for Scalable Vehicle Trajectory Prediction","summary":"  Vehicle trajectory prediction has increasingly relied on data-driven\nsolutions, but their ability to scale to different data domains and the impact\nof larger dataset sizes on their generalization remain under-explored. While\nthese questions can be studied by employing multiple datasets, it is\nchallenging due to several discrepancies, e.g., in data formats, map\nresolution, and semantic annotation types. To address these challenges, we\nintroduce UniTraj, a comprehensive framework that unifies various datasets,\nmodels, and evaluation criteria, presenting new opportunities for the vehicle\ntrajectory prediction field. In particular, using UniTraj, we conduct extensive\nexperiments and find that model performance significantly drops when\ntransferred to other datasets. However, enlarging data size and diversity can\nsubstantially improve performance, leading to a new state-of-the-art result for\nthe nuScenes dataset. We provide insights into dataset characteristics to\nexplain these findings. The code can be found here:\nhttps://github.com/vita-epfl/UniTraj\n","authors":["Lan Feng","Mohammadhossein Bahari","Kaouther Messaoud Ben Amor","√âloi Zablocki","Matthieu Cord","Alexandre Alahi"],"pdf_url":"https://arxiv.org/pdf/2403.15098v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2312.12359v2","updated":"2024-03-27T10:18:04Z","published":"2023-12-19T17:40:27Z","title":"CLIP-DINOiser: Teaching CLIP a few DINO tricks for open-vocabulary\n  semantic segmentation","summary":"  The popular CLIP model displays impressive zero-shot capabilities thanks to\nits seamless interaction with arbitrary text prompts. However, its lack of\nspatial awareness makes it unsuitable for dense computer vision tasks, e.g.,\nsemantic segmentation, without an additional fine-tuning step that often uses\nannotations and can potentially suppress its original open-vocabulary\nproperties. Meanwhile, self-supervised representation methods have demonstrated\ngood localization properties without human-made annotations nor explicit\nsupervision. In this work, we take the best of both worlds and propose an\nopen-vocabulary semantic segmentation method, which does not require any\nannotations. We propose to locally improve dense MaskCLIP features, which are\ncomputed with a simple modification of CLIP's last pooling layer, by\nintegrating localization priors extracted from self-supervised features. By\ndoing so, we greatly improve the performance of MaskCLIP and produce smooth\noutputs. Moreover, we show that the used self-supervised feature properties can\ndirectly be learnt from CLIP features. Our method CLIP-DINOiser needs only a\nsingle forward pass of CLIP and two light convolutional layers at inference, no\nextra supervision nor extra memory and reaches state-of-the-art results on\nchallenging and fine-grained benchmarks such as COCO, Pascal Context,\nCityscapes and ADE20k. The code to reproduce our results is available at\nhttps://github.com/wysoczanska/clip_dinoiser.\n","authors":["Monika Wysocza≈Ñska","Oriane Sim√©oni","Micha√´l Ramamonjisoa","Andrei Bursuc","Tomasz Trzci≈Ñski","Patrick P√©rez"],"pdf_url":"https://arxiv.org/pdf/2312.12359v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2312.12480v2","updated":"2024-03-27T10:12:32Z","published":"2023-12-19T15:34:52Z","title":"Continual-MAE: Adaptive Distribution Masked Autoencoders for Continual\n  Test-Time Adaptation","summary":"  Continual Test-Time Adaptation (CTTA) is proposed to migrate a source\npre-trained model to continually changing target distributions, addressing\nreal-world dynamism. Existing CTTA methods mainly rely on entropy minimization\nor teacher-student pseudo-labeling schemes for knowledge extraction in\nunlabeled target domains. However, dynamic data distributions cause\nmiscalibrated predictions and noisy pseudo-labels in existing self-supervised\nlearning methods, hindering the effective mitigation of error accumulation and\ncatastrophic forgetting problems during the continual adaptation process. To\ntackle these issues, we propose a continual self-supervised method, Adaptive\nDistribution Masked Autoencoders (ADMA), which enhances the extraction of\ntarget domain knowledge while mitigating the accumulation of distribution\nshifts. Specifically, we propose a Distribution-aware Masking (DaM) mechanism\nto adaptively sample masked positions, followed by establishing consistency\nconstraints between the masked target samples and the original target samples.\nAdditionally, for masked tokens, we utilize an efficient decoder to reconstruct\na hand-crafted feature descriptor (e.g., Histograms of Oriented Gradients),\nleveraging its invariant properties to boost task-relevant representations.\nThrough conducting extensive experiments on four widely recognized benchmarks,\nour proposed method attains state-of-the-art performance in both classification\nand segmentation CTTA tasks. Our project page:\nhttps://sites.google.com/view/continual-mae/home.\n","authors":["Jiaming Liu","Ran Xu","Senqiao Yang","Renrui Zhang","Qizhe Zhang","Zehui Chen","Yandong Guo","Shanghang Zhang"],"pdf_url":"https://arxiv.org/pdf/2312.12480v2.pdf","comment":"Accepted by CVPR2024"},{"id":"http://arxiv.org/abs/2403.18417v1","updated":"2024-03-27T10:09:38Z","published":"2024-03-27T10:09:38Z","title":"ECNet: Effective Controllable Text-to-Image Diffusion Models","summary":"  The conditional text-to-image diffusion models have garnered significant\nattention in recent years. However, the precision of these models is often\ncompromised mainly for two reasons, ambiguous condition input and inadequate\ncondition guidance over single denoising loss. To address the challenges, we\nintroduce two innovative solutions. Firstly, we propose a Spatial Guidance\nInjector (SGI) which enhances conditional detail by encoding text inputs with\nprecise annotation information. This method directly tackles the issue of\nambiguous control inputs by providing clear, annotated guidance to the model.\nSecondly, to overcome the issue of limited conditional supervision, we\nintroduce Diffusion Consistency Loss (DCL), which applies supervision on the\ndenoised latent code at any given time step. This encourages consistency\nbetween the latent code at each time step and the input signal, thereby\nenhancing the robustness and accuracy of the output. The combination of SGI and\nDCL results in our Effective Controllable Network (ECNet), which offers a more\naccurate controllable end-to-end text-to-image generation framework with a more\nprecise conditioning input and stronger controllable supervision. We validate\nour approach through extensive experiments on generation under various\nconditions, such as human body skeletons, facial landmarks, and sketches of\ngeneral objects. The results consistently demonstrate that our method\nsignificantly enhances the controllability and robustness of the generated\nimages, outperforming existing state-of-the-art controllable text-to-image\nmodels.\n","authors":["Sicheng Li","Keqiang Sun","Zhixin Lai","Xiaoshi Wu","Feng Qiu","Haoran Xie","Kazunori Miyata","Hongsheng Li"],"pdf_url":"https://arxiv.org/pdf/2403.18417v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2309.06075v2","updated":"2024-03-27T09:51:15Z","published":"2023-09-12T09:12:37Z","title":"A2V: A Semi-Supervised Domain Adaptation Framework for Brain Vessel\n  Segmentation via Two-Phase Training Angiography-to-Venography Translation","summary":"  We present a semi-supervised domain adaptation framework for brain vessel\nsegmentation from different image modalities. Existing state-of-the-art methods\nfocus on a single modality, despite the wide range of available cerebrovascular\nimaging techniques. This can lead to significant distribution shifts that\nnegatively impact the generalization across modalities. By relying on annotated\nangiographies and a limited number of annotated venographies, our framework\naccomplishes image-to-image translation and semantic segmentation, leveraging a\ndisentangled and semantically rich latent space to represent heterogeneous data\nand perform image-level adaptation from source to target domains. Moreover, we\nreduce the typical complexity of cycle-based architectures and minimize the use\nof adversarial training, which allows us to build an efficient and intuitive\nmodel with stable training. We evaluate our method on magnetic resonance\nangiographies and venographies. While achieving state-of-the-art performance in\nthe source domain, our method attains a Dice score coefficient in the target\ndomain that is only 8.9% lower, highlighting its promising potential for robust\ncerebrovascular image segmentation across different modalities.\n","authors":["Francesco Galati","Daniele Falcetta","Rosa Cortese","Barbara Casolla","Ferran Prados","Ninon Burgos","Maria A. Zuluaga"],"pdf_url":"https://arxiv.org/pdf/2309.06075v2.pdf","comment":"Accepted at the 34th British Machine Vision Conference (BMVC)"},{"id":"http://arxiv.org/abs/2403.18407v1","updated":"2024-03-27T09:49:37Z","published":"2024-03-27T09:49:37Z","title":"A Channel-ensemble Approach: Unbiased and Low-variance Pseudo-labels is\n  Critical for Semi-supervised Classification","summary":"  Semi-supervised learning (SSL) is a practical challenge in computer vision.\nPseudo-label (PL) methods, e.g., FixMatch and FreeMatch, obtain the State Of\nThe Art (SOTA) performances in SSL. These approaches employ a\nthreshold-to-pseudo-label (T2L) process to generate PLs by truncating the\nconfidence scores of unlabeled data predicted by the self-training method.\nHowever, self-trained models typically yield biased and high-variance\npredictions, especially in the scenarios when a little labeled data are\nsupplied. To address this issue, we propose a lightweight channel-based\nensemble method to effectively consolidate multiple inferior PLs into the\ntheoretically guaranteed unbiased and low-variance one. Importantly, our\napproach can be readily extended to any SSL framework, such as FixMatch or\nFreeMatch. Experimental results demonstrate that our method significantly\noutperforms state-of-the-art techniques on CIFAR10/100 in terms of\neffectiveness and efficiency.\n","authors":["Jiaqi Wu","Junbiao Pang","Baochang Zhang","Qingming Huang"],"pdf_url":"https://arxiv.org/pdf/2403.18407v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.18406v1","updated":"2024-03-27T09:48:23Z","published":"2024-03-27T09:48:23Z","title":"An Image Grid Can Be Worth a Video: Zero-shot Video Question Answering\n  Using a VLM","summary":"  Stimulated by the sophisticated reasoning capabilities of recent Large\nLanguage Models (LLMs), a variety of strategies for bridging video modality\nhave been devised. A prominent strategy involves Video Language Models\n(VideoLMs), which train a learnable interface with video data to connect\nadvanced vision encoders with LLMs. Recently, an alternative strategy has\nsurfaced, employing readily available foundation models, such as VideoLMs and\nLLMs, across multiple stages for modality bridging. In this study, we introduce\na simple yet novel strategy where only a single Vision Language Model (VLM) is\nutilized. Our starting point is the plain insight that a video comprises a\nseries of images, or frames, interwoven with temporal information. The essence\nof video comprehension lies in adeptly managing the temporal aspects along with\nthe spatial details of each frame. Initially, we transform a video into a\nsingle composite image by arranging multiple frames in a grid layout. The\nresulting single image is termed as an image grid. This format, while\nmaintaining the appearance of a solitary image, effectively retains temporal\ninformation within the grid structure. Therefore, the image grid approach\nenables direct application of a single high-performance VLM without\nnecessitating any video-data training. Our extensive experimental analysis\nacross ten zero-shot video question answering benchmarks, including five\nopen-ended and five multiple-choice benchmarks, reveals that the proposed Image\nGrid Vision Language Model (IG-VLM) surpasses the existing methods in nine out\nof ten benchmarks.\n","authors":["Wonkyun Kim","Changin Choi","Wonseok Lee","Wonjong Rhee"],"pdf_url":"https://arxiv.org/pdf/2403.18406v1.pdf","comment":"Our code is available at https://github.com/imagegridworth/IG-VLM"},{"id":"http://arxiv.org/abs/2403.05262v2","updated":"2024-03-27T09:43:41Z","published":"2024-03-08T12:35:07Z","title":"Debiasing Multimodal Large Language Models","summary":"  In the realms of computer vision and natural language processing, Large\nVision-Language Models (LVLMs) have become indispensable tools, proficient in\ngenerating textual descriptions based on visual inputs. Despite their\nadvancements, our investigation reveals a noteworthy bias in the generated\ncontent, where the output is primarily influenced by the underlying Large\nLanguage Models (LLMs) prior rather than the input image. Our empirical\nexperiments underscore the persistence of this bias, as LVLMs often provide\nconfident answers even in the absence of relevant images or given incongruent\nvisual input. To rectify these biases and redirect the model's focus toward\nvision information, we introduce two simple, training-free strategies. Firstly,\nfor tasks such as classification or multi-choice question-answering (QA), we\npropose a ``calibration'' step through affine transformation to adjust the\noutput distribution. This ``Post-Hoc debias'' approach ensures uniform scores\nfor each answer when the image is absent, serving as an effective\nregularization technique to alleviate the influence of LLM priors. For more\nintricate open-ended generation tasks, we extend this method to ``Debias\nsampling'', drawing inspirations from contrastive decoding methods.\nFurthermore, our investigation sheds light on the instability of LVLMs across\nvarious decoding configurations. Through systematic exploration of different\nsettings, we significantly enhance performance, surpassing reported results and\nraising concerns about the fairness of existing evaluations. Comprehensive\nexperiments substantiate the effectiveness of our proposed strategies in\nmitigating biases. These strategies not only prove beneficial in minimizing\nhallucinations but also contribute to the generation of more helpful and\nprecise illustrations.\n","authors":["Yi-Fan Zhang","Weichen Yu","Qingsong Wen","Xue Wang","Zhang Zhang","Liang Wang","Rong Jin","Tieniu Tan"],"pdf_url":"https://arxiv.org/pdf/2403.05262v2.pdf","comment":"38 pages, 17 figures"},{"id":"http://arxiv.org/abs/2401.01647v2","updated":"2024-03-27T09:39:41Z","published":"2024-01-03T09:46:43Z","title":"SIGNeRF: Scene Integrated Generation for Neural Radiance Fields","summary":"  Advances in image diffusion models have recently led to notable improvements\nin the generation of high-quality images. In combination with Neural Radiance\nFields (NeRFs), they enabled new opportunities in 3D generation. However, most\ngenerative 3D approaches are object-centric and applying them to editing\nexisting photorealistic scenes is not trivial. We propose SIGNeRF, a novel\napproach for fast and controllable NeRF scene editing and scene-integrated\nobject generation. A new generative update strategy ensures 3D consistency\nacross the edited images, without requiring iterative optimization. We find\nthat depth-conditioned diffusion models inherently possess the capability to\ngenerate 3D consistent views by requesting a grid of images instead of single\nviews. Based on these insights, we introduce a multi-view reference sheet of\nmodified images. Our method updates an image collection consistently based on\nthe reference sheet and refines the original NeRF with the newly generated\nimage set in one go. By exploiting the depth conditioning mechanism of the\nimage diffusion model, we gain fine control over the spatial location of the\nedit and enforce shape guidance by a selected region or an external mesh.\n","authors":["Jan-Niklas Dihlmann","Andreas Engelhardt","Hendrik Lensch"],"pdf_url":"https://arxiv.org/pdf/2401.01647v2.pdf","comment":"Project Page: https://signerf.jdihlmann.com"},{"id":"http://arxiv.org/abs/2403.18397v1","updated":"2024-03-27T09:35:56Z","published":"2024-03-27T09:35:56Z","title":"Colour and Brush Stroke Pattern Recognition in Abstract Art using\n  Modified Deep Convolutional Generative Adversarial Networks","summary":"  Abstract Art is an immensely popular, discussed form of art that often has\nthe ability to depict the emotions of an artist. Many researchers have made\nattempts to study abstract art in the form of edge detection, brush stroke and\nemotion recognition algorithms using machine and deep learning. This papers\ndescribes the study of a wide distribution of abstract paintings using\nGenerative Adversarial Neural Networks(GAN). GANs have the ability to learn and\nreproduce a distribution enabling researchers and scientists to effectively\nexplore and study the generated image space. However, the challenge lies in\ndeveloping an efficient GAN architecture that overcomes common training\npitfalls. This paper addresses this challenge by introducing a modified-DCGAN\n(mDCGAN) specifically designed for high-quality artwork generation. The\napproach involves a thorough exploration of the modifications made, delving\ninto the intricate workings of DCGANs, optimisation techniques, and\nregularisation methods aimed at improving stability and realism in art\ngeneration enabling effective study of generated patterns. The proposed mDCGAN\nincorporates meticulous adjustments in layer configurations and architectural\nchoices, offering tailored solutions to the unique demands of art generation\nwhile effectively combating issues like mode collapse and gradient vanishing.\nFurther this paper explores the generated latent space by performing random\nwalks to understand vector relationships between brush strokes and colours in\nthe abstract art space and a statistical analysis of unstable outputs after a\ncertain period of GAN training and compare its significant difference. These\nfindings validate the effectiveness of the proposed approach, emphasising its\npotential to revolutionise the field of digital art generation and digital art\necosystem.\n","authors":["Srinitish Srinivasan","Varenya Pathak"],"pdf_url":"https://arxiv.org/pdf/2403.18397v1.pdf","comment":"28 pages, 5 tables, 7 figures"},{"id":"http://arxiv.org/abs/2403.11656v2","updated":"2024-03-27T09:34:44Z","published":"2024-03-18T10:53:00Z","title":"LocalStyleFool: Regional Video Style Transfer Attack Using Segment\n  Anything Model","summary":"  Previous work has shown that well-crafted adversarial perturbations can\nthreaten the security of video recognition systems. Attackers can invade such\nmodels with a low query budget when the perturbations are semantic-invariant,\nsuch as StyleFool. Despite the query efficiency, the naturalness of the minutia\nareas still requires amelioration, since StyleFool leverages style transfer to\nall pixels in each frame. To close the gap, we propose LocalStyleFool, an\nimproved black-box video adversarial attack that superimposes regional\nstyle-transfer-based perturbations on videos. Benefiting from the popularity\nand scalably usability of Segment Anything Model (SAM), we first extract\ndifferent regions according to semantic information and then track them through\nthe video stream to maintain the temporal consistency. Then, we add\nstyle-transfer-based perturbations to several regions selected based on the\nassociative criterion of transfer-based gradient information and regional area.\nPerturbation fine adjustment is followed to make stylized videos adversarial.\nWe demonstrate that LocalStyleFool can improve both intra-frame and inter-frame\nnaturalness through a human-assessed survey, while maintaining competitive\nfooling rate and query efficiency. Successful experiments on the\nhigh-resolution dataset also showcase that scrupulous segmentation of SAM helps\nto improve the scalability of adversarial attacks under high-resolution data.\n","authors":["Yuxin Cao","Jinghao Li","Xi Xiao","Derui Wang","Minhui Xue","Hao Ge","Wei Liu","Guangwu Hu"],"pdf_url":"https://arxiv.org/pdf/2403.11656v2.pdf","comment":"Accepted to 2024 IEEE Security and Privacy Workshops (SPW)"},{"id":"http://arxiv.org/abs/2403.18388v1","updated":"2024-03-27T09:25:20Z","published":"2024-03-27T09:25:20Z","title":"FTBC: Forward Temporal Bias Correction for Optimizing ANN-SNN Conversion","summary":"  Spiking Neural Networks (SNNs) offer a promising avenue for energy-efficient\ncomputing compared with Artificial Neural Networks (ANNs), closely mirroring\nbiological neural processes. However, this potential comes with inherent\nchallenges in directly training SNNs through spatio-temporal backpropagation --\nstemming from the temporal dynamics of spiking neurons and their discrete\nsignal processing -- which necessitates alternative ways of training, most\nnotably through ANN-SNN conversion. In this work, we introduce a lightweight\nForward Temporal Bias Correction (FTBC) technique, aimed at enhancing\nconversion accuracy without the computational overhead. We ground our method on\nprovided theoretical findings that through proper temporal bias calibration the\nexpected error of ANN-SNN conversion can be reduced to be zero after each time\nstep. We further propose a heuristic algorithm for finding the temporal bias\nonly in the forward pass, thus eliminating the computational burden of\nbackpropagation and we evaluate our method on CIFAR-10/100 and ImageNet\ndatasets, achieving a notable increase in accuracy on all datasets. Codes are\nreleased at a GitHub repository.\n","authors":["Xiaofeng Wu","Velibor Bojkovic","Bin Gu","Kun Suo","Kai Zou"],"pdf_url":"https://arxiv.org/pdf/2403.18388v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2312.06733v3","updated":"2024-03-27T09:24:56Z","published":"2023-12-11T10:43:28Z","title":"TULIP: Transformer for Upsampling of LiDAR Point Cloud","summary":"  LiDAR Upsampling is a challenging task for the perception systems of robots\nand autonomous vehicles, due to the sparse and irregular structure of\nlarge-scale scene contexts. Recent works propose to solve this problem by\nconverting LiDAR data from 3D Euclidean space into an image super-resolution\nproblem in 2D image space. Although their methods can generate high-resolution\nrange images with fine-grained details, the resulting 3D point clouds often\nblur out details and predict invalid points. In this paper, we propose TULIP, a\nnew method to reconstruct high-resolution LiDAR point clouds from\nlow-resolution LiDAR input. We also follow a range image-based approach but\nspecifically modify the patch and window geometries of a Swin-Transformer-based\nnetwork to better fit the characteristics of range images. We conducted several\nexperiments on three public real-world and simulated datasets. TULIP\noutperforms state-of-the-art methods in all relevant metrics and generates\nrobust and more realistic point clouds than prior works.\n","authors":["Bin Yang","Patrick Pfreundschuh","Roland Siegwart","Marco Hutter","Peyman Moghadam","Vaishakh Patil"],"pdf_url":"https://arxiv.org/pdf/2312.06733v3.pdf","comment":"The paper was accepted by CVPR20224"},{"id":"http://arxiv.org/abs/2403.05218v2","updated":"2024-03-27T09:21:42Z","published":"2024-03-08T11:09:46Z","title":"3D Face Reconstruction Using A Spectral-Based Graph Convolution Encoder","summary":"  Monocular 3D face reconstruction plays a crucial role in avatar generation,\nwith significant demand in web-related applications such as generating virtual\nfinancial advisors in FinTech. Current reconstruction methods predominantly\nrely on deep learning techniques and employ 2D self-supervision as a means to\nguide model learning. However, these methods encounter challenges in capturing\nthe comprehensive 3D structural information of the face due to the utilization\nof 2D images for model training purposes. To overcome this limitation and\nenhance the reconstruction of 3D structural features, we propose an innovative\napproach that integrates existing 2D features with 3D features to guide the\nmodel learning process. Specifically, we introduce the 3D-ID Loss, which\nleverages the high-dimensional structure features extracted from a\nSpectral-Based Graph Convolution Encoder applied to the facial mesh. This\napproach surpasses the sole reliance on the 3D information provided by the\nfacial mesh vertices coordinates. Our model is trained using 2D-3D data pairs\nfrom a combination of datasets and achieves state-of-the-art performance on the\nNoW benchmark.\n","authors":["Haoxin Xu","Zezheng Zhao","Yuxin Cao","Chunyu Chen","Hao Ge","Ziyao Liu"],"pdf_url":"https://arxiv.org/pdf/2403.05218v2.pdf","comment":"4 pages, 3 figures. Accepted to WWW 2024"},{"id":"http://arxiv.org/abs/2403.18383v1","updated":"2024-03-27T09:21:07Z","published":"2024-03-27T09:21:07Z","title":"Generative Multi-modal Models are Good Class-Incremental Learners","summary":"  In class-incremental learning (CIL) scenarios, the phenomenon of catastrophic\nforgetting caused by the classifier's bias towards the current task has long\nposed a significant challenge. It is mainly caused by the characteristic of\ndiscriminative models. With the growing popularity of the generative\nmulti-modal models, we would explore replacing discriminative models with\ngenerative ones for CIL. However, transitioning from discriminative to\ngenerative models requires addressing two key challenges. The primary challenge\nlies in transferring the generated textual information into the classification\nof distinct categories. Additionally, it requires formulating the task of CIL\nwithin a generative framework. To this end, we propose a novel generative\nmulti-modal model (GMM) framework for class-incremental learning. Our approach\ndirectly generates labels for images using an adapted generative model. After\nobtaining the detailed text, we use a text encoder to extract text features and\nemploy feature matching to determine the most similar label as the\nclassification prediction. In the conventional CIL settings, we achieve\nsignificantly better results in long-sequence task scenarios. Under the\nFew-shot CIL setting, we have improved by at least 14\\% accuracy over all the\ncurrent state-of-the-art methods with significantly less forgetting. Our code\nis available at \\url{https://github.com/DoubleClass/GMM}.\n","authors":["Xusheng Cao","Haori Lu","Linlan Huang","Xialei Liu","Ming-Ming Cheng"],"pdf_url":"https://arxiv.org/pdf/2403.18383v1.pdf","comment":"Accepted at CVPR 2024"},{"id":"http://arxiv.org/abs/2401.17879v2","updated":"2024-03-27T09:17:14Z","published":"2024-01-31T14:36:49Z","title":"AEROBLADE: Training-Free Detection of Latent Diffusion Images Using\n  Autoencoder Reconstruction Error","summary":"  With recent text-to-image models, anyone can generate deceptively realistic\nimages with arbitrary contents, fueling the growing threat of visual\ndisinformation. A key enabler for generating high-resolution images with low\ncomputational cost has been the development of latent diffusion models (LDMs).\nIn contrast to conventional diffusion models, LDMs perform the denoising\nprocess in the low-dimensional latent space of a pre-trained autoencoder (AE)\ninstead of the high-dimensional image space. Despite their relevance, the\nforensic analysis of LDMs is still in its infancy. In this work we propose\nAEROBLADE, a novel detection method which exploits an inherent component of\nLDMs: the AE used to transform images between image and latent space. We find\nthat generated images can be more accurately reconstructed by the AE than real\nimages, allowing for a simple detection approach based on the reconstruction\nerror. Most importantly, our method is easy to implement and does not require\nany training, yet nearly matches the performance of detectors that rely on\nextensive training. We empirically demonstrate that AEROBLADE is effective\nagainst state-of-the-art LDMs, including Stable Diffusion and Midjourney.\nBeyond detection, our approach allows for the qualitative analysis of images,\nwhich can be leveraged for identifying inpainted regions. We release our code\nand data at https://github.com/jonasricker/aeroblade .\n","authors":["Jonas Ricker","Denis Lukovnikov","Asja Fischer"],"pdf_url":"https://arxiv.org/pdf/2401.17879v2.pdf","comment":"Accepted to CVPR 2024"},{"id":"http://arxiv.org/abs/2403.00174v2","updated":"2024-03-27T09:13:19Z","published":"2024-02-29T22:58:13Z","title":"A citizen science toolkit to collect human perceptions of urban\n  environments using open street view images","summary":"  Street View-level Imagery (SVI) is a valuable data source for studies (e.g.,\nenvironmental assessments, green space identification or land cover\nclassification). While commercial SVI is available, such providers commonly\nrestrict copying or reuse in ways necessary for research. Open SVI datasets are\nreadily available from less restrictive sources, such as Mapillary, but due to\nthe heterogeneity of the images, these require substantial preprocessing,\nfiltering, and careful quality checks. We present an efficient method for\nautomated downloading, processing, cropping, and filtering open SVI, to be used\nin a survey of human perceptions of the streets portrayed in these images. We\ndemonstrate our open-source reusable SVI preparation and smartphone-friendly\nperception-survey software with Amsterdam (Netherlands) as the case study.\nUsing a citizen science approach, we collected from 331 people 22,637 ratings\nabout their perceptions for various criteria. We have published our software in\na public repository for future re-use and reproducibility.\n","authors":["Matthew Danish","SM Labib","Britta Ricker","Marco Helbich"],"pdf_url":"https://arxiv.org/pdf/2403.00174v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.18373v1","updated":"2024-03-27T09:10:01Z","published":"2024-03-27T09:10:01Z","title":"BAM: Box Abstraction Monitors for Real-time OoD Detection in Object\n  Detection","summary":"  Out-of-distribution (OoD) detection techniques for deep neural networks\n(DNNs) become crucial thanks to their filtering of abnormal inputs, especially\nwhen DNNs are used in safety-critical applications and interact with an open\nand dynamic environment. Nevertheless, integrating OoD detection into\nstate-of-the-art (SOTA) object detection DNNs poses significant challenges,\npartly due to the complexity introduced by the SOTA OoD construction methods,\nwhich require the modification of DNN architecture and the introduction of\ncomplex loss functions. This paper proposes a simple, yet surprisingly\neffective, method that requires neither retraining nor architectural change in\nobject detection DNN, called Box Abstraction-based Monitors (BAM). The novelty\nof BAM stems from using a finite union of convex box abstractions to capture\nthe learned features of objects for in-distribution (ID) data, and an important\nobservation that features from OoD data are more likely to fall outside of\nthese boxes. The union of convex regions within the feature space allows the\nformation of non-convex and interpretable decision boundaries, overcoming the\nlimitations of VOS-like detectors without sacrificing real-time performance.\nExperiments integrating BAM into Faster R-CNN-based object detection DNNs\ndemonstrate a considerably improved performance against SOTA OoD detection\ntechniques.\n","authors":["Changshun Wu","Weicheng He","Chih-Hong Cheng","Xiaowei Huang","Saddek Bensalem"],"pdf_url":"https://arxiv.org/pdf/2403.18373v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.17905v2","updated":"2024-03-27T09:07:02Z","published":"2024-03-26T17:45:06Z","title":"Scalable Non-Cartesian Magnetic Resonance Imaging with R2D2","summary":"  We propose a new approach for non-Cartesian magnetic resonance image\nreconstruction. While unrolled architectures provide robustness via\ndata-consistency layers, embedding measurement operators in Deep Neural Network\n(DNN) can become impractical at large scale. Alternative Plug-and-Play (PnP)\napproaches, where the denoising DNNs are blind to the measurement setting, are\nnot affected by this limitation and have also proven effective, but their\nhighly iterative nature also affects scalability. To address this scalability\nchallenge, we leverage the \"Residual-to-Residual DNN series for high-Dynamic\nrange imaging (R2D2)\" approach recently introduced in astronomical imaging.\nR2D2's reconstruction is formed as a series of residual images, iteratively\nestimated as outputs of DNNs taking the previous iteration's image estimate and\nassociated data residual as inputs. The method can be interpreted as a learned\nversion of the Matching Pursuit algorithm. We demonstrate R2D2 in simulation,\nconsidering radial k-space sampling acquisition sequences. Our preliminary\nresults suggest that R2D2 achieves: (i) suboptimal performance compared to its\nunrolled incarnation R2D2-Net, which is however non-scalable due to the\nnecessary embedding of NUFFT-based data-consistency layers; (ii) superior\nreconstruction quality to a scalable version of R2D2-Net embedding an FFT-based\napproximation for data consistency; (iii) superior reconstruction quality to\nPnP, while only requiring few iterations.\n","authors":["Yiwei Chen","Chao Tang","Amir Aghabiglou","Chung San Chu","Yves Wiaux"],"pdf_url":"https://arxiv.org/pdf/2403.17905v2.pdf","comment":"submitted to IEEE EUSIPCO 2024"},{"id":"http://arxiv.org/abs/2403.18370v1","updated":"2024-03-27T09:06:36Z","published":"2024-03-27T09:06:36Z","title":"Ship in Sight: Diffusion Models for Ship-Image Super Resolution","summary":"  In recent years, remarkable advancements have been achieved in the field of\nimage generation, primarily driven by the escalating demand for high-quality\noutcomes across various image generation subtasks, such as inpainting,\ndenoising, and super resolution. A major effort is devoted to exploring the\napplication of super-resolution techniques to enhance the quality of\nlow-resolution images. In this context, our method explores in depth the\nproblem of ship image super resolution, which is crucial for coastal and port\nsurveillance. We investigate the opportunity given by the growing interest in\ntext-to-image diffusion models, taking advantage of the prior knowledge that\nsuch foundation models have already learned. In particular, we present a\ndiffusion-model-based architecture that leverages text conditioning during\ntraining while being class-aware, to best preserve the crucial details of the\nships during the generation of the super-resoluted image. Since the specificity\nof this task and the scarcity availability of off-the-shelf data, we also\nintroduce a large labeled ship dataset scraped from online ship images, mostly\nfrom ShipSpotting\\footnote{\\url{www.shipspotting.com}} website. Our method\nachieves more robust results than other deep learning models previously\nemployed for super resolution, as proven by the multiple experiments performed.\nMoreover, we investigate how this model can benefit downstream tasks, such as\nclassification and object detection, thus emphasizing practical implementation\nin a real-world scenario. Experimental results show flexibility, reliability,\nand impressive performance of the proposed framework over state-of-the-art\nmethods for different tasks. The code is available at:\nhttps://github.com/LuigiSigillo/ShipinSight .\n","authors":["Luigi Sigillo","Riccardo Fosco Gramaccioni","Alessandro Nicolosi","Danilo Comminiello"],"pdf_url":"https://arxiv.org/pdf/2403.18370v1.pdf","comment":"Accepted at 2024 International Joint Conference on Neural Networks\n  (IJCNN)"},{"id":"http://arxiv.org/abs/2312.10114v2","updated":"2024-03-27T09:00:54Z","published":"2023-12-15T09:49:21Z","title":"FoMo-Bench: a multi-modal, multi-scale and multi-task Forest Monitoring\n  Benchmark for remote sensing foundation models","summary":"  Forests are an essential part of Earth's ecosystems and natural systems, as\nwell as providing services on which humanity depends, yet they are rapidly\nchanging as a result of land use decisions and climate change. Understanding\nand mitigating negative effects requires parsing data on forests at global\nscale from a broad array of sensory modalities, and recently many such problems\nhave been approached using machine learning algorithms for remote sensing. To\ndate, forest-monitoring problems have largely been addressed in isolation.\nInspired by the rise of foundation models for computer vision and remote\nsensing, we here present the first unified Forest Monitoring Benchmark\n(FoMo-Bench). FoMo-Bench consists of 15 diverse datasets encompassing\nsatellite, aerial, and inventory data, covering a variety of geographical\nregions, and including multispectral, red-green-blue, synthetic aperture radar\n(SAR) and LiDAR data with various temporal, spatial and spectral resolutions.\nFoMo-Bench includes multiple types of forest-monitoring tasks, spanning\nclassification, segmentation, and object detection. To further enhance the\ndiversity of tasks and geographies represented in FoMo-Bench, we introduce a\nnovel global dataset, TalloS, combining satellite imagery with ground-based\nannotations for tree species classification, encompassing 1,000+ categories\nacross multiple hierarchical taxonomic levels (species, genus, family).\nFinally, we propose FoMo-Net, a baseline foundation model with the capacity to\nprocess any combination of commonly used spectral bands in remote sensing,\nacross diverse ground sampling distances and geographical locations worldwide.\nThis work aims to inspire research collaborations between machine learning and\nforest biology researchers in exploring scalable multi-modal and multi-task\nmodels for forest monitoring. All code and data will be made publicly\navailable.\n","authors":["Nikolaos Ioannis Bountos","Arthur Ouaknine","David Rolnick"],"pdf_url":"https://arxiv.org/pdf/2312.10114v2.pdf","comment":"26 pages"},{"id":"http://arxiv.org/abs/2402.19473v2","updated":"2024-03-27T09:00:25Z","published":"2024-02-29T18:59:01Z","title":"Retrieval-Augmented Generation for AI-Generated Content: A Survey","summary":"  The development of Artificial Intelligence Generated Content (AIGC) has been\nfacilitated by advancements in model algorithms, the increasing scale of\nfoundation models, and the availability of ample high-quality datasets. While\nAIGC has achieved remarkable performance, it still faces several challenges,\nsuch as the difficulty of maintaining up-to-date and long-tail knowledge, the\nrisk of data leakage, and the high costs associated with training and\ninference. Retrieval-Augmented Generation(RAG) has recently emerged as a\nparadigm to address such challenges. In particular, RAG introduces the\ninformation retrieval process, which enhances the generation process by\nretrieving relevant objects from available data stores, leading to higher\naccuracy and better robustness. In this paper, we comprehensively review\nexisting efforts that integrate RAG technique into AIGC scenarios. We first\nclassify RAG foundations according to how the retriever augments the generator,\ndistilling the fundamental abstractions of the augmentation methodologies for\nvarious retrievers and generators. This unified perspective encompasses all RAG\nscenarios, illuminating advancements and pivotal technologies that help with\npotential future progress. We also summarize additional enhancements methods\nfor RAG, facilitating effective engineering and implementation of RAG systems.\nThen from another view, we survey on practical applications of RAG across\ndifferent modalities and tasks, offering valuable references for researchers\nand practitioners. Furthermore, we introduce the benchmarks for RAG, discuss\nthe limitations of current RAG systems, and suggest potential directions for\nfuture research.Project Repo: https://github.com/hymie122/RAG-Survey.\n","authors":["Penghao Zhao","Hailin Zhang","Qinhan Yu","Zhengren Wang","Yunteng Geng","Fangcheng Fu","Ling Yang","Wentao Zhang","Bin Cui"],"pdf_url":"https://arxiv.org/pdf/2402.19473v2.pdf","comment":"Citing 380 papers, 36 pages, 16 figures. Project:\n  https://github.com/hymie122/RAG-Survey"},{"id":"http://arxiv.org/abs/2310.03325v2","updated":"2024-03-27T08:54:35Z","published":"2023-10-05T05:41:21Z","title":"Learning Concept-Based Causal Transition and Symbolic Reasoning for\n  Visual Planning","summary":"  Visual planning simulates how humans make decisions to achieve desired goals\nin the form of searching for visual causal transitions between an initial\nvisual state and a final visual goal state. It has become increasingly\nimportant in egocentric vision with its advantages in guiding agents to perform\ndaily tasks in complex environments. In this paper, we propose an interpretable\nand generalizable visual planning framework consisting of i) a novel\nSubstitution-based Concept Learner (SCL) that abstracts visual inputs into\ndisentangled concept representations, ii) symbol abstraction and reasoning that\nperforms task planning via the self-learned symbols, and iii) a Visual Causal\nTransition model (ViCT) that grounds visual causal transitions to semantically\nsimilar real-world actions. Given an initial state, we perform goal-conditioned\nvisual planning with a symbolic reasoning method fueled by the learned\nrepresentations and causal transitions to reach the goal state. To verify the\neffectiveness of the proposed model, we collect a large-scale visual planning\ndataset based on AI2-THOR, dubbed as CCTP. Extensive experiments on this\nchallenging dataset demonstrate the superior performance of our method in\nvisual task planning. Empirically, we show that our framework can generalize to\nunseen task trajectories, unseen object categories, and real-world data.\nFurther details of this work are provided at\nhttps://fqyqc.github.io/ConTranPlan/.\n","authors":["Yilue Qian","Peiyu Yu","Ying Nian Wu","Yao Su","Wei Wang","Lifeng Fan"],"pdf_url":"https://arxiv.org/pdf/2310.03325v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.15837v2","updated":"2024-03-27T08:54:06Z","published":"2024-03-23T13:24:31Z","title":"Centered Masking for Language-Image Pre-Training","summary":"  We introduce Gaussian masking for Language-Image Pre-Training (GLIP) a novel,\nstraightforward, and effective technique for masking image patches during\npre-training of a vision-language model. GLIP builds on Fast Language-Image\nPre-Training (FLIP), which randomly masks image patches while training a CLIP\nmodel. GLIP replaces random masking with centered masking, that uses a Gaussian\ndistribution and is inspired by the importance of image patches at the center\nof the image. GLIP retains the same computational savings as FLIP, while\nimproving performance across a range of downstream datasets and tasks, as\ndemonstrated by our experimental results. We show the benefits of GLIP to be\neasy to obtain, requiring no delicate tuning of the Gaussian, and also\napplicable to data sets containing images without an obvious center focus.\n","authors":["Mingliang Liang","Martha Larson"],"pdf_url":"https://arxiv.org/pdf/2403.15837v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.18361v1","updated":"2024-03-27T08:53:13Z","published":"2024-03-27T08:53:13Z","title":"ViTAR: Vision Transformer with Any Resolution","summary":"  his paper tackles a significant challenge faced by Vision Transformers\n(ViTs): their constrained scalability across different image resolutions.\nTypically, ViTs experience a performance decline when processing resolutions\ndifferent from those seen during training. Our work introduces two key\ninnovations to address this issue. Firstly, we propose a novel module for\ndynamic resolution adjustment, designed with a single Transformer block,\nspecifically to achieve highly efficient incremental token integration.\nSecondly, we introduce fuzzy positional encoding in the Vision Transformer to\nprovide consistent positional awareness across multiple resolutions, thereby\npreventing overfitting to any single training resolution. Our resulting model,\nViTAR (Vision Transformer with Any Resolution), demonstrates impressive\nadaptability, achieving 83.3\\% top-1 accuracy at a 1120x1120 resolution and\n80.4\\% accuracy at a 4032x4032 resolution, all while reducing computational\ncosts. ViTAR also shows strong performance in downstream tasks such as instance\nand semantic segmentation and can easily combined with self-supervised learning\ntechniques like Masked AutoEncoder. Our work provides a cost-effective solution\nfor enhancing the resolution scalability of ViTs, paving the way for more\nversatile and efficient high-resolution image processing.\n","authors":["Qihang Fan","Quanzeng You","Xiaotian Han","Yongfei Liu","Yunzhe Tao","Huaibo Huang","Ran He","Hongxia Yang"],"pdf_url":"https://arxiv.org/pdf/2403.18361v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.18360v1","updated":"2024-03-27T08:52:44Z","published":"2024-03-27T08:52:44Z","title":"Learning CNN on ViT: A Hybrid Model to Explicitly Class-specific\n  Boundaries for Domain Adaptation","summary":"  Most domain adaptation (DA) methods are based on either a convolutional\nneural networks (CNNs) or a vision transformers (ViTs). They align the\ndistribution differences between domains as encoders without considering their\nunique characteristics. For instance, ViT excels in accuracy due to its\nsuperior ability to capture global representations, while CNN has an advantage\nin capturing local representations. This fact has led us to design a hybrid\nmethod to fully take advantage of both ViT and CNN, called Explicitly\nClass-specific Boundaries (ECB). ECB learns CNN on ViT to combine their\ndistinct strengths. In particular, we leverage ViT's properties to explicitly\nfind class-specific decision boundaries by maximizing the discrepancy between\nthe outputs of the two classifiers to detect target samples far from the source\nsupport. In contrast, the CNN encoder clusters target features based on the\npreviously defined class-specific boundaries by minimizing the discrepancy\nbetween the probabilities of the two classifiers. Finally, ViT and CNN mutually\nexchange knowledge to improve the quality of pseudo labels and reduce the\nknowledge discrepancies of these models. Compared to conventional DA methods,\nour ECB achieves superior performance, which verifies its effectiveness in this\nhybrid model. The project website can be found\nhttps://dotrannhattuong.github.io/ECB/website/.\n","authors":["Ba Hung Ngo","Nhat-Tuong Do-Tran","Tuan-Ngoc Nguyen","Hae-Gon Jeon","Tae Jong Choi"],"pdf_url":"https://arxiv.org/pdf/2403.18360v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.18356v1","updated":"2024-03-27T08:48:47Z","published":"2024-03-27T08:48:47Z","title":"MonoHair: High-Fidelity Hair Modeling from a Monocular Video","summary":"  Undoubtedly, high-fidelity 3D hair is crucial for achieving realism, artistic\nexpression, and immersion in computer graphics. While existing 3D hair modeling\nmethods have achieved impressive performance, the challenge of achieving\nhigh-quality hair reconstruction persists: they either require strict capture\nconditions, making practical applications difficult, or heavily rely on learned\nprior data, obscuring fine-grained details in images. To address these\nchallenges, we propose MonoHair,a generic framework to achieve high-fidelity\nhair reconstruction from a monocular video, without specific requirements for\nenvironments. Our approach bifurcates the hair modeling process into two main\nstages: precise exterior reconstruction and interior structure inference. The\nexterior is meticulously crafted using our Patch-based Multi-View Optimization\n(PMVO). This method strategically collects and integrates hair information from\nmultiple views, independent of prior data, to produce a high-fidelity exterior\n3D line map. This map not only captures intricate details but also facilitates\nthe inference of the hair's inner structure. For the interior, we employ a\ndata-driven, multi-view 3D hair reconstruction method. This method utilizes 2D\nstructural renderings derived from the reconstructed exterior, mirroring the\nsynthetic 2D inputs used during training. This alignment effectively bridges\nthe domain gap between our training data and real-world data, thereby enhancing\nthe accuracy and reliability of our interior structure inference. Lastly, we\ngenerate a strand model and resolve the directional ambiguity by our hair\ngrowth algorithm. Our experiments demonstrate that our method exhibits\nrobustness across diverse hairstyles and achieves state-of-the-art performance.\nFor more results, please refer to our project page\nhttps://keyuwu-cs.github.io/MonoHair/.\n","authors":["Keyu Wu","Lingchen Yang","Zhiyi Kuang","Yao Feng","Xutao Han","Yuefan Shen","Hongbo Fu","Kun Zhou","Youyi Zheng"],"pdf_url":"https://arxiv.org/pdf/2403.18356v1.pdf","comment":"Accepted by IEEE CVPR 2024"},{"id":"http://arxiv.org/abs/2403.18351v1","updated":"2024-03-27T08:42:47Z","published":"2024-03-27T08:42:47Z","title":"Generating Diverse Agricultural Data for Vision-Based Farming\n  Applications","summary":"  We present a specialized procedural model for generating synthetic\nagricultural scenes, focusing on soybean crops, along with various weeds. This\nmodel is capable of simulating distinct growth stages of these plants, diverse\nsoil conditions, and randomized field arrangements under varying lighting\nconditions. The integration of real-world textures and environmental factors\ninto the procedural generation process enhances the photorealism and\napplicability of the synthetic data. Our dataset includes 12,000 images with\nsemantic labels, offering a comprehensive resource for computer vision tasks in\nprecision agriculture, such as semantic segmentation for autonomous weed\ncontrol. We validate our model's effectiveness by comparing the synthetic data\nagainst real agricultural images, demonstrating its potential to significantly\naugment training data for machine learning models in agriculture. This approach\nnot only provides a cost-effective solution for generating high-quality,\ndiverse data but also addresses specific needs in agricultural vision tasks\nthat are not fully covered by general-purpose models.\n","authors":["Mikolaj Cieslak","Umabharathi Govindarajan","Alejandro Garcia","Anuradha Chandrashekar","Torsten H√§drich","Aleksander Mendoza-Drosik","Dominik L. Michels","S√∂ren Pirk","Chia-Chun Fu","Wojciech Pa≈Çubicki"],"pdf_url":"https://arxiv.org/pdf/2403.18351v1.pdf","comment":"10 pages, 8 figures, 3 tables"},{"id":"http://arxiv.org/abs/2403.18347v1","updated":"2024-03-27T08:38:56Z","published":"2024-03-27T08:38:56Z","title":"A Quantum Fuzzy-based Approach for Real-Time Detection of Solar Coronal\n  Holes","summary":"  The detection and analysis of the solar coronal holes (CHs) is an important\nfield of study in the domain of solar physics. Mainly, it is required for the\nproper prediction of the geomagnetic storms which directly or indirectly affect\nvarious space and ground-based systems. For the detection of CHs till date, the\nsolar scientist depends on manual hand-drawn approaches. However, with the\nadvancement of image processing technologies, some automated image segmentation\nmethods have been used for the detection of CHs. In-spite of this, fast and\naccurate detection of CHs are till a major issues. Here in this work, a novel\nquantum computing-based fast fuzzy c-mean technique has been developed for fast\ndetection of the CHs region. The task has been carried out in two stages, in\nfirst stage the solar image has been segmented using a quantum computing based\nfast fuzzy c-mean (QCFFCM) and in the later stage the CHs has been extracted\nout from the segmented image based on image morphological operation. In the\nwork, quantum computing has been used to optimize the cost function of the fast\nfuzzy c-mean (FFCM) algorithm, where quantum approximate optimization algorithm\n(QAOA) has been used to optimize the quadratic part of the cost function. The\nproposed method has been tested for 193 \\AA{} SDO/AIA full-disk solar image\ndatasets and has been compared with the existing techniques. The outcome shows\nthe comparable performance of the proposed method with the existing one within\na very lesser time.\n","authors":["Sanmoy Bandyopadhyay","Suman Kundu"],"pdf_url":"https://arxiv.org/pdf/2403.18347v1.pdf","comment":"14 pages, 5 figures, 3 tables"},{"id":"http://arxiv.org/abs/2403.18346v1","updated":"2024-03-27T08:38:49Z","published":"2024-03-27T08:38:49Z","title":"Quantifying and Mitigating Unimodal Biases in Multimodal Large Language\n  Models: A Causal Perspective","summary":"  Recent advancements in Large Language Models (LLMs) have facilitated the\ndevelopment of Multimodal LLMs (MLLMs). Despite their impressive capabilities,\nMLLMs often suffer from an over-reliance on unimodal biases (e.g., language\nbias and vision bias), leading to incorrect answers in complex multimodal\ntasks. To investigate this issue, we propose a causal framework to interpret\nthe biases in Visual Question Answering (VQA) problems. Within our framework,\nwe devise a causal graph to elucidate the predictions of MLLMs on VQA problems,\nand assess the causal effect of biases through an in-depth causal analysis.\nMotivated by the causal graph, we introduce a novel MORE dataset, consisting of\n12,000 VQA instances. This dataset is designed to challenge MLLMs' abilities,\nnecessitating multi-hop reasoning and the surmounting of unimodal biases.\nFurthermore, we propose two strategies to mitigate unimodal biases and enhance\nMLLMs' reasoning capabilities, including a Decompose-Verify-Answer (DeVA)\nframework for limited-access MLLMs and the refinement of open-source MLLMs\nthrough fine-tuning. Extensive quantitative and qualitative experiments offer\nvaluable insights for future research.\n","authors":["Meiqi Chen","Yixin Cao","Yan Zhang","Chaochao Lu"],"pdf_url":"https://arxiv.org/pdf/2403.18346v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.18342v1","updated":"2024-03-27T08:32:48Z","published":"2024-03-27T08:32:48Z","title":"Learning Inclusion Matching for Animation Paint Bucket Colorization","summary":"  Colorizing line art is a pivotal task in the production of hand-drawn cel\nanimation. This typically involves digital painters using a paint bucket tool\nto manually color each segment enclosed by lines, based on RGB values\npredetermined by a color designer. This frame-by-frame process is both arduous\nand time-intensive. Current automated methods mainly focus on segment matching.\nThis technique migrates colors from a reference to the target frame by aligning\nfeatures within line-enclosed segments across frames. However, issues like\nocclusion and wrinkles in animations often disrupt these direct\ncorrespondences, leading to mismatches. In this work, we introduce a new\nlearning-based inclusion matching pipeline, which directs the network to\ncomprehend the inclusion relationships between segments rather than relying\nsolely on direct visual correspondences. Our method features a two-stage\npipeline that integrates a coarse color warping module with an inclusion\nmatching module, enabling more nuanced and accurate colorization. To facilitate\nthe training of our network, we also develope a unique dataset, referred to as\nPaintBucket-Character. This dataset includes rendered line arts alongside their\ncolorized counterparts, featuring various 3D characters. Extensive experiments\ndemonstrate the effectiveness and superiority of our method over existing\ntechniques.\n","authors":["Yuekun Dai","Shangchen Zhou","Qinyue Li","Chongyi Li","Chen Change Loy"],"pdf_url":"https://arxiv.org/pdf/2403.18342v1.pdf","comment":"accepted to CVPR 2024. Project Page:\n  https://ykdai.github.io/projects/InclusionMatching"},{"id":"http://arxiv.org/abs/2403.18339v1","updated":"2024-03-27T08:28:14Z","published":"2024-03-27T08:28:14Z","title":"H2ASeg: Hierarchical Adaptive Interaction and Weighting Network for\n  Tumor Segmentation in PET/CT Images","summary":"  Positron emission tomography (PET) combined with computed tomography (CT)\nimaging is routinely used in cancer diagnosis and prognosis by providing\ncomplementary information. Automatically segmenting tumors in PET/CT images can\nsignificantly improve examination efficiency. Traditional multi-modal\nsegmentation solutions mainly rely on concatenation operations for modality\nfusion, which fail to effectively model the non-linear dependencies between PET\nand CT modalities. Recent studies have investigated various approaches to\noptimize the fusion of modality-specific features for enhancing joint\nrepresentations. However, modality-specific encoders used in these methods\noperate independently, inadequately leveraging the synergistic relationships\ninherent in PET and CT modalities, for example, the complementarity between\nsemantics and structure. To address these issues, we propose a Hierarchical\nAdaptive Interaction and Weighting Network termed H2ASeg to explore the\nintrinsic cross-modal correlations and transfer potential complementary\ninformation. Specifically, we design a Modality-Cooperative Spatial Attention\n(MCSA) module that performs intra- and inter-modal interactions globally and\nlocally. Additionally, a Target-Aware Modality Weighting (TAMW) module is\ndeveloped to highlight tumor-related features within multi-modal features,\nthereby refining tumor segmentation. By embedding these modules across\ndifferent layers, H2ASeg can hierarchically model cross-modal correlations,\nenabling a nuanced understanding of both semantic and structural tumor\nfeatures. Extensive experiments demonstrate the superiority of H2ASeg,\noutperforming state-of-the-art methods on AutoPet-II and Hecktor2022\nbenchmarks. The code is released at https://github.com/G14nTDo4/H2ASeg.\n","authors":["Jinpeng Lu","Jingyun Chen","Linghan Cai","Songhan Jiang","Yongbing Zhang"],"pdf_url":"https://arxiv.org/pdf/2403.18339v1.pdf","comment":"10 pages,4 figures"},{"id":"http://arxiv.org/abs/2403.17301v2","updated":"2024-03-27T08:23:09Z","published":"2024-03-26T01:06:47Z","title":"Physical 3D Adversarial Attacks against Monocular Depth Estimation in\n  Autonomous Driving","summary":"  Deep learning-based monocular depth estimation (MDE), extensively applied in\nautonomous driving, is known to be vulnerable to adversarial attacks. Previous\nphysical attacks against MDE models rely on 2D adversarial patches, so they\nonly affect a small, localized region in the MDE map but fail under various\nviewpoints. To address these limitations, we propose 3D Depth Fool\n(3D$^2$Fool), the first 3D texture-based adversarial attack against MDE models.\n3D$^2$Fool is specifically optimized to generate 3D adversarial textures\nagnostic to model types of vehicles and to have improved robustness in bad\nweather conditions, such as rain and fog. Experimental results validate the\nsuperior performance of our 3D$^2$Fool across various scenarios, including\nvehicles, MDE models, weather conditions, and viewpoints. Real-world\nexperiments with printed 3D textures on physical vehicle models further\ndemonstrate that our 3D$^2$Fool can cause an MDE error of over 10 meters.\n","authors":["Junhao Zheng","Chenhao Lin","Jiahao Sun","Zhengyu Zhao","Qian Li","Chao Shen"],"pdf_url":"https://arxiv.org/pdf/2403.17301v2.pdf","comment":"Accepted by CVPR 2024"},{"id":"http://arxiv.org/abs/2306.02928v2","updated":"2024-03-27T08:21:17Z","published":"2023-06-05T14:45:38Z","title":"Weakly-Supervised Conditional Embedding for Referred Visual Search","summary":"  This paper introduces a new challenge for image similarity search in the\ncontext of fashion, addressing the inherent ambiguity in this domain stemming\nfrom complex images. We present Referred Visual Search (RVS), a task allowing\nusers to define more precisely the desired similarity, following recent\ninterest in the industry. We release a new large public dataset,\nLAION-RVS-Fashion, consisting of 272k fashion products with 842k images\nextracted from LAION, designed explicitly for this task. However, unlike\ntraditional visual search methods in the industry, we demonstrate that superior\nperformance can be achieved by bypassing explicit object detection and adopting\nweakly-supervised conditional contrastive learning on image tuples. Our method\nis lightweight and demonstrates robustness, reaching Recall at one superior to\nstrong detection-based baselines against 2M distractors. Code, data and models\nare available at https://www.github.com/Simon-Lepage/CondViT-LRVSF .\n","authors":["Simon Lepage","J√©r√©mie Mary","David Picard"],"pdf_url":"https://arxiv.org/pdf/2306.02928v2.pdf","comment":"28 pages, 13 figures, 5 tables"},{"id":"http://arxiv.org/abs/2403.18334v1","updated":"2024-03-27T08:16:33Z","published":"2024-03-27T08:16:33Z","title":"DODA: Diffusion for Object-detection Domain Adaptation in Agriculture","summary":"  The diverse and high-quality content generated by recent generative models\ndemonstrates the great potential of using synthetic data to train downstream\nmodels. However, in vision, especially in objection detection, related areas\nare not fully explored, the synthetic images are merely used to balance the\nlong tails of existing datasets, and the accuracy of the generated labels is\nlow, the full potential of generative models has not been exploited. In this\npaper, we propose DODA, a data synthesizer that can generate high-quality\nobject detection data for new domains in agriculture. Specifically, we improve\nthe controllability of layout-to-image through encoding layout as an image,\nthereby improving the quality of labels, and use a visual encoder to provide\nvisual clues for the diffusion model to decouple visual features from the\ndiffusion model, and empowering the model the ability to generate data in new\ndomains. On the Global Wheat Head Detection (GWHD) Dataset, which is the\nlargest dataset in agriculture and contains diverse domains, using the data\nsynthesized by DODA improves the performance of the object detector by\n12.74-17.76 AP$_{50}$ in the domain that was significantly shifted from the\ntraining data.\n","authors":["Shuai Xiang","Pieter M. Blok","James Burridge","Haozhou Wang","Wei Guo"],"pdf_url":"https://arxiv.org/pdf/2403.18334v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.18330v1","updated":"2024-03-27T08:11:25Z","published":"2024-03-27T08:11:25Z","title":"Tracking-Assisted Object Detection with Event Cameras","summary":"  Event-based object detection has recently garnered attention in the computer\nvision community due to the exceptional properties of event cameras, such as\nhigh dynamic range and no motion blur. However, feature asynchronism and\nsparsity cause invisible objects due to no relative motion to the camera,\nposing a significant challenge in the task. Prior works have studied various\nmemory mechanisms to preserve as many features as possible at the current time,\nguided by temporal clues. While these implicit-learned memories retain some\nshort-term information, they still struggle to preserve long-term features\neffectively. In this paper, we consider those invisible objects as\npseudo-occluded objects and aim to reveal their features. Firstly, we introduce\nvisibility attribute of objects and contribute an auto-labeling algorithm to\nappend additional visibility labels on an existing event camera dataset.\nSecondly, we exploit tracking strategies for pseudo-occluded objects to\nmaintain their permanence and retain their bounding boxes, even when features\nhave not been available for a very long time. These strategies can be treated\nas an explicit-learned memory guided by the tracking objective to record the\ndisplacements of objects across frames. Lastly, we propose a spatio-temporal\nfeature aggregation module to enrich the latent features and a consistency loss\nto increase the robustness of the overall pipeline. We conduct comprehensive\nexperiments to verify our method's effectiveness where still objects are\nretained but real occluded objects are discarded. The results demonstrate that\n(1) the additional visibility labels can assist in supervised training, and (2)\nour method outperforms state-of-the-art approaches with a significant\nimprovement of 7.9% absolute mAP.\n","authors":["Ting-Kang Yen","Igor Morawski","Shusil Dangi","Kai He","Chung-Yi Lin","Jia-Fong Yeh","Hung-Ting Su","Winston Hsu"],"pdf_url":"https://arxiv.org/pdf/2403.18330v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.18328v1","updated":"2024-03-27T08:09:04Z","published":"2024-03-27T08:09:04Z","title":"PIPNet3D: Interpretable Detection of Alzheimer in MRI Scans","summary":"  Information from neuroimaging examinations (CT, MRI) is increasingly used to\nsupport diagnoses of dementia, e.g., Alzheimer's disease. While current\nclinical practice is mainly based on visual inspection and feature engineering,\nDeep Learning approaches can be used to automate the analysis and to discover\nnew image-biomarkers. Part-prototype neural networks (PP-NN) are an alternative\nto standard blackbox models, and have shown promising results in general\ncomputer vision. PP-NN's base their reasoning on prototypical image regions\nthat are learned fully unsupervised, and combined with a simple-to-understand\ndecision layer. We present PIPNet3D, a PP-NN for volumetric images. We apply\nPIPNet3D to the clinical case study of Alzheimer's Disease diagnosis from\nstructural Magnetic Resonance Imaging (sMRI). We assess the quality of\nprototypes under a systematic evaluation framework, propose new metrics to\nevaluate brain prototypes and perform an evaluation with domain experts. Our\nresults show that PIPNet3D is an interpretable, compact model for Alzheimer's\ndiagnosis with its reasoning well aligned to medical domain knowledge. Notably,\nPIPNet3D achieves the same accuracy as its blackbox counterpart; and removing\nthe remaining clinically irrelevant prototypes from its decision process does\nnot decrease predictive performance.\n","authors":["Lisa Anita De Santi","J√∂rg Schl√∂tterer","Michael Scheschenja","Joel Wessendorf","Meike Nauta","Vincenzo Positano","Christin Seifert"],"pdf_url":"https://arxiv.org/pdf/2403.18328v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.10030v2","updated":"2024-03-27T07:52:10Z","published":"2024-03-15T05:30:29Z","title":"Multi-criteria Token Fusion with One-step-ahead Attention for Efficient\n  Vision Transformers","summary":"  Vision Transformer (ViT) has emerged as a prominent backbone for computer\nvision. For more efficient ViTs, recent works lessen the quadratic cost of the\nself-attention layer by pruning or fusing the redundant tokens. However, these\nworks faced the speed-accuracy trade-off caused by the loss of information.\nHere, we argue that token fusion needs to consider diverse relations between\ntokens to minimize information loss. In this paper, we propose a Multi-criteria\nToken Fusion (MCTF), that gradually fuses the tokens based on multi-criteria\n(e.g., similarity, informativeness, and size of fused tokens). Further, we\nutilize the one-step-ahead attention, which is the improved approach to capture\nthe informativeness of the tokens. By training the model equipped with MCTF\nusing a token reduction consistency, we achieve the best speed-accuracy\ntrade-off in the image classification (ImageNet1K). Experimental results prove\nthat MCTF consistently surpasses the previous reduction methods with and\nwithout training. Specifically, DeiT-T and DeiT-S with MCTF reduce FLOPs by\nabout 44% while improving the performance (+0.5%, and +0.3%) over the base\nmodel, respectively. We also demonstrate the applicability of MCTF in various\nVision Transformers (e.g., T2T-ViT, LV-ViT), achieving at least 31% speedup\nwithout performance degradation. Code is available at\nhttps://github.com/mlvlab/MCTF.\n","authors":["Sanghyeok Lee","Joonmyung Choi","Hyunwoo J. Kim"],"pdf_url":"https://arxiv.org/pdf/2403.10030v2.pdf","comment":"Conference on Computer Vision and Pattern Recognition (CVPR), 2024"},{"id":"http://arxiv.org/abs/2403.18321v1","updated":"2024-03-27T07:50:45Z","published":"2024-03-27T07:50:45Z","title":"Implementation of the Principal Component Analysis onto High-Performance\n  Computer Facilities for Hyperspectral Dimensionality Reduction: Results and\n  Comparisons","summary":"  Dimensionality reduction represents a critical preprocessing step in order to\nincrease the efficiency and the performance of many hyperspectral imaging\nalgorithms. However, dimensionality reduction algorithms, such as the Principal\nComponent Analysis (PCA), suffer from their computationally demanding nature,\nbecoming advisable for their implementation onto high-performance computer\narchitectures for applications under strict latency constraints. This work\npresents the implementation of the PCA algorithm onto two different\nhigh-performance devices, namely, an NVIDIA Graphics Processing Unit (GPU) and\na Kalray manycore, uncovering a highly valuable set of tips and tricks in order\nto take full advantage of the inherent parallelism of these high-performance\ncomputing platforms, and hence, reducing the time that is required to process a\ngiven hyperspectral image. Moreover, the achieved results obtained with\ndifferent hyperspectral images have been compared with the ones that were\nobtained with a field programmable gate array (FPGA)-based implementation of\nthe PCA algorithm that has been recently published, providing, for the first\ntime in the literature, a comprehensive analysis in order to highlight the pros\nand cons of each option.\n","authors":["E. Martel","R. Lazcano","J. Lopez","D. Madro√±al","R. Salvador","S. Lopez","E. Juarez","R. Guerra","C. Sanz","R. Sarmiento"],"pdf_url":"https://arxiv.org/pdf/2403.18321v1.pdf","comment":"30 pages, 10 figures"},{"id":"http://arxiv.org/abs/2403.18318v1","updated":"2024-03-27T07:40:51Z","published":"2024-03-27T07:40:51Z","title":"Uncertainty-Aware SAR ATR: Defending Against Adversarial Attacks via\n  Bayesian Neural Networks","summary":"  Adversarial attacks have demonstrated the vulnerability of Machine Learning\n(ML) image classifiers in Synthetic Aperture Radar (SAR) Automatic Target\nRecognition (ATR) systems. An adversarial attack can deceive the classifier\ninto making incorrect predictions by perturbing the input SAR images, for\nexample, with a few scatterers attached to the on-ground objects. Therefore, it\nis critical to develop robust SAR ATR systems that can detect potential\nadversarial attacks by leveraging the inherent uncertainty in ML classifiers,\nthereby effectively alerting human decision-makers. In this paper, we propose a\nnovel uncertainty-aware SAR ATR for detecting adversarial attacks.\nSpecifically, we leverage the capability of Bayesian Neural Networks (BNNs) in\nperforming image classification with quantified epistemic uncertainty to\nmeasure the confidence for each input SAR image. By evaluating the uncertainty,\nour method alerts when the input SAR image is likely to be adversarially\ngenerated. Simultaneously, we also generate visual explanations that reveal the\nspecific regions in the SAR image where the adversarial scatterers are likely\nto to be present, thus aiding human decision-making with hints of evidence of\nadversarial attacks. Experiments on the MSTAR dataset demonstrate that our\napproach can identify over 80% adversarial SAR images with fewer than 20% false\nalarms, and our visual explanations can identify up to over 90% of scatterers\nin an adversarial SAR image.\n","authors":["Tian Ye","Rajgopal Kannan","Viktor Prasanna","Carl Busart"],"pdf_url":"https://arxiv.org/pdf/2403.18318v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.08251v2","updated":"2024-03-27T07:33:42Z","published":"2022-12-16T02:43:52Z","title":"Task-Adaptive Saliency Guidance for Exemplar-free Class Incremental\n  Learning","summary":"  Exemplar-free Class Incremental Learning (EFCIL) aims to sequentially learn\ntasks with access only to data from the current one. EFCIL is of interest\nbecause it mitigates concerns about privacy and long-term storage of data,\nwhile at the same time alleviating the problem of catastrophic forgetting in\nincremental learning. In this work, we introduce task-adaptive saliency for\nEFCIL and propose a new framework, which we call Task-Adaptive Saliency\nSupervision (TASS), for mitigating the negative effects of saliency drift\nbetween different tasks. We first apply boundary-guided saliency to maintain\ntask adaptivity and \\textit{plasticity} on model attention. Besides, we\nintroduce task-agnostic low-level signals as auxiliary supervision to increase\nthe \\textit{stability} of model attention. Finally, we introduce a module for\ninjecting and recovering saliency noise to increase the robustness of saliency\npreservation. Our experiments demonstrate that our method can better preserve\nsaliency maps across tasks and achieve state-of-the-art results on the\nCIFAR-100, Tiny-ImageNet, and ImageNet-Subset EFCIL benchmarks. Code is\navailable at \\url{https://github.com/scok30/tass}.\n","authors":["Xialei Liu","Jiang-Tian Zhai","Andrew D. Bagdanov","Ke Li","Ming-Ming Cheng"],"pdf_url":"https://arxiv.org/pdf/2212.08251v2.pdf","comment":"Accepted at CVPR 2024"},{"id":"http://arxiv.org/abs/2307.09136v2","updated":"2024-03-27T07:16:28Z","published":"2023-07-18T10:34:21Z","title":"The Effects of Mixed Sample Data Augmentation are Class Dependent","summary":"  Mixed Sample Data Augmentation (MSDA) techniques, such as Mixup, CutMix, and\nPuzzleMix, have been widely acknowledged for enhancing performance in a variety\nof tasks. A previous study reported the class dependency of traditional data\naugmentation (DA), where certain classes benefit disproportionately compared to\nothers. This paper reveals a class dependent effect of MSDA, where some classes\nexperience improved performance while others experience degraded performance.\nThis research addresses the issue of class dependency in MSDA and proposes an\nalgorithm to mitigate it. The approach involves training on a mixture of MSDA\nand non-MSDA data, which not only mitigates the negative impact on the affected\nclasses, but also improves overall accuracy. Furthermore, we provide in-depth\nanalysis and discussion of why MSDA introduced class dependencies and which\nclasses are most likely to have them.\n","authors":["Haeil Lee","Hansang Lee","Junmo Kim"],"pdf_url":"https://arxiv.org/pdf/2307.09136v2.pdf","comment":"21 pages, 18 figures, Overall Revision"},{"id":"http://arxiv.org/abs/2402.18920v5","updated":"2024-03-27T07:16:21Z","published":"2024-02-29T07:26:23Z","title":"Spectral Meets Spatial: Harmonising 3D Shape Matching and Interpolation","summary":"  Although 3D shape matching and interpolation are highly interrelated, they\nare often studied separately and applied sequentially to relate different 3D\nshapes, thus resulting in sub-optimal performance. In this work we present a\nunified framework to predict both point-wise correspondences and shape\ninterpolation between 3D shapes. To this end, we combine the deep functional\nmap framework with classical surface deformation models to map shapes in both\nspectral and spatial domains. On the one hand, by incorporating spatial maps,\nour method obtains more accurate and smooth point-wise correspondences compared\nto previous functional map methods for shape matching. On the other hand, by\nintroducing spectral maps, our method gets rid of commonly used but\ncomputationally expensive geodesic distance constraints that are only valid for\nnear-isometric shape deformations. Furthermore, we propose a novel test-time\nadaptation scheme to capture both pose-dominant and shape-dominant\ndeformations. Using different challenging datasets, we demonstrate that our\nmethod outperforms previous state-of-the-art methods for both shape matching\nand interpolation, even compared to supervised approaches.\n","authors":["Dongliang Cao","Marvin Eisenberger","Nafie El Amrani","Daniel Cremers","Florian Bernard"],"pdf_url":"https://arxiv.org/pdf/2402.18920v5.pdf","comment":"accepted by CVPR2024"},{"id":"http://arxiv.org/abs/2308.13356v3","updated":"2024-03-27T07:12:09Z","published":"2023-08-25T13:05:06Z","title":"CEIMVEN: An Approach of Cutting Edge Implementation of Modified Versions\n  of EfficientNet (V1-V2) Architecture for Breast Cancer Detection and\n  Classification from Ultrasound Images","summary":"  Undoubtedly breast cancer identifies itself as one of the most widespread and\nterrifying cancers across the globe. Millions of women are getting affected\neach year from it. Breast cancer remains the major one for being the reason of\nlargest number of demise of women. In the recent time of research, Medical\nImage Computing and Processing has been playing a significant role for\ndetecting and classifying breast cancers from ultrasound images and mammograms,\nalong with the celestial touch of deep neural networks. In this research, we\nfocused mostly on our rigorous implementations and iterative result analysis of\ndifferent cutting-edge modified versions of EfficientNet architectures namely\nEfficientNet-V1 (b0-b7) and EfficientNet-V2 (b0-b3) with ultrasound image,\nnamed as CEIMVEN. We utilized transfer learning approach here for using the\npre-trained models of EfficientNet versions. We activated the hyper-parameter\ntuning procedures, added fully connected layers, discarded the unprecedented\noutliers and recorded the accuracy results from our custom modified\nEfficientNet architectures. Our deep learning model training approach was\nrelated to both identifying the cancer affected areas with region of interest\n(ROI) techniques and multiple classifications (benign, malignant and normal).\nThe approximate testing accuracies we got from the modified versions of\nEfficientNet-V1 (b0- 99.15%, b1- 98.58%, b2- 98.43%, b3- 98.01%, b4- 98.86%,\nb5- 97.72%, b6- 97.72%, b7- 98.72%) and EfficientNet-V2 (b0- 99.29%, b1-\n99.01%, b2- 98.72%, b3- 99.43%) are showing very bright future and strong\npotentials of deep learning approach for the successful detection and\nclassification of breast cancers from the ultrasound images at a very early\nstage. The code for this research is available here:\nhttps://github.com/ac005sheekar/CEIMVEN-Breast.\n","authors":["Sheekar Banerjee","Md. Kamrul Hasan Monir"],"pdf_url":"https://arxiv.org/pdf/2308.13356v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.18301v1","updated":"2024-03-27T06:55:23Z","published":"2024-03-27T06:55:23Z","title":"Selective Mixup Fine-Tuning for Optimizing Non-Decomposable Objectives","summary":"  The rise in internet usage has led to the generation of massive amounts of\ndata, resulting in the adoption of various supervised and semi-supervised\nmachine learning algorithms, which can effectively utilize the colossal amount\nof data to train models. However, before deploying these models in the real\nworld, these must be strictly evaluated on performance measures like worst-case\nrecall and satisfy constraints such as fairness. We find that current\nstate-of-the-art empirical techniques offer sub-optimal performance on these\npractical, non-decomposable performance objectives. On the other hand, the\ntheoretical techniques necessitate training a new model from scratch for each\nperformance objective. To bridge the gap, we propose SelMix, a selective\nmixup-based inexpensive fine-tuning technique for pre-trained models, to\noptimize for the desired objective. The core idea of our framework is to\ndetermine a sampling distribution to perform a mixup of features between\nsamples from particular classes such that it optimizes the given objective. We\ncomprehensively evaluate our technique against the existing empirical and\ntheoretically principled methods on standard benchmark datasets for imbalanced\nclassification. We find that proposed SelMix fine-tuning significantly improves\nthe performance for various practical non-decomposable objectives across\nbenchmarks.\n","authors":["Shrinivas Ramasubramanian","Harsh Rangwani","Sho Takemori","Kunal Samanta","Yuhei Umeda","Venkatesh Babu Radhakrishnan"],"pdf_url":"https://arxiv.org/pdf/2403.18301v1.pdf","comment":"ICLR 2024 SpotLight"},{"id":"http://arxiv.org/abs/2403.07392v3","updated":"2024-03-27T06:44:13Z","published":"2024-03-12T07:59:41Z","title":"ViT-CoMer: Vision Transformer with Convolutional Multi-scale Feature\n  Interaction for Dense Predictions","summary":"  Although Vision Transformer (ViT) has achieved significant success in\ncomputer vision, it does not perform well in dense prediction tasks due to the\nlack of inner-patch information interaction and the limited diversity of\nfeature scale. Most existing studies are devoted to designing vision-specific\ntransformers to solve the above problems, which introduce additional\npre-training costs. Therefore, we present a plain, pre-training-free, and\nfeature-enhanced ViT backbone with Convolutional Multi-scale feature\ninteraction, named ViT-CoMer, which facilitates bidirectional interaction\nbetween CNN and transformer. Compared to the state-of-the-art, ViT-CoMer has\nthe following advantages: (1) We inject spatial pyramid multi-receptive field\nconvolutional features into the ViT architecture, which effectively alleviates\nthe problems of limited local information interaction and single-feature\nrepresentation in ViT. (2) We propose a simple and efficient CNN-Transformer\nbidirectional fusion interaction module that performs multi-scale fusion across\nhierarchical features, which is beneficial for handling dense prediction tasks.\n(3) We evaluate the performance of ViT-CoMer across various dense prediction\ntasks, different frameworks, and multiple advanced pre-training. Notably, our\nViT-CoMer-L achieves 64.3% AP on COCO val2017 without extra training data, and\n62.1% mIoU on ADE20K val, both of which are comparable to state-of-the-art\nmethods. We hope ViT-CoMer can serve as a new backbone for dense prediction\ntasks to facilitate future research. The code will be released at\nhttps://github.com/Traffic-X/ViT-CoMer.\n","authors":["Chunlong Xia","Xinliang Wang","Feng Lv","Xin Hao","Yifeng Shi"],"pdf_url":"https://arxiv.org/pdf/2403.07392v3.pdf","comment":"CVPR2024"},{"id":"http://arxiv.org/abs/2403.18294v1","updated":"2024-03-27T06:40:26Z","published":"2024-03-27T06:40:26Z","title":"Multi-scale Unified Network for Image Classification","summary":"  Convolutional Neural Networks (CNNs) have advanced significantly in visual\nrepresentation learning and recognition. However, they face notable challenges\nin performance and computational efficiency when dealing with real-world,\nmulti-scale image inputs. Conventional methods rescale all input images into a\nfixed size, wherein a larger fixed size favors performance but rescaling small\nsize images to a larger size incurs digitization noise and increased\ncomputation cost. In this work, we carry out a comprehensive, layer-wise\ninvestigation of CNN models in response to scale variation, based on Centered\nKernel Alignment (CKA) analysis. The observations reveal lower layers are more\nsensitive to input image scale variations than high-level layers. Inspired by\nthis insight, we propose Multi-scale Unified Network (MUSN) consisting of\nmulti-scale subnets, a unified network, and scale-invariant constraint. Our\nmethod divides the shallow layers into multi-scale subnets to enable feature\nextraction from multi-scale inputs, and the low-level features are unified in\ndeep layers for extracting high-level semantic features. A scale-invariant\nconstraint is posed to maintain feature consistency across different scales.\nExtensive experiments on ImageNet and other scale-diverse datasets, demonstrate\nthat MSUN achieves significant improvements in both model performance and\ncomputational efficiency. Particularly, MSUN yields an accuracy increase up to\n44.53% and diminishes FLOPs by 7.01-16.13% in multi-scale scenarios.\n","authors":["Wenzhuo Liu","Fei Zhu","Cheng-Lin Liu"],"pdf_url":"https://arxiv.org/pdf/2403.18294v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.18293v1","updated":"2024-03-27T06:37:51Z","published":"2024-03-27T06:37:51Z","title":"Efficient Test-Time Adaptation of Vision-Language Models","summary":"  Test-time adaptation with pre-trained vision-language models has attracted\nincreasing attention for tackling distribution shifts during the test time.\nThough prior studies have achieved very promising performance, they involve\nintensive computation which is severely unaligned with test-time adaptation. We\ndesign TDA, a training-free dynamic adapter that enables effective and\nefficient test-time adaptation with vision-language models. TDA works with a\nlightweight key-value cache that maintains a dynamic queue with few-shot pseudo\nlabels as values and the corresponding test-sample features as keys. Leveraging\nthe key-value cache, TDA allows adapting to test data gradually via progressive\npseudo label refinement which is super-efficient without incurring any\nbackpropagation. In addition, we introduce negative pseudo labeling that\nalleviates the adverse impact of pseudo label noises by assigning pseudo labels\nto certain negative classes when the model is uncertain about its pseudo label\npredictions. Extensive experiments over two benchmarks demonstrate TDA's\nsuperior effectiveness and efficiency as compared with the state-of-the-art.\nThe code has been released in \\url{https://kdiaaa.github.io/tda/}.\n","authors":["Adilbek Karmanov","Dayan Guan","Shijian Lu","Abdulmotaleb El Saddik","Eric Xing"],"pdf_url":"https://arxiv.org/pdf/2403.18293v1.pdf","comment":"Accepted to CVPR 2024. The code has been released in\n  \\url{https://kdiaaa.github.io/tda/}"},{"id":"http://arxiv.org/abs/2403.18291v1","updated":"2024-03-27T06:28:19Z","published":"2024-03-27T06:28:19Z","title":"Towards Non-Exemplar Semi-Supervised Class-Incremental Learning","summary":"  Deep neural networks perform remarkably well in close-world scenarios.\nHowever, novel classes emerged continually in real applications, making it\nnecessary to learn incrementally. Class-incremental learning (CIL) aims to\ngradually recognize new classes while maintaining the discriminability of old\nones. Existing CIL methods have two limitations: a heavy reliance on preserving\nold data for forgetting mitigation and the need for vast labeled data for\nknowledge adaptation. To overcome these issues, we propose a non-exemplar\nsemi-supervised CIL framework with contrastive learning and semi-supervised\nincremental prototype classifier (Semi-IPC). On the one hand, contrastive\nlearning helps the model learn rich representations, easing the trade-off\nbetween learning representations of new classes and forgetting that of old\nclasses. On the other hand, Semi-IPC learns a prototype for each class with\nunsupervised regularization, enabling the model to incrementally learn from\npartially labeled new data while maintaining the knowledge of old classes.\nExperiments on benchmark datasets demonstrate the strong performance of our\nmethod: without storing any old samples and only using less than 1% of labels,\nSemi-IPC outperforms advanced exemplar-based methods. We hope our work offers\nnew insights for future CIL research. The code will be made publicly available.\n","authors":["Wenzhuo Liu","Fei Zhu","Cheng-Lin Liu"],"pdf_url":"https://arxiv.org/pdf/2403.18291v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.15864v2","updated":"2024-03-27T06:26:09Z","published":"2023-11-27T14:32:33Z","title":"InterControl: Generate Human Motion Interactions by Controlling Every\n  Joint","summary":"  Text-conditioned human motion synthesis has made remarkable progress with the\nemergence of diffusion models in recent research. However, the majority of\nthese motion diffusion models are primarily designed for a single character and\noverlook multi-human interactions. In our approach, we strive to explore this\nproblem by synthesizing human motion with interactions for a group of\ncharacters of any size. The key aspect of our approach is the adaptation of\nhuman-wise interactions as pairs of human joints that can be either in contact\nor separated by a desired distance. In contrast to existing methods that\nnecessitate training motion generation models on multi-human motion datasets\nwith a fixed number of characters, our approach inherently possesses the\nflexibility to model human interactions involving an arbitrary number of\nindividuals, thereby transcending the limitations imposed by the training data.\nWe introduce a novel controllable motion generation method, InterControl, to\nencourage the synthesized motions maintaining the desired distance between\njoint pairs. It consists of a motion controller and an inverse kinematics\nguidance module that realistically and accurately aligns the joints of\nsynthesized characters to the desired location. Furthermore, we demonstrate\nthat the distance between joint pairs for human-wise interactions can be\ngenerated using an off-the-shelf Large Language Model (LLM). Experimental\nresults highlight the capability of our framework to generate interactions with\nmultiple human characters and its potential to work with off-the-shelf\nphysics-based character simulators.\n","authors":["Zhenzhi Wang","Jingbo Wang","Yixuan Li","Dahua Lin","Bo Dai"],"pdf_url":"https://arxiv.org/pdf/2311.15864v2.pdf","comment":"Generate human interactions with only single-person data via joint\n  contact pairs, code https://github.com/zhenzhiwang/intercontrol"},{"id":"http://arxiv.org/abs/2403.18282v1","updated":"2024-03-27T06:18:40Z","published":"2024-03-27T06:18:40Z","title":"SGDM: Static-Guided Dynamic Module Make Stronger Visual Models","summary":"  The spatial attention mechanism has been widely used to improve object\ndetection performance. However, its operation is currently limited to static\nconvolutions lacking content-adaptive features. This paper innovatively\napproaches from the perspective of dynamic convolution. We propose Razor\nDynamic Convolution (RDConv) to address thetwo flaws in dynamic weight\nconvolution, making it hard to implement in spatial mechanism: 1) it is\ncomputation-heavy; 2) when generating weights, spatial information is\ndisregarded. Firstly, by using Razor Operation to generate certain features, we\nvastly reduce the parameters of the entire dynamic convolution operation.\nSecondly, we added a spatial branch inside RDConv to generate convolutional\nkernel parameters with richer spatial information. Embedding dynamic\nconvolution will also bring the problem of sensitivity to high-frequency noise.\nWe propose the Static-Guided Dynamic Module (SGDM) to address this limitation.\nBy using SGDM, we utilize a set of asymmetric static convolution kernel\nparameters to guide the construction of dynamic convolution. We introduce the\nmechanism of shared weights in static convolution to solve the problem of\ndynamic convolution being sensitive to high-frequency noise. Extensive\nexperiments illustrate that multiple different object detection backbones\nequipped with SGDM achieve a highly competitive boost in performance(e.g., +4%\nmAP with YOLOv5n on VOC and +1.7% mAP with YOLOv8n on COCO) with negligible\nparameter increase(i.e., +0.33M on YOLOv5n and +0.19M on YOLOv8n).\n","authors":["Wenjie Xing","Zhenchao Cui","Jing Qi"],"pdf_url":"https://arxiv.org/pdf/2403.18282v1.pdf","comment":"16 pages, 4 figures"},{"id":"http://arxiv.org/abs/2403.18281v1","updated":"2024-03-27T06:17:21Z","published":"2024-03-27T06:17:21Z","title":"AIR-HLoc: Adaptive Image Retrieval for Efficient Visual Localisation","summary":"  State-of-the-art (SOTA) hierarchical localisation pipelines (HLoc) rely on\nimage retrieval (IR) techniques to establish 2D-3D correspondences by selecting\nthe $k$ most similar images from a reference image database for a given query\nimage. Although higher values of $k$ enhance localisation robustness, the\ncomputational cost for feature matching increases linearly with $k$. In this\npaper, we observe that queries that are the most similar to images in the\ndatabase result in a higher proportion of feature matches and, thus, more\naccurate positioning. Thus, a small number of images is sufficient for queries\nvery similar to images in the reference database. We then propose a novel\napproach, AIR-HLoc, which divides query images into different localisation\ndifficulty levels based on their similarity to the reference image database. We\nconsider an image with high similarity to the reference image as an easy query\nand an image with low similarity as a hard query. Easy queries show a limited\nimprovement in accuracy when increasing $k$. Conversely, higher values of $k$\nsignificantly improve accuracy for hard queries. Given the limited improvement\nin accuracy when increasing $k$ for easy queries and the significant\nimprovement for hard queries, we adapt the value of $k$ to the query's\ndifficulty level. Therefore, AIR-HLoc optimizes processing time by adaptively\nassigning different values of $k$ based on the similarity between the query and\nreference images without losing accuracy. Our extensive experiments on the\nCambridge Landmarks, 7Scenes, and Aachen Day-Night-v1.1 datasets demonstrate\nour algorithm's efficacy, reducing 30\\%, 26\\%, and 11\\% in computational\noverhead while maintaining SOTA accuracy compared to HLoc with fixed image\nretrieval.\n","authors":["Changkun Liu","Huajian Huang","Zhengyang Ma","Tristan Braud"],"pdf_url":"https://arxiv.org/pdf/2403.18281v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.07711v2","updated":"2024-03-27T06:02:38Z","published":"2024-03-12T14:53:56Z","title":"SSM Meets Video Diffusion Models: Efficient Video Generation with\n  Structured State Spaces","summary":"  Given the remarkable achievements in image generation through diffusion\nmodels, the research community has shown increasing interest in extending these\nmodels to video generation. Recent diffusion models for video generation have\npredominantly utilized attention layers to extract temporal features. However,\nattention layers are limited by their memory consumption, which increases\nquadratically with the length of the sequence. This limitation presents\nsignificant challenges when attempting to generate longer video sequences using\ndiffusion models. To overcome this challenge, we propose leveraging state-space\nmodels (SSMs). SSMs have recently gained attention as viable alternatives due\nto their linear memory consumption relative to sequence length. In the\nexperiments, we first evaluate our SSM-based model with UCF101, a standard\nbenchmark of video generation. In addition, to investigate the potential of\nSSMs for longer video generation, we perform an experiment using the MineRL\nNavigate dataset, varying the number of frames to 64, 200, and 400. In these\nsettings, our SSM-based model can considerably save memory consumption for\nlonger sequences, while maintaining competitive FVD scores to the\nattention-based models. Our codes are available at\nhttps://github.com/shim0114/SSM-Meets-Video-Diffusion-Models.\n","authors":["Yuta Oshima","Shohei Taniguchi","Masahiro Suzuki","Yutaka Matsuo"],"pdf_url":"https://arxiv.org/pdf/2403.07711v2.pdf","comment":"Accepted as workshop paper at ICLR 2024"},{"id":"http://arxiv.org/abs/2303.08231v3","updated":"2024-03-27T06:00:18Z","published":"2023-03-14T20:55:27Z","title":"Rotation-Invariant Transformer for Point Cloud Matching","summary":"  The intrinsic rotation invariance lies at the core of matching point clouds\nwith handcrafted descriptors. However, it is widely despised by recent deep\nmatchers that obtain the rotation invariance extrinsically via data\naugmentation. As the finite number of augmented rotations can never span the\ncontinuous SO(3) space, these methods usually show instability when facing\nrotations that are rarely seen. To this end, we introduce RoITr, a\nRotation-Invariant Transformer to cope with the pose variations in the point\ncloud matching task. We contribute both on the local and global levels.\nStarting from the local level, we introduce an attention mechanism embedded\nwith Point Pair Feature (PPF)-based coordinates to describe the pose-invariant\ngeometry, upon which a novel attention-based encoder-decoder architecture is\nconstructed. We further propose a global transformer with rotation-invariant\ncross-frame spatial awareness learned by the self-attention mechanism, which\nsignificantly improves the feature distinctiveness and makes the model robust\nwith respect to the low overlap. Experiments are conducted on both the rigid\nand non-rigid public benchmarks, where RoITr outperforms all the\nstate-of-the-art models by a considerable margin in the low-overlapping\nscenarios. Especially when the rotations are enlarged on the challenging\n3DLoMatch benchmark, RoITr surpasses the existing methods by at least 13 and 5\npercentage points in terms of Inlier Ratio and Registration Recall,\nrespectively.\n","authors":["Hao Yu","Zheng Qin","Ji Hou","Mahdi Saleh","Dongsheng Li","Benjamin Busam","Slobodan Ilic"],"pdf_url":"https://arxiv.org/pdf/2303.08231v3.pdf","comment":"Accepted to CVPR 2023"},{"id":"http://arxiv.org/abs/2403.18274v1","updated":"2024-03-27T05:57:45Z","published":"2024-03-27T05:57:45Z","title":"DVLO: Deep Visual-LiDAR Odometry with Local-to-Global Feature Fusion and\n  Bi-Directional Structure Alignment","summary":"  Information inside visual and LiDAR data is well complementary derived from\nthe fine-grained texture of images and massive geometric information in point\nclouds. However, it remains challenging to explore effective visual-LiDAR\nfusion, mainly due to the intrinsic data structure inconsistency between two\nmodalities: Images are regular and dense, but LiDAR points are unordered and\nsparse. To address the problem, we propose a local-to-global fusion network\nwith bi-directional structure alignment. To obtain locally fused features, we\nproject points onto image plane as cluster centers and cluster image pixels\naround each center. Image pixels are pre-organized as pseudo points for\nimage-to-point structure alignment. Then, we convert points to pseudo images by\ncylindrical projection (point-to-image structure alignment) and perform\nadaptive global feature fusion between point features with local fused\nfeatures. Our method achieves state-of-the-art performance on KITTI odometry\nand FlyingThings3D scene flow datasets compared to both single-modal and\nmulti-modal methods. Codes will be released later.\n","authors":["Jiuming Liu","Dong Zhuo","Zhiheng Feng","Siting Zhu","Chensheng Peng","Zhe Liu","Hesheng Wang"],"pdf_url":"https://arxiv.org/pdf/2403.18274v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.18271v1","updated":"2024-03-27T05:55:16Z","published":"2024-03-27T05:55:16Z","title":"Unleashing the Potential of SAM for Medical Adaptation via Hierarchical\n  Decoding","summary":"  The Segment Anything Model (SAM) has garnered significant attention for its\nversatile segmentation abilities and intuitive prompt-based interface. However,\nits application in medical imaging presents challenges, requiring either\nsubstantial training costs and extensive medical datasets for full model\nfine-tuning or high-quality prompts for optimal performance. This paper\nintroduces H-SAM: a prompt-free adaptation of SAM tailored for efficient\nfine-tuning of medical images via a two-stage hierarchical decoding procedure.\nIn the initial stage, H-SAM employs SAM's original decoder to generate a prior\nprobabilistic mask, guiding a more intricate decoding process in the second\nstage. Specifically, we propose two key designs: 1) A class-balanced,\nmask-guided self-attention mechanism addressing the unbalanced label\ndistribution, enhancing image embedding; 2) A learnable mask cross-attention\nmechanism spatially modulating the interplay among different image regions\nbased on the prior mask. Moreover, the inclusion of a hierarchical pixel\ndecoder in H-SAM enhances its proficiency in capturing fine-grained and\nlocalized details. This approach enables SAM to effectively integrate learned\nmedical priors, facilitating enhanced adaptation for medical image segmentation\nwith limited samples. Our H-SAM demonstrates a 4.78% improvement in average\nDice compared to existing prompt-free SAM variants for multi-organ segmentation\nusing only 10% of 2D slices. Notably, without using any unlabeled data, H-SAM\neven outperforms state-of-the-art semi-supervised models relying on extensive\nunlabeled training data across various medical datasets. Our code is available\nat https://github.com/Cccccczh404/H-SAM.\n","authors":["Zhiheng Cheng","Qingyue Wei","Hongru Zhu","Yan Wang","Liangqiong Qu","Wei Shao","Yuyin Zhou"],"pdf_url":"https://arxiv.org/pdf/2403.18271v1.pdf","comment":"CVPR 2024"},{"id":"http://arxiv.org/abs/2403.18270v1","updated":"2024-03-27T05:52:39Z","published":"2024-03-27T05:52:39Z","title":"Image Deraining via Self-supervised Reinforcement Learning","summary":"  The quality of images captured outdoors is often affected by the weather. One\nfactor that interferes with sight is rain, which can obstruct the view of\nobservers and computer vision applications that rely on those images. The work\naims to recover rain images by removing rain streaks via Self-supervised\nReinforcement Learning (RL) for image deraining (SRL-Derain). We locate rain\nstreak pixels from the input rain image via dictionary learning and use\npixel-wise RL agents to take multiple inpainting actions to remove rain\nprogressively. To our knowledge, this work is the first attempt where\nself-supervised RL is applied to image deraining. Experimental results on\nseveral benchmark image-deraining datasets show that the proposed SRL-Derain\nperforms favorably against state-of-the-art few-shot and self-supervised\nderaining and denoising methods.\n","authors":["He-Hao Liao","Yan-Tsung Peng","Wen-Tao Chu","Ping-Chun Hsieh","Chung-Chi Tsai"],"pdf_url":"https://arxiv.org/pdf/2403.18270v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.18266v1","updated":"2024-03-27T05:38:48Z","published":"2024-03-27T05:38:48Z","title":"Branch-Tuning: Balancing Stability and Plasticity for Continual\n  Self-Supervised Learning","summary":"  Self-supervised learning (SSL) has emerged as an effective paradigm for\nderiving general representations from vast amounts of unlabeled data. However,\nas real-world applications continually integrate new content, the high\ncomputational and resource demands of SSL necessitate continual learning rather\nthan complete retraining. This poses a challenge in striking a balance between\nstability and plasticity when adapting to new information. In this paper, we\nemploy Centered Kernel Alignment for quantitatively analyzing model stability\nand plasticity, revealing the critical roles of batch normalization layers for\nstability and convolutional layers for plasticity. Motivated by this, we\npropose Branch-tuning, an efficient and straightforward method that achieves a\nbalance between stability and plasticity in continual SSL. Branch-tuning\nconsists of branch expansion and compression, and can be easily applied to\nvarious SSL methods without the need of modifying the original methods,\nretaining old data or models. We validate our method through incremental\nexperiments on various benchmark datasets, demonstrating its effectiveness and\npractical value in real-world scenarios. We hope our work offers new insights\nfor future continual self-supervised learning research. The code will be made\npublicly available.\n","authors":["Wenzhuo Liu","Fei Zhu","Cheng-Lin Liu"],"pdf_url":"https://arxiv.org/pdf/2403.18266v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.03532v2","updated":"2024-03-27T05:28:55Z","published":"2024-03-06T08:18:02Z","title":"Extend Your Own Correspondences: Unsupervised Distant Point Cloud\n  Registration by Progressive Distance Extension","summary":"  Registration of point clouds collected from a pair of distant vehicles\nprovides a comprehensive and accurate 3D view of the driving scenario, which is\nvital for driving safety related applications, yet existing literature suffers\nfrom the expensive pose label acquisition and the deficiency to generalize to\nnew data distributions. In this paper, we propose EYOC, an unsupervised distant\npoint cloud registration method that adapts to new point cloud distributions on\nthe fly, requiring no global pose labels. The core idea of EYOC is to train a\nfeature extractor in a progressive fashion, where in each round, the feature\nextractor, trained with near point cloud pairs, can label slightly farther\npoint cloud pairs, enabling self-supervision on such far point cloud pairs.\nThis process continues until the derived extractor can be used to register\ndistant point clouds. Particularly, to enable high-fidelity correspondence\nlabel generation, we devise an effective spatial filtering scheme to select the\nmost representative correspondences to register a point cloud pair, and then\nutilize the aligned point clouds to discover more correct correspondences.\nExperiments show that EYOC can achieve comparable performance with\nstate-of-the-art supervised methods at a lower training cost. Moreover, it\noutwits supervised methods regarding generalization performance on new data\ndistributions.\n","authors":["Quan Liu","Hongzi Zhu","Zhenxi Wang","Yunsong Zhou","Shan Chang","Minyi Guo"],"pdf_url":"https://arxiv.org/pdf/2403.03532v2.pdf","comment":"In Proceedings of the IEEE/CVF Conference on Computer Vision and\n  Pattern Recognition (CVPR), 2024"},{"id":"http://arxiv.org/abs/2402.02561v2","updated":"2024-03-27T05:23:40Z","published":"2024-02-04T16:27:37Z","title":"Foundation Model Makes Clustering A Better Initialization For Cold-Start\n  Active Learning","summary":"  Active learning selects the most informative samples from the unlabelled\ndataset to annotate in the context of a limited annotation budget. While\nnumerous methods have been proposed for subsequent sample selection based on an\ninitialized model, scant attention has been paid to the indispensable phase of\nactive learning: selecting samples for model cold-start initialization. Most of\nthe previous studies resort to random sampling or naive clustering. However,\nrandom sampling is prone to fluctuation, and naive clustering suffers from\nconvergence speed, particularly when dealing with high-dimensional data such as\nimaging data. In this work, we propose to integrate foundation models with\nclustering methods to select samples for cold-start active learning\ninitialization. Foundation models refer to those trained on massive datasets by\nthe self-supervised paradigm and capable of generating informative and\ncompacted embeddings for various downstream tasks. Leveraging these embeddings\nto replace raw features such as pixel values, clustering quickly converges and\nidentifies better initial samples. For a comprehensive comparison, we included\na classic ImageNet-supervised model to acquire embeddings. Experiments on two\nclinical tasks of image classification and segmentation demonstrated that\nfoundation model-based clustering efficiently pinpointed informative initial\nsamples, leading to models showcasing enhanced performance than the baseline\nmethods. We envisage that this study provides an effective paradigm for future\ncold-start active learning.\n","authors":["Han Yuan","Chuan Hong"],"pdf_url":"https://arxiv.org/pdf/2402.02561v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.17456v3","updated":"2024-03-27T05:22:18Z","published":"2023-11-29T08:56:24Z","title":"DifFlow3D: Toward Robust Uncertainty-Aware Scene Flow Estimation with\n  Iterative Diffusion-Based Refinement","summary":"  Scene flow estimation, which aims to predict per-point 3D displacements of\ndynamic scenes, is a fundamental task in the computer vision field. However,\nprevious works commonly suffer from unreliable correlation caused by locally\nconstrained searching ranges, and struggle with accumulated inaccuracy arising\nfrom the coarse-to-fine structure. To alleviate these problems, we propose a\nnovel uncertainty-aware scene flow estimation network (DifFlow3D) with the\ndiffusion probabilistic model. Iterative diffusion-based refinement is designed\nto enhance the correlation robustness and resilience to challenging cases, e.g.\ndynamics, noisy inputs, repetitive patterns, etc. To restrain the generation\ndiversity, three key flow-related features are leveraged as conditions in our\ndiffusion model. Furthermore, we also develop an uncertainty estimation module\nwithin diffusion to evaluate the reliability of estimated scene flow. Our\nDifFlow3D achieves state-of-the-art performance, with 24.0% and 29.1% EPE3D\nreduction respectively on FlyingThings3D and KITTI 2015 datasets. Notably, our\nmethod achieves an unprecedented millimeter-level accuracy (0.0078m in EPE3D)\non the KITTI dataset. Additionally, our diffusion-based refinement paradigm can\nbe readily integrated as a plug-and-play module into existing scene flow\nnetworks, significantly increasing their estimation accuracy. Codes are\nreleased at https://github.com/IRMVLab/DifFlow3D.\n","authors":["Jiuming Liu","Guangming Wang","Weicai Ye","Chaokang Jiang","Jinru Han","Zhe Liu","Guofeng Zhang","Dalong Du","Hesheng Wang"],"pdf_url":"https://arxiv.org/pdf/2311.17456v3.pdf","comment":"Camera-ready version of CVPR 2024. Codes are released at\n  https://github.com/IRMVLab/DifFlow3D"},{"id":"http://arxiv.org/abs/2403.18260v1","updated":"2024-03-27T05:22:06Z","published":"2024-03-27T05:22:06Z","title":"Toward Interactive Regional Understanding in Vision-Large Language\n  Models","summary":"  Recent Vision-Language Pre-training (VLP) models have demonstrated\nsignificant advancements. Nevertheless, these models heavily rely on image-text\npairs that capture only coarse and global information of an image, leading to a\nlimitation in their regional understanding ability. In this work, we introduce\n\\textbf{RegionVLM}, equipped with explicit regional modeling capabilities,\nallowing them to understand user-indicated image regions. To achieve this, we\ndesign a simple yet innovative architecture, requiring no modifications to the\nmodel architecture or objective function. Additionally, we leverage a dataset\nthat contains a novel source of information, namely Localized Narratives, which\nhas been overlooked in previous VLP research. Our experiments demonstrate that\nour single generalist model not only achieves an interactive dialogue system\nbut also exhibits superior performance on various zero-shot region\nunderstanding tasks, without compromising its ability for global image\nunderstanding.\n","authors":["Jungbeom Lee","Sanghyuk Chun","Sangdoo Yun"],"pdf_url":"https://arxiv.org/pdf/2403.18260v1.pdf","comment":"NAACL 2024 Main Conference"},{"id":"http://arxiv.org/abs/2209.02200v3","updated":"2024-03-27T05:16:02Z","published":"2022-09-06T03:42:18Z","title":"Task-wise Sampling Convolutions for Arbitrary-Oriented Object Detection\n  in Aerial Images","summary":"  Arbitrary-oriented object detection (AOOD) has been widely applied to locate\nand classify objects with diverse orientations in remote sensing images.\nHowever, the inconsistent features for the localization and classification\ntasks in AOOD models may lead to ambiguity and low-quality object predictions,\nwhich constrains the detection performance. In this article, an AOOD method\ncalled task-wise sampling convolutions (TS-Conv) is proposed. TS-Conv\nadaptively samples task-wise features from respective sensitive regions and\nmaps these features together in alignment to guide a dynamic label assignment\nfor better predictions. Specifically, sampling positions of the localization\nconvolution in TS-Conv are supervised by the oriented bounding box (OBB)\nprediction associated with spatial coordinates, while sampling positions and\nconvolutional kernel of the classification convolution are designed to be\nadaptively adjusted according to different orientations for improving the\norientation robustness of features. Furthermore, a dynamic\ntask-consistent-aware label assignment (DTLA) strategy is developed to select\noptimal candidate positions and assign labels dynamically according to ranked\ntask-aware scores obtained from TS-Conv. Extensive experiments on several\npublic datasets covering multiple scenes, multimodal images, and multiple\ncategories of objects demonstrate the effectiveness, scalability, and superior\nperformance of the proposed TS-Conv.\n","authors":["Zhanchao Huang","Wei Li","Xiang-Gen Xia","Hao Wang","Ran Tao"],"pdf_url":"https://arxiv.org/pdf/2209.02200v3.pdf","comment":"15 pages, 13 figures, 11 tables"}],"Machine Learning 1":[{"id":"http://arxiv.org/abs/2403.18807v1","updated":"2024-03-27T17:53:30Z","published":"2024-03-27T17:53:30Z","title":"ECoDepth: Effective Conditioning of Diffusion Models for Monocular Depth\n  Estimation","summary":"  In the absence of parallax cues, a learning-based single image depth\nestimation (SIDE) model relies heavily on shading and contextual cues in the\nimage. While this simplicity is attractive, it is necessary to train such\nmodels on large and varied datasets, which are difficult to capture. It has\nbeen shown that using embeddings from pre-trained foundational models, such as\nCLIP, improves zero shot transfer in several applications. Taking inspiration\nfrom this, in our paper we explore the use of global image priors generated\nfrom a pre-trained ViT model to provide more detailed contextual information.\nWe argue that the embedding vector from a ViT model, pre-trained on a large\ndataset, captures greater relevant information for SIDE than the usual route of\ngenerating pseudo image captions, followed by CLIP based text embeddings. Based\non this idea, we propose a new SIDE model using a diffusion backbone which is\nconditioned on ViT embeddings. Our proposed design establishes a new\nstate-of-the-art (SOTA) for SIDE on NYUv2 dataset, achieving Abs Rel error of\n0.059(14% improvement) compared to 0.069 by the current SOTA (VPD). And on\nKITTI dataset, achieving Sq Rel error of 0.139 (2% improvement) compared to\n0.142 by the current SOTA (GEDepth). For zero-shot transfer with a model\ntrained on NYUv2, we report mean relative improvement of (20%, 23%, 81%, 25%)\nover NeWCRFs on (Sun-RGBD, iBims1, DIODE, HyperSim) datasets, compared to (16%,\n18%, 45%, 9%) by ZoeDepth. The code is available at\nhttps://github.com/Aradhye2002/EcoDepth.\n","authors":["Suraj Patni","Aradhye Agarwal","Chetan Arora"],"pdf_url":"https://arxiv.org/pdf/2403.18807v1.pdf","comment":"Accepted at IEEE/CVF Conference on Computer Vision and Pattern\n  Recognition (CVPR) 2024"},{"id":"http://arxiv.org/abs/2403.18802v1","updated":"2024-03-27T17:48:55Z","published":"2024-03-27T17:48:55Z","title":"Long-form factuality in large language models","summary":"  Large language models (LLMs) often generate content that contains factual\nerrors when responding to fact-seeking prompts on open-ended topics. To\nbenchmark a model's long-form factuality in open domains, we first use GPT-4 to\ngenerate LongFact, a prompt set comprising thousands of questions spanning 38\ntopics. We then propose that LLM agents can be used as automated evaluators for\nlong-form factuality through a method which we call Search-Augmented Factuality\nEvaluator (SAFE). SAFE utilizes an LLM to break down a long-form response into\na set of individual facts and to evaluate the accuracy of each fact using a\nmulti-step reasoning process comprising sending search queries to Google Search\nand determining whether a fact is supported by the search results. Furthermore,\nwe propose extending F1 score as an aggregated metric for long-form factuality.\nTo do so, we balance the percentage of supported facts in a response\n(precision) with the percentage of provided facts relative to a hyperparameter\nrepresenting a user's preferred response length (recall).\n  Empirically, we demonstrate that LLM agents can achieve superhuman rating\nperformance - on a set of ~16k individual facts, SAFE agrees with crowdsourced\nhuman annotators 72% of the time, and on a random subset of 100 disagreement\ncases, SAFE wins 76% of the time. At the same time, SAFE is more than 20 times\ncheaper than human annotators. We also benchmark thirteen language models on\nLongFact across four model families (Gemini, GPT, Claude, and PaLM-2), finding\nthat larger language models generally achieve better long-form factuality.\nLongFact, SAFE, and all experimental code are available at\nhttps://github.com/google-deepmind/long-form-factuality.\n","authors":["Jerry Wei","Chengrun Yang","Xinying Song","Yifeng Lu","Nathan Hu","Dustin Tran","Daiyi Peng","Ruibo Liu","Da Huang","Cosmo Du","Quoc V. Le"],"pdf_url":"https://arxiv.org/pdf/2403.18802v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2305.13525v2","updated":"2024-03-27T17:47:56Z","published":"2023-05-22T22:41:49Z","title":"A 4D Hybrid Algorithm to Scale Parallel Training to Thousands of GPUs","summary":"  Large communication costs are a critical bottleneck in training\nstate-of-the-art neural networks on distributed systems. This paper introduces\nAxoNN, a novel four-dimensional (4D) parallelization approach, inspired by\nAgarwal's algorithm for matrix multiplication, for parallelizing tensor\ncomputations in deep learning, AxoNN employs two key strategies to minimize\ncommunication overhead. First, we optimize communication by overlapping\nexpensive collective operations (reduce-scatter, all-gather, all-reduce) with\ncomputations. Our experiments with a 20-billion parameter transformer model\ndemonstrate that these optimizations deliver nearly 53\\% improvement. Second,\nwe present an analytical model to assist users in identifying\ncommunication-minimizing configurations within the vast search space defined by\nour 4D algorithm. This model empowers practitioners by simplifying the tuning\nprocess for their specific training workloads. When training an 80-billion\nparameter model on 1024 GPUs of Perlmutter, AxoNN surpasses Megatron-LM, a\nstate-of-the-art framework, by a significant 26%. Additionally, it achieves 57%\nof the theoretical peak FLOP/s.\n","authors":["Siddharth Singh","Prajwal Singhania","Aditya K. Ranjan","Zack Sating","Abhinav Bhatele"],"pdf_url":"https://arxiv.org/pdf/2305.13525v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.13483v4","updated":"2024-03-27T17:38:27Z","published":"2023-02-27T02:42:27Z","title":"CrystalBox: Future-Based Explanations for Input-Driven Deep RL Systems","summary":"  We present CrystalBox, a novel, model-agnostic, posthoc explainability\nframework for Deep Reinforcement Learning (DRL) controllers in the large family\nof input-driven environments which includes computer systems. We combine the\nnatural decomposability of reward functions in input-driven environments with\nthe explanatory power of decomposed returns. We propose an efficient algorithm\nto generate future-based explanations across both discrete and continuous\ncontrol environments. Using applications such as adaptive bitrate streaming and\ncongestion control, we demonstrate CrystalBox's capability to generate\nhigh-fidelity explanations. We further illustrate its higher utility across\nthree practical use cases: contrastive explanations, network observability, and\nguided reward design, as opposed to prior explainability techniques that\nidentify salient features.\n","authors":["Sagar Patel","Sangeetha Abdu Jyothi","Nina Narodytska"],"pdf_url":"https://arxiv.org/pdf/2302.13483v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.18775v1","updated":"2024-03-27T17:23:39Z","published":"2024-03-27T17:23:39Z","title":"ImageNet-D: Benchmarking Neural Network Robustness on Diffusion\n  Synthetic Object","summary":"  We establish rigorous benchmarks for visual perception robustness. Synthetic\nimages such as ImageNet-C, ImageNet-9, and Stylized ImageNet provide specific\ntype of evaluation over synthetic corruptions, backgrounds, and textures, yet\nthose robustness benchmarks are restricted in specified variations and have low\nsynthetic quality. In this work, we introduce generative model as a data source\nfor synthesizing hard images that benchmark deep models' robustness. Leveraging\ndiffusion models, we are able to generate images with more diversified\nbackgrounds, textures, and materials than any prior work, where we term this\nbenchmark as ImageNet-D. Experimental results show that ImageNet-D results in a\nsignificant accuracy drop to a range of vision models, from the standard ResNet\nvisual classifier to the latest foundation models like CLIP and MiniGPT-4,\nsignificantly reducing their accuracy by up to 60\\%. Our work suggests that\ndiffusion models can be an effective source to test vision models. The code and\ndataset are available at https://github.com/chenshuang-zhang/imagenet_d.\n","authors":["Chenshuang Zhang","Fei Pan","Junmo Kim","In So Kweon","Chengzhi Mao"],"pdf_url":"https://arxiv.org/pdf/2403.18775v1.pdf","comment":"Accepted at CVPR 2024"},{"id":"http://arxiv.org/abs/2309.04381v2","updated":"2024-03-27T17:07:47Z","published":"2023-09-08T15:23:40Z","title":"Generalization Bounds: Perspectives from Information Theory and\n  PAC-Bayes","summary":"  A fundamental question in theoretical machine learning is generalization.\nOver the past decades, the PAC-Bayesian approach has been established as a\nflexible framework to address the generalization capabilities of machine\nlearning algorithms, and design new ones. Recently, it has garnered increased\ninterest due to its potential applicability for a variety of learning\nalgorithms, including deep neural networks. In parallel, an\ninformation-theoretic view of generalization has developed, wherein the\nrelation between generalization and various information measures has been\nestablished. This framework is intimately connected to the PAC-Bayesian\napproach, and a number of results have been independently discovered in both\nstrands. In this monograph, we highlight this strong connection and present a\nunified treatment of PAC-Bayesian and information-theoretic generalization\nbounds. We present techniques and results that the two perspectives have in\ncommon, and discuss the approaches and interpretations that differ. In\nparticular, we demonstrate how many proofs in the area share a modular\nstructure, through which the underlying ideas can be intuited. We pay special\nattention to the conditional mutual information (CMI) framework; analytical\nstudies of the information complexity of learning algorithms; and the\napplication of the proposed methods to deep learning. This monograph is\nintended to provide a comprehensive introduction to information-theoretic\ngeneralization bounds and their connection to PAC-Bayes, serving as a\nfoundation from which the most recent developments are accessible. It is aimed\nbroadly towards researchers with an interest in generalization and theoretical\nmachine learning.\n","authors":["Fredrik Hellstr√∂m","Giuseppe Durisi","Benjamin Guedj","Maxim Raginsky"],"pdf_url":"https://arxiv.org/pdf/2309.04381v2.pdf","comment":"228 pages"},{"id":"http://arxiv.org/abs/2403.06054v4","updated":"2024-03-27T17:06:10Z","published":"2024-03-10T00:47:05Z","title":"Decoupled Data Consistency with Diffusion Purification for Image\n  Restoration","summary":"  Diffusion models have recently gained traction as a powerful class of deep\ngenerative priors, excelling in a wide range of image restoration tasks due to\ntheir exceptional ability to model data distributions. To solve image\nrestoration problems, many existing techniques achieve data consistency by\nincorporating additional likelihood gradient steps into the reverse sampling\nprocess of diffusion models. However, the additional gradient steps pose a\nchallenge for real-world practical applications as they incur a large\ncomputational overhead, thereby increasing inference time. They also present\nadditional difficulties when using accelerated diffusion model samplers, as the\nnumber of data consistency steps is limited by the number of reverse sampling\nsteps. In this work, we propose a novel diffusion-based image restoration\nsolver that addresses these issues by decoupling the reverse process from the\ndata consistency steps. Our method involves alternating between a\nreconstruction phase to maintain data consistency and a refinement phase that\nenforces the prior via diffusion purification. Our approach demonstrates\nversatility, making it highly adaptable for efficient problem-solving in latent\nspace. Additionally, it reduces the necessity for numerous sampling steps\nthrough the integration of consistency models. The efficacy of our approach is\nvalidated through comprehensive experiments across various image restoration\ntasks, including image denoising, deblurring, inpainting, and super-resolution.\n","authors":["Xiang Li","Soo Min Kwon","Ismail R. Alkhouri","Saiprasad Ravishankar","Qing Qu"],"pdf_url":"https://arxiv.org/pdf/2403.06054v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.18766v1","updated":"2024-03-27T17:05:03Z","published":"2024-03-27T17:05:03Z","title":"Superior Parallel Big Data Clustering through Competitive Stochastic\n  Sample Size Optimization in Big-means","summary":"  This paper introduces a novel K-means clustering algorithm, an advancement on\nthe conventional Big-means methodology. The proposed method efficiently\nintegrates parallel processing, stochastic sampling, and competitive\noptimization to create a scalable variant designed for big data applications.\nIt addresses scalability and computation time challenges typically faced with\ntraditional techniques. The algorithm adjusts sample sizes dynamically for each\nworker during execution, optimizing performance. Data from these sample sizes\nare continually analyzed, facilitating the identification of the most efficient\nconfiguration. By incorporating a competitive element among workers using\ndifferent sample sizes, efficiency within the Big-means algorithm is further\nstimulated. In essence, the algorithm balances computational time and\nclustering quality by employing a stochastic, competitive sampling strategy in\na parallel computing setting.\n","authors":["Rustam Mussabayev","Ravil Mussabayev"],"pdf_url":"https://arxiv.org/pdf/2403.18766v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.18765v1","updated":"2024-03-27T17:03:31Z","published":"2024-03-27T17:03:31Z","title":"CaT: Constraints as Terminations for Legged Locomotion Reinforcement\n  Learning","summary":"  Deep Reinforcement Learning (RL) has demonstrated impressive results in\nsolving complex robotic tasks such as quadruped locomotion. Yet, current\nsolvers fail to produce efficient policies respecting hard constraints. In this\nwork, we advocate for integrating constraints into robot learning and present\nConstraints as Terminations (CaT), a novel constrained RL algorithm. Departing\nfrom classical constrained RL formulations, we reformulate constraints through\nstochastic terminations during policy learning: any violation of a constraint\ntriggers a probability of terminating potential future rewards the RL agent\ncould attain. We propose an algorithmic approach to this formulation, by\nminimally modifying widely used off-the-shelf RL algorithms in robot learning\n(such as Proximal Policy Optimization). Our approach leads to excellent\nconstraint adherence without introducing undue complexity and computational\noverhead, thus mitigating barriers to broader adoption. Through empirical\nevaluation on the real quadruped robot Solo crossing challenging obstacles, we\ndemonstrate that CaT provides a compelling solution for incorporating\nconstraints into RL frameworks. Videos and code are available at\nhttps://constraints-as-terminations.github.io.\n","authors":["Elliot Chane-Sane","Pierre-Alexandre Leziart","Thomas Flayols","Olivier Stasse","Philippe Sou√®res","Nicolas Mansard"],"pdf_url":"https://arxiv.org/pdf/2403.18765v1.pdf","comment":"Project webpage: https://constraints-as-terminations.github.io"},{"id":"http://arxiv.org/abs/2311.01483v3","updated":"2024-03-27T16:56:23Z","published":"2023-11-02T14:47:06Z","title":"FedSN: A Novel Federated Learning Framework over LEO Satellite Networks","summary":"  Recently, a large number of Low Earth Orbit (LEO) satellites have been\nlaunched and deployed successfully in space by commercial companies, such as\nSpaceX. Due to multimodal sensors equipped by the LEO satellites, they serve\nnot only for communication but also for various machine learning applications,\nsuch as space modulation recognition, remote sensing image classification, etc.\nHowever, the ground station (GS) may be incapable of downloading such a large\nvolume of raw sensing data for centralized model training due to the limited\ncontact time with LEO satellites (e.g. 5 minutes). Therefore, federated\nlearning (FL) has emerged as the promising solution to address this problem via\non-device training. Unfortunately, to enable FL on LEO satellites, we still\nface three critical challenges that are i) heterogeneous computing and memory\ncapabilities, ii) limited uplink rate, and iii) model staleness. To this end,\nwe propose FedSN as a general FL framework to tackle the above challenges, and\nfully explore data diversity on LEO satellites. Specifically, we first present\na novel sub-structure scheme to enable heterogeneous local model training\nconsidering different computing, memory, and communication constraints on LEO\nsatellites. Additionally, we propose a pseudo-synchronous model aggregation\nstrategy to dynamically schedule model aggregation for compensating model\nstaleness. To further demonstrate the effectiveness of the FedSN, we evaluate\nit using space modulation recognition and remote sensing image classification\ntasks by leveraging the data from real-world satellite networks. Extensive\nexperimental results demonstrate that FedSN framework achieves higher accuracy,\nlower computing, and communication overhead than the state-of-the-art\nbenchmarks and the effectiveness of each components in FedSN.\n","authors":["Zheng Lin","Zhe Chen","Zihan Fang","Xianhao Chen","Xiong Wang","Yue Gao"],"pdf_url":"https://arxiv.org/pdf/2311.01483v3.pdf","comment":"14 pages, 17 figures"},{"id":"http://arxiv.org/abs/2403.18756v1","updated":"2024-03-27T16:56:14Z","published":"2024-03-27T16:56:14Z","title":"Detection of subclinical atherosclerosis by image-based deep learning on\n  chest x-ray","summary":"  Aims. To develop a deep-learning based system for recognition of subclinical\natherosclerosis on a plain frontal chest x-ray. Methods and Results. A\ndeep-learning algorithm to predict coronary artery calcium (CAC) score (the\nAI-CAC model) was developed on 460 chest x-ray (80% training cohort, 20%\ninternal validation cohort) of primary prevention patients (58.4% male, median\nage 63 [51-74] years) with available paired chest x-ray and chest computed\ntomography (CT) indicated for any clinical reason and performed within 3\nmonths. The CAC score calculated on chest CT was used as ground truth. The\nmodel was validated on an temporally-independent cohort of 90 patients from the\nsame institution (external validation). The diagnostic accuracy of the AI-CAC\nmodel assessed by the area under the curve (AUC) was the primary outcome.\nOverall, median AI-CAC score was 35 (0-388) and 28.9% patients had no AI-CAC.\nAUC of the AI-CAC model to identify a CAC>0 was 0.90 in the internal validation\ncohort and 0.77 in the external validation cohort. Sensitivity was consistently\nabove 92% in both cohorts. In the overall cohort (n=540), among patients with\nAI-CAC=0, a single ASCVD event occurred, after 4.3 years. Patients with\nAI-CAC>0 had significantly higher Kaplan Meier estimates for ASCVD events\n(13.5% vs. 3.4%, log-rank=0.013). Conclusion. The AI-CAC model seems to\naccurately detect subclinical atherosclerosis on chest x-ray with elevated\nsensitivity, and to predict ASCVD events with elevated negative predictive\nvalue. Adoption of the AI-CAC model to refine CV risk stratification or as an\nopportunistic screening tool requires prospective evaluation.\n","authors":["Guglielmo Gallone","Francesco Iodice","Alberto Presta","Davide Tore","Ovidio de Filippo","Michele Visciano","Carlo Alberto Barbano","Alessandro Serafini","Paola Gorrini","Alessandro Bruno","Walter Grosso Marra","James Hughes","Mario Iannaccone","Paolo Fonio","Attilio Fiandrotti","Alessandro Depaoli","Marco Grangetto","Gaetano Maria de Ferrari","Fabrizio D'Ascenzo"],"pdf_url":"https://arxiv.org/pdf/2403.18756v1.pdf","comment":"Submitted to European Heart Journal - Cardiovascular Imaging Added\n  also the additional material 44 pages (30 main paper, 14 additional\n  material), 14 figures (5 main manuscript, 9 additional material)"},{"id":"http://arxiv.org/abs/2403.14623v2","updated":"2024-03-27T16:49:35Z","published":"2024-03-21T17:59:41Z","title":"Simplified Diffusion Schr√∂dinger Bridge","summary":"  This paper introduces a novel theoretical simplification of the Diffusion\nSchr\\\"odinger Bridge (DSB) that facilitates its unification with Score-based\nGenerative Models (SGMs), addressing the limitations of DSB in complex data\ngeneration and enabling faster convergence and enhanced performance. By\nemploying SGMs as an initial solution for DSB, our approach capitalizes on the\nstrengths of both frameworks, ensuring a more efficient training process and\nimproving the performance of SGM. We also propose a reparameterization\ntechnique that, despite theoretical approximations, practically improves the\nnetwork's fitting capabilities. Our extensive experimental evaluations confirm\nthe effectiveness of the simplified DSB, demonstrating its significant\nimprovements. We believe the contributions of this work pave the way for\nadvanced generative modeling. The code is available at\nhttps://github.com/checkcrab/SDSB.\n","authors":["Zhicong Tang","Tiankai Hang","Shuyang Gu","Dong Chen","Baining Guo"],"pdf_url":"https://arxiv.org/pdf/2403.14623v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.03683v2","updated":"2024-03-27T16:44:22Z","published":"2023-11-07T03:19:16Z","title":"Preventing Arbitrarily High Confidence on Far-Away Data in\n  Point-Estimated Discriminative Neural Networks","summary":"  Discriminatively trained, deterministic neural networks are the de facto\nchoice for classification problems. However, even though they achieve\nstate-of-the-art results on in-domain test sets, they tend to be overconfident\non out-of-distribution (OOD) data. For instance, ReLU networks - a popular\nclass of neural network architectures - have been shown to almost always yield\nhigh confidence predictions when the test data are far away from the training\nset, even when they are trained with OOD data. We overcome this problem by\nadding a term to the output of the neural network that corresponds to the logit\nof an extra class, that we design to dominate the logits of the original\nclasses as we move away from the training data.This technique provably prevents\narbitrarily high confidence on far-away test data while maintaining a simple\ndiscriminative point-estimate training. Evaluation on various benchmarks\ndemonstrates strong performance against competitive baselines on both far-away\nand realistic OOD data.\n","authors":["Ahmad Rashid","Serena Hacker","Guojun Zhang","Agustinus Kristiadi","Pascal Poupart"],"pdf_url":"https://arxiv.org/pdf/2311.03683v2.pdf","comment":"Accepted at AISTATS 2024"},{"id":"http://arxiv.org/abs/2403.18742v1","updated":"2024-03-27T16:39:28Z","published":"2024-03-27T16:39:28Z","title":"Understanding the Learning Dynamics of Alignment with Human Feedback","summary":"  Aligning large language models (LLMs) with human intentions has become a\ncritical task for safely deploying models in real-world systems. While existing\nalignment approaches have seen empirical success, theoretically understanding\nhow these methods affect model behavior remains an open question. Our work\nprovides an initial attempt to theoretically analyze the learning dynamics of\nhuman preference alignment. We formally show how the distribution of preference\ndatasets influences the rate of model updates and provide rigorous guarantees\non the training accuracy. Our theory also reveals an intricate phenomenon where\nthe optimization is prone to prioritizing certain behaviors with higher\npreference distinguishability. We empirically validate our findings on\ncontemporary LLMs and alignment tasks, reinforcing our theoretical insights and\nshedding light on considerations for future alignment approaches. Disclaimer:\nThis paper contains potentially offensive text; reader discretion is advised.\n","authors":["Shawn Im","Yixuan Li"],"pdf_url":"https://arxiv.org/pdf/2403.18742v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.18739v1","updated":"2024-03-27T16:32:32Z","published":"2024-03-27T16:32:32Z","title":"Usage-Specific Survival Modeling Based on Operational Data and Neural\n  Networks","summary":"  Accurate predictions of when a component will fail are crucial when planning\nmaintenance, and by modeling the distribution of these failure times, survival\nmodels have shown to be particularly useful in this context. The presented\nmethodology is based on conventional neural network-based survival models that\nare trained using data that is continuously gathered and stored at specific\ntimes, called snapshots. An important property of this type of training data is\nthat it can contain more than one snapshot from a specific individual which\nresults in that standard maximum likelihood training can not be directly\napplied since the data is not independent. However, the papers show that if the\ndata is in a specific format where all snapshot times are the same for all\nindividuals, called homogeneously sampled, maximum likelihood training can be\napplied and produce desirable results. In many cases, the data is not\nhomogeneously sampled and in this case, it is proposed to resample the data to\nmake it homogeneously sampled. How densely the dataset is sampled turns out to\nbe an important parameter; it should be chosen large enough to produce good\nresults, but this also increases the size of the dataset which makes training\nslow. To reduce the number of samples needed during training, the paper also\nproposes a technique to, instead of resampling the dataset once before the\ntraining starts, randomly resample the dataset at the start of each epoch\nduring the training. The proposed methodology is evaluated on both a simulated\ndataset and an experimental dataset of starter battery failures. The results\nshow that if the data is homogeneously sampled the methodology works as\nintended and produces accurate survival models. The results also show that\nrandomly resampling the dataset on each epoch is an effective way to reduce the\nsize of the training data.\n","authors":["Olov Holmer","Mattias Krysander","Erik Frisk"],"pdf_url":"https://arxiv.org/pdf/2403.18739v1.pdf","comment":"7 pages"},{"id":"http://arxiv.org/abs/2403.18735v1","updated":"2024-03-27T16:24:26Z","published":"2024-03-27T16:24:26Z","title":"Nonlinear model reduction for operator learning","summary":"  Operator learning provides methods to approximate mappings between\ninfinite-dimensional function spaces. Deep operator networks (DeepONets) are a\nnotable architecture in this field. Recently, an extension of DeepONet based on\nmodel reduction and neural networks, proper orthogonal decomposition\n(POD)-DeepONet, has been able to outperform other architectures in terms of\naccuracy for several benchmark tests. We extend this idea towards nonlinear\nmodel order reduction by proposing an efficient framework that combines neural\nnetworks with kernel principal component analysis (KPCA) for operator learning.\nOur results demonstrate the superior performance of KPCA-DeepONet over\nPOD-DeepONet.\n","authors":["Hamidreza Eivazi","Stefan Wittek","Andreas Rausch"],"pdf_url":"https://arxiv.org/pdf/2403.18735v1.pdf","comment":"Published as a Tiny Paper at ICLR 2024 (Notable)"},{"id":"http://arxiv.org/abs/2403.18731v1","updated":"2024-03-27T16:21:24Z","published":"2024-03-27T16:21:24Z","title":"Enhancing Manufacturing Quality Prediction Models through the\n  Integration of Explainability Methods","summary":"  This research presents a method that utilizes explainability techniques to\namplify the performance of machine learning (ML) models in forecasting the\nquality of milling processes, as demonstrated in this paper through a\nmanufacturing use case. The methodology entails the initial training of ML\nmodels, followed by a fine-tuning phase where irrelevant features identified\nthrough explainability methods are eliminated. This procedural refinement\nresults in performance enhancements, paving the way for potential reductions in\nmanufacturing costs and a better understanding of the trained ML models. This\nstudy highlights the usefulness of explainability techniques in both explaining\nand optimizing predictive models in the manufacturing realm.\n","authors":["Dennis Gross","Helge Spieker","Arnaud Gotlieb","Ricardo Knoblauch"],"pdf_url":"https://arxiv.org/pdf/2403.18731v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.03100v2","updated":"2024-03-27T16:14:34Z","published":"2024-03-05T16:35:25Z","title":"NaturalSpeech 3: Zero-Shot Speech Synthesis with Factorized Codec and\n  Diffusion Models","summary":"  While recent large-scale text-to-speech (TTS) models have achieved\nsignificant progress, they still fall short in speech quality, similarity, and\nprosody. Considering speech intricately encompasses various attributes (e.g.,\ncontent, prosody, timbre, and acoustic details) that pose significant\nchallenges for generation, a natural idea is to factorize speech into\nindividual subspaces representing different attributes and generate them\nindividually. Motivated by it, we propose NaturalSpeech 3, a TTS system with\nnovel factorized diffusion models to generate natural speech in a zero-shot\nway. Specifically, 1) we design a neural codec with factorized vector\nquantization (FVQ) to disentangle speech waveform into subspaces of content,\nprosody, timbre, and acoustic details; 2) we propose a factorized diffusion\nmodel to generate attributes in each subspace following its corresponding\nprompt. With this factorization design, NaturalSpeech 3 can effectively and\nefficiently model intricate speech with disentangled subspaces in a\ndivide-and-conquer way. Experiments show that NaturalSpeech 3 outperforms the\nstate-of-the-art TTS systems on quality, similarity, prosody, and\nintelligibility, and achieves on-par quality with human recordings.\nFurthermore, we achieve better performance by scaling to 1B parameters and 200K\nhours of training data.\n","authors":["Zeqian Ju","Yuancheng Wang","Kai Shen","Xu Tan","Detai Xin","Dongchao Yang","Yanqing Liu","Yichong Leng","Kaitao Song","Siliang Tang","Zhizheng Wu","Tao Qin","Xiang-Yang Li","Wei Ye","Shikun Zhang","Jiang Bian","Lei He","Jinyu Li","Sheng Zhao"],"pdf_url":"https://arxiv.org/pdf/2403.03100v2.pdf","comment":"Achieving human-level quality and naturalness on multi-speaker\n  datasets (e.g., LibriSpeech) in a zero-shot way"},{"id":"http://arxiv.org/abs/2402.07868v2","updated":"2024-03-27T16:12:43Z","published":"2024-02-12T18:29:17Z","title":"Nesting Particle Filters for Experimental Design in Dynamical Systems","summary":"  In this paper, we propose a novel approach to Bayesian experimental design\nfor non-exchangeable data that formulates it as risk-sensitive policy\noptimization. We develop the Inside-Out SMC$^2$ algorithm, a nested sequential\nMonte Carlo technique to infer optimal designs, and embed it into a particle\nMarkov chain Monte Carlo framework to perform gradient-based policy\namortization. Our approach is distinct from other amortized experimental design\ntechniques, as it does not rely on contrastive estimators. Numerical validation\non a set of dynamical systems showcases the efficacy of our method in\ncomparison to other state-of-the-art strategies.\n","authors":["Sahel Iqbal","Adrien Corenflos","Simo S√§rkk√§","Hany Abdulsamad"],"pdf_url":"https://arxiv.org/pdf/2402.07868v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2309.11798v3","updated":"2024-03-27T16:12:18Z","published":"2023-09-21T06:04:06Z","title":"A Comprehensive Review of Community Detection in Graphs","summary":"  The study of complex networks has significantly advanced our understanding of\ncommunity structures which serves as a crucial feature of real-world graphs.\nDetecting communities in graphs is a challenging problem with applications in\nsociology, biology, and computer science. Despite the efforts of an\ninterdisciplinary community of scientists, a satisfactory solution to this\nproblem has not yet been achieved. This review article delves into the topic of\ncommunity detection in graphs, which serves as a thorough exposition of various\ncommunity detection methods from perspectives of modularity-based method,\nspectral clustering, probabilistic modelling, and deep learning. Along with the\nmethods, a new community detection method designed by us is also presented.\nAdditionally, the performance of these methods on the datasets with and without\nground truth is compared. In conclusion, this comprehensive review provides a\ndeep understanding of community detection in graphs.\n","authors":["Jiakang Li","Songning Lai","Zhihao Shuai","Yuan Tan","Yifan Jia","Mianyang Yu","Zichen Song","Xiaokang Peng","Ziyang Xu","Yongxin Ni","Haifeng Qiu","Jiayu Yang","Yutong Liu","Yonggang Lu"],"pdf_url":"https://arxiv.org/pdf/2309.11798v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.18717v1","updated":"2024-03-27T16:06:37Z","published":"2024-03-27T16:06:37Z","title":"Semi-Supervised Learning for Deep Causal Generative Models","summary":"  Developing models that can answer questions of the form \"How would $x$ change\nif $y$ had been $z$?\" is fundamental for advancing medical image analysis.\nTraining causal generative models that address such counterfactual questions,\nthough, currently requires that all relevant variables have been observed and\nthat corresponding labels are available in training data. However, clinical\ndata may not have complete records for all patients and state of the art causal\ngenerative models are unable to take full advantage of this. We thus develop,\nfor the first time, a semi-supervised deep causal generative model that\nexploits the causal relationships between variables to maximise the use of all\navailable data. We explore this in the setting where each sample is either\nfully labelled or fully unlabelled, as well as the more clinically realistic\ncase of having different labels missing for each sample. We leverage techniques\nfrom causal inference to infer missing values and subsequently generate\nrealistic counterfactuals, even for samples with incomplete labels.\n","authors":["Yasin Ibrahim","Hermione Warr","Konstantinos Kamnitsas"],"pdf_url":"https://arxiv.org/pdf/2403.18717v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2401.07494v3","updated":"2024-03-27T16:06:34Z","published":"2024-01-15T06:26:53Z","title":"Input Convex Lipschitz RNN: A Fast and Robust Approach for Engineering\n  Tasks","summary":"  Computational efficiency and non-adversarial robustness are critical factors\nin real-world engineering applications. Yet, conventional neural networks often\nfall short in addressing both simultaneously, or even separately. Drawing\ninsights from natural physical systems and existing literature, it is known\nthat an input convex architecture enhances computational efficiency, while a\nLipschitz-constrained architecture bolsters non-adversarial robustness. By\nleveraging the strengths of convexity and Lipschitz continuity, we develop a\nnovel network architecture, termed Input Convex Lipschitz Recurrent Neural\nNetworks. This model is explicitly designed for fast and robust\noptimization-based tasks and outperforms existing recurrent units across a\nspectrum of engineering tasks in terms of computational efficiency and\nnon-adversarial robustness, including real-world solar irradiance prediction\nfor Solar PV system planning at LHT Holdings in Singapore and real-time Model\nPredictive Control optimization for a nonlinear chemical reactor.\n","authors":["Zihao Wang","P S Pravin","Zhe Wu"],"pdf_url":"https://arxiv.org/pdf/2401.07494v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2305.03123v3","updated":"2024-03-27T16:03:32Z","published":"2023-04-13T16:01:28Z","title":"ChatGPT Needs SPADE (Sustainability, PrivAcy, Digital divide, and\n  Ethics) Evaluation: A Review","summary":"  ChatGPT is another large language model (LLM) vastly available for the\nconsumers on their devices but due to its performance and ability to converse\neffectively, it has gained a huge popularity amongst research as well as\nindustrial community. Recently, many studies have been published to show the\neffectiveness, efficiency, integration, and sentiments of chatGPT and other\nLLMs. In contrast, this study focuses on the important aspects that are mostly\noverlooked, i.e. sustainability, privacy, digital divide, and ethics and\nsuggests that not only chatGPT but every subsequent entry in the category of\nconversational bots should undergo Sustainability, PrivAcy, Digital divide, and\nEthics (SPADE) evaluation. This paper discusses in detail the issues and\nconcerns raised over chatGPT in line with aforementioned characteristics. We\nalso discuss the recent EU AI Act briefly in accordance with the SPADE\nevaluation. We support our hypothesis by some preliminary data collection and\nvisualizations along with hypothesized facts. We also suggest mitigations and\nrecommendations for each of the concerns. Furthermore, we also suggest some\npolicies and recommendations for EU AI policy act concerning ethics, digital\ndivide, and sustainability.\n","authors":["Sunder Ali Khowaja","Parus Khuwaja","Kapal Dev","Weizheng Wang","Lewis Nkenyereye"],"pdf_url":"https://arxiv.org/pdf/2305.03123v3.pdf","comment":"29 pages, 8 figures, 4 tables"},{"id":"http://arxiv.org/abs/2403.17878v2","updated":"2024-03-27T16:01:00Z","published":"2024-03-26T17:10:15Z","title":"Empowering Data Mesh with Federated Learning","summary":"  The evolution of data architecture has seen the rise of data lakes, aiming to\nsolve the bottlenecks of data management and promote intelligent\ndecision-making. However, this centralized architecture is limited by the\nproliferation of data sources and the growing demand for timely analysis and\nprocessing. A new data paradigm, Data Mesh, is proposed to overcome these\nchallenges. Data Mesh treats domains as a first-class concern by distributing\nthe data ownership from the central team to each data domain, while keeping the\nfederated governance to monitor domains and their data products. Many\nmulti-million dollar organizations like Paypal, Netflix, and Zalando have\nalready transformed their data analysis pipelines based on this new\narchitecture. In this decentralized architecture where data is locally\npreserved by each domain team, traditional centralized machine learning is\nincapable of conducting effective analysis across multiple domains, especially\nfor security-sensitive organizations. To this end, we introduce a pioneering\napproach that incorporates Federated Learning into Data Mesh. To the best of\nour knowledge, this is the first open-source applied work that represents a\ncritical advancement toward the integration of federated learning methods into\nthe Data Mesh paradigm, underscoring the promising prospects for\nprivacy-preserving and decentralized data analysis strategies within Data Mesh\narchitecture.\n","authors":["Haoyuan Li","Salman Toor"],"pdf_url":"https://arxiv.org/pdf/2403.17878v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.18710v1","updated":"2024-03-27T15:57:42Z","published":"2024-03-27T15:57:42Z","title":"Deep Learning for Traffic Flow Prediction using Cellular Automata-based\n  Model and CNN-LSTM architecture","summary":"  Recent works have attempted to use deep learning to predict future states of\ntraffic flow, but have met with mixed results. These approaches face two key\nchallenges. First, training deep learning neural networks requires large\namounts of training data which are not yet easily available for traffic flow\nsystems. Second, even when data is available, the neural networks require\naccess to historical data that covers most possible traffic flow dynamics to\nsuccessfully predict future traffic states. Specifically, these deep learning\napproaches do not fully leverage domain-knowledge about traffic flow dynamics,\ndespite a significant existing knowledge-base. In this work, we propose to\nsolve both issues using a Convolutional Neural Network (CNNs) with Long Short\nTerm Memory (LSTM) deep learning architecture to successfully predict traffic\nflow, while leveraging a cellular automata-based statistical mechanics model of\ntraffic flow to generate training and test data. Another major contribution of\nthis paper is the insight that training data for a large traffic system can\nactually be sampled from the simulations of a much smaller traffic system. This\nis achieved through observing that the normalized energy distribution of the\nstatistical mechanics model is scale invariant, which significantly eases the\nburden of data generation for large scale traffic systems. The resulting\nsimulations indicate good agreement between the predicted and the true traffic\nflow dynamics.\n","authors":["Zhaohui Yang","Kshitij Jerath"],"pdf_url":"https://arxiv.org/pdf/2403.18710v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.18705v1","updated":"2024-03-27T15:54:55Z","published":"2024-03-27T15:54:55Z","title":"Conditional Wasserstein Distances with Applications in Bayesian OT Flow\n  Matching","summary":"  In inverse problems, many conditional generative models approximate the\nposterior measure by minimizing a distance between the joint measure and its\nlearned approximation. While this approach also controls the distance between\nthe posterior measures in the case of the Kullback--Leibler divergence, this is\nin general not hold true for the Wasserstein distance. In this paper, we\nintroduce a conditional Wasserstein distance via a set of restricted couplings\nthat equals the expected Wasserstein distance of the posteriors. Interestingly,\nthe dual formulation of the conditional Wasserstein-1 flow resembles losses in\nthe conditional Wasserstein GAN literature in a quite natural way. We derive\ntheoretical properties of the conditional Wasserstein distance, characterize\nthe corresponding geodesics and velocity fields as well as the flow ODEs.\nSubsequently, we propose to approximate the velocity fields by relaxing the\nconditional Wasserstein distance. Based on this, we propose an extension of OT\nFlow Matching for solving Bayesian inverse problems and demonstrate its\nnumerical advantages on an inverse problem and class-conditional image\ngeneration.\n","authors":["Jannis Chemseddine","Paul Hagemann","Christian Wald","Gabriele Steidl"],"pdf_url":"https://arxiv.org/pdf/2403.18705v1.pdf","comment":"This paper supersedes arXiv:2310.13433"},{"id":"http://arxiv.org/abs/2403.18703v1","updated":"2024-03-27T15:52:54Z","published":"2024-03-27T15:52:54Z","title":"Fpga-Based Neural Thrust Controller for UAVs","summary":"  The advent of unmanned aerial vehicles (UAVs) has improved a variety of\nfields by providing a versatile, cost-effective and accessible platform for\nimplementing state-of-the-art algorithms. To accomplish a broader range of\ntasks, there is a growing need for enhanced on-board computing to cope with\nincreasing complexity and dynamic environmental conditions. Recent advances\nhave seen the application of Deep Neural Networks (DNNs), particularly in\ncombination with Reinforcement Learning (RL), to improve the adaptability and\nperformance of UAVs, especially in unknown environments. However, the\ncomputational requirements of DNNs pose a challenge to the limited computing\nresources available on many UAVs. This work explores the use of Field\nProgrammable Gate Arrays (FPGAs) as a viable solution to this challenge,\noffering flexibility, high performance, energy and time efficiency. We propose\na novel hardware board equipped with an Artix-7 FPGA for a popular open-source\nmicro-UAV platform. We successfully validate its functionality by implementing\nan RL-based low-level controller using real-world experiments.\n","authors":["Sharif Azem","David Scheunert","Mengguang Li","Jonas Gehrunger","Kai Cui","Christian Hochberger","Heinz Koepp"],"pdf_url":"https://arxiv.org/pdf/2403.18703v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.11800v3","updated":"2024-03-27T15:48:29Z","published":"2024-02-19T03:08:02Z","title":"Stochastic Approximation with Delayed Updates: Finite-Time Rates under\n  Markovian Sampling","summary":"  Motivated by applications in large-scale and multi-agent reinforcement\nlearning, we study the non-asymptotic performance of stochastic approximation\n(SA) schemes with delayed updates under Markovian sampling. While the effect of\ndelays has been extensively studied for optimization, the manner in which they\ninteract with the underlying Markov process to shape the finite-time\nperformance of SA remains poorly understood. In this context, our first main\ncontribution is to show that under time-varying bounded delays, the delayed SA\nupdate rule guarantees exponentially fast convergence of the \\emph{last\niterate} to a ball around the SA operator's fixed point. Notably, our bound is\n\\emph{tight} in its dependence on both the maximum delay $\\tau_{max}$, and the\nmixing time $\\tau_{mix}$. To achieve this tight bound, we develop a novel\ninductive proof technique that, unlike various existing delayed-optimization\nanalyses, relies on establishing uniform boundedness of the iterates. As such,\nour proof may be of independent interest. Next, to mitigate the impact of the\nmaximum delay on the convergence rate, we provide the first finite-time\nanalysis of a delay-adaptive SA scheme under Markovian sampling. In particular,\nwe show that the exponent of convergence of this scheme gets scaled down by\n$\\tau_{avg}$, as opposed to $\\tau_{max}$ for the vanilla delayed SA rule; here,\n$\\tau_{avg}$ denotes the average delay across all iterations. Moreover, the\nadaptive scheme requires no prior knowledge of the delay sequence for step-size\ntuning. Our theoretical findings shed light on the finite-time effects of\ndelays for a broad class of algorithms, including TD learning, Q-learning, and\nstochastic gradient descent under Markovian sampling.\n","authors":["Arman Adibi","Nicolo Dal Fabbro","Luca Schenato","Sanjeev Kulkarni","H. Vincent Poor","George J. Pappas","Hamed Hassani","Aritra Mitra"],"pdf_url":"https://arxiv.org/pdf/2402.11800v3.pdf","comment":"Accepted to the 27th International Conference on Artificial\n  Intelligence and Statistics (AISTATS) 2024!"},{"id":"http://arxiv.org/abs/2403.18699v1","updated":"2024-03-27T15:48:16Z","published":"2024-03-27T15:48:16Z","title":"Contrastive Learning with Orthonormal Anchors (CLOA)","summary":"  This study focuses on addressing the instability issues prevalent in\ncontrastive learning, specifically examining the InfoNCE loss function and its\nderivatives. We reveal a critical observation that these loss functions exhibit\na restrictive behavior, leading to a convergence phenomenon where embeddings\ntend to merge into a singular point. This \"over-fusion\" effect detrimentally\naffects classification accuracy in subsequent supervised-learning tasks.\nThrough theoretical analysis, we demonstrate that embeddings, when equalized or\nconfined to a rank-1 linear subspace, represent a local minimum for InfoNCE. In\nresponse to this challenge, our research introduces an innovative strategy that\nleverages the same or fewer labeled data than typically used in the fine-tuning\nphase. The loss we proposed, Orthonormal Anchor Regression Loss, is designed to\ndisentangle embedding clusters, significantly enhancing the distinctiveness of\neach embedding while simultaneously ensuring their aggregation into dense,\nwell-defined clusters. Our method demonstrates remarkable improvements with\njust a fraction of the conventional label requirements, as evidenced by our\nresults on CIFAR10 and CIFAR100 datasets.\n","authors":["Huanran Li","Daniel Pimentel-Alarc√≥n"],"pdf_url":"https://arxiv.org/pdf/2403.18699v1.pdf","comment":"11 pages, 4 figures"},{"id":"http://arxiv.org/abs/2303.12091v3","updated":"2024-03-27T15:44:25Z","published":"2023-03-21T09:07:15Z","title":"Adaptive Negative Evidential Deep Learning for Open-set Semi-supervised\n  Learning","summary":"  Semi-supervised learning (SSL) methods assume that labeled data, unlabeled\ndata and test data are from the same distribution. Open-set semi-supervised\nlearning (Open-set SSL) considers a more practical scenario, where unlabeled\ndata and test data contain new categories (outliers) not observed in labeled\ndata (inliers). Most previous works focused on outlier detection via binary\nclassifiers, which suffer from insufficient scalability and inability to\ndistinguish different types of uncertainty. In this paper, we propose a novel\nframework, Adaptive Negative Evidential Deep Learning (ANEDL) to tackle these\nlimitations. Concretely, we first introduce evidential deep learning (EDL) as\nan outlier detector to quantify different types of uncertainty, and design\ndifferent uncertainty metrics for self-training and inference. Furthermore, we\npropose a novel adaptive negative optimization strategy, making EDL more\ntailored to the unlabeled dataset containing both inliers and outliers. As\ndemonstrated empirically, our proposed method outperforms existing\nstate-of-the-art methods across four datasets.\n","authors":["Yang Yu","Danruo Deng","Furui Liu","Yueming Jin","Qi Dou","Guangyong Chen","Pheng-Ann Heng"],"pdf_url":"https://arxiv.org/pdf/2303.12091v3.pdf","comment":"Accepted by AAAI2024"},{"id":"http://arxiv.org/abs/2403.18687v1","updated":"2024-03-27T15:34:27Z","published":"2024-03-27T15:34:27Z","title":"InceptionTime vs. Wavelet -- A comparison for time series classification","summary":"  Neural networks were used to classify infrasound data. Two different\napproaches were compared. One based on the direct classification of time series\ndata, using a custom implementation of the InceptionTime network. For the other\napproach, we generated 2D images of the wavelet transformation of the signals,\nwhich were subsequently classified using a ResNet implementation. Choosing\nappropriate hyperparameter settings, both achieve a classification accuracy of\nabove 90 %, with the direct approach reaching 95.2 %.\n","authors":["Daniel Klenkert","Daniel Schaeffer","Julian Stauch"],"pdf_url":"https://arxiv.org/pdf/2403.18687v1.pdf","comment":"4 pages, 1 figure"},{"id":"http://arxiv.org/abs/2403.18685v1","updated":"2024-03-27T15:29:08Z","published":"2024-03-27T15:29:08Z","title":"Representatividad Muestral en la Incertidumbre Sim√©trica Multivariada\n  para la Selecci√≥n de Atributos","summary":"  In this work, we analyze the behavior of the multivariate symmetric\nuncertainty (MSU) measure through the use of statistical simulation techniques\nunder various mixes of informative and non-informative randomly generated\nfeatures. Experiments show how the number of attributes, their cardinalities,\nand the sample size affect the MSU. In this thesis, through observation of\nresults, it is proposed an heuristic condition that preserves good quality in\nthe MSU under different combinations of these three factors, providing a new\nuseful criterion to help drive the process of dimension reduction.\n  --\n  En el presente trabajo hemos analizado el comportamiento de una versi\\'on\nmultivariada de la incertidumbre sim\\'etrica a trav\\'es de t\\'ecnicas de\nsimulaci\\'on estad\\'isticas sobre varias combinaciones de atributos\ninformativos y no-informativos generados de forma aleatoria. Los experimentos\nmuestran como el n\\'umero de atributos, sus cardinalidades y el tama\\~no\nmuestral afectan al MSU como medida. En esta tesis, mediante la observaci\\'on\nde resultados hemos propuesto una condici\\'on que preserva una buena calidad en\nel MSU bajo diferentes combinaciones de los tres factores mencionados, lo cual\nprovee un nuevo y valioso criterio para llevar a cabo el proceso de reducci\\'on\nde dimensionalidad.\n","authors":["Gustavo Sosa-Cabrera"],"pdf_url":"https://arxiv.org/pdf/2403.18685v1.pdf","comment":"52 pages, in Spanish. Advisors: Miguel Garc\\'ia-Torres, Santiago\n  G\\'omez-Guerrero, Christian E. Schaerer Serra"},{"id":"http://arxiv.org/abs/2403.18681v1","updated":"2024-03-27T15:24:54Z","published":"2024-03-27T15:24:54Z","title":"TransFusion: Contrastive Learning with Transformers","summary":"  This paper proposes a novel framework, TransFusion, designed to make the\nprocess of contrastive learning more analytical and explainable. TransFusion\nconsists of attention blocks whose softmax being replaced by ReLU, and its\nfinal block's weighted-sum operation is truncated to leave the adjacency matrix\nas the output. The model is trained by minimizing the Jensen-Shannon Divergence\nbetween its output and the target affinity matrix, which indicates whether each\npair of samples belongs to the same or different classes. The main contribution\nof TransFusion lies in defining a theoretical limit for answering two\nfundamental questions in the field: the maximum level of data augmentation and\nthe minimum batch size required for effective contrastive learning.\nFurthermore, experimental results indicate that TransFusion successfully\nextracts features that isolate clusters from complex real-world data, leading\nto improved classification accuracy in downstream tasks.\n","authors":["Huanran Li","Daniel Pimentel-Alarc√≥n"],"pdf_url":"https://arxiv.org/pdf/2403.18681v1.pdf","comment":"17 pages, 4 figures,"},{"id":"http://arxiv.org/abs/2403.18680v1","updated":"2024-03-27T15:22:16Z","published":"2024-03-27T15:22:16Z","title":"NL-ITI: Optimizing Probing and Intervention for Improvement of ITI\n  Method","summary":"  Large Language Models (LLM) are prone to returning false information. It\nconstitutes one of major challenges in the AI field. In our work, we explore\nparadigm introduced by Inference-Time-Intervention (ITI). In first stage, it\nidentifies attention heads, which contain the highest amount of desired type of\nknowledge (e.g., truthful). Afterwards, during inference, LLM activations are\nshifted for chosen subset of attention heads. We further improved the ITI\nframework by introducing a nonlinear probing and multi-token intervention -\nNon-Linear ITI (NL-ITI). NL-ITI is tested on diverse multiple-choice\nbenchmarks, including TruthfulQA, on which we report around 14% MC1 metric\nimprovement with respect to the baseline ITI results. NL-ITI achieves also\nencouraging results on other testsets - on Business Ethics subdomain of MMLU,\naround 18% MC1 improvement over baseline LLaMA2-7B. Additionally, NL-ITI\nperforms better while being less invasive in the behavior of LLM at the same\ntime (as measured by Kullback-Leibler divergence).\n","authors":["Jakub Hoscilowicz","Adam Wiacek","Jan Chojnacki","Adam Cieslak","Leszek Michon","Vitalii Urbanevych","Artur Janicki"],"pdf_url":"https://arxiv.org/pdf/2403.18680v1.pdf","comment":"Code is available at https://github.com/Samsung/NL-ITI"},{"id":"http://arxiv.org/abs/2403.17143v2","updated":"2024-03-27T15:15:16Z","published":"2024-03-25T19:40:26Z","title":"Guided Distant Supervision for Multilingual Relation Extraction Data:\n  Adapting to a New Language","summary":"  Relation extraction is essential for extracting and understanding\nbiographical information in the context of digital humanities and related\nsubjects. There is a growing interest in the community to build datasets\ncapable of training machine learning models to extract relationships. However,\nannotating such datasets can be expensive and time-consuming, in addition to\nbeing limited to English. This paper applies guided distant supervision to\ncreate a large biographical relationship extraction dataset for German. Our\ndataset, composed of more than 80,000 instances for nine relationship types, is\nthe largest biographical German relationship extraction dataset. We also create\na manually annotated dataset with 2000 instances to evaluate the models and\nrelease it together with the dataset compiled using guided distant supervision.\nWe train several state-of-the-art machine learning models on the automatically\ncreated dataset and release them as well. Furthermore, we experiment with\nmultilingual and cross-lingual experiments that could benefit many low-resource\nlanguages.\n","authors":["Alistair Plum","Tharindu Ranasinghe","Christoph Purschke"],"pdf_url":"https://arxiv.org/pdf/2403.17143v2.pdf","comment":"Accepted to LREC-COLING 2024 (The 2024 Joint International Conference\n  on Computational Linguistics, Language Resources and Evaluation)"},{"id":"http://arxiv.org/abs/2403.18671v1","updated":"2024-03-27T15:15:14Z","published":"2024-03-27T15:15:14Z","title":"Fact Checking Beyond Training Set","summary":"  Evaluating the veracity of everyday claims is time consuming and in some\ncases requires domain expertise. We empirically demonstrate that the commonly\nused fact checking pipeline, known as the retriever-reader, suffers from\nperformance deterioration when it is trained on the labeled data from one\ndomain and used in another domain. Afterwards, we delve into each component of\nthe pipeline and propose novel algorithms to address this problem. We propose\nan adversarial algorithm to make the retriever component robust against\ndistribution shift. Our core idea is to initially train a bi-encoder on the\nlabeled source data, and then, to adversarially train two separate document and\nclaim encoders using unlabeled target data. We then focus on the reader\ncomponent and propose to train it such that it is insensitive towards the order\nof claims and evidence documents. Our empirical evaluations support the\nhypothesis that such a reader shows a higher robustness against distribution\nshift. To our knowledge, there is no publicly available multi-topic fact\nchecking dataset. Thus, we propose a simple automatic method to re-purpose two\nwell-known fact checking datasets. We then construct eight fact checking\nscenarios from these datasets, and compare our model to a set of strong\nbaseline models, including recent domain adaptation models that use GPT4 for\ngenerating synthetic data.\n","authors":["Payam Karisani","Heng Ji"],"pdf_url":"https://arxiv.org/pdf/2403.18671v1.pdf","comment":"NAACL 2024"},{"id":"http://arxiv.org/abs/2403.18668v1","updated":"2024-03-27T15:11:07Z","published":"2024-03-27T15:11:07Z","title":"Aiming for Relevance","summary":"  Vital signs are crucial in intensive care units (ICUs). They are used to\ntrack the patient's state and to identify clinically significant changes.\nPredicting vital sign trajectories is valuable for early detection of adverse\nevents. However, conventional machine learning metrics like RMSE often fail to\ncapture the true clinical relevance of such predictions. We introduce novel\nvital sign prediction performance metrics that align with clinical contexts,\nfocusing on deviations from clinical norms, overall trends, and trend\ndeviations. These metrics are derived from empirical utility curves obtained in\na previous study through interviews with ICU clinicians. We validate the\nmetrics' usefulness using simulated and real clinical datasets (MIMIC and\neICU). Furthermore, we employ these metrics as loss functions for neural\nnetworks, resulting in models that excel in predicting clinically significant\nevents. This research paves the way for clinically relevant machine learning\nmodel evaluation and optimization, promising to improve ICU patient care. 10\npages, 9 figures.\n","authors":["Bar Eini Porat","Danny Eytan","Uri Shalit"],"pdf_url":"https://arxiv.org/pdf/2403.18668v1.pdf","comment":"10 pages, 9 figures, AMIA Informatics 2024"},{"id":"http://arxiv.org/abs/2403.18664v1","updated":"2024-03-27T15:08:00Z","published":"2024-03-27T15:08:00Z","title":"Neural Network-Based Piecewise Survival Models","summary":"  In this paper, a family of neural network-based survival models is presented.\nThe models are specified based on piecewise definitions of the hazard function\nand the density function on a partitioning of the time; both constant and\nlinear piecewise definitions are presented, resulting in a family of four\nmodels. The models can be seen as an extension of the commonly used\ndiscrete-time and piecewise exponential models and thereby add flexibility to\nthis set of standard models. Using a simulated dataset the models are shown to\nperform well compared to the highly expressive, state-of-the-art energy-based\nmodel, while only requiring a fraction of the computation time.\n","authors":["Olov Holmer","Erik Frisk","Mattias Krysander"],"pdf_url":"https://arxiv.org/pdf/2403.18664v1.pdf","comment":"7 pages"},{"id":"http://arxiv.org/abs/2403.13374v3","updated":"2024-03-27T14:57:54Z","published":"2024-03-20T08:15:08Z","title":"Byzantine-resilient Federated Learning With Adaptivity to Data\n  Heterogeneity","summary":"  This paper deals with federated learning (FL) in the presence of malicious\nByzantine attacks and data heterogeneity. A novel Robust Average Gradient\nAlgorithm (RAGA) is proposed, which leverages the geometric median for\naggregation and can freely select the round number for local updating.\nDifferent from most existing resilient approaches, which perform convergence\nanalysis based on strongly-convex loss function or homogeneously distributed\ndataset, we conduct convergence analysis for not only strongly-convex but also\nnon-convex loss function over heterogeneous dataset. According to our\ntheoretical analysis, as long as the fraction of dataset from malicious users\nis less than half, RAGA can achieve convergence at rate\n$\\mathcal{O}({1}/{T^{2/3- \\delta}})$ where $T$ is the iteration number and\n$\\delta \\in (0, 2/3)$ for non-convex loss function, and at linear rate for\nstrongly-convex loss function. Moreover, stationary point or global optimal\nsolution is proved to obtainable as data heterogeneity vanishes. Experimental\nresults corroborate the robustness of RAGA to Byzantine attacks and verifies\nthe advantage of RAGA over baselines on convergence performance under various\nintensity of Byzantine attacks, for heterogeneous dataset.\n","authors":["Shiyuan Zuo","Xingrun Yan","Rongfei Fan","Han Hu","Hangguan Shan","Tony Q. S. Quek"],"pdf_url":"https://arxiv.org/pdf/2403.13374v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.17251v2","updated":"2024-03-27T14:48:48Z","published":"2023-03-30T09:29:53Z","title":"Demystifying Misconceptions in Social Bots Research","summary":"  Research on social bots aims at advancing knowledge and providing solutions\nto one of the most debated forms of online manipulation. Yet, social bot\nresearch is plagued by widespread biases, hyped results, and misconceptions\nthat set the stage for ambiguities, unrealistic expectations, and seemingly\nirreconcilable findings. Overcoming such issues is instrumental towards\nensuring reliable solutions and reaffirming the validity of the scientific\nmethod. In this contribution, we review some recent results in social bots\nresearch, highlighting and revising factual errors as well as methodological\nand conceptual biases. More importantly, we demystify common misconceptions,\naddressing fundamental points on how social bots research is discussed. Our\nanalysis surfaces the need to discuss research about online disinformation and\nmanipulation in a rigorous, unbiased, and responsible way. This article\nbolsters such effort by identifying and refuting common fallacious arguments\nused by both proponents and opponents of social bots research, as well as\nproviding directions toward sound methodologies for future research in the\nfield.\n","authors":["Stefano Cresci","Kai-Cheng Yang","Angelo Spognardi","Roberto Di Pietro","Filippo Menczer","Marinella Petrocchi"],"pdf_url":"https://arxiv.org/pdf/2303.17251v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2308.12882v2","updated":"2024-03-27T14:47:41Z","published":"2023-08-23T17:42:00Z","title":"LCANets++: Robust Audio Classification using Multi-layer Neural Networks\n  with Lateral Competition","summary":"  Audio classification aims at recognizing audio signals, including speech\ncommands or sound events. However, current audio classifiers are susceptible to\nperturbations and adversarial attacks. In addition, real-world audio\nclassification tasks often suffer from limited labeled data. To help bridge\nthese gaps, previous work developed neuro-inspired convolutional neural\nnetworks (CNNs) with sparse coding via the Locally Competitive Algorithm (LCA)\nin the first layer (i.e., LCANets) for computer vision. LCANets learn in a\ncombination of supervised and unsupervised learning, reducing dependency on\nlabeled samples. Motivated by the fact that auditory cortex is also sparse, we\nextend LCANets to audio recognition tasks and introduce LCANets++, which are\nCNNs that perform sparse coding in multiple layers via LCA. We demonstrate that\nLCANets++ are more robust than standard CNNs and LCANets against perturbations,\ne.g., background noise, as well as black-box and white-box attacks, e.g.,\nevasion and fast gradient sign (FGSM) attacks.\n","authors":["Sayanton V. Dibbo","Juston S. Moore","Garrett T. Kenyon","Michael A. Teti"],"pdf_url":"https://arxiv.org/pdf/2308.12882v2.pdf","comment":"Accepted at 2024 IEEE International Conference on Acoustics, Speech\n  and Signal Processing Workshops (ICASSPW)"},{"id":"http://arxiv.org/abs/2403.18637v1","updated":"2024-03-27T14:42:08Z","published":"2024-03-27T14:42:08Z","title":"Transformers-based architectures for stroke segmentation: A review","summary":"  Stroke remains a significant global health concern, necessitating precise and\nefficient diagnostic tools for timely intervention and improved patient\noutcomes. The emergence of deep learning methodologies has transformed the\nlandscape of medical image analysis. Recently, Transformers, initially designed\nfor natural language processing, have exhibited remarkable capabilities in\nvarious computer vision applications, including medical image analysis. This\ncomprehensive review aims to provide an in-depth exploration of the\ncutting-edge Transformer-based architectures applied in the context of stroke\nsegmentation. It commences with an exploration of stroke pathology, imaging\nmodalities, and the challenges associated with accurate diagnosis and\nsegmentation. Subsequently, the review delves into the fundamental ideas of\nTransformers, offering detailed insights into their architectural intricacies\nand the underlying mechanisms that empower them to effectively capture complex\nspatial information within medical images. The existing literature is\nsystematically categorized and analyzed, discussing various approaches that\nleverage Transformers for stroke segmentation. A critical assessment is\nprovided, highlighting the strengths and limitations of these methods,\nincluding considerations of performance and computational efficiency.\nAdditionally, this review explores potential avenues for future research and\ndevelopment\n","authors":["Yalda Zafari-Ghadim","Essam A. Rashed","Mohamed Mabrok"],"pdf_url":"https://arxiv.org/pdf/2403.18637v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.18635v1","updated":"2024-03-27T14:40:25Z","published":"2024-03-27T14:40:25Z","title":"Fusion approaches for emotion recognition from speech using acoustic and\n  text-based features","summary":"  In this paper, we study different approaches for classifying emotions from\nspeech using acoustic and text-based features. We propose to obtain\ncontextualized word embeddings with BERT to represent the information contained\nin speech transcriptions and show that this results in better performance than\nusing Glove embeddings. We also propose and compare different strategies to\ncombine the audio and text modalities, evaluating them on IEMOCAP and\nMSP-PODCAST datasets. We find that fusing acoustic and text-based systems is\nbeneficial on both datasets, though only subtle differences are observed across\nthe evaluated fusion approaches. Finally, for IEMOCAP, we show the large effect\nthat the criteria used to define the cross-validation folds have on results. In\nparticular, the standard way of creating folds for this dataset results in a\nhighly optimistic estimation of performance for the text-based system,\nsuggesting that some previous works may overestimate the advantage of\nincorporating transcriptions.\n","authors":["Leonardo Pepino","Pablo Riera","Luciana Ferrer","Agustin Gravano"],"pdf_url":"https://arxiv.org/pdf/2403.18635v1.pdf","comment":"5 pages. Accepted in ICASSP 2020"},{"id":"http://arxiv.org/abs/2403.18631v1","updated":"2024-03-27T14:38:02Z","published":"2024-03-27T14:38:02Z","title":"First Experiences with the Identification of People at Risk for Diabetes\n  in Argentina using Machine Learning Techniques","summary":"  Detecting Type 2 Diabetes (T2D) and Prediabetes (PD) is a real challenge for\nmedicine due to the absence of pathogenic symptoms and the lack of known\nassociated risk factors. Even though some proposals for machine learning models\nenable the identification of people at risk, the nature of the condition makes\nit so that a model suitable for one population may not necessarily be suitable\nfor another. In this article, the development and assessment of predictive\nmodels to identify people at risk for T2D and PD specifically in Argentina are\ndiscussed. First, the database was thoroughly preprocessed and three specific\ndatasets were generated considering a compromise between the number of records\nand the amount of available variables. After applying 5 different\nclassification models, the results obtained show that a very good performance\nwas observed for two datasets with some of these models. In particular, RF, DT,\nand ANN demonstrated great classification power, with good values for the\nmetrics under consideration. Given the lack of this type of tool in Argentina,\nthis work represents the first step towards the development of more\nsophisticated models.\n","authors":["Enzo Rucci","Gonzalo Tittarelli","Franco Ronchetti","Jorge F. Elgart","Laura Lanzarini","Juan Jos√© Gagliardino"],"pdf_url":"https://arxiv.org/pdf/2403.18631v1.pdf","comment":"Accepted for publication in Computer Science - CACIC 2023"},{"id":"http://arxiv.org/abs/2403.16451v3","updated":"2024-03-27T14:36:21Z","published":"2024-03-25T06:30:54Z","title":"DeepMachining: Online Prediction of Machining Errors of Lathe Machines","summary":"  We describe DeepMachining, a deep learning-based AI system for online\nprediction of machining errors of lathe machine operations. We have built and\nevaluated DeepMachining based on manufacturing data from factories.\nSpecifically, we first pretrain a deep learning model for a given lathe\nmachine's operations to learn the salient features of machining states. Then,\nwe fine-tune the pretrained model to adapt to specific machining tasks. We\ndemonstrate that DeepMachining achieves high prediction accuracy for multiple\ntasks that involve different workpieces and cutting tools. To the best of our\nknowledge, this work is one of the first factory experiments using pre-trained\ndeep-learning models to predict machining errors of lathe machines.\n","authors":["Xiang-Li Lu","Hwai-Jung Hsu","Che-Wei Chou","H. T. Kung","Chen-Hsin Lee"],"pdf_url":"https://arxiv.org/pdf/2403.16451v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.18613v1","updated":"2024-03-27T14:28:44Z","published":"2024-03-27T14:28:44Z","title":"Scalable Lipschitz Estimation for CNNs","summary":"  Estimating the Lipschitz constant of deep neural networks is of growing\ninterest as it is useful for informing on generalisability and adversarial\nrobustness. Convolutional neural networks (CNNs) in particular, underpin much\nof the recent success in computer vision related applications. However,\nalthough existing methods for estimating the Lipschitz constant can be tight,\nthey have limited scalability when applied to CNNs. To tackle this, we propose\na novel method to accelerate Lipschitz constant estimation for CNNs. The core\nidea is to divide a large convolutional block via a joint layer and width-wise\npartition, into a collection of smaller blocks. We prove an upper-bound on the\nLipschitz constant of the larger block in terms of the Lipschitz constants of\nthe smaller blocks. Through varying the partition factor, the resulting method\ncan be adjusted to prioritise either accuracy or scalability and permits\nparallelisation. We demonstrate an enhanced scalability and comparable accuracy\nto existing baselines through a range of experiments.\n","authors":["Yusuf Sulehman","Tingting Mu"],"pdf_url":"https://arxiv.org/pdf/2403.18613v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.18597v1","updated":"2024-03-27T14:20:11Z","published":"2024-03-27T14:20:11Z","title":"Heterogeneous Peridynamic Neural Operators: Discover Biotissue\n  Constitutive Law and Microstructure From Digital Image Correlation\n  Measurements","summary":"  Human tissues are highly organized structures with specific collagen fiber\narrangements varying from point to point. The effects of such heterogeneity\nplay an important role for tissue function, and hence it is of critical to\ndiscover and understand the distribution of such fiber orientations from\nexperimental measurements, such as the digital image correlation data. To this\nend, we introduce the heterogeneous peridynamic neural operator (HeteroPNO)\napproach, for data-driven constitutive modeling of heterogeneous anisotropic\nmaterials. The goal is to learn both a nonlocal constitutive law together with\nthe material microstructure, in the form of a heterogeneous fiber orientation\nfield, from loading field-displacement field measurements. To this end, we\npropose a two-phase learning approach. Firstly, we learn a homogeneous\nconstitutive law in the form of a neural network-based kernel function and a\nnonlocal bond force, to capture complex homogeneous material responses from\ndata. Then, in the second phase we reinitialize the learnt bond force and the\nkernel function, and training them together with a fiber orientation field for\neach material point. Owing to the state-based peridynamic skeleton, our\nHeteroPNO-learned material models are objective and have the balance of linear\nand angular momentum guaranteed. Moreover, the effects from heterogeneity and\nnonlinear constitutive relationship are captured by the kernel function and the\nbond force respectively, enabling physical interpretability. As a result, our\nHeteroPNO architecture can learn a constitutive model for a biological tissue\nwith anisotropic heterogeneous response undergoing large deformation regime.\nMoreover, the framework is capable to provide displacement and stress field\npredictions for new and unseen loading instances.\n","authors":["Siavash Jafarzadeh","Stewart Silling","Lu Zhang","Colton Ross","Chung-Hao Lee","S. M. Rakibur Rahman","Shuodao Wang","Yue Yu"],"pdf_url":"https://arxiv.org/pdf/2403.18597v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.18587v1","updated":"2024-03-27T14:11:23Z","published":"2024-03-27T14:11:23Z","title":"The Impact of Uniform Inputs on Activation Sparsity and Energy-Latency\n  Attacks in Computer Vision","summary":"  Resource efficiency plays an important role for machine learning nowadays.\nThe energy and decision latency are two critical aspects to ensure a\nsustainable and practical application. Unfortunately, the energy consumption\nand decision latency are not robust against adversaries. Researchers have\nrecently demonstrated that attackers can compute and submit so-called sponge\nexamples at inference time to increase the energy consumption and decision\nlatency of neural networks. In computer vision, the proposed strategy crafts\ninputs with less activation sparsity which could otherwise be used to\naccelerate the computation. In this paper, we analyze the mechanism how these\nenergy-latency attacks reduce activation sparsity. In particular, we find that\ninput uniformity is a key enabler. A uniform image, that is, an image with\nmostly flat, uniformly colored surfaces, triggers more activations due to a\nspecific interplay of convolution, batch normalization, and ReLU activation.\nBased on these insights, we propose two new simple, yet effective strategies\nfor crafting sponge examples: sampling images from a probability distribution\nand identifying dense, yet inconspicuous inputs in natural datasets. We\nempirically examine our findings in a comprehensive evaluation with multiple\nimage classification models and show that our attack achieves the same sparsity\neffect as prior sponge-example methods, but at a fraction of computation\neffort. We also show that our sponge examples transfer between different neural\nnetworks. Finally, we discuss applications of our findings for the good by\nimproving efficiency by increasing sparsity.\n","authors":["Andreas M√ºller","Erwin Quiring"],"pdf_url":"https://arxiv.org/pdf/2403.18587v1.pdf","comment":"Accepted at the DLSP 2024"},{"id":"http://arxiv.org/abs/2403.18582v1","updated":"2024-03-27T14:03:41Z","published":"2024-03-27T14:03:41Z","title":"One flow to correct them all: improving simulations in high-energy\n  physics with a single normalising flow and a switch","summary":"  Simulated events are key ingredients in almost all high-energy physics\nanalyses. However, imperfections in the simulation can lead to sizeable\ndifferences between the observed data and simulated events. The effects of such\nmismodelling on relevant observables must be corrected either effectively via\nscale factors, with weights or by modifying the distributions of the\nobservables and their correlations. We introduce a correction method that\ntransforms one multidimensional distribution (simulation) into another one\n(data) using a simple architecture based on a single normalising flow with a\nboolean condition. We demonstrate the effectiveness of the method on a\nphysics-inspired toy dataset with non-trivial mismodelling of several\nobservables and their correlations.\n","authors":["Caio Cesar Daumann","Mauro Donega","Johannes Erdmann","Massimiliano Galli","Jan Lukas Sp√§h","Davide Valsecchi"],"pdf_url":"https://arxiv.org/pdf/2403.18582v1.pdf","comment":"19 pages, 12 figures"},{"id":"http://arxiv.org/abs/2306.09459v3","updated":"2024-03-27T14:02:58Z","published":"2023-06-15T19:29:08Z","title":"Recurrent Action Transformer with Memory","summary":"  Recently, the use of transformers in offline reinforcement learning has\nbecome a rapidly developing area. This is due to their ability to treat the\nagent's trajectory in the environment as a sequence, thereby reducing the\npolicy learning problem to sequence modeling. In environments where the agent's\ndecisions depend on past events, it is essential to capture both the event\nitself and the decision point in the context of the model. However, the\nquadratic complexity of the attention mechanism limits the potential for\ncontext expansion. One solution to this problem is to enhance transformers with\nmemory mechanisms. In this paper, we propose the Recurrent Action Transformer\nwith Memory (RATE) - a model that incorporates recurrent memory. To evaluate\nour model, we conducted extensive experiments on both memory-intensive\nenvironments (VizDoom-Two-Color, T-Maze) and classic Atari games and MuJoCo\ncontrol environments. The results show that the use of memory can significantly\nimprove performance in memory-intensive environments while maintaining or\nimproving results in classic environments. We hope that our findings will\nstimulate research on memory mechanisms for transformers applicable to offline\nreinforcement learning.\n","authors":["Alexey Staroverov","Egor Cherepanov","Dmitry Yudin","Alexey K. Kovalev","Aleksandr I. Panov"],"pdf_url":"https://arxiv.org/pdf/2306.09459v3.pdf","comment":"15 pages, 11 figures"},{"id":"http://arxiv.org/abs/2309.11427v2","updated":"2024-03-27T14:02:57Z","published":"2023-09-20T16:01:45Z","title":"Generative Pre-Training of Time-Series Data for Unsupervised Fault\n  Detection in Semiconductor Manufacturing","summary":"  This paper introduces TRACE-GPT, which stands for Time-seRies\nAnomaly-detection with Convolutional Embedding and Generative Pre-trained\nTransformers. TRACE-GPT is designed to pre-train univariate time-series sensor\ndata and detect faults on unlabeled datasets in semiconductor manufacturing. In\nsemiconductor industry, classifying abnormal time-series sensor data from\nnormal data is important because it is directly related to wafer defect.\nHowever, small, unlabeled, and even mixed training data without enough\nanomalies make classification tasks difficult. In this research, we capture\nfeatures of time-series data with temporal convolutional embedding and\nGenerative Pre-trained Transformer (GPT) to classify abnormal sequences from\nnormal sequences using cross entropy loss. We prove that our model shows better\nperformance than previous unsupervised models with both an open dataset, the\nUniversity of California Riverside (UCR) time-series classification archive,\nand the process log of our Chemical Vapor Deposition (CVD) equipment. Our model\nhas the highest F1 score at Equal Error Rate (EER) across all datasets and is\nonly 0.026 below the supervised state-of-the-art baseline on the open dataset.\n","authors":["Sewoong Lee","JinKyou Choi","Min Su Kim"],"pdf_url":"https://arxiv.org/pdf/2309.11427v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.18579v1","updated":"2024-03-27T13:59:09Z","published":"2024-03-27T13:59:09Z","title":"On Optimizing Hyperparameters for Quantum Neural Networks","summary":"  The increasing capabilities of Machine Learning (ML) models go hand in hand\nwith an immense amount of data and computational power required for training.\nTherefore, training is usually outsourced into HPC facilities, where we have\nstarted to experience limits in scaling conventional HPC hardware, as theorized\nby Moore's law. Despite heavy parallelization and optimization efforts, current\nstate-of-the-art ML models require weeks for training, which is associated with\nan enormous $CO_2$ footprint. Quantum Computing, and specifically Quantum\nMachine Learning (QML), can offer significant theoretical speed-ups and\nenhanced expressive power. However, training QML models requires tuning various\nhyperparameters, which is a nontrivial task and suboptimal choices can highly\naffect the trainability and performance of the models. In this study, we\nidentify the most impactful hyperparameters and collect data about the\nperformance of QML models. We compare different configurations and provide\nresearchers with performance data and concrete suggestions for hyperparameter\nselection.\n","authors":["Sabrina Herbst","Vincenzo De Maio","Ivona Brandic"],"pdf_url":"https://arxiv.org/pdf/2403.18579v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.18578v1","updated":"2024-03-27T13:59:05Z","published":"2024-03-27T13:59:05Z","title":"SteinGen: Generating Fidelitous and Diverse Graph Samples","summary":"  Generating graphs that preserve characteristic structures while promoting\nsample diversity can be challenging, especially when the number of graph\nobservations is small. Here, we tackle the problem of graph generation from\nonly one observed graph. The classical approach of graph generation from\nparametric models relies on the estimation of parameters, which can be\ninconsistent or expensive to compute due to intractable normalisation\nconstants. Generative modelling based on machine learning techniques to\ngenerate high-quality graph samples avoids parameter estimation but usually\nrequires abundant training samples. Our proposed generating procedure,\nSteinGen, which is phrased in the setting of graphs as realisations of\nexponential random graph models, combines ideas from Stein's method and MCMC by\nemploying Markovian dynamics which are based on a Stein operator for the target\nmodel. SteinGen uses the Glauber dynamics associated with an estimated Stein\noperator to generate a sample, and re-estimates the Stein operator from the\nsample after every sampling step. We show that on a class of exponential random\ngraph models this novel \"estimation and re-estimation\" generation strategy\nyields high distributional similarity (high fidelity) to the original data,\ncombined with high sample diversity.\n","authors":["Gesine Reinert","Wenkai Xu"],"pdf_url":"https://arxiv.org/pdf/2403.18578v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.09283v3","updated":"2024-03-27T13:55:14Z","published":"2024-02-14T16:14:03Z","title":"Attacks, Defenses and Evaluations for LLM Conversation Safety: A Survey","summary":"  Large Language Models (LLMs) are now commonplace in conversation\napplications. However, their risks of misuse for generating harmful responses\nhave raised serious societal concerns and spurred recent research on LLM\nconversation safety. Therefore, in this survey, we provide a comprehensive\noverview of recent studies, covering three critical aspects of LLM conversation\nsafety: attacks, defenses, and evaluations. Our goal is to provide a structured\nsummary that enhances understanding of LLM conversation safety and encourages\nfurther investigation into this important subject. For easy reference, we have\ncategorized all the studies mentioned in this survey according to our taxonomy,\navailable at: https://github.com/niconi19/LLM-conversation-safety.\n","authors":["Zhichen Dong","Zhanhui Zhou","Chao Yang","Jing Shao","Yu Qiao"],"pdf_url":"https://arxiv.org/pdf/2402.09283v3.pdf","comment":"Accepted to NAACL 2024"},{"id":"http://arxiv.org/abs/2403.18570v1","updated":"2024-03-27T13:51:26Z","published":"2024-03-27T13:51:26Z","title":"Physics-Informed Graph Neural Networks for Water Distribution Systems","summary":"  Water distribution systems (WDS) are an integral part of critical\ninfrastructure which is pivotal to urban development. As 70% of the world's\npopulation will likely live in urban environments in 2050, efficient simulation\nand planning tools for WDS play a crucial role in reaching UN's sustainable\ndevelopmental goal (SDG) 6 - \"Clean water and sanitation for all\". In this\nrealm, we propose a novel and efficient machine learning emulator, more\nprecisely, a physics-informed deep learning (DL) model, for hydraulic state\nestimation in WDS. Using a recursive approach, our model only needs a few graph\nconvolutional neural network (GCN) layers and employs an innovative algorithm\nbased on message passing. Unlike conventional machine learning tasks, the model\nuses hydraulic principles to infer two additional hydraulic state features in\nthe process of reconstructing the available ground truth feature in an\nunsupervised manner. To the best of our knowledge, this is the first DL\napproach to emulate the popular hydraulic simulator EPANET, utilizing no\nadditional information. Like most DL models and unlike the hydraulic simulator,\nour model demonstrates vastly faster emulation times that do not increase\ndrastically with the size of the WDS. Moreover, we achieve high accuracy on the\nground truth and very similar results compared to the hydraulic simulator as\ndemonstrated through experiments on five real-world WDS datasets.\n","authors":["Inaam Ashraf","Janine Strotherm","Luca Hermes","Barbara Hammer"],"pdf_url":"https://arxiv.org/pdf/2403.18570v1.pdf","comment":"Extended version of the paper with the same title published at\n  Proceedings of the AAAI Conference on Artificial Intelligence 2024"},{"id":"http://arxiv.org/abs/2403.18569v1","updated":"2024-03-27T13:50:13Z","published":"2024-03-27T13:50:13Z","title":"PDNNet: PDN-Aware GNN-CNN Heterogeneous Network for Dynamic IR Drop\n  Prediction","summary":"  IR drop on the power delivery network (PDN) is closely related to PDN's\nconfiguration and cell current consumption. As the integrated circuit (IC)\ndesign is growing larger, dynamic IR drop simulation becomes computationally\nunaffordable and machine learning based IR drop prediction has been explored as\na promising solution. Although CNN-based methods have been adapted to IR drop\nprediction task in several works, the shortcomings of overlooking PDN\nconfiguration is non-negligible. In this paper, we consider not only how to\nproperly represent cell-PDN relation, but also how to model IR drop following\nits physical nature in the feature aggregation procedure. Thus, we propose a\nnovel graph structure, PDNGraph, to unify the representations of the PDN\nstructure and the fine-grained cell-PDN relation. We further propose a\ndual-branch heterogeneous network, PDNNet, incorporating two parallel GNN-CNN\nbranches to favorably capture the above features during the learning process.\nSeveral key designs are presented to make the dynamic IR drop prediction highly\neffective and interpretable. We are the first work to apply graph structure to\ndeep-learning based dynamic IR drop prediction method. Experiments show that\nPDNNet outperforms the state-of-the-art CNN-based methods by up to 39.3%\nreduction in prediction error and achieves 545x speedup compared to the\ncommercial tool, which demonstrates the superiority of our method.\n","authors":["Yuxiang Zhao","Zhuomin Chai","Xun Jiang","Yibo Lin","Runsheng Wang","Ru Huang"],"pdf_url":"https://arxiv.org/pdf/2403.18569v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2310.12370v2","updated":"2024-03-27T13:44:21Z","published":"2023-10-18T22:34:32Z","title":"No-Regret Learning in Bilateral Trade via Global Budget Balance","summary":"  Bilateral trade models the problem of intermediating between two rational\nagents -- a seller and a buyer -- both characterized by a private valuation for\nan item they want to trade. We study the online learning version of the\nproblem, in which at each time step a new seller and buyer arrive and the\nlearner has to set prices for them without any knowledge about their\n(adversarially generated) valuations.\n  In this setting, known impossibility results rule out the existence of\nno-regret algorithms when budget balanced has to be enforced at each time step.\nIn this paper, we introduce the notion of \\emph{global budget balance}, which\nonly requires the learner to fulfill budget balance over the entire time\nhorizon. Under this natural relaxation, we provide the first no-regret\nalgorithms for adversarial bilateral trade under various feedback models.\nFirst, we show that in the full-feedback model, the learner can guarantee\n$\\tilde O(\\sqrt{T})$ regret against the best fixed prices in hindsight, and\nthat this bound is optimal up to poly-logarithmic terms. Second, we provide a\nlearning algorithm guaranteeing a $\\tilde O(T^{3/4})$ regret upper bound with\none-bit feedback, which we complement with a $\\Omega(T^{5/7})$ lower bound that\nholds even in the two-bit feedback model. Finally, we introduce and analyze an\nalternative benchmark that is provably stronger than the best fixed prices in\nhindsight and is inspired by the literature on bandits with knapsacks.\n","authors":["Martino Bernasconi","Matteo Castiglioni","Andrea Celli","Federico Fusco"],"pdf_url":"https://arxiv.org/pdf/2310.12370v2.pdf","comment":"Accepted at STOC 2024"},{"id":"http://arxiv.org/abs/2403.18560v1","updated":"2024-03-27T13:42:14Z","published":"2024-03-27T13:42:14Z","title":"Noise-Robust Keyword Spotting through Self-supervised Pretraining","summary":"  Voice assistants are now widely available, and to activate them a keyword\nspotting (KWS) algorithm is used. Modern KWS systems are mainly trained using\nsupervised learning methods and require a large amount of labelled data to\nachieve a good performance. Leveraging unlabelled data through self-supervised\nlearning (SSL) has been shown to increase the accuracy in clean conditions.\nThis paper explores how SSL pretraining such as Data2Vec can be used to enhance\nthe robustness of KWS models in noisy conditions, which is under-explored.\n  Models of three different sizes are pretrained using different pretraining\napproaches and then fine-tuned for KWS. These models are then tested and\ncompared to models trained using two baseline supervised learning methods, one\nbeing standard training using clean data and the other one being multi-style\ntraining (MTR). The results show that pretraining and fine-tuning on clean data\nis superior to supervised learning on clean data across all testing conditions,\nand superior to supervised MTR for testing conditions of SNR above 5 dB. This\nindicates that pretraining alone can increase the model's robustness. Finally,\nit is found that using noisy data for pretraining models, especially with the\nData2Vec-denoising approach, significantly enhances the robustness of KWS\nmodels in noisy conditions.\n","authors":["Jacob M√∏rk","Holger Severin Bovbjerg","Gergely Kiss","Zheng-Hua Tan"],"pdf_url":"https://arxiv.org/pdf/2403.18560v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2401.06712v2","updated":"2024-03-27T13:38:35Z","published":"2024-01-12T17:26:51Z","title":"Few-Shot Detection of Machine-Generated Text using Style Representations","summary":"  The advent of instruction-tuned language models that convincingly mimic human\nwriting poses a significant risk of abuse. However, such abuse may be\ncounteracted with the ability to detect whether a piece of text was composed by\na language model rather than a human author. Some previous approaches to this\nproblem have relied on supervised methods by training on corpora of confirmed\nhuman- and machine- written documents. Unfortunately, model under-specification\nposes an unavoidable challenge for neural network-based detectors, making them\nbrittle in the face of data shifts, such as the release of newer language\nmodels producing still more fluent text than the models used to train the\ndetectors. Other approaches require access to the models that may have\ngenerated a document in question, which is often impractical. In light of these\nchallenges, we pursue a fundamentally different approach not relying on samples\nfrom language models of concern at training time. Instead, we propose to\nleverage representations of writing style estimated from human-authored text.\nIndeed, we find that features effective at distinguishing among human authors\nare also effective at distinguishing human from machine authors, including\nstate-of-the-art large language models like Llama-2, ChatGPT, and GPT-4.\nFurthermore, given a handful of examples composed by each of several specific\nlanguage models of interest, our approach affords the ability to predict which\nmodel generated a given document. The code and data to reproduce our\nexperiments are available at\nhttps://github.com/LLNL/LUAR/tree/main/fewshot_iclr2024.\n","authors":["Rafael Rivera Soto","Kailin Koch","Aleem Khan","Barry Chen","Marcus Bishop","Nicholas Andrews"],"pdf_url":"https://arxiv.org/pdf/2401.06712v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2310.00117v4","updated":"2024-03-27T13:38:00Z","published":"2023-09-29T20:11:15Z","title":"ABScribe: Rapid Exploration & Organization of Multiple Writing\n  Variations in Human-AI Co-Writing Tasks using Large Language Models","summary":"  Exploring alternative ideas by rewriting text is integral to the writing\nprocess. State-of-the-art Large Language Models (LLMs) can simplify writing\nvariation generation. However, current interfaces pose challenges for\nsimultaneous consideration of multiple variations: creating new variations\nwithout overwriting text can be difficult, and pasting them sequentially can\nclutter documents, increasing workload and disrupting writers' flow. To tackle\nthis, we present ABScribe, an interface that supports rapid, yet visually\nstructured, exploration and organization of writing variations in human-AI\nco-writing tasks. With ABScribe, users can swiftly modify variations using LLM\nprompts, which are auto-converted into reusable buttons. Variations are stored\nadjacently within text fields for rapid in-place comparisons using mouse-over\ninteractions on a popup toolbar. Our user study with 12 writers shows that\nABScribe significantly reduces task workload (d = 1.20, p < 0.001), enhances\nuser perceptions of the revision process (d = 2.41, p < 0.001) compared to a\npopular baseline workflow, and provides insights into how writers explore\nvariations using LLMs.\n","authors":["Mohi Reza","Nathan Laundry","Ilya Musabirov","Peter Dushniku","Zhi Yuan \"Michael\" Yu","Kashish Mittal","Tovi Grossman","Michael Liut","Anastasia Kuzminykh","Joseph Jay Williams"],"pdf_url":"https://arxiv.org/pdf/2310.00117v4.pdf","comment":"CHI 2024"},{"id":"http://arxiv.org/abs/2403.18542v1","updated":"2024-03-27T13:22:38Z","published":"2024-03-27T13:22:38Z","title":"Attention-aware semantic relevance predicting Chinese sentence reading","summary":"  In recent years, several influential computational models and metrics have\nbeen proposed to predict how humans comprehend and process sentence. One\nparticularly promising approach is contextual semantic similarity. Inspired by\nthe attention algorithm in Transformer and human memory mechanisms, this study\nproposes an ``attention-aware'' approach for computing contextual semantic\nrelevance. This new approach takes into account the different contributions of\ncontextual parts and the expectation effect, allowing it to incorporate\ncontextual information fully. The attention-aware approach also facilitates the\nsimulation of existing reading models and evaluate them. The resulting\n``attention-aware'' metrics of semantic relevance can more accurately predict\nfixation durations in Chinese reading tasks recorded in an eye-tracking corpus\nthan those calculated by existing approaches. The study's findings further\nprovide strong support for the presence of semantic preview benefits in Chinese\nnaturalistic reading. Furthermore, the attention-aware metrics of semantic\nrelevance, being memory-based, possess high interpretability from both\nlinguistic and cognitive standpoints, making them a valuable computational tool\nfor modeling eye-movements in reading and further gaining insight into the\nprocess of language comprehension. Our approach underscores the potential of\nthese metrics to advance our comprehension of how humans understand and process\nlanguage, ultimately leading to a better understanding of language\ncomprehension and processing.\n","authors":["Kun Sun"],"pdf_url":"https://arxiv.org/pdf/2403.18542v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.18540v1","updated":"2024-03-27T13:17:15Z","published":"2024-03-27T13:17:15Z","title":"skscope: Fast Sparsity-Constrained Optimization in Python","summary":"  Applying iterative solvers on sparsity-constrained optimization (SCO)\nrequires tedious mathematical deduction and careful programming/debugging that\nhinders these solvers' broad impact. In the paper, the library skscope is\nintroduced to overcome such an obstacle. With skscope, users can solve the SCO\nby just programming the objective function. The convenience of skscope is\ndemonstrated through two examples in the paper, where sparse linear regression\nand trend filtering are addressed with just four lines of code. More\nimportantly, skscope's efficient implementation allows state-of-the-art solvers\nto quickly attain the sparse solution regardless of the high dimensionality of\nparameter space. Numerical experiments reveal the available solvers in skscope\ncan achieve up to 80x speedup on the competing relaxation solutions obtained\nvia the benchmarked convex solver. skscope is published on the Python Package\nIndex (PyPI) and Conda, and its source code is available at:\nhttps://github.com/abess-team/skscope.\n","authors":["Zezhi Wang","Jin Zhu","Peng Chen","Huiyang Peng","Xiaoke Zhang","Anran Wang","Yu Zheng","Junxian Zhu","Xueqin Wang"],"pdf_url":"https://arxiv.org/pdf/2403.18540v1.pdf","comment":"4 pages"},{"id":"http://arxiv.org/abs/2403.18539v1","updated":"2024-03-27T13:14:29Z","published":"2024-03-27T13:14:29Z","title":"Safe and Robust Reinforcement-Learning: Principles and Practice","summary":"  Reinforcement Learning (RL) has shown remarkable success in solving\nrelatively complex tasks, yet the deployment of RL systems in real-world\nscenarios poses significant challenges related to safety and robustness. This\npaper aims to identify and further understand those challenges thorough the\nexploration of the main dimensions of the safe and robust RL landscape,\nencompassing algorithmic, ethical, and practical considerations. We conduct a\ncomprehensive review of methodologies and open problems that summarizes the\nefforts in recent years to address the inherent risks associated with RL\napplications.\n  After discussing and proposing definitions for both safe and robust RL, the\npaper categorizes existing research works into different algorithmic approaches\nthat enhance the safety and robustness of RL agents. We examine techniques such\nas uncertainty estimation, optimisation methodologies, exploration-exploitation\ntrade-offs, and adversarial training. Environmental factors, including\nsim-to-real transfer and domain adaptation, are also scrutinized to understand\nhow RL systems can adapt to diverse and dynamic surroundings. Moreover, human\ninvolvement is an integral ingredient of the analysis, acknowledging the broad\nset of roles that humans can take in this context.\n  Importantly, to aid practitioners in navigating the complexities of safe and\nrobust RL implementation, this paper introduces a practical checklist derived\nfrom the synthesized literature. The checklist encompasses critical aspects of\nalgorithm design, training environment considerations, and ethical guidelines.\nIt will serve as a resource for developers and policymakers alike to ensure the\nresponsible deployment of RL systems in many application domains.\n","authors":["Taku Yamagata","Raul Santos-Rodriguez"],"pdf_url":"https://arxiv.org/pdf/2403.18539v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.18535v1","updated":"2024-03-27T13:11:34Z","published":"2024-03-27T13:11:34Z","title":"Theoretical Bound-Guided Hierarchical VAE for Neural Image Codecs","summary":"  Recent studies reveal a significant theoretical link between variational\nautoencoders (VAEs) and rate-distortion theory, notably in utilizing VAEs to\nestimate the theoretical upper bound of the information rate-distortion\nfunction of images. Such estimated theoretical bounds substantially exceed the\nperformance of existing neural image codecs (NICs). To narrow this gap, we\npropose a theoretical bound-guided hierarchical VAE (BG-VAE) for NIC. The\nproposed BG-VAE leverages the theoretical bound to guide the NIC model towards\nenhanced performance. We implement the BG-VAE using Hierarchical VAEs and\ndemonstrate its effectiveness through extensive experiments. Along with\nadvanced neural network blocks, we provide a versatile, variable-rate NIC that\noutperforms existing methods when considering both rate-distortion performance\nand computational complexity. The code is available at BG-VAE.\n","authors":["Yichi Zhang","Zhihao Duan","Yuning Huang","Fengqing Zhu"],"pdf_url":"https://arxiv.org/pdf/2403.18535v1.pdf","comment":"2024 IEEE International Conference on Multimedia and Expo (ICME2024)"},{"id":"http://arxiv.org/abs/2403.18525v1","updated":"2024-03-27T12:59:44Z","published":"2024-03-27T12:59:44Z","title":"Language Plays a Pivotal Role in the Object-Attribute Compositional\n  Generalization of CLIP","summary":"  Vision-language models, such as CLIP, have shown promising\nOut-of-Distribution (OoD) generalization under various types of distribution\nshifts. Recent studies attempted to investigate the leading cause of this\ncapability. In this work, we follow the same path, but focus on a specific type\nof OoD data - images with novel compositions of attribute-object pairs - and\nstudy whether such models can successfully classify those images into\ncomposition classes. We carefully designed an authentic image test dataset\ncalled ImageNet-AO, consisting of attributes for objects that are unlikely\nencountered in the CLIP training sets. We found that CLIPs trained with large\ndatasets such as OpenAI CLIP, LAION-400M, and LAION-2B show orders-of-magnitude\nimprovement in effective compositional OoD generalization compared to both\nsupervised models and CLIPs trained with smaller datasets, such as CC-12M and\nYFCC-15M. Our results provide evidence that the scale and diversity of training\ndata and language supervision play a key role in unlocking the compositional\ngeneralization abilities of vision-language models.\n","authors":["Reza Abbasi","Mohammad Samiei","Mohammad Hossein Rohban","Mahdieh Soleymani Baghshah"],"pdf_url":"https://arxiv.org/pdf/2403.18525v1.pdf","comment":"Oral accepted at OODCV 2023(http://www.ood-cv.org)"},{"id":"http://arxiv.org/abs/2303.10365v3","updated":"2024-03-27T12:53:12Z","published":"2023-03-18T08:48:16Z","title":"CroSel: Cross Selection of Confident Pseudo Labels for Partial-Label\n  Learning","summary":"  Partial-label learning (PLL) is an important weakly supervised learning\nproblem, which allows each training example to have a candidate label set\ninstead of a single ground-truth label. Identification-based methods have been\nwidely explored to tackle label ambiguity issues in PLL, which regard the true\nlabel as a latent variable to be identified. However, identifying the true\nlabels accurately and completely remains challenging, causing noise in pseudo\nlabels during model training. In this paper, we propose a new method called\nCroSel, which leverages historical predictions from the model to identify true\nlabels for most training examples. First, we introduce a cross selection\nstrategy, which enables two deep models to select true labels of partially\nlabeled data for each other. Besides, we propose a novel consistency\nregularization term called co-mix to avoid sample waste and tiny noise caused\nby false selection. In this way, CroSel can pick out the true labels of most\nexamples with high precision. Extensive experiments demonstrate the superiority\nof CroSel, which consistently outperforms previous state-of-the-art methods on\nbenchmark datasets. Additionally, our method achieves over 90\\% accuracy and\nquantity for selecting true labels on CIFAR-type datasets under various\nsettings.\n","authors":["Shiyu Tian","Hongxin Wei","Yiqun Wang","Lei Feng"],"pdf_url":"https://arxiv.org/pdf/2303.10365v3.pdf","comment":"Accepted by CVPR 2024"},{"id":"http://arxiv.org/abs/2403.18519v1","updated":"2024-03-27T12:50:27Z","published":"2024-03-27T12:50:27Z","title":"Improving Line Search Methods for Large Scale Neural Network Training","summary":"  In recent studies, line search methods have shown significant improvements in\nthe performance of traditional stochastic gradient descent techniques,\neliminating the need for a specific learning rate schedule. In this paper, we\nidentify existing issues in state-of-the-art line search methods, propose\nenhancements, and rigorously evaluate their effectiveness. We test these\nmethods on larger datasets and more complex data domains than before.\nSpecifically, we improve the Armijo line search by integrating the momentum\nterm from ADAM in its search direction, enabling efficient large-scale\ntraining, a task that was previously prone to failure using Armijo line search\nmethods. Our optimization approach outperforms both the previous Armijo\nimplementation and tuned learning rate schedules for Adam. Our evaluation\nfocuses on Transformers and CNNs in the domains of NLP and image data. Our work\nis publicly available as a Python package, which provides a hyperparameter free\nPytorch optimizer.\n","authors":["Philip Kenneweg","Tristan Kenneweg","Barbara Hammer"],"pdf_url":"https://arxiv.org/pdf/2403.18519v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.18517v1","updated":"2024-03-27T12:49:14Z","published":"2024-03-27T12:49:14Z","title":"Efficient Algorithms for Regularized Nonnegative Scale-invariant\n  Low-rank Approximation Models","summary":"  Regularized nonnegative low-rank approximations such as sparse Nonnegative\nMatrix Factorization or sparse Nonnegative Tucker Decomposition are an\nimportant branch of dimensionality reduction models with enhanced\ninterpretability. However, from a practical perspective, the choice of\nregularizers and regularization coefficients, as well as the design of\nefficient algorithms, is challenging because of the multifactor nature of these\nmodels and the lack of theory to back these choices. This paper aims at\nimproving upon these issues. By studying a more general model called the\nHomogeneous Regularized Scale-Invariant, we prove that the scale-invariance\ninherent to low-rank approximation models causes an implicit regularization\nwith both unexpected beneficial and detrimental effects. This observation\nallows to better understand the effect of regularization functions in low-rank\napproximation models, to guide the choice of the regularization\nhyperparameters, and to design balancing strategies to enhance the convergence\nspeed of dedicated optimization algorithms. Some of these results were already\nknown but restricted to specific instances of regularized low-rank\napproximations. We also derive a generic Majorization Minimization algorithm\nthat handles many regularized nonnegative low-rank approximations, with\nconvergence guarantees. We showcase our contributions on sparse Nonnegative\nMatrix Factorization, ridge-regularized Canonical Polyadic decomposition and\nsparse Nonnegative Tucker Decomposition.\n","authors":["Jeremy E. Cohen","Valentin Leplat"],"pdf_url":"https://arxiv.org/pdf/2403.18517v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.18514v1","updated":"2024-03-27T12:44:57Z","published":"2024-03-27T12:44:57Z","title":"CT-3DFlow : Leveraging 3D Normalizing Flows for Unsupervised Detection\n  of Pathological Pulmonary CT scans","summary":"  Unsupervised pathology detection can be implemented by training a model on\nhealthy data only and measuring the deviation from the training set upon\ninference, for example with CNN-based feature extraction and one-class\nclassifiers, or reconstruction-score-based methods such as AEs, GANs and\nDiffusion models. Normalizing Flows (NF) have the ability to directly learn the\nprobability distribution of training examples through an invertible\narchitecture. We leverage this property in a novel 3D NF-based model named\nCT-3DFlow, specifically tailored for patient-level pulmonary pathology\ndetection in chest CT data. Our model is trained unsupervised on healthy 3D\npulmonary CT patches, and detects deviations from its log-likelihood\ndistribution as anomalies. We aggregate patches-level likelihood values from a\npatient's CT scan to provide a patient-level 'normal'/'abnormal' prediction.\nOut-of-distribution detection performance is evaluated using expert annotations\non a separate chest CT test dataset, outperforming other state-of-the-art\nmethods.\n","authors":["Aissam Djahnine","Alexandre Popoff","Emilien Jupin-Delevaux","Vincent Cottin","Olivier Nempont","Loic Boussel"],"pdf_url":"https://arxiv.org/pdf/2403.18514v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.18509v1","updated":"2024-03-27T12:39:16Z","published":"2024-03-27T12:39:16Z","title":"Distributed Maximum Consensus over Noisy Links","summary":"  We introduce a distributed algorithm, termed noise-robust distributed maximum\nconsensus (RD-MC), for estimating the maximum value within a multi-agent\nnetwork in the presence of noisy communication links. Our approach entails\nredefining the maximum consensus problem as a distributed optimization problem,\nallowing a solution using the alternating direction method of multipliers.\nUnlike existing algorithms that rely on multiple sets of noise-corrupted\nestimates, RD-MC employs a single set, enhancing both robustness and\nefficiency. To further mitigate the effects of link noise and improve\nrobustness, we apply moving averaging to the local estimates. Through extensive\nsimulations, we demonstrate that RD-MC is significantly more robust to\ncommunication link noise compared to existing maximum-consensus algorithms.\n","authors":["Ehsan Lari","Reza Arablouei","Naveen K. D. Venkategowda","Stefan Werner"],"pdf_url":"https://arxiv.org/pdf/2403.18509v1.pdf","comment":"5 pages, 7 figures, submitted to EUSIPCO 2024 conference"},{"id":"http://arxiv.org/abs/2403.18506v1","updated":"2024-03-27T12:35:23Z","published":"2024-03-27T12:35:23Z","title":"Faster Convergence for Transformer Fine-tuning with Line Search Methods","summary":"  Recent works have shown that line search methods greatly increase performance\nof traditional stochastic gradient descent methods on a variety of datasets and\narchitectures [1], [2]. In this work we succeed in extending line search\nmethods to the novel and highly popular Transformer architecture and dataset\ndomains in natural language processing. More specifically, we combine the\nArmijo line search with the Adam optimizer and extend it by subdividing the\nnetworks architecture into sensible units and perform the line search\nseparately on these local units. Our optimization method outperforms the\ntraditional Adam optimizer and achieves significant performance improvements\nfor small data sets or small training budgets, while performing equal or better\nfor other tested cases. Our work is publicly available as a python package,\nwhich provides a hyperparameter-free pytorch optimizer that is compatible with\narbitrary network architectures.\n","authors":["Philip Kenneweg","Leonardo Galli","Tristan Kenneweg","Barbara Hammer"],"pdf_url":"https://arxiv.org/pdf/2403.18506v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.08579v2","updated":"2024-03-27T12:28:02Z","published":"2024-03-13T14:34:34Z","title":"Machine Learning Optimized Orthogonal Basis Piecewise Polynomial\n  Approximation","summary":"  Piecewise Polynomials (PPs) are utilized in several engineering disciplines,\nlike trajectory planning, to approximate position profiles given in the form of\na set of points. While the approximation target along with domain-specific\nrequirements, like Ck -continuity, can be formulated as a system of equations\nand a result can be computed directly, such closed-form solutions posses\nlimited flexibility with respect to polynomial degrees, polynomial bases or\nadding further domain-specific requirements. Sufficiently complex optimization\ngoals soon call for the use of numerical methods, like gradient descent. Since\ngradient descent lies at the heart of training Artificial Neural Networks\n(ANNs), modern Machine Learning (ML) frameworks like TensorFlow come with a set\nof gradient-based optimizers potentially suitable for a wide range of\noptimization problems beyond the training task for ANNs. Our approach is to\nutilize the versatility of PP models and combine it with the potential of\nmodern ML optimizers for the use in function approximation in 1D trajectory\nplanning in the context of electronic cam design. We utilize available\noptimizers of the ML framework TensorFlow directly, outside of the scope of\nANNs, to optimize model parameters of our PP model. In this paper, we show how\nan orthogonal polynomial basis contributes to improving approximation and\ncontinuity optimization performance. Utilizing Chebyshev polynomials of the\nfirst kind, we develop a novel regularization approach enabling clearly\nimproved convergence behavior. We show that, using this regularization\napproach, Chebyshev basis performs better than power basis for all relevant\noptimizers in the combined approximation and continuity optimization setting\nand demonstrate usability of the presented approach within the electronic cam\ndomain.\n","authors":["Hannes Waclawek","Stefan Huber"],"pdf_url":"https://arxiv.org/pdf/2403.08579v2.pdf","comment":"Submitted to LION18"},{"id":"http://arxiv.org/abs/2311.04698v3","updated":"2024-03-27T12:24:17Z","published":"2023-11-08T14:10:19Z","title":"Challenging Common Paradigms in Multi-Task Learning","summary":"  While multi-task learning (MTL) has gained significant attention in recent\nyears, its underlying mechanisms remain poorly understood. Recent methods did\nnot yield consistent performance improvements over single task learning (STL)\nbaselines, underscoring the importance of gaining more profound insights about\nchallenges specific to MTL. In our study, we challenge paradigms in MTL in the\ncontext of STL: First, the impact of the choice of optimizer has only been\nmildly investigated in MTL. We show the pivotal role of common STL tools such\nas the Adam optimizer in MTL empirically in various experiments. To further\ninvestigate Adam's effectiveness, we theoretical derive a partial loss-scale\ninvariance under mild assumptions. Second, the notion of gradient conflicts has\noften been phrased as a specific problem in MTL. We delve into the role of\ngradient conflicts in MTL and compare it to STL. For angular gradient alignment\nwe find no evidence that this is a unique problem in MTL. We emphasize\ndifferences in gradient magnitude as the main distinguishing factor. Lastly, we\ncompare the transferability of features learned through MTL and STL on common\nimage corruptions, and find light evidence that MTL can lead to superior\ntransferability. Overall, we find surprising similarities between STL and MTL\nsuggesting to consider methods from both fields in a broader context.\n","authors":["Cathrin Elich","Lukas Kirchdorfer","Jan M. K√∂hler","Lukas Schott"],"pdf_url":"https://arxiv.org/pdf/2311.04698v3.pdf","comment":"-"},{"id":"http://arxiv.org/abs/2403.18495v1","updated":"2024-03-27T12:15:22Z","published":"2024-03-27T12:15:22Z","title":"Direct mineral content prediction from drill core images via transfer\n  learning","summary":"  Deep subsurface exploration is important for mining, oil and gas industries,\nas well as in the assessment of geological units for the disposal of chemical\nor nuclear waste, or the viability of geothermal energy systems. Typically,\ndetailed examinations of subsurface formations or units are performed on\ncuttings or core materials extracted during drilling campaigns, as well as on\ngeophysical borehole data, which provide detailed information about the\npetrophysical properties of the rocks. Depending on the volume of rock samples\nand the analytical program, the laboratory analysis and diagnostics can be very\ntime-consuming. This study investigates the potential of utilizing machine\nlearning, specifically convolutional neural networks (CNN), to assess the\nlithology and mineral content solely from analysis of drill core images, aiming\nto support and expedite the subsurface geological exploration. The paper\noutlines a comprehensive methodology, encompassing data preprocessing, machine\nlearning methods, and transfer learning techniques. The outcome reveals a\nremarkable 96.7% accuracy in the classification of drill core segments into\ndistinct formation classes. Furthermore, a CNN model was trained for the\nevaluation of mineral content using a learning data set from multidimensional\nlog analysis data (silicate, total clay, carbonate). When benchmarked against\nlaboratory XRD measurements on samples from the cores, both the advanced\nmultidimensional log analysis model and the neural network approach developed\nhere provide equally good performance. This work demonstrates that deep\nlearning and particularly transfer learning can support extracting\npetrophysical properties, including mineral content and formation\nclassification, from drill core images, thus offering a road map for enhancing\nmodel performance and data set quality in image-based analysis of drill cores.\n","authors":["Romana Boiger","Sergey V. Churakov","Ignacio Ballester Llagaria","Georg Kosakowski","Raphael W√ºst","Nikolaos I. Prasianakis"],"pdf_url":"https://arxiv.org/pdf/2403.18495v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.18494v1","updated":"2024-03-27T12:10:30Z","published":"2024-03-27T12:10:30Z","title":"Learning in PINNs: Phase transition, total diffusion, and generalization","summary":"  We investigate the learning dynamics of fully-connected neural networks\nthrough the lens of gradient signal-to-noise ratio (SNR), examining the\nbehavior of first-order optimizers like Adam in non-convex objectives. By\ninterpreting the drift/diffusion phases in the information bottleneck theory,\nfocusing on gradient homogeneity, we identify a third phase termed ``total\ndiffusion\", characterized by equilibrium in the learning rates and homogeneous\ngradients. This phase is marked by an abrupt SNR increase, uniform residuals\nacross the sample space and the most rapid training convergence. We propose a\nresidual-based re-weighting scheme to accelerate this diffusion in quadratic\nloss functions, enhancing generalization. We also explore the information\ncompression phenomenon, pinpointing a significant saturation-induced\ncompression of activations at the total diffusion phase, with deeper layers\nexperiencing negligible information loss. Supported by experimental data on\nphysics-informed neural networks (PINNs), which underscore the importance of\ngradient homogeneity due to their PDE-based sample inter-dependence, our\nfindings suggest that recognizing phase transitions could refine ML\noptimization strategies for improved generalization.\n","authors":["Sokratis J. Anagnostopoulos","Juan Diego Toscano","Nikolaos Stergiopulos","George Em Karniadakis"],"pdf_url":"https://arxiv.org/pdf/2403.18494v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.18489v1","updated":"2024-03-27T12:01:51Z","published":"2024-03-27T12:01:51Z","title":"Impact of Employing Weather Forecast Data as Input to the Estimation of\n  Evapotranspiration by Deep Neural Network Models","summary":"  Reference Evapotranspiration (ET0) is a key parameter for designing smart\nirrigation scheduling, since it is related by a coefficient to the water needs\nof a crop. The United Nations Food and Agriculture Organization, proposed a\nstandard method for ET0 computation (FAO56PM), based on the parameterization of\nthe Penman-Monteith equation, that is widely adopted in the literature. To\ncompute ET0 using the FAO56-PM method, four main weather parameters are needed:\ntemperature, humidity, wind, and solar radiation (SR). One way to make daily\nET0 estimations for future days is to use freely available weather forecast\nservices (WFSs), where many meteorological parameters are estimated up to the\nnext 15 days. A problem with this method is that currently, SR is not provided\nas a free forecast parameter on most of those online services or, normally,\nsuch forecasts present a financial cost penalty. For this reason, several ET0\nestimation models using machine and deep learning were developed and presented\nin the literature, that use as input features a reduced set of carefully\nselected weather parameters, that are compatible with common freely available\nWFSs. However, most studies on this topic have only evaluated model performance\nusing data from weather stations (WSs), without considering the effect of using\nweather forecast data. In this study, the performance of authors' previous\nmodels is evaluated when using weather forecast data from two online WFSs, in\nthe following scenarios: (i) direct ET0 estimation by an ANN model, and (ii)\nestimate SR by ANN model, and then use that estimation for ET0 computation,\nusing the FAO56-PM method. Employing data collected from two WFSs and a WS\nlocated in Vale do Lobo, Portugal, the latter approach achieved the best\nresult, with a coefficient of determination (R2) ranging between 0.893 and\n0.667, when considering forecasts up to 15 days.\n","authors":["Pedro J. Vaz","Gabriela Sch√ºtz","Carlos Guerrero","Pedro J. S. Cardoso"],"pdf_url":"https://arxiv.org/pdf/2403.18489v1.pdf","comment":"A partial version of the work submitted to ESRE/INTERNATIONAL\n  CONFERENCE ON ENVIRONMENTAL SCIENCES AND RENEWABLE ENERGY"},{"id":"http://arxiv.org/abs/2403.18486v1","updated":"2024-03-27T11:58:45Z","published":"2024-03-27T11:58:45Z","title":"Synthesizing EEG Signals from Event-Related Potential Paradigms with\n  Conditional Diffusion Models","summary":"  Data scarcity in the brain-computer interface field can be alleviated through\nthe use of generative models, specifically diffusion models. While diffusion\nmodels have previously been successfully applied to electroencephalogram (EEG)\ndata, existing models lack flexibility w.r.t.~sampling or require alternative\nrepresentations of the EEG data. To overcome these limitations, we introduce a\nnovel approach to conditional diffusion models that utilizes classifier-free\nguidance to directly generate subject-, session-, and class-specific EEG data.\nIn addition to commonly used metrics, domain-specific metrics are employed to\nevaluate the specificity of the generated samples. The results indicate that\nthe proposed model can generate EEG data that resembles real data for each\nsubject, session, and class.\n","authors":["Guido Klein","Pierre Guetschel","Gianluigi Silvestri","Michael Tangermann"],"pdf_url":"https://arxiv.org/pdf/2403.18486v1.pdf","comment":"submitted to 9th Graz BCI conference, 6 pages, 3 figures, first\n  figure is split into two subfigures, 1 table"},{"id":"http://arxiv.org/abs/2311.12028v2","updated":"2024-03-27T11:43:28Z","published":"2023-11-20T18:59:51Z","title":"Hourglass Tokenizer for Efficient Transformer-Based 3D Human Pose\n  Estimation","summary":"  Transformers have been successfully applied in the field of video-based 3D\nhuman pose estimation. However, the high computational costs of these video\npose transformers (VPTs) make them impractical on resource-constrained devices.\nIn this paper, we present a plug-and-play pruning-and-recovering framework,\ncalled Hourglass Tokenizer (HoT), for efficient transformer-based 3D human pose\nestimation from videos. Our HoT begins with pruning pose tokens of redundant\nframes and ends with recovering full-length tokens, resulting in a few pose\ntokens in the intermediate transformer blocks and thus improving the model\nefficiency. To effectively achieve this, we propose a token pruning cluster\n(TPC) that dynamically selects a few representative tokens with high semantic\ndiversity while eliminating the redundancy of video frames. In addition, we\ndevelop a token recovering attention (TRA) to restore the detailed\nspatio-temporal information based on the selected tokens, thereby expanding the\nnetwork output to the original full-length temporal resolution for fast\ninference. Extensive experiments on two benchmark datasets (i.e., Human3.6M and\nMPI-INF-3DHP) demonstrate that our method can achieve both high efficiency and\nestimation accuracy compared to the original VPT models. For instance, applying\nto MotionBERT and MixSTE on Human3.6M, our HoT can save nearly 50% FLOPs\nwithout sacrificing accuracy and nearly 40% FLOPs with only 0.2% accuracy drop,\nrespectively. Code and models are available at\nhttps://github.com/NationalGAILab/HoT.\n","authors":["Wenhao Li","Mengyuan Liu","Hong Liu","Pichao Wang","Jialun Cai","Nicu Sebe"],"pdf_url":"https://arxiv.org/pdf/2311.12028v2.pdf","comment":"Accepted by CVPR 2024, Open Sourced"},{"id":"http://arxiv.org/abs/2403.18452v1","updated":"2024-03-27T11:11:08Z","published":"2024-03-27T11:11:08Z","title":"SingularTrajectory: Universal Trajectory Predictor Using Diffusion Model","summary":"  There are five types of trajectory prediction tasks: deterministic,\nstochastic, domain adaptation, momentary observation, and few-shot. These\nassociated tasks are defined by various factors, such as the length of input\npaths, data split and pre-processing methods. Interestingly, even though they\ncommonly take sequential coordinates of observations as input and infer future\npaths in the same coordinates as output, designing specialized architectures\nfor each task is still necessary. For the other task, generality issues can\nlead to sub-optimal performances. In this paper, we propose SingularTrajectory,\na diffusion-based universal trajectory prediction framework to reduce the\nperformance gap across the five tasks. The core of SingularTrajectory is to\nunify a variety of human dynamics representations on the associated tasks. To\ndo this, we first build a Singular space to project all types of motion\npatterns from each task into one embedding space. We next propose an adaptive\nanchor working in the Singular space. Unlike traditional fixed anchor methods\nthat sometimes yield unacceptable paths, our adaptive anchor enables correct\nanchors, which are put into a wrong location, based on a traversability map.\nFinally, we adopt a diffusion-based predictor to further enhance the prototype\npaths using a cascaded denoising process. Our unified framework ensures the\ngenerality across various benchmark settings such as input modality, and\ntrajectory lengths. Extensive experiments on five public benchmarks demonstrate\nthat SingularTrajectory substantially outperforms existing models, highlighting\nits effectiveness in estimating general dynamics of human movements. Code is\npublicly available at https://github.com/inhwanbae/SingularTrajectory .\n","authors":["Inhwan Bae","Young-Jae Park","Hae-Gon Jeon"],"pdf_url":"https://arxiv.org/pdf/2403.18452v1.pdf","comment":"Accepted at CVPR 2024"},{"id":"http://arxiv.org/abs/2403.18451v1","updated":"2024-03-27T11:11:06Z","published":"2024-03-27T11:11:06Z","title":"CoRAST: Towards Foundation Model-Powered Correlated Data Analysis in\n  Resource-Constrained CPS and IoT","summary":"  Foundation models (FMs) emerge as a promising solution to harness distributed\nand diverse environmental data by leveraging prior knowledge to understand the\ncomplicated temporal and spatial correlations within heterogeneous datasets.\nUnlike distributed learning frameworks such as federated learning, which often\nstruggle with multimodal data, FMs can transform diverse inputs into\nembeddings. This process facilitates the integration of information from\nvarious modalities and the application of prior learning to new domains.\nHowever, deploying FMs in resource-constrained edge systems poses significant\nchallenges. To this end, we introduce CoRAST, a novel learning framework that\nutilizes FMs for enhanced analysis of distributed, correlated heterogeneous\ndata. Utilizing a server-based FM, CoRAST can exploit existing environment\ninformation to extract temporal, spatial, and cross-modal correlations among\nsensor data. This enables CoRAST to offer context-aware insights for localized\nclient tasks through FM-powered global representation learning. Our evaluation\non real-world weather dataset demonstrates CoRAST's ability to exploit\ncorrelated heterogeneous data through environmental representation learning to\nreduce the forecast errors by up to 50.3% compared to the baselines.\n","authors":["Yi Hu","Jinhang Zuo","Alanis Zhao","Bob Iannucci","Carlee Joe-Wong"],"pdf_url":"https://arxiv.org/pdf/2403.18451v1.pdf","comment":"accepted and to be published in 2024 IEEE International Workshop on\n  Foundation Models for Cyber-Physical Systems & Internet of Things (FMSys)"},{"id":"http://arxiv.org/abs/2403.09267v3","updated":"2024-03-27T11:11:02Z","published":"2024-03-14T10:44:10Z","title":"Deep Limit Order Book Forecasting","summary":"  We exploit cutting-edge deep learning methodologies to explore the\npredictability of high-frequency Limit Order Book mid-price changes for a\nheterogeneous set of stocks traded on the NASDAQ exchange. In so doing, we\nrelease `LOBFrame', an open-source code base to efficiently process large-scale\nLimit Order Book data and quantitatively assess state-of-the-art deep learning\nmodels' forecasting capabilities. Our results are twofold. We demonstrate that\nthe stocks' microstructural characteristics influence the efficacy of deep\nlearning methods and that their high forecasting power does not necessarily\ncorrespond to actionable trading signals. We argue that traditional machine\nlearning metrics fail to adequately assess the quality of forecasts in the\nLimit Order Book context. As an alternative, we propose an innovative\noperational framework that evaluates predictions' practicality by focusing on\nthe probability of accurately forecasting complete transactions. This work\noffers academics and practitioners an avenue to make informed and robust\ndecisions on the application of deep learning techniques, their scope and\nlimitations, effectively exploiting emergent statistical properties of the\nLimit Order Book.\n","authors":["Antonio Briola","Silvia Bartolucci","Tomaso Aste"],"pdf_url":"https://arxiv.org/pdf/2403.09267v3.pdf","comment":"43 pages, 14 figures, 12 Tables"},{"id":"http://arxiv.org/abs/2403.18447v1","updated":"2024-03-27T11:06:44Z","published":"2024-03-27T11:06:44Z","title":"Can Language Beat Numerical Regression? Language-Based Multimodal\n  Trajectory Prediction","summary":"  Language models have demonstrated impressive ability in context understanding\nand generative performance. Inspired by the recent success of language\nfoundation models, in this paper, we propose LMTraj (Language-based Multimodal\nTrajectory predictor), which recasts the trajectory prediction task into a sort\nof question-answering problem. Departing from traditional numerical regression\nmodels, which treat the trajectory coordinate sequence as continuous signals,\nwe consider them as discrete signals like text prompts. Specially, we first\ntransform an input space for the trajectory coordinate into the natural\nlanguage space. Here, the entire time-series trajectories of pedestrians are\nconverted into a text prompt, and scene images are described as text\ninformation through image captioning. The transformed numerical and image data\nare then wrapped into the question-answering template for use in a language\nmodel. Next, to guide the language model in understanding and reasoning\nhigh-level knowledge, such as scene context and social relationships between\npedestrians, we introduce an auxiliary multi-task question and answering. We\nthen train a numerical tokenizer with the prompt data. We encourage the\ntokenizer to separate the integer and decimal parts well, and leverage it to\ncapture correlations between the consecutive numbers in the language model.\nLastly, we train the language model using the numerical tokenizer and all of\nthe question-answer prompts. Here, we propose a beam-search-based most-likely\nprediction and a temperature-based multimodal prediction to implement both\ndeterministic and stochastic inferences. Applying our LMTraj, we show that the\nlanguage-based model can be a powerful pedestrian trajectory predictor, and\noutperforms existing numerical-based predictor methods. Code is publicly\navailable at https://github.com/inhwanbae/LMTrajectory .\n","authors":["Inhwan Bae","Junoh Lee","Hae-Gon Jeon"],"pdf_url":"https://arxiv.org/pdf/2403.18447v1.pdf","comment":"Accepted at CVPR 2024"},{"id":"http://arxiv.org/abs/2403.18444v1","updated":"2024-03-27T11:00:53Z","published":"2024-03-27T11:00:53Z","title":"FRESCO: Federated Reinforcement Energy System for Cooperative\n  Optimization","summary":"  The rise in renewable energy is creating new dynamics in the energy grid that\npromise to create a cleaner and more participative energy grid, where\ntechnology plays a crucial part in making the required flexibility to achieve\nthe vision of the next-generation grid. This work presents FRESCO, a framework\nthat aims to ease the implementation of energy markets using a hierarchical\ncontrol architecture of reinforcement learning agents trained using federated\nlearning. The core concept we are proving is that having greedy agents subject\nto changing conditions from a higher level agent creates a cooperative setup\nthat will allow for fulfilling all the individual objectives. This paper\npresents a general overview of the framework, the current progress, and some\ninsights we obtained from the recent results.\n","authors":["Nicolas Mauricio Cuadrado","Roberto Alejandro Gutierrez","Martin Tak√°ƒç"],"pdf_url":"https://arxiv.org/pdf/2403.18444v1.pdf","comment":"Tiny Paper at ICLR 2023"},{"id":"http://arxiv.org/abs/2403.18439v1","updated":"2024-03-27T10:47:06Z","published":"2024-03-27T10:47:06Z","title":"Generalized Policy Learning for Smart Grids: FL TRPO Approach","summary":"  The smart grid domain requires bolstering the capabilities of existing energy\nmanagement systems; Federated Learning (FL) aligns with this goal as it\ndemonstrates a remarkable ability to train models on heterogeneous datasets\nwhile maintaining data privacy, making it suitable for smart grid applications,\nwhich often involve disparate data distributions and interdependencies among\nfeatures that hinder the suitability of linear models. This paper introduces a\nframework that combines FL with a Trust Region Policy Optimization (FL TRPO)\naiming to reduce energy-associated emissions and costs. Our approach reveals\nlatent interconnections and employs personalized encoding methods to capture\nunique insights, understanding the relationships between features and optimal\nstrategies, allowing our model to generalize to previously unseen data.\nExperimental results validate the robustness of our approach, affirming its\nproficiency in effectively learning policy models for smart grid challenges.\n","authors":["Yunxiang Li","Nicolas Mauricio Cuadrado","Samuel Horv√°th","Martin Tak√°ƒç"],"pdf_url":"https://arxiv.org/pdf/2403.18439v1.pdf","comment":"ICLR 2024 Workshop: Tackling Climate Change with Machine Learning"},{"id":"http://arxiv.org/abs/2403.18438v1","updated":"2024-03-27T10:45:16Z","published":"2024-03-27T10:45:16Z","title":"Global Vegetation Modeling with Pre-Trained Weather Transformers","summary":"  Accurate vegetation models can produce further insights into the complex\ninteraction between vegetation activity and ecosystem processes. Previous\nresearch has established that long-term trends and short-term variability of\ntemperature and precipitation affect vegetation activity. Motivated by the\nrecent success of Transformer-based Deep Learning models for medium-range\nweather forecasting, we adapt the publicly available pre-trained FourCastNet to\nmodel vegetation activity while accounting for the short-term dynamics of\nclimate variability. We investigate how the learned global representation of\nthe atmosphere's state can be transferred to model the normalized difference\nvegetation index (NDVI). Our model globally estimates vegetation activity at a\nresolution of \\SI{0.25}{\\degree} while relying only on meteorological data. We\ndemonstrate that leveraging pre-trained weather models improves the NDVI\nestimates compared to learning an NDVI model from scratch. Additionally, we\ncompare our results to other recent data-driven NDVI modeling approaches from\nmachine learning and ecology literature. We further provide experimental\nevidence on how much data and training time is necessary to turn FourCastNet\ninto an effective vegetation model. Code and models will be made available upon\npublication.\n","authors":["Pascal Janetzky","Florian Gallusser","Simon Hentschel","Andreas Hotho","Anna Krause"],"pdf_url":"https://arxiv.org/pdf/2403.18438v1.pdf","comment":"Tackling Climate Change with Machine Learning Workshop @ ICLR 2024"},{"id":"http://arxiv.org/abs/2403.18436v1","updated":"2024-03-27T10:40:27Z","published":"2024-03-27T10:40:27Z","title":"Collaborative Active Learning in Conditional Trust Environment","summary":"  In this paper, we investigate collaborative active learning, a paradigm in\nwhich multiple collaborators explore a new domain by leveraging their combined\nmachine learning capabilities without disclosing their existing data and\nmodels. Instead, the collaborators share prediction results from the new domain\nand newly acquired labels. This collaboration offers several advantages: (a) it\naddresses privacy and security concerns by eliminating the need for direct\nmodel and data disclosure; (b) it enables the use of different data sources and\ninsights without direct data exchange; and (c) it promotes cost-effectiveness\nand resource efficiency through shared labeling costs. To realize these\nbenefits, we introduce a collaborative active learning framework designed to\nfulfill the aforementioned objectives. We validate the effectiveness of the\nproposed framework through simulations. The results demonstrate that\ncollaboration leads to higher AUC scores compared to independent efforts,\nhighlighting the framework's ability to overcome the limitations of individual\nmodels. These findings support the use of collaborative approaches in active\nlearning, emphasizing their potential to enhance outcomes through collective\nexpertise and shared resources. Our work provides a foundation for further\nresearch on collaborative active learning and its practical applications in\nvarious domains where data privacy, cost efficiency, and model performance are\ncritical considerations.\n","authors":["Zan-Kai Chong","Hiroyuki Ohsaki","Bryan Ng"],"pdf_url":"https://arxiv.org/pdf/2403.18436v1.pdf","comment":"5 pages, 9 figures, conference"},{"id":"http://arxiv.org/abs/2403.18425v1","updated":"2024-03-27T10:26:42Z","published":"2024-03-27T10:26:42Z","title":"U-Sketch: An Efficient Approach for Sketch to Image Diffusion Models","summary":"  Diffusion models have demonstrated remarkable performance in text-to-image\nsynthesis, producing realistic and high resolution images that faithfully\nadhere to the corresponding text-prompts. Despite their great success, they\nstill fall behind in sketch-to-image synthesis tasks, where in addition to\ntext-prompts, the spatial layout of the generated images has to closely follow\nthe outlines of certain reference sketches. Employing an MLP latent edge\npredictor to guide the spatial layout of the synthesized image by predicting\nedge maps at each denoising step has been recently proposed. Despite yielding\npromising results, the pixel-wise operation of the MLP does not take into\naccount the spatial layout as a whole, and demands numerous denoising\niterations to produce satisfactory images, leading to time inefficiency. To\nthis end, we introduce U-Sketch, a framework featuring a U-Net type latent edge\npredictor, which is capable of efficiently capturing both local and global\nfeatures, as well as spatial correlations between pixels. Moreover, we propose\nthe addition of a sketch simplification network that offers the user the choice\nof preprocessing and simplifying input sketches for enhanced outputs. The\nexperimental results, corroborated by user feedback, demonstrate that our\nproposed U-Net latent edge predictor leads to more realistic results, that are\nbetter aligned with the spatial outlines of the reference sketches, while\ndrastically reducing the number of required denoising steps and, consequently,\nthe overall execution time.\n","authors":["Ilias Mitsouras","Eleftherios Tsonis","Paraskevi Tzouveli","Athanasios Voulodimos"],"pdf_url":"https://arxiv.org/pdf/2403.18425v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.18423v1","updated":"2024-03-27T10:24:25Z","published":"2024-03-27T10:24:25Z","title":"SemRoDe: Macro Adversarial Training to Learn Representations That are\n  Robust to Word-Level Attacks","summary":"  Language models (LMs) are indispensable tools for natural language processing\ntasks, but their vulnerability to adversarial attacks remains a concern. While\ncurrent research has explored adversarial training techniques, their\nimprovements to defend against word-level attacks have been limited. In this\nwork, we propose a novel approach called Semantic Robust Defence (SemRoDe), a\nMacro Adversarial Training strategy to enhance the robustness of LMs. Drawing\ninspiration from recent studies in the image domain, we investigate and later\nconfirm that in a discrete data setting such as language, adversarial samples\ngenerated via word substitutions do indeed belong to an adversarial domain\nexhibiting a high Wasserstein distance from the base domain. Our method learns\na robust representation that bridges these two domains. We hypothesize that if\nsamples were not projected into an adversarial domain, but instead to a domain\nwith minimal shift, it would improve attack robustness. We align the domains by\nincorporating a new distance-based objective. With this, our model is able to\nlearn more generalized representations by aligning the model's high-level\noutput features and therefore better handling unseen adversarial samples. This\nmethod can be generalized across word embeddings, even when they share minimal\noverlap at both vocabulary and word-substitution levels. To evaluate the\neffectiveness of our approach, we conduct experiments on BERT and RoBERTa\nmodels on three datasets. The results demonstrate promising state-of-the-art\nrobustness.\n","authors":["Brian Formento","Wenjie Feng","Chuan Sheng Foo","Luu Anh Tuan","See-Kiong Ng"],"pdf_url":"https://arxiv.org/pdf/2403.18423v1.pdf","comment":"Published in NAACL 2024 (Main Track)"},{"id":"http://arxiv.org/abs/2402.01739v2","updated":"2024-03-27T10:21:24Z","published":"2024-01-29T12:05:02Z","title":"OpenMoE: An Early Effort on Open Mixture-of-Experts Language Models","summary":"  To help the open-source community have a better understanding of\nMixture-of-Experts (MoE) based large language models (LLMs), we train and\nrelease OpenMoE, a series of fully open-sourced and reproducible decoder-only\nMoE LLMs, ranging from 650M to 34B parameters and trained on up to over 1T\ntokens. Our investigation confirms that MoE-based LLMs can offer a more\nfavorable cost-effectiveness trade-off than dense LLMs, highlighting the\npotential effectiveness for future LLM development.\n  One more important contribution of this study is an in-depth analysis of the\nrouting mechanisms within our OpenMoE models, leading to three significant\nfindings: Context-Independent Specialization, Early Routing Learning, and\nDrop-towards-the-End. We discovered that routing decisions in MoE models are\npredominantly based on token IDs, with minimal context relevance. The\ntoken-to-expert assignments are determined early in the pre-training phase and\nremain largely unchanged. This imperfect routing can result in performance\ndegradation, particularly in sequential tasks like multi-turn conversations,\nwhere tokens appearing later in a sequence are more likely to be dropped.\nFinally, we rethink our design based on the above-mentioned observations and\nanalysis. To facilitate future MoE LLM development, we propose potential\nstrategies for mitigating the issues we found and further improving\noff-the-shelf MoE LLM designs.\n","authors":["Fuzhao Xue","Zian Zheng","Yao Fu","Jinjie Ni","Zangwei Zheng","Wangchunshu Zhou","Yang You"],"pdf_url":"https://arxiv.org/pdf/2402.01739v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.01191v2","updated":"2024-03-27T10:12:31Z","published":"2023-11-02T12:36:19Z","title":"VIGraph: Generative Self-supervised Learning for Class-Imbalanced Node\n  Classification","summary":"  Class imbalance in graph data presents significant challenges for node\nclassification. While existing methods, such as SMOTE-based approaches,\npartially mitigate this issue, they still exhibit limitations in constructing\nimbalanced graphs. Generative self-supervised learning (SSL) methods,\nexemplified by graph autoencoders (GAEs), offer a promising solution by\ndirectly generating minority nodes from the data itself, yet their potential\nremains underexplored. In this paper, we delve into the shortcomings of\nSMOTE-based approaches in the construction of imbalanced graphs. Furthermore,\nwe introduce VIGraph, a simple yet effective generative SSL approach that\nrelies on the Variational GAE as the fundamental model. VIGraph strictly\nadheres to the concept of imbalance when constructing imbalanced graphs and\ninnovatively leverages the variational inference (VI) ability of Variational\nGAE to generate nodes for minority classes. VIGraph introduces comprehensive\ntraining strategies, including cross-view contrastive learning at the decoding\nphase to capture semantic knowledge, adjacency matrix reconstruction to\npreserve graph structure, and alignment strategy to ensure stable training.\nVIGraph can generate high-quality nodes directly usable for classification,\neliminating the need to integrate the generated nodes back to the graph as well\nas additional retraining found in SMOTE-based methods. We conduct extensive\nexperiments, results from which demonstrate the superiority and generality of\nour approach.\n","authors":["Yulan Hu","Sheng Ouyang","Zhirui Yang","Yong Liu"],"pdf_url":"https://arxiv.org/pdf/2311.01191v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.18415v1","updated":"2024-03-27T10:06:33Z","published":"2024-03-27T10:06:33Z","title":"The Topos of Transformer Networks","summary":"  The transformer neural network has significantly out-shined all other neural\nnetwork architectures as the engine behind large language models. We provide a\ntheoretical analysis of the expressivity of the transformer architecture\nthrough the lens of topos theory. From this viewpoint, we show that many common\nneural network architectures, such as the convolutional, recurrent and graph\nconvolutional networks, can be embedded in a pretopos of piecewise-linear\nfunctions, but that the transformer necessarily lives in its topos completion.\nIn particular, this suggests that the two network families instantiate\ndifferent fragments of logic: the former are first order, whereas transformers\nare higher-order reasoners. Furthermore, we draw parallels with architecture\nsearch and gradient descent, integrating our analysis in the framework of\ncybernetic agents.\n","authors":["Mattia Jacopo Villani","Peter McBurney"],"pdf_url":"https://arxiv.org/pdf/2403.18415v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2309.06075v2","updated":"2024-03-27T09:51:15Z","published":"2023-09-12T09:12:37Z","title":"A2V: A Semi-Supervised Domain Adaptation Framework for Brain Vessel\n  Segmentation via Two-Phase Training Angiography-to-Venography Translation","summary":"  We present a semi-supervised domain adaptation framework for brain vessel\nsegmentation from different image modalities. Existing state-of-the-art methods\nfocus on a single modality, despite the wide range of available cerebrovascular\nimaging techniques. This can lead to significant distribution shifts that\nnegatively impact the generalization across modalities. By relying on annotated\nangiographies and a limited number of annotated venographies, our framework\naccomplishes image-to-image translation and semantic segmentation, leveraging a\ndisentangled and semantically rich latent space to represent heterogeneous data\nand perform image-level adaptation from source to target domains. Moreover, we\nreduce the typical complexity of cycle-based architectures and minimize the use\nof adversarial training, which allows us to build an efficient and intuitive\nmodel with stable training. We evaluate our method on magnetic resonance\nangiographies and venographies. While achieving state-of-the-art performance in\nthe source domain, our method attains a Dice score coefficient in the target\ndomain that is only 8.9% lower, highlighting its promising potential for robust\ncerebrovascular image segmentation across different modalities.\n","authors":["Francesco Galati","Daniele Falcetta","Rosa Cortese","Barbara Casolla","Ferran Prados","Ninon Burgos","Maria A. Zuluaga"],"pdf_url":"https://arxiv.org/pdf/2309.06075v2.pdf","comment":"Accepted at the 34th British Machine Vision Conference (BMVC)"},{"id":"http://arxiv.org/abs/2310.05723v2","updated":"2024-03-27T09:48:34Z","published":"2023-10-09T13:47:05Z","title":"Planning to Go Out-of-Distribution in Offline-to-Online Reinforcement\n  Learning","summary":"  Offline pretraining with a static dataset followed by online fine-tuning\n(offline-to-online, or OtO) is a paradigm well matched to a real-world RL\ndeployment process. In this scenario, we aim to find the best-performing policy\nwithin a limited budget of online interactions. Previous work in the OtO\nsetting has focused on correcting for bias introduced by the policy-constraint\nmechanisms of offline RL algorithms. Such constraints keep the learned policy\nclose to the behavior policy that collected the dataset, but we show this can\nunnecessarily limit policy performance if the behavior policy is far from\noptimal. Instead, we forgo constraints and frame OtO RL as an exploration\nproblem that aims to maximize the benefit of online data-collection. We first\nstudy the major online RL exploration methods based on intrinsic rewards and\nUCB in the OtO setting, showing that intrinsic rewards add training instability\nthrough reward-function modification, and UCB methods are myopic and it is\nunclear which learned-component's ensemble to use for action selection. We then\nintroduce an algorithm for planning to go out-of-distribution (PTGOOD) that\navoids these issues. PTGOOD uses a non-myopic planning procedure that targets\nexploration in relatively high-reward regions of the state-action space\nunlikely to be visited by the behavior policy. By leveraging concepts from the\nConditional Entropy Bottleneck, PTGOOD encourages data collected online to\nprovide new information relevant to improving the final deployment policy\nwithout altering rewards. We show empirically in several continuous control\ntasks that PTGOOD significantly improves agent returns during online\nfine-tuning and avoids the suboptimal policy convergence that many of our\nbaselines exhibit in several environments.\n","authors":["Trevor McInroe","Adam Jelley","Stefano V. Albrecht","Amos Storkey"],"pdf_url":"https://arxiv.org/pdf/2310.05723v2.pdf","comment":"10 pages, 17 figures, preprint"},{"id":"http://arxiv.org/abs/2403.18406v1","updated":"2024-03-27T09:48:23Z","published":"2024-03-27T09:48:23Z","title":"An Image Grid Can Be Worth a Video: Zero-shot Video Question Answering\n  Using a VLM","summary":"  Stimulated by the sophisticated reasoning capabilities of recent Large\nLanguage Models (LLMs), a variety of strategies for bridging video modality\nhave been devised. A prominent strategy involves Video Language Models\n(VideoLMs), which train a learnable interface with video data to connect\nadvanced vision encoders with LLMs. Recently, an alternative strategy has\nsurfaced, employing readily available foundation models, such as VideoLMs and\nLLMs, across multiple stages for modality bridging. In this study, we introduce\na simple yet novel strategy where only a single Vision Language Model (VLM) is\nutilized. Our starting point is the plain insight that a video comprises a\nseries of images, or frames, interwoven with temporal information. The essence\nof video comprehension lies in adeptly managing the temporal aspects along with\nthe spatial details of each frame. Initially, we transform a video into a\nsingle composite image by arranging multiple frames in a grid layout. The\nresulting single image is termed as an image grid. This format, while\nmaintaining the appearance of a solitary image, effectively retains temporal\ninformation within the grid structure. Therefore, the image grid approach\nenables direct application of a single high-performance VLM without\nnecessitating any video-data training. Our extensive experimental analysis\nacross ten zero-shot video question answering benchmarks, including five\nopen-ended and five multiple-choice benchmarks, reveals that the proposed Image\nGrid Vision Language Model (IG-VLM) surpasses the existing methods in nine out\nof ten benchmarks.\n","authors":["Wonkyun Kim","Changin Choi","Wonseok Lee","Wonjong Rhee"],"pdf_url":"https://arxiv.org/pdf/2403.18406v1.pdf","comment":"Our code is available at https://github.com/imagegridworth/IG-VLM"},{"id":"http://arxiv.org/abs/2403.18402v1","updated":"2024-03-27T09:44:50Z","published":"2024-03-27T09:44:50Z","title":"On Spectrogram Analysis in a Multiple Classifier Fusion Framework for\n  Power Grid Classification Using Electric Network Frequency","summary":"  The Electric Network Frequency (ENF) serves as a unique signature inherent to\npower distribution systems. Here, a novel approach for power grid\nclassification is developed, leveraging ENF. Spectrograms are generated from\naudio and power recordings across different grids, revealing distinctive ENF\npatterns that aid in grid classification through a fusion of classifiers. Four\ntraditional machine learning classifiers plus a Convolutional Neural Network\n(CNN), optimized using Neural Architecture Search, are developed for One-vs-All\nclassification. This process generates numerous predictions per sample, which\nare then compiled and used to train a shallow multi-label neural network\nspecifically designed to model the fusion process, ultimately leading to the\nconclusive class prediction for each sample. Experimental findings reveal that\nboth validation and testing accuracy outperform those of current\nstate-of-the-art classifiers, underlining the effectiveness and robustness of\nthe proposed methodology.\n","authors":["Georgios Tzolopoulos","Christos Korgialas","Constantine Kotropoulos"],"pdf_url":"https://arxiv.org/pdf/2403.18402v1.pdf","comment":"13th International Conference on Pattern Recognition Applications and\n  Methods (ICPRAM)"},{"id":"http://arxiv.org/abs/2403.18397v1","updated":"2024-03-27T09:35:56Z","published":"2024-03-27T09:35:56Z","title":"Colour and Brush Stroke Pattern Recognition in Abstract Art using\n  Modified Deep Convolutional Generative Adversarial Networks","summary":"  Abstract Art is an immensely popular, discussed form of art that often has\nthe ability to depict the emotions of an artist. Many researchers have made\nattempts to study abstract art in the form of edge detection, brush stroke and\nemotion recognition algorithms using machine and deep learning. This papers\ndescribes the study of a wide distribution of abstract paintings using\nGenerative Adversarial Neural Networks(GAN). GANs have the ability to learn and\nreproduce a distribution enabling researchers and scientists to effectively\nexplore and study the generated image space. However, the challenge lies in\ndeveloping an efficient GAN architecture that overcomes common training\npitfalls. This paper addresses this challenge by introducing a modified-DCGAN\n(mDCGAN) specifically designed for high-quality artwork generation. The\napproach involves a thorough exploration of the modifications made, delving\ninto the intricate workings of DCGANs, optimisation techniques, and\nregularisation methods aimed at improving stability and realism in art\ngeneration enabling effective study of generated patterns. The proposed mDCGAN\nincorporates meticulous adjustments in layer configurations and architectural\nchoices, offering tailored solutions to the unique demands of art generation\nwhile effectively combating issues like mode collapse and gradient vanishing.\nFurther this paper explores the generated latent space by performing random\nwalks to understand vector relationships between brush strokes and colours in\nthe abstract art space and a statistical analysis of unstable outputs after a\ncertain period of GAN training and compare its significant difference. These\nfindings validate the effectiveness of the proposed approach, emphasising its\npotential to revolutionise the field of digital art generation and digital art\necosystem.\n","authors":["Srinitish Srinivasan","Varenya Pathak"],"pdf_url":"https://arxiv.org/pdf/2403.18397v1.pdf","comment":"28 pages, 5 tables, 7 figures"},{"id":"http://arxiv.org/abs/2403.18393v1","updated":"2024-03-27T09:30:50Z","published":"2024-03-27T09:30:50Z","title":"Tensor-based Graph Learning with Consistency and Specificity for\n  Multi-view Clustering","summary":"  Graph learning is widely recognized as a crucial technique in multi-view\nclustering. Existing graph learning methods typically involve constructing an\nadaptive neighbor graph based on probabilistic neighbors and then learning a\nconsensus graph to for clustering, however, they are confronted with two\nlimitations. Firstly, they often rely on Euclidean distance to measure\nsimilarity when constructing the adaptive neighbor graph, which proves\ninadequate in capturing the intrinsic structure among data points in many\nreal-world scenarios. Secondly, most of these methods focus solely on consensus\ngraph, ignoring view-specific graph information. In response to the\naforementioned drawbacks, we in this paper propose a novel tensor-based graph\nlearning framework that simultaneously considers consistency and specificity\nfor multi-view clustering. Specifically, we calculate the similarity distance\non the Stiefel manifold to preserve the intrinsic structure among data points.\nBy making an assumption that the learned neighbor graph of each view comprises\nboth a consistent graph and a view-specific graph, we formulate a new\ntensor-based target graph learning paradigm. Owing to the benefits of tensor\nsingular value decomposition (t-SVD) in uncovering high-order correlations,\nthis model is capable of achieving a complete understanding of the target\ngraph. Furthermore, we develop an iterative algorithm to solve the proposed\nobjective optimization problem. Experiments conducted on real-world datasets\nhave demonstrated the superior performance of the proposed method over some\nstate-of-the-art multi-view clustering methods. The source code has been\nreleased on https://github.com/lshi91/CSTGL-Code.\n","authors":["Long Shi","Lei Cao","Yunshan Ye","Yu Zhao","Badong Chen"],"pdf_url":"https://arxiv.org/pdf/2403.18393v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.18383v1","updated":"2024-03-27T09:21:07Z","published":"2024-03-27T09:21:07Z","title":"Generative Multi-modal Models are Good Class-Incremental Learners","summary":"  In class-incremental learning (CIL) scenarios, the phenomenon of catastrophic\nforgetting caused by the classifier's bias towards the current task has long\nposed a significant challenge. It is mainly caused by the characteristic of\ndiscriminative models. With the growing popularity of the generative\nmulti-modal models, we would explore replacing discriminative models with\ngenerative ones for CIL. However, transitioning from discriminative to\ngenerative models requires addressing two key challenges. The primary challenge\nlies in transferring the generated textual information into the classification\nof distinct categories. Additionally, it requires formulating the task of CIL\nwithin a generative framework. To this end, we propose a novel generative\nmulti-modal model (GMM) framework for class-incremental learning. Our approach\ndirectly generates labels for images using an adapted generative model. After\nobtaining the detailed text, we use a text encoder to extract text features and\nemploy feature matching to determine the most similar label as the\nclassification prediction. In the conventional CIL settings, we achieve\nsignificantly better results in long-sequence task scenarios. Under the\nFew-shot CIL setting, we have improved by at least 14\\% accuracy over all the\ncurrent state-of-the-art methods with significantly less forgetting. Our code\nis available at \\url{https://github.com/DoubleClass/GMM}.\n","authors":["Xusheng Cao","Haori Lu","Linlan Huang","Xialei Liu","Ming-Ming Cheng"],"pdf_url":"https://arxiv.org/pdf/2403.18383v1.pdf","comment":"Accepted at CVPR 2024"},{"id":"http://arxiv.org/abs/2403.18379v1","updated":"2024-03-27T09:17:50Z","published":"2024-03-27T09:17:50Z","title":"IIP-Mixer:Intra-Inter Patch Mixing Architecture for Battery Remaining\n  Useful Life Prediction","summary":"  Accurately estimating the Remaining Useful Life (RUL) of lithium-ion\nbatteries is crucial for maintaining the safe and stable operation of\nrechargeable battery management systems. However, this task is often\nchallenging due to the complex temporal dynamics involved. Recently,\nattention-based networks, such as Transformers and Informer, have been the\npopular architecture in time series forecasting. Despite their effectiveness,\nthese models with abundant parameters necessitate substantial training time to\nunravel temporal patterns. To tackle these challenges, we propose a simple\nMLP-Mixer-based architecture named 'Intra-Inter Patch Mixer' (IIP-Mixer), which\nis an architecture based exclusively on multi-layer perceptrons (MLPs),\nextracting information by mixing operations along both intra-patch and\ninter-patch dimensions for battery RUL prediction. The proposed IIP-Mixer\ncomprises parallel dual-head mixer layers: the intra-patch mixing MLP,\ncapturing local temporal patterns in the short-term period, and the inter-patch\nmixing MLP, capturing global temporal patterns in the long-term period.\nNotably, to address the varying importance of features in RUL prediction, we\nintroduce a weighted loss function in the MLP-Mixer-based architecture, marking\nthe first time such an approach has been employed. Our experiments demonstrate\nthat IIP-Mixer achieves competitive performance in battery RUL prediction,\noutperforming other popular time-series frameworks\n","authors":["Guangzai Ye","Li Feng","Jianlan Guo","Yuqiang Chen"],"pdf_url":"https://arxiv.org/pdf/2403.18379v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.18375v1","updated":"2024-03-27T09:14:36Z","published":"2024-03-27T09:14:36Z","title":"Stragglers-Aware Low-Latency Synchronous Federated Learning via\n  Layer-Wise Model Updates","summary":"  Synchronous federated learning (FL) is a popular paradigm for collaborative\nedge learning. It typically involves a set of heterogeneous devices locally\ntraining neural network (NN) models in parallel with periodic centralized\naggregations. As some of the devices may have limited computational resources\nand varying availability, FL latency is highly sensitive to stragglers.\nConventional approaches discard incomplete intra-model updates done by\nstragglers, alter the amount of local workload and architecture, or resort to\nasynchronous settings; which all affect the trained model performance under\ntight training latency constraints. In this work, we propose straggler-aware\nlayer-wise federated learning (SALF) that leverages the optimization procedure\nof NNs via backpropagation to update the global model in a layer-wise fashion.\nSALF allows stragglers to synchronously convey partial gradients, having each\nlayer of the global model be updated independently with a different\ncontributing set of users. We provide a theoretical analysis, establishing\nconvergence guarantees for the global model under mild assumptions on the\ndistribution of the participating devices, revealing that SALF converges at the\nsame asymptotic rate as FL with no timing limitations. This insight is matched\nwith empirical observations, demonstrating the performance gains of SALF\ncompared to alternative mechanisms mitigating the device heterogeneity gap in\nFL.\n","authors":["Natalie Lang","Alejandro Cohen","Nir Shlezinger"],"pdf_url":"https://arxiv.org/pdf/2403.18375v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2312.08533v4","updated":"2024-03-27T09:11:48Z","published":"2023-12-13T21:46:09Z","title":"World Models via Policy-Guided Trajectory Diffusion","summary":"  World models are a powerful tool for developing intelligent agents. By\npredicting the outcome of a sequence of actions, world models enable policies\nto be optimised via on-policy reinforcement learning (RL) using synthetic data,\ni.e. in \"in imagination\". Existing world models are autoregressive in that they\ninterleave predicting the next state with sampling the next action from the\npolicy. Prediction error inevitably compounds as the trajectory length grows.\nIn this work, we propose a novel world modelling approach that is not\nautoregressive and generates entire on-policy trajectories in a single pass\nthrough a diffusion model. Our approach, Policy-Guided Trajectory Diffusion\n(PolyGRAD), leverages a denoising model in addition to the gradient of the\naction distribution of the policy to diffuse a trajectory of initially random\nstates and actions into an on-policy synthetic trajectory. We analyse the\nconnections between PolyGRAD, score-based generative models, and\nclassifier-guided diffusion models. Our results demonstrate that PolyGRAD\noutperforms state-of-the-art baselines in terms of trajectory prediction error\nfor short trajectories, with the exception of autoregressive diffusion. For\nshort trajectories, PolyGRAD obtains similar errors to autoregressive\ndiffusion, but with lower computational requirements. For long trajectories,\nPolyGRAD obtains comparable performance to baselines. Our experiments\ndemonstrate that PolyGRAD enables performant policies to be trained via\non-policy RL in imagination for MuJoCo continuous control domains. Thus,\nPolyGRAD introduces a new paradigm for accurate on-policy world modelling\nwithout autoregressive sampling.\n","authors":["Marc Rigter","Jun Yamada","Ingmar Posner"],"pdf_url":"https://arxiv.org/pdf/2312.08533v4.pdf","comment":"Published in TMLR, March 2024"},{"id":"http://arxiv.org/abs/2102.12920v5","updated":"2024-03-27T09:07:29Z","published":"2021-02-25T15:18:13Z","title":"Emerging Trends in Federated Learning: From Model Fusion to Federated X\n  Learning","summary":"  Federated learning is a new learning paradigm that decouples data collection\nand model training via multi-party computation and model aggregation. As a\nflexible learning setting, federated learning has the potential to integrate\nwith other learning frameworks. We conduct a focused survey of federated\nlearning in conjunction with other learning algorithms. Specifically, we\nexplore various learning algorithms to improve the vanilla federated averaging\nalgorithm and review model fusion methods such as adaptive aggregation,\nregularization, clustered methods, and Bayesian methods. Following the emerging\ntrends, we also discuss federated learning in the intersection with other\nlearning paradigms, termed federated X learning, where X includes multitask\nlearning, meta-learning, transfer learning, unsupervised learning, and\nreinforcement learning. In addition to reviewing state-of-the-art studies, this\npaper also identifies key challenges and applications in this field, while also\nhighlighting promising future directions.\n","authors":["Shaoxiong Ji","Yue Tan","Teemu Saravirta","Zhiqin Yang","Yixin Liu","Lauri Vasankari","Shirui Pan","Guodong Long","Anwar Walid"],"pdf_url":"https://arxiv.org/pdf/2102.12920v5.pdf","comment":"To appear in the International Journal of Machine Learning and\n  Cybernetics"},{"id":"http://arxiv.org/abs/2403.17905v2","updated":"2024-03-27T09:07:02Z","published":"2024-03-26T17:45:06Z","title":"Scalable Non-Cartesian Magnetic Resonance Imaging with R2D2","summary":"  We propose a new approach for non-Cartesian magnetic resonance image\nreconstruction. While unrolled architectures provide robustness via\ndata-consistency layers, embedding measurement operators in Deep Neural Network\n(DNN) can become impractical at large scale. Alternative Plug-and-Play (PnP)\napproaches, where the denoising DNNs are blind to the measurement setting, are\nnot affected by this limitation and have also proven effective, but their\nhighly iterative nature also affects scalability. To address this scalability\nchallenge, we leverage the \"Residual-to-Residual DNN series for high-Dynamic\nrange imaging (R2D2)\" approach recently introduced in astronomical imaging.\nR2D2's reconstruction is formed as a series of residual images, iteratively\nestimated as outputs of DNNs taking the previous iteration's image estimate and\nassociated data residual as inputs. The method can be interpreted as a learned\nversion of the Matching Pursuit algorithm. We demonstrate R2D2 in simulation,\nconsidering radial k-space sampling acquisition sequences. Our preliminary\nresults suggest that R2D2 achieves: (i) suboptimal performance compared to its\nunrolled incarnation R2D2-Net, which is however non-scalable due to the\nnecessary embedding of NUFFT-based data-consistency layers; (ii) superior\nreconstruction quality to a scalable version of R2D2-Net embedding an FFT-based\napproximation for data consistency; (iii) superior reconstruction quality to\nPnP, while only requiring few iterations.\n","authors":["Yiwei Chen","Chao Tang","Amir Aghabiglou","Chung San Chu","Yves Wiaux"],"pdf_url":"https://arxiv.org/pdf/2403.17905v2.pdf","comment":"submitted to IEEE EUSIPCO 2024"},{"id":"http://arxiv.org/abs/2403.18370v1","updated":"2024-03-27T09:06:36Z","published":"2024-03-27T09:06:36Z","title":"Ship in Sight: Diffusion Models for Ship-Image Super Resolution","summary":"  In recent years, remarkable advancements have been achieved in the field of\nimage generation, primarily driven by the escalating demand for high-quality\noutcomes across various image generation subtasks, such as inpainting,\ndenoising, and super resolution. A major effort is devoted to exploring the\napplication of super-resolution techniques to enhance the quality of\nlow-resolution images. In this context, our method explores in depth the\nproblem of ship image super resolution, which is crucial for coastal and port\nsurveillance. We investigate the opportunity given by the growing interest in\ntext-to-image diffusion models, taking advantage of the prior knowledge that\nsuch foundation models have already learned. In particular, we present a\ndiffusion-model-based architecture that leverages text conditioning during\ntraining while being class-aware, to best preserve the crucial details of the\nships during the generation of the super-resoluted image. Since the specificity\nof this task and the scarcity availability of off-the-shelf data, we also\nintroduce a large labeled ship dataset scraped from online ship images, mostly\nfrom ShipSpotting\\footnote{\\url{www.shipspotting.com}} website. Our method\nachieves more robust results than other deep learning models previously\nemployed for super resolution, as proven by the multiple experiments performed.\nMoreover, we investigate how this model can benefit downstream tasks, such as\nclassification and object detection, thus emphasizing practical implementation\nin a real-world scenario. Experimental results show flexibility, reliability,\nand impressive performance of the proposed framework over state-of-the-art\nmethods for different tasks. The code is available at:\nhttps://github.com/LuigiSigillo/ShipinSight .\n","authors":["Luigi Sigillo","Riccardo Fosco Gramaccioni","Alessandro Nicolosi","Danilo Comminiello"],"pdf_url":"https://arxiv.org/pdf/2403.18370v1.pdf","comment":"Accepted at 2024 International Joint Conference on Neural Networks\n  (IJCNN)"},{"id":"http://arxiv.org/abs/2307.13352v2","updated":"2024-03-27T09:04:04Z","published":"2023-07-25T09:14:45Z","title":"High Dimensional Distributed Gradient Descent with Arbitrary Number of\n  Byzantine Attackers","summary":"  Robust distributed learning with Byzantine failures has attracted extensive\nresearch interests in recent years. However, most of existing methods suffer\nfrom curse of dimensionality, which is increasingly serious with the growing\ncomplexity of modern machine learning models. In this paper, we design a new\nmethod that is suitable for high dimensional problems, under arbitrary number\nof Byzantine attackers. The core of our design is a direct high dimensional\nsemi-verified mean estimation method. Our idea is to identify a subspace first.\nThe components of mean value perpendicular to this subspace can be estimated\nvia gradient vectors uploaded from worker machines, while the components within\nthis subspace are estimated using auxiliary dataset. We then use our new method\nas the aggregator of distributed learning problems. Our theoretical analysis\nshows that the new method has minimax optimal statistical rates. In particular,\nthe dependence on dimensionality is significantly improved compared with\nprevious works.\n","authors":["Puning Zhao","Zhiguo Wan"],"pdf_url":"https://arxiv.org/pdf/2307.13352v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.10158v2","updated":"2024-03-27T08:57:20Z","published":"2024-03-15T10:01:19Z","title":"Functional Graph Convolutional Networks: A unified multi-task and\n  multi-modal learning framework to facilitate health and social-care insights","summary":"  This paper introduces a novel Functional Graph Convolutional Network (funGCN)\nframework that combines Functional Data Analysis and Graph Convolutional\nNetworks to address the complexities of multi-task and multi-modal learning in\ndigital health and longitudinal studies. With the growing importance of health\nsolutions to improve health care and social support, ensure healthy lives, and\npromote well-being at all ages, funGCN offers a unified approach to handle\nmultivariate longitudinal data for multiple entities and ensures\ninterpretability even with small sample sizes. Key innovations include\ntask-specific embedding components that manage different data types, the\nability to perform classification, regression, and forecasting, and the\ncreation of a knowledge graph for insightful data interpretation. The efficacy\nof funGCN is validated through simulation experiments and a real-data\napplication.\n","authors":["Tobia Boschi","Francesca Bonin","Rodrigo Ordonez-Hurtado","C√©cile Rousseau","Alessandra Pascale","John Dinsmore"],"pdf_url":"https://arxiv.org/pdf/2403.10158v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.18364v1","updated":"2024-03-27T08:57:15Z","published":"2024-03-27T08:57:15Z","title":"Intent-Aware DRL-Based Uplink Dynamic Scheduler for 5G-NR","summary":"  We investigate the problem of supporting Industrial Internet of Things user\nequipment (IIoT UEs) with intent (i.e., requested quality of service (QoS)) and\nrandom traffic arrival. A deep reinforcement learning (DRL) based centralized\ndynamic scheduler for time-frequency resources is proposed to learn how to\nschedule the available communication resources among the IIoT UEs. The proposed\nscheduler leverages an RL framework to adapt to the dynamic changes in the\nwireless communication system and traffic arrivals. Moreover, a graph-based\nreduction scheme is proposed to reduce the state and action space of the RL\nframework to allow fast convergence and a better learning strategy. Simulation\nresults demonstrate the effectiveness of the proposed intelligent scheduler in\nguaranteeing the expressed intent of IIoT UEs compared to several traditional\nscheduling schemes, such as round-robin, semi-static, and heuristic approaches.\nThe proposed scheduler also outperforms the contention-free and\ncontention-based schemes in maximizing the number of successfully computed\ntasks.\n","authors":["Salwa Mostafa","Mateus P. Mota","Alvaro Valcarce","Mehdi Bennis"],"pdf_url":"https://arxiv.org/pdf/2403.18364v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2310.03325v2","updated":"2024-03-27T08:54:35Z","published":"2023-10-05T05:41:21Z","title":"Learning Concept-Based Causal Transition and Symbolic Reasoning for\n  Visual Planning","summary":"  Visual planning simulates how humans make decisions to achieve desired goals\nin the form of searching for visual causal transitions between an initial\nvisual state and a final visual goal state. It has become increasingly\nimportant in egocentric vision with its advantages in guiding agents to perform\ndaily tasks in complex environments. In this paper, we propose an interpretable\nand generalizable visual planning framework consisting of i) a novel\nSubstitution-based Concept Learner (SCL) that abstracts visual inputs into\ndisentangled concept representations, ii) symbol abstraction and reasoning that\nperforms task planning via the self-learned symbols, and iii) a Visual Causal\nTransition model (ViCT) that grounds visual causal transitions to semantically\nsimilar real-world actions. Given an initial state, we perform goal-conditioned\nvisual planning with a symbolic reasoning method fueled by the learned\nrepresentations and causal transitions to reach the goal state. To verify the\neffectiveness of the proposed model, we collect a large-scale visual planning\ndataset based on AI2-THOR, dubbed as CCTP. Extensive experiments on this\nchallenging dataset demonstrate the superior performance of our method in\nvisual task planning. Empirically, we show that our framework can generalize to\nunseen task trajectories, unseen object categories, and real-world data.\nFurther details of this work are provided at\nhttps://fqyqc.github.io/ConTranPlan/.\n","authors":["Yilue Qian","Peiyu Yu","Ying Nian Wu","Yao Su","Wei Wang","Lifeng Fan"],"pdf_url":"https://arxiv.org/pdf/2310.03325v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.15837v2","updated":"2024-03-27T08:54:06Z","published":"2024-03-23T13:24:31Z","title":"Centered Masking for Language-Image Pre-Training","summary":"  We introduce Gaussian masking for Language-Image Pre-Training (GLIP) a novel,\nstraightforward, and effective technique for masking image patches during\npre-training of a vision-language model. GLIP builds on Fast Language-Image\nPre-Training (FLIP), which randomly masks image patches while training a CLIP\nmodel. GLIP replaces random masking with centered masking, that uses a Gaussian\ndistribution and is inspired by the importance of image patches at the center\nof the image. GLIP retains the same computational savings as FLIP, while\nimproving performance across a range of downstream datasets and tasks, as\ndemonstrated by our experimental results. We show the benefits of GLIP to be\neasy to obtain, requiring no delicate tuning of the Gaussian, and also\napplicable to data sets containing images without an obvious center focus.\n","authors":["Mingliang Liang","Martha Larson"],"pdf_url":"https://arxiv.org/pdf/2403.15837v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.17767v2","updated":"2024-03-27T08:49:19Z","published":"2024-03-26T14:54:35Z","title":"Asymptotic Bayes risk of semi-supervised learning with uncertain\n  labeling","summary":"  This article considers a semi-supervised classification setting on a Gaussian\nmixture model, where the data is not labeled strictly as usual, but instead\nwith uncertain labels. Our main aim is to compute the Bayes risk for this\nmodel. We compare the behavior of the Bayes risk and the best known algorithm\nfor this model. This comparison eventually gives new insights over the\nalgorithm.\n","authors":["Victor Leger","Romain Couillet"],"pdf_url":"https://arxiv.org/pdf/2403.17767v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.18355v1","updated":"2024-03-27T08:48:16Z","published":"2024-03-27T08:48:16Z","title":"Supervised Multiple Kernel Learning approaches for multi-omics data\n  integration","summary":"  Advances in high-throughput technologies have originated an ever-increasing\navailability of omics datasets. The integration of multiple heterogeneous data\nsources is currently an issue for biology and bioinformatics. Multiple kernel\nlearning (MKL) has shown to be a flexible and valid approach to consider the\ndiverse nature of multi-omics inputs, despite being an underused tool in\ngenomic data mining.We provide novel MKL approaches based on different kernel\nfusion strategies.To learn from the meta-kernel of input kernels, we\nadaptedunsupervised integration algorithms for supervised tasks with support\nvector machines.We also tested deep learning architectures for kernel fusion\nand classification.The results show that MKL-based models can compete with more\ncomplex, state-of-the-art, supervised multi-omics integrative approaches.\nMultiple kernel learning offers a natural framework for predictive models in\nmulti-omics genomic data. Our results offer a direction for bio-data mining\nresearch and further development of methods for heterogeneous data integration.\n","authors":["Mitja Briscik","Gabriele Tazza","Marie-Agnes Dillies","L√°szl√≥ Vid√°cs","S√©bastien Dejean"],"pdf_url":"https://arxiv.org/pdf/2403.18355v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2305.02151v2","updated":"2024-03-27T08:43:28Z","published":"2023-05-03T14:33:23Z","title":"Identifying the Correlation Between Language Distance and Cross-Lingual\n  Transfer in a Multilingual Representation Space","summary":"  Prior research has investigated the impact of various linguistic features on\ncross-lingual transfer performance. In this study, we investigate the manner in\nwhich this effect can be mapped onto the representation space. While past\nstudies have focused on the impact on cross-lingual alignment in multilingual\nlanguage models during fine-tuning, this study examines the absolute evolution\nof the respective language representation spaces produced by MLLMs. We place a\nspecific emphasis on the role of linguistic characteristics and investigate\ntheir inter-correlation with the impact on representation spaces and\ncross-lingual transfer performance. Additionally, this paper provides\npreliminary evidence of how these findings can be leveraged to enhance transfer\nto linguistically distant languages.\n","authors":["Fred Philippy","Siwen Guo","Shohreh Haddadan"],"pdf_url":"https://arxiv.org/pdf/2305.02151v2.pdf","comment":"SIGTYP Workshop 2023 (co-located with EACL 2023)"},{"id":"http://arxiv.org/abs/2403.18351v1","updated":"2024-03-27T08:42:47Z","published":"2024-03-27T08:42:47Z","title":"Generating Diverse Agricultural Data for Vision-Based Farming\n  Applications","summary":"  We present a specialized procedural model for generating synthetic\nagricultural scenes, focusing on soybean crops, along with various weeds. This\nmodel is capable of simulating distinct growth stages of these plants, diverse\nsoil conditions, and randomized field arrangements under varying lighting\nconditions. The integration of real-world textures and environmental factors\ninto the procedural generation process enhances the photorealism and\napplicability of the synthetic data. Our dataset includes 12,000 images with\nsemantic labels, offering a comprehensive resource for computer vision tasks in\nprecision agriculture, such as semantic segmentation for autonomous weed\ncontrol. We validate our model's effectiveness by comparing the synthetic data\nagainst real agricultural images, demonstrating its potential to significantly\naugment training data for machine learning models in agriculture. This approach\nnot only provides a cost-effective solution for generating high-quality,\ndiverse data but also addresses specific needs in agricultural vision tasks\nthat are not fully covered by general-purpose models.\n","authors":["Mikolaj Cieslak","Umabharathi Govindarajan","Alejandro Garcia","Anuradha Chandrashekar","Torsten H√§drich","Aleksander Mendoza-Drosik","Dominik L. Michels","S√∂ren Pirk","Chia-Chun Fu","Wojciech Pa≈Çubicki"],"pdf_url":"https://arxiv.org/pdf/2403.18351v1.pdf","comment":"10 pages, 8 figures, 3 tables"},{"id":"http://arxiv.org/abs/2403.18347v1","updated":"2024-03-27T08:38:56Z","published":"2024-03-27T08:38:56Z","title":"A Quantum Fuzzy-based Approach for Real-Time Detection of Solar Coronal\n  Holes","summary":"  The detection and analysis of the solar coronal holes (CHs) is an important\nfield of study in the domain of solar physics. Mainly, it is required for the\nproper prediction of the geomagnetic storms which directly or indirectly affect\nvarious space and ground-based systems. For the detection of CHs till date, the\nsolar scientist depends on manual hand-drawn approaches. However, with the\nadvancement of image processing technologies, some automated image segmentation\nmethods have been used for the detection of CHs. In-spite of this, fast and\naccurate detection of CHs are till a major issues. Here in this work, a novel\nquantum computing-based fast fuzzy c-mean technique has been developed for fast\ndetection of the CHs region. The task has been carried out in two stages, in\nfirst stage the solar image has been segmented using a quantum computing based\nfast fuzzy c-mean (QCFFCM) and in the later stage the CHs has been extracted\nout from the segmented image based on image morphological operation. In the\nwork, quantum computing has been used to optimize the cost function of the fast\nfuzzy c-mean (FFCM) algorithm, where quantum approximate optimization algorithm\n(QAOA) has been used to optimize the quadratic part of the cost function. The\nproposed method has been tested for 193 \\AA{} SDO/AIA full-disk solar image\ndatasets and has been compared with the existing techniques. The outcome shows\nthe comparable performance of the proposed method with the existing one within\na very lesser time.\n","authors":["Sanmoy Bandyopadhyay","Suman Kundu"],"pdf_url":"https://arxiv.org/pdf/2403.18347v1.pdf","comment":"14 pages, 5 figures, 3 tables"},{"id":"http://arxiv.org/abs/2403.18343v1","updated":"2024-03-27T08:34:39Z","published":"2024-03-27T08:34:39Z","title":"The Artificial Neural Twin -- Process Optimization and Continual\n  Learning in Distributed Process Chains","summary":"  Industrial process optimization and control is crucial to increase economic\nand ecologic efficiency. However, data sovereignty, differing goals, or the\nrequired expert knowledge for implementation impede holistic implementation.\nFurther, the increasing use of data-driven AI-methods in process models and\nindustrial sensory often requires regular fine-tuning to accommodate\ndistribution drifts. We propose the Artificial Neural Twin, which combines\nconcepts from model predictive control, deep learning, and sensor networks to\naddress these issues. Our approach introduces differentiable data fusion to\nestimate the state of distributed process steps and their dependence on input\ndata. By treating the interconnected process steps as a quasi neural-network,\nwe can backpropagate loss gradients for process optimization or model\nfine-tuning to process parameters or AI models respectively. The concept is\ndemonstrated on a virtual machine park simulated in Unity, consisting of bulk\nmaterial processes in plastic recycling.\n","authors":["Johannes Emmert","Ronald Mendez","Houman Mirzaalian Dastjerdi","Christopher Syben","Andreas Maier"],"pdf_url":"https://arxiv.org/pdf/2403.18343v1.pdf","comment":"20 pages, 11 figures"},{"id":"http://arxiv.org/abs/2403.18337v1","updated":"2024-03-27T08:21:41Z","published":"2024-03-27T08:21:41Z","title":"Macroscale fracture surface segmentation via semi-supervised learning\n  considering the structural similarity","summary":"  To this date the safety assessment of materials, used for example in the\nnuclear power sector, commonly relies on a fracture mechanical analysis\nutilizing macroscopic concepts, where a global load quantity K or J is compared\nto the materials fracture toughness curve. Part of the experimental effort\ninvolved in these concepts is dedicated to the quantitative analysis of\nfracture surfaces. Within the scope of this study a methodology for the\nsemi-supervised training of deep learning models for fracture surface\nsegmentation on a macroscopic level was established. Therefore, three distinct\nand unique datasets were created to analyze the influence of structural\nsimilarity on the segmentation capability. The structural similarity differs\ndue to the assessed materials and specimen, as well as imaging-induced variance\ndue to fluctuations in image acquisition in different laboratories. The\ndatasets correspond to typical isolated laboratory conditions, complex\nreal-world circumstances, and a curated subset of the two. We implemented a\nweak-to-strong consistency regularization for semi-supervised learning. On the\nheterogeneous dataset we were able to train robust and well-generalizing models\nthat learned feature representations from images across different domains\nwithout observing a significant drop in prediction quality. Furthermore, our\napproach reduced the number of labeled images required for training by a factor\nof 6. To demonstrate the success of our method and the benefit of our approach\nfor the fracture mechanics assessment, we utilized the models for initial crack\nsize measurements with the area average method. For the laboratory setting, the\ndeep learning assisted measurements proved to have the same quality as manual\nmeasurements. For models trained on the heterogeneous dataset, very good\nmeasurement accuracies with mean deviations smaller than 1 % could be\nachieved...\n","authors":["Johannes Rosenberger","Johannes Tlatlik","Sebastian M√ºnstermann"],"pdf_url":"https://arxiv.org/pdf/2403.18337v1.pdf","comment":"During review title changed to: Deep learning based initial crack\n  size measurements utilizing macroscale fracture surface segmentation"},{"id":"http://arxiv.org/abs/2403.18336v1","updated":"2024-03-27T08:21:01Z","published":"2024-03-27T08:21:01Z","title":"A Dataset for Pharmacovigilance in German, French, and Japanese:\n  Annotating Adverse Drug Reactions across Languages","summary":"  User-generated data sources have gained significance in uncovering Adverse\nDrug Reactions (ADRs), with an increasing number of discussions occurring in\nthe digital world. However, the existing clinical corpora predominantly revolve\naround scientific articles in English. This work presents a multilingual corpus\nof texts concerning ADRs gathered from diverse sources, including patient fora,\nsocial media, and clinical reports in German, French, and Japanese. Our corpus\ncontains annotations covering 12 entity types, four attribute types, and 13\nrelation types. It contributes to the development of real-world multilingual\nlanguage models for healthcare. We provide statistics to highlight certain\nchallenges associated with the corpus and conduct preliminary experiments\nresulting in strong baselines for extracting entities and relations between\nthese entities, both within and across languages.\n","authors":["Lisa Raithel","Hui-Syuan Yeh","Shuntaro Yada","Cyril Grouin","Thomas Lavergne","Aur√©lie N√©v√©ol","Patrick Paroubek","Philippe Thomas","Tomohiro Nishiyama","Sebastian M√∂ller","Eiji Aramaki","Yuji Matsumoto","Roland Roller","Pierre Zweigenbaum"],"pdf_url":"https://arxiv.org/pdf/2403.18336v1.pdf","comment":"Accepted at LREC-COLING 2024"},{"id":"http://arxiv.org/abs/2403.18330v1","updated":"2024-03-27T08:11:25Z","published":"2024-03-27T08:11:25Z","title":"Tracking-Assisted Object Detection with Event Cameras","summary":"  Event-based object detection has recently garnered attention in the computer\nvision community due to the exceptional properties of event cameras, such as\nhigh dynamic range and no motion blur. However, feature asynchronism and\nsparsity cause invisible objects due to no relative motion to the camera,\nposing a significant challenge in the task. Prior works have studied various\nmemory mechanisms to preserve as many features as possible at the current time,\nguided by temporal clues. While these implicit-learned memories retain some\nshort-term information, they still struggle to preserve long-term features\neffectively. In this paper, we consider those invisible objects as\npseudo-occluded objects and aim to reveal their features. Firstly, we introduce\nvisibility attribute of objects and contribute an auto-labeling algorithm to\nappend additional visibility labels on an existing event camera dataset.\nSecondly, we exploit tracking strategies for pseudo-occluded objects to\nmaintain their permanence and retain their bounding boxes, even when features\nhave not been available for a very long time. These strategies can be treated\nas an explicit-learned memory guided by the tracking objective to record the\ndisplacements of objects across frames. Lastly, we propose a spatio-temporal\nfeature aggregation module to enrich the latent features and a consistency loss\nto increase the robustness of the overall pipeline. We conduct comprehensive\nexperiments to verify our method's effectiveness where still objects are\nretained but real occluded objects are discarded. The results demonstrate that\n(1) the additional visibility labels can assist in supervised training, and (2)\nour method outperforms state-of-the-art approaches with a significant\nimprovement of 7.9% absolute mAP.\n","authors":["Ting-Kang Yen","Igor Morawski","Shusil Dangi","Kai He","Chung-Yi Lin","Jia-Fong Yeh","Hung-Ting Su","Winston Hsu"],"pdf_url":"https://arxiv.org/pdf/2403.18330v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.18326v1","updated":"2024-03-27T08:07:07Z","published":"2024-03-27T08:07:07Z","title":"Privacy-Preserving Distributed Nonnegative Matrix Factorization","summary":"  Nonnegative matrix factorization (NMF) is an effective data representation\ntool with numerous applications in signal processing and machine learning.\nHowever, deploying NMF in a decentralized manner over ad-hoc networks\nintroduces privacy concerns due to the conventional approach of sharing raw\ndata among network agents. To address this, we propose a privacy-preserving\nalgorithm for fully-distributed NMF that decomposes a distributed large data\nmatrix into left and right matrix factors while safeguarding each agent's local\ndata privacy. It facilitates collaborative estimation of the left matrix factor\namong agents and enables them to estimate their respective right factors\nwithout exposing raw data. To ensure data privacy, we secure information\nexchanges between neighboring agents utilizing the Paillier cryptosystem, a\nprobabilistic asymmetric algorithm for public-key cryptography that allows\ncomputations on encrypted data without decryption. Simulation results conducted\non synthetic and real-world datasets demonstrate the effectiveness of the\nproposed algorithm in achieving privacy-preserving distributed NMF over ad-hoc\nnetworks.\n","authors":["Ehsan Lari","Reza Arablouei","Stefan Werner"],"pdf_url":"https://arxiv.org/pdf/2403.18326v1.pdf","comment":"5 pages, 1 figure, submitted to EUSIPCO 2024 conference"},{"id":"http://arxiv.org/abs/2403.18322v1","updated":"2024-03-27T07:52:10Z","published":"2024-03-27T07:52:10Z","title":"Quantum Algorithms: A New Frontier in Financial Crime Prevention","summary":"  Financial crimes fast proliferation and sophistication require novel\napproaches that provide robust and effective solutions. This paper explores the\npotential of quantum algorithms in combating financial crimes. It highlights\nthe advantages of quantum computing by examining traditional and Machine\nLearning (ML) techniques alongside quantum approaches. The study showcases\nadvanced methodologies such as Quantum Machine Learning (QML) and Quantum\nArtificial Intelligence (QAI) as powerful solutions for detecting and\npreventing financial crimes, including money laundering, financial crime\ndetection, cryptocurrency attacks, and market manipulation. These quantum\napproaches leverage the inherent computational capabilities of quantum\ncomputers to overcome limitations faced by classical methods. Furthermore, the\npaper illustrates how quantum computing can support enhanced financial risk\nmanagement analysis. Financial institutions can improve their ability to\nidentify and mitigate risks, leading to more robust risk management strategies\nby exploiting the quantum advantage. This research underscores the\ntransformative impact of quantum algorithms on financial risk management. By\nembracing quantum technologies, organisations can enhance their capabilities to\ncombat evolving threats and ensure the integrity and stability of financial\nsystems.\n","authors":["Abraham Itzhak Weinberg","Alessio Faccia"],"pdf_url":"https://arxiv.org/pdf/2403.18322v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.18321v1","updated":"2024-03-27T07:50:45Z","published":"2024-03-27T07:50:45Z","title":"Implementation of the Principal Component Analysis onto High-Performance\n  Computer Facilities for Hyperspectral Dimensionality Reduction: Results and\n  Comparisons","summary":"  Dimensionality reduction represents a critical preprocessing step in order to\nincrease the efficiency and the performance of many hyperspectral imaging\nalgorithms. However, dimensionality reduction algorithms, such as the Principal\nComponent Analysis (PCA), suffer from their computationally demanding nature,\nbecoming advisable for their implementation onto high-performance computer\narchitectures for applications under strict latency constraints. This work\npresents the implementation of the PCA algorithm onto two different\nhigh-performance devices, namely, an NVIDIA Graphics Processing Unit (GPU) and\na Kalray manycore, uncovering a highly valuable set of tips and tricks in order\nto take full advantage of the inherent parallelism of these high-performance\ncomputing platforms, and hence, reducing the time that is required to process a\ngiven hyperspectral image. Moreover, the achieved results obtained with\ndifferent hyperspectral images have been compared with the ones that were\nobtained with a field programmable gate array (FPGA)-based implementation of\nthe PCA algorithm that has been recently published, providing, for the first\ntime in the literature, a comprehensive analysis in order to highlight the pros\nand cons of each option.\n","authors":["E. Martel","R. Lazcano","J. Lopez","D. Madro√±al","R. Salvador","S. Lopez","E. Juarez","R. Guerra","C. Sanz","R. Sarmiento"],"pdf_url":"https://arxiv.org/pdf/2403.18321v1.pdf","comment":"30 pages, 10 figures"},{"id":"http://arxiv.org/abs/2403.18316v1","updated":"2024-03-27T07:38:36Z","published":"2024-03-27T07:38:36Z","title":"Multi-Modal Contrastive Learning for Online Clinical Time-Series\n  Applications","summary":"  Electronic Health Record (EHR) datasets from Intensive Care Units (ICU)\ncontain a diverse set of data modalities. While prior works have successfully\nleveraged multiple modalities in supervised settings, we apply advanced\nself-supervised multi-modal contrastive learning techniques to ICU data,\nspecifically focusing on clinical notes and time-series for clinically relevant\nonline prediction tasks. We introduce a loss function Multi-Modal Neighborhood\nContrastive Loss (MM-NCL), a soft neighborhood function, and showcase the\nexcellent linear probe and zero-shot performance of our approach.\n","authors":["Fabian Baldenweg","Manuel Burger","Gunnar R√§tsch","Rita Kuznetsova"],"pdf_url":"https://arxiv.org/pdf/2403.18316v1.pdf","comment":"Accepted as a Workshop Paper at TS4H@ICLR2024"},{"id":"http://arxiv.org/abs/2403.12820v2","updated":"2024-03-27T07:35:47Z","published":"2024-03-19T15:21:00Z","title":"A Physics-embedded Deep Learning Framework for Cloth Simulation","summary":"  Delicate cloth simulations have long been desired in computer graphics.\nVarious methods were proposed to improve engaged force interactions, collision\nhandling, and numerical integrations. Deep learning has the potential to\nachieve fast and real-time simulation, but common neural network structures\noften demand many parameters to capture cloth dynamics. This paper proposes a\nphysics-embedded learning framework that directly encodes physical features of\ncloth simulation. The convolutional neural network is used to represent spatial\ncorrelations of the mass-spring system, after which three branches are designed\nto learn linear, nonlinear, and time derivate features of cloth physics. The\nframework can also integrate with other external forces and collision handling\nthrough either traditional simulators or sub neural networks. The model is\ntested across different cloth animation cases, without training with new data.\nAgreement with baselines and predictive realism successfully validate its\ngeneralization ability. Inference efficiency of the proposed model also defeats\ntraditional physics simulation. This framework is also designed to easily\nintegrate with other visual refinement techniques like wrinkle carving, which\nleaves significant chances to incorporate prevailing macing learning techniques\nin 3D cloth amination.\n","authors":["Zhiwei Zhao"],"pdf_url":"https://arxiv.org/pdf/2403.12820v2.pdf","comment":"A derivation is incomplete, and updations are being processed"},{"id":"http://arxiv.org/abs/2403.18310v1","updated":"2024-03-27T07:22:32Z","published":"2024-03-27T07:22:32Z","title":"A thermodynamically consistent physics-informed deep learning material\n  model for short fiber/polymer nanocomposites","summary":"  This work proposes a physics-informed deep learning (PIDL)-based constitutive\nmodel for investigating the viscoelastic-viscoplastic behavior of short\nfiber-reinforced nanoparticle-filled epoxies under various ambient conditions.\nThe deep-learning model is trained to enforce thermodynamic principles, leading\nto a thermodynamically consistent constitutive model. To accomplish this, a\nlong short-term memory network is combined with a feed-forward neural network\nto predict internal variables required for characterizing the internal\ndissipation of the nanocomposite materials. In addition, another feed-forward\nneural network is used to indicate the free-energy function, which enables\ndefining the thermodynamic state of the entire system. The PIDL model is\ninitially developed for the three-dimensional case by generating synthetic data\nfrom a classical constitutive model. The model is then trained by extracting\nthe data directly from cyclic loading-unloading experimental tests. Numerical\nexamples show that the PIDL model can accurately predict the mechanical\nbehavior of epoxy-based nanocomposites for different volume fractions of fibers\nand nanoparticles under various hygrothermal conditions.\n","authors":["Betim Bahtiri","Behrouz Arash","Sven Scheffler","Maximilian Jux","Raimund Rolfes"],"pdf_url":"https://arxiv.org/pdf/2403.18310v1.pdf","comment":"arXiv admin note: text overlap with arXiv:2305.08102"},{"id":"http://arxiv.org/abs/2310.17072v3","updated":"2024-03-27T07:04:58Z","published":"2023-10-26T00:28:37Z","title":"MMP++: Motion Manifold Primitives with Parametric Curve Models","summary":"  Motion Manifold Primitives (MMP), a manifold-based approach for encoding\nbasic motion skills, can produce diverse trajectories, enabling the system to\nadapt to unseen constraints. Nonetheless, we argue that current MMP models lack\ncrucial functionalities of movement primitives, such as temporal and via-points\nmodulation, found in traditional approaches. This shortfall primarily stems\nfrom MMP's reliance on discrete-time trajectories. To overcome these\nlimitations, we introduce Motion Manifold Primitives++ (MMP++), a new model\nthat integrates the strengths of both MMP and traditional methods by\nincorporating parametric curve representations into the MMP framework.\nFurthermore, we identify a significant challenge with MMP++: performance\ndegradation due to geometric distortions in the latent space, meaning that\nsimilar motions are not closely positioned. To address this, Isometric Motion\nManifold Primitives++ (IMMP++) is proposed to ensure the latent space\naccurately preserves the manifold's geometry. Our experimental results across\nvarious applications, including 2-DoF planar motions, 7-DoF robot arm motions,\nand SE(3) trajectory planning, show that MMP++ and IMMP++ outperform existing\nmethods in trajectory generation tasks, achieving substantial improvements in\nsome cases. Moreover, they enable the modulation of latent coordinates and\nvia-points, thereby allowing efficient online adaptation to dynamic\nenvironments.\n","authors":["Yonghyeon Lee"],"pdf_url":"https://arxiv.org/pdf/2310.17072v3.pdf","comment":"12 pages. This work has been submitted to the IEEE for possible\n  publication"},{"id":"http://arxiv.org/abs/2403.18302v1","updated":"2024-03-27T06:58:01Z","published":"2024-03-27T06:58:01Z","title":"Super-Resolution of SOHO/MDI Magnetograms of Solar Active Regions Using\n  SDO/HMI Data and an Attention-Aided Convolutional Neural Network","summary":"  Image super-resolution has been an important subject in image processing and\nrecognition. Here, we present an attention-aided convolutional neural network\n(CNN) for solar image super-resolution. Our method, named SolarCNN, aims to\nenhance the quality of line-of-sight (LOS) magnetograms of solar active regions\n(ARs) collected by the Michelson Doppler Imager (MDI) on board the Solar and\nHeliospheric Observatory (SOHO). The ground-truth labels used for training\nSolarCNN are the LOS magnetograms collected by the Helioseismic and Magnetic\nImager (HMI) on board the Solar Dynamics Observatory (SDO). Solar ARs consist\nof strong magnetic fields in which magnetic energy can suddenly be released to\nproduce extreme space weather events, such as solar flares, coronal mass\nejections, and solar energetic particles. SOHO/MDI covers Solar Cycle 23, which\nis stronger with more eruptive events than Cycle 24. Enhanced SOHO/MDI\nmagnetograms allow for better understanding and forecasting of violent events\nof space weather. Experimental results show that SolarCNN improves the quality\nof SOHO/MDI magnetograms in terms of the structural similarity index measure\n(SSIM), Pearson's correlation coefficient (PCC), and the peak signal-to-noise\nratio (PSNR).\n","authors":["Chunhui Xu","Jason T. L. Wang","Haimin Wang","Haodi Jiang","Qin Li","Yasser Abduallah","Yan Xu"],"pdf_url":"https://arxiv.org/pdf/2403.18302v1.pdf","comment":"17 pages, 7 figures"},{"id":"http://arxiv.org/abs/2302.06912v4","updated":"2024-03-27T06:57:30Z","published":"2023-02-14T08:56:50Z","title":"Regret-Based Defense in Adversarial Reinforcement Learning","summary":"  Deep Reinforcement Learning (DRL) policies have been shown to be vulnerable\nto small adversarial noise in observations. Such adversarial noise can have\ndisastrous consequences in safety-critical environments. For instance, a\nself-driving car receiving adversarially perturbed sensory observations about\nnearby signs (e.g., a stop sign physically altered to be perceived as a speed\nlimit sign) or objects (e.g., cars altered to be recognized as trees) can be\nfatal. Existing approaches for making RL algorithms robust to an\nobservation-perturbing adversary have focused on reactive approaches that\niteratively improve against adversarial examples generated at each iteration.\nWhile such approaches have been shown to provide improvements over regular RL\nmethods, they are reactive and can fare significantly worse if certain\ncategories of adversarial examples are not generated during training. To that\nend, we pursue a more proactive approach that relies on directly optimizing a\nwell-studied robustness measure, regret instead of expected value. We provide a\nprincipled approach that minimizes maximum regret over a \"neighborhood\" of\nobservations to the received \"observation\". Our regret criterion can be used to\nmodify existing value- and policy-based Deep RL methods. We demonstrate that\nour approaches provide a significant improvement in performance across a wide\nvariety of benchmarks against leading approaches for robust Deep RL.\n","authors":["Roman Belaire","Pradeep Varakantham","Thanh Nguyen","David Lo"],"pdf_url":"https://arxiv.org/pdf/2302.06912v4.pdf","comment":"Accepted at AAMAS 2024"},{"id":"http://arxiv.org/abs/2403.18301v1","updated":"2024-03-27T06:55:23Z","published":"2024-03-27T06:55:23Z","title":"Selective Mixup Fine-Tuning for Optimizing Non-Decomposable Objectives","summary":"  The rise in internet usage has led to the generation of massive amounts of\ndata, resulting in the adoption of various supervised and semi-supervised\nmachine learning algorithms, which can effectively utilize the colossal amount\nof data to train models. However, before deploying these models in the real\nworld, these must be strictly evaluated on performance measures like worst-case\nrecall and satisfy constraints such as fairness. We find that current\nstate-of-the-art empirical techniques offer sub-optimal performance on these\npractical, non-decomposable performance objectives. On the other hand, the\ntheoretical techniques necessitate training a new model from scratch for each\nperformance objective. To bridge the gap, we propose SelMix, a selective\nmixup-based inexpensive fine-tuning technique for pre-trained models, to\noptimize for the desired objective. The core idea of our framework is to\ndetermine a sampling distribution to perform a mixup of features between\nsamples from particular classes such that it optimizes the given objective. We\ncomprehensively evaluate our technique against the existing empirical and\ntheoretically principled methods on standard benchmark datasets for imbalanced\nclassification. We find that proposed SelMix fine-tuning significantly improves\nthe performance for various practical non-decomposable objectives across\nbenchmarks.\n","authors":["Shrinivas Ramasubramanian","Harsh Rangwani","Sho Takemori","Kunal Samanta","Yuhei Umeda","Venkatesh Babu Radhakrishnan"],"pdf_url":"https://arxiv.org/pdf/2403.18301v1.pdf","comment":"ICLR 2024 SpotLight"},{"id":"http://arxiv.org/abs/2403.18296v1","updated":"2024-03-27T06:46:59Z","published":"2024-03-27T06:46:59Z","title":"GeNet: A Graph Neural Network-based Anti-noise Task-Oriented Semantic\n  Communication Paradigm","summary":"  Traditional approaches to semantic communication tasks rely on the knowledge\nof the signal-to-noise ratio (SNR) to mitigate channel noise. However, these\nmethods necessitate training under specific SNR conditions, entailing\nconsiderable time and computational resources. In this paper, we propose GeNet,\na Graph Neural Network (GNN)-based paradigm for semantic communication aimed at\ncombating noise, thereby facilitating Task-Oriented Communication (TOC). We\npropose a novel approach where we first transform the input data image into\ngraph structures. Then we leverage a GNN-based encoder to extract semantic\ninformation from the source data. This extracted semantic information is then\ntransmitted through the channel. At the receiver's end, a GNN-based decoder is\nutilized to reconstruct the relevant semantic information from the source data\nfor TOC. Through experimental evaluation, we show GeNet's effectiveness in\nanti-noise TOC while decoupling the SNR dependency. We further evaluate GeNet's\nperformance by varying the number of nodes, revealing its versatility as a new\nparadigm for semantic communication. Additionally, we show GeNet's robustness\nto geometric transformations by testing it with different rotation angles,\nwithout resorting to data augmentation.\n","authors":["Chunhang Zheng","Kechao Cai"],"pdf_url":"https://arxiv.org/pdf/2403.18296v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.18286v1","updated":"2024-03-27T06:25:40Z","published":"2024-03-27T06:25:40Z","title":"Few-Shot Recalibration of Language Models","summary":"  Recent work has uncovered promising ways to extract well-calibrated\nconfidence estimates from language models (LMs), where the model's confidence\nscore reflects how likely it is to be correct. However, while LMs may appear\nwell-calibrated over broad distributions, this often hides significant\nmiscalibration within narrower slices (e.g., systemic over-confidence in math\ncan balance out systemic under-confidence in history, yielding perfect\ncalibration in aggregate). To attain well-calibrated confidence estimates for\nany slice of a distribution, we propose a new framework for few-shot\nslice-specific recalibration. Specifically, we train a recalibration model that\ntakes in a few unlabeled examples from any given slice and predicts a curve\nthat remaps confidence scores to be more accurate for that slice. Our trained\nmodel can recalibrate for arbitrary new slices, without using any labeled data\nfrom that slice. This enables us to identify domain-specific confidence\nthresholds above which the LM's predictions can be trusted, and below which it\nshould abstain. Experiments show that our few-shot recalibrator consistently\noutperforms existing calibration methods, for instance improving calibration\nerror for PaLM2-Large on MMLU by 16%, as compared to temperature scaling.\n","authors":["Xiang Lisa Li","Urvashi Khandelwal","Kelvin Guu"],"pdf_url":"https://arxiv.org/pdf/2403.18286v1.pdf","comment":"preprint"},{"id":"http://arxiv.org/abs/2403.18269v1","updated":"2024-03-27T05:50:23Z","published":"2024-03-27T05:50:23Z","title":"Clustering Change Sign Detection by Fusing Mixture Complexity","summary":"  This paper proposes an early detection method for cluster structural changes.\nCluster structure refers to discrete structural characteristics, such as the\nnumber of clusters, when data are represented using finite mixture models, such\nas Gaussian mixture models. We focused on scenarios in which the cluster\nstructure gradually changed over time. For finite mixture models, the concept\nof mixture complexity (MC) measures the continuous cluster size by considering\nthe cluster proportion bias and overlap between clusters. In this paper, we\npropose MC fusion as an extension of MC to handle situations in which multiple\nmixture numbers are possible in a finite mixture model. By incorporating the\nfusion of multiple models, our approach accurately captured the cluster\nstructure during transitional periods of gradual change. Moreover, we introduce\na method for detecting changes in the cluster structure by examining the\ntransition of MC fusion. We demonstrate the effectiveness of our method through\nempirical analysis using both artificial and real-world datasets.\n","authors":["Kento Urano","Ryo Yuki","Kenji Yamanishi"],"pdf_url":"https://arxiv.org/pdf/2403.18269v1.pdf","comment":"23 pages"},{"id":"http://arxiv.org/abs/2312.12558v2","updated":"2024-03-27T05:48:21Z","published":"2023-12-19T19:53:58Z","title":"Sample Efficient Reinforcement Learning with Partial Dynamics Knowledge","summary":"  The problem of sample complexity of online reinforcement learning is often\nstudied in the literature without taking into account any partial knowledge\nabout the system dynamics that could potentially accelerate the learning\nprocess. In this paper, we study the sample complexity of online Q-learning\nmethods when some prior knowledge about the dynamics is available or can be\nlearned efficiently. We focus on systems that evolve according to an additive\ndisturbance model of the form $S_{h+1} = f(S_h, A_h) + W_h$, where $f$\nrepresents the underlying system dynamics, and $W_h$ are unknown disturbances\nindependent of states and actions. In the setting of finite episodic Markov\ndecision processes with $S$ states, $A$ actions, and episode length $H$, we\npresent an optimistic Q-learning algorithm that achieves\n$\\tilde{\\mathcal{O}}(\\text{Poly}(H)\\sqrt{T})$ regret under perfect knowledge of\n$f$, where $T$ is the total number of interactions with the system. This is in\ncontrast to the typical $\\tilde{\\mathcal{O}}(\\text{Poly}(H)\\sqrt{SAT})$ regret\nfor existing Q-learning methods. Further, if only a noisy estimate $\\hat{f}$ of\n$f$ is available, our method can learn an approximately optimal policy in a\nnumber of samples that is independent of the cardinalities of state and action\nspaces. The sub-optimality gap depends on the approximation error $\\hat{f}-f$,\nas well as the Lipschitz constant of the corresponding optimal value function.\nOur approach does not require modeling of the transition probabilities and\nenjoys the same memory complexity as model-free methods.\n","authors":["Meshal Alharbi","Mardavij Roozbehani","Munther Dahleh"],"pdf_url":"https://arxiv.org/pdf/2312.12558v2.pdf","comment":"Published in the 38th Annual AAAI Conference on Artificial\n  Intelligence"},{"id":"http://arxiv.org/abs/2305.14258v2","updated":"2024-03-27T05:45:37Z","published":"2023-05-23T17:11:33Z","title":"Weakly Supervised AUC Optimization: A Unified Partial AUC Approach","summary":"  Since acquiring perfect supervision is usually difficult, real-world machine\nlearning tasks often confront inaccurate, incomplete, or inexact supervision,\ncollectively referred to as weak supervision. In this work, we present WSAUC, a\nunified framework for weakly supervised AUC optimization problems, which covers\nnoisy label learning, positive-unlabeled learning, multi-instance learning, and\nsemi-supervised learning scenarios. Within the WSAUC framework, we first frame\nthe AUC optimization problems in various weakly supervised scenarios as a\ncommon formulation of minimizing the AUC risk on contaminated sets, and\ndemonstrate that the empirical risk minimization problems are consistent with\nthe true AUC. Then, we introduce a new type of partial AUC, specifically, the\nreversed partial AUC (rpAUC), which serves as a robust training objective for\nAUC maximization in the presence of contaminated labels. WSAUC offers a\nuniversal solution for AUC optimization in various weakly supervised scenarios\nby maximizing the empirical rpAUC. Theoretical and experimental results under\nmultiple settings support the effectiveness of WSAUC on a range of weakly\nsupervised AUC optimization tasks.\n","authors":["Zheng Xie","Yu Liu","Hao-Yuan He","Ming Li","Zhi-Hua Zhou"],"pdf_url":"https://arxiv.org/pdf/2305.14258v2.pdf","comment":"Accepted by IEEE TPAMI"},{"id":"http://arxiv.org/abs/2403.18267v1","updated":"2024-03-27T05:41:50Z","published":"2024-03-27T05:41:50Z","title":"DSF-GAN: DownStream Feedback Generative Adversarial Network","summary":"  Utility and privacy are two crucial measurements of the quality of synthetic\ntabular data. While significant advancements have been made in privacy\nmeasures, generating synthetic samples with high utility remains challenging.\nTo enhance the utility of synthetic samples, we propose a novel architecture\ncalled the DownStream Feedback Generative Adversarial Network (DSF-GAN). This\napproach incorporates feedback from a downstream prediction model during\ntraining to augment the generator's loss function with valuable information.\nThus, DSF-GAN utilizes a downstream prediction task to enhance the utility of\nsynthetic samples. To evaluate our method, we tested it using two popular\ndatasets. Our experiments demonstrate improved model performance when training\non synthetic samples generated by DSF-GAN, compared to those generated by the\nsame GAN architecture without feedback. The evaluation was conducted on the\nsame validation set comprising real samples. All code and datasets used in this\nresearch will be made openly available for ease of reproduction.\n","authors":["Oriel Perets","Nadav Rappoport"],"pdf_url":"https://arxiv.org/pdf/2403.18267v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.18266v1","updated":"2024-03-27T05:38:48Z","published":"2024-03-27T05:38:48Z","title":"Branch-Tuning: Balancing Stability and Plasticity for Continual\n  Self-Supervised Learning","summary":"  Self-supervised learning (SSL) has emerged as an effective paradigm for\nderiving general representations from vast amounts of unlabeled data. However,\nas real-world applications continually integrate new content, the high\ncomputational and resource demands of SSL necessitate continual learning rather\nthan complete retraining. This poses a challenge in striking a balance between\nstability and plasticity when adapting to new information. In this paper, we\nemploy Centered Kernel Alignment for quantitatively analyzing model stability\nand plasticity, revealing the critical roles of batch normalization layers for\nstability and convolutional layers for plasticity. Motivated by this, we\npropose Branch-tuning, an efficient and straightforward method that achieves a\nbalance between stability and plasticity in continual SSL. Branch-tuning\nconsists of branch expansion and compression, and can be easily applied to\nvarious SSL methods without the need of modifying the original methods,\nretaining old data or models. We validate our method through incremental\nexperiments on various benchmark datasets, demonstrating its effectiveness and\npractical value in real-world scenarios. We hope our work offers new insights\nfor future continual self-supervised learning research. The code will be made\npublicly available.\n","authors":["Wenzhuo Liu","Fei Zhu","Cheng-Lin Liu"],"pdf_url":"https://arxiv.org/pdf/2403.18266v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.02561v2","updated":"2024-03-27T05:23:40Z","published":"2024-02-04T16:27:37Z","title":"Foundation Model Makes Clustering A Better Initialization For Cold-Start\n  Active Learning","summary":"  Active learning selects the most informative samples from the unlabelled\ndataset to annotate in the context of a limited annotation budget. While\nnumerous methods have been proposed for subsequent sample selection based on an\ninitialized model, scant attention has been paid to the indispensable phase of\nactive learning: selecting samples for model cold-start initialization. Most of\nthe previous studies resort to random sampling or naive clustering. However,\nrandom sampling is prone to fluctuation, and naive clustering suffers from\nconvergence speed, particularly when dealing with high-dimensional data such as\nimaging data. In this work, we propose to integrate foundation models with\nclustering methods to select samples for cold-start active learning\ninitialization. Foundation models refer to those trained on massive datasets by\nthe self-supervised paradigm and capable of generating informative and\ncompacted embeddings for various downstream tasks. Leveraging these embeddings\nto replace raw features such as pixel values, clustering quickly converges and\nidentifies better initial samples. For a comprehensive comparison, we included\na classic ImageNet-supervised model to acquire embeddings. Experiments on two\nclinical tasks of image classification and segmentation demonstrated that\nfoundation model-based clustering efficiently pinpointed informative initial\nsamples, leading to models showcasing enhanced performance than the baseline\nmethods. We envisage that this study provides an effective paradigm for future\ncold-start active learning.\n","authors":["Han Yuan","Chuan Hong"],"pdf_url":"https://arxiv.org/pdf/2402.02561v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.17458v2","updated":"2024-03-27T04:54:59Z","published":"2024-03-26T07:46:27Z","title":"Expectations Versus Reality: Evaluating Intrusion Detection Systems in\n  Practice","summary":"  Our paper provides empirical comparisons between recent IDSs to provide an\nobjective comparison between them to help users choose the most appropriate\nsolution based on their requirements. Our results show that no one solution is\nthe best, but is dependent on external variables such as the types of attacks,\ncomplexity, and network environment in the dataset. For example, BoT_IoT and\nStratosphere IoT datasets both capture IoT-related attacks, but the deep neural\nnetwork performed the best when tested using the BoT_IoT dataset while HELAD\nperformed the best when tested using the Stratosphere IoT dataset. So although\nwe found that a deep neural network solution had the highest average F1 scores\non tested datasets, it is not always the best-performing one. We further\ndiscuss difficulties in using IDS from literature and project repositories,\nwhich complicated drawing definitive conclusions regarding IDS selection.\n","authors":["Jake Hesford","Daniel Cheng","Alan Wan","Larry Huynh","Seungho Kim","Hyoungshick Kim","Jin B. Hong"],"pdf_url":"https://arxiv.org/pdf/2403.17458v2.pdf","comment":"10 pages"},{"id":"http://arxiv.org/abs/2312.07950v3","updated":"2024-03-27T04:51:51Z","published":"2023-12-13T07:56:27Z","title":"CBQ: Cross-Block Quantization for Large Language Models","summary":"  Post-training quantization (PTQ) has played a key role in compressing large\nlanguage models (LLMs) with ultra-low costs. However, existing PTQ methods only\nfocus on handling the outliers within one layer or one block, which ignores the\ndependency of blocks and leads to severe performance degradation in low-bit\nsettings. In this paper, we propose CBQ, a cross-block reconstruction-based PTQ\nmethod for LLMs. CBQ employs a cross-block dependency using a homologous\nreconstruction scheme, establishing long-range dependencies across multiple\nblocks to minimize error accumulation. Furthermore, CBQ incorporates a\ncoarse-to-fine preprocessing (CFP) strategy for suppressing weight and\nactivation outliers, coupled with an adaptive LoRA-Rounding technique for\nprecise weight quantization. These innovations enable CBQ to not only handle\nextreme outliers effectively but also improve overall quantization accuracy.\nExtensive experiments show that CBQ achieves superior low-bit quantization\n(W4A4, W4A8, W2A16) and outperforms existing state-of-the-art methods across\nvarious LLMs and datasets. Notably, CBQ quantizes the 4-bit LLAMA1-65B model\nwithin only 4.3 hours on a single GPU, achieving a commendable tradeoff between\nperformance and quantization efficiency.\n","authors":["Xin Ding","Xiaoyu Liu","Zhijun Tu","Yun Zhang","Wei Li","Jie Hu","Hanting Chen","Yehui Tang","Zhiwei Xiong","Baoqun Yin","Yunhe Wang"],"pdf_url":"https://arxiv.org/pdf/2312.07950v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.18252v1","updated":"2024-03-27T04:49:23Z","published":"2024-03-27T04:49:23Z","title":"Beyond Embeddings: The Promise of Visual Table in Multi-Modal Models","summary":"  Visual representation learning has been a cornerstone in computer vision,\nevolving from supervised learning with human-annotated labels to aligning\nimage-text pairs from the Internet. Despite recent advancements in multi-modal\nlarge language models (MLLMs), the visual representations they rely on, such as\nCLIP embeddings, often lack access to external world knowledge critical for\nreal-world visual reasoning. In this work, we propose Visual Table, a novel\nvisual representation tailored for MLLMs. It provides hierarchical text\ndescriptions of holistic visual scenes, consisting of a scene description and\nmultiple object-centric descriptions that encompass categories, attributes, and\nknowledge at instance level. We further develop a scalable generator for visual\ntable generation and train it on small-scale annotations from GPT4V. Extensive\nevaluations demonstrate that, with generated visual tables as additional visual\nrepresentations, our model can consistently outperform the state-of-the-art\n(SOTA) MLLMs across diverse benchmarks. When visual tables serve as standalone\nvisual representations, our model can closely match or even beat the SOTA MLLMs\nthat are built on CLIP visual embeddings. Our code is available at\nhttps://github.com/LaVi-Lab/Visual-Table.\n","authors":["Yiwu Zhong","Zi-Yuan Hu","Michael R. Lyu","Liwei Wang"],"pdf_url":"https://arxiv.org/pdf/2403.18252v1.pdf","comment":"Project page: https://github.com/LaVi-Lab/Visual-Table"},{"id":"http://arxiv.org/abs/2401.16025v2","updated":"2024-03-27T04:36:17Z","published":"2024-01-29T10:17:54Z","title":"Simple Policy Optimization","summary":"  PPO (Proximal Policy Optimization) algorithm has demonstrated excellent\nperformance in many fields, and it is considered as a simple version of TRPO\n(Trust Region Policy Optimization) algorithm. However, the ratio clipping\noperation in PPO may not always effectively enforce the trust region\nconstraints, this can be a potential factor affecting the stability of the\nalgorithm. In this paper, we propose Simple Policy Optimization (SPO)\nalgorithm, which introduces a novel clipping method for KL divergence between\nthe old and current policies. Extensive experimental results in Atari 2600\nenvironments indicate that, compared to the mainstream variants of PPO, SPO\nachieves better sample efficiency, extremely low KL divergence, and higher\npolicy entropy, and is robust to the increase in network depth or complexity.\nMore importantly, SPO maintains the simplicity of an unconstrained first-order\nalgorithm. Code is available at\nhttps://github.com/MyRepositories-hub/Simple-Policy-Optimization.\n","authors":["Zhengpeng Xie"],"pdf_url":"https://arxiv.org/pdf/2401.16025v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.18241v1","updated":"2024-03-27T04:09:34Z","published":"2024-03-27T04:09:34Z","title":"NeuSDFusion: A Spatial-Aware Generative Model for 3D Shape Completion,\n  Reconstruction, and Generation","summary":"  3D shape generation aims to produce innovative 3D content adhering to\nspecific conditions and constraints. Existing methods often decompose 3D shapes\ninto a sequence of localized components, treating each element in isolation\nwithout considering spatial consistency. As a result, these approaches exhibit\nlimited versatility in 3D data representation and shape generation, hindering\ntheir ability to generate highly diverse 3D shapes that comply with the\nspecified constraints. In this paper, we introduce a novel spatial-aware 3D\nshape generation framework that leverages 2D plane representations for enhanced\n3D shape modeling. To ensure spatial coherence and reduce memory usage, we\nincorporate a hybrid shape representation technique that directly learns a\ncontinuous signed distance field representation of the 3D shape using\northogonal 2D planes. Additionally, we meticulously enforce spatial\ncorrespondences across distinct planes using a transformer-based autoencoder\nstructure, promoting the preservation of spatial relationships in the generated\n3D shapes. This yields an algorithm that consistently outperforms\nstate-of-the-art 3D shape generation methods on various tasks, including\nunconditional shape generation, multi-modal shape completion, single-view\nreconstruction, and text-to-shape synthesis.\n","authors":["Ruikai Cui","Weizhe Liu","Weixuan Sun","Senbo Wang","Taizhang Shang","Yang Li","Xibin Song","Han Yan","Zhennan Wu","Shenzhou Chen","Hongdong Li","Pan Ji"],"pdf_url":"https://arxiv.org/pdf/2403.18241v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2206.08657v6","updated":"2024-03-27T03:53:23Z","published":"2022-06-17T09:42:35Z","title":"BridgeTower: Building Bridges Between Encoders in Vision-Language\n  Representation Learning","summary":"  Vision-Language (VL) models with the Two-Tower architecture have dominated\nvisual-language representation learning in recent years. Current VL models\neither use lightweight uni-modal encoders and learn to extract, align and fuse\nboth modalities simultaneously in a deep cross-modal encoder, or feed the\nlast-layer uni-modal representations from the deep pre-trained uni-modal\nencoders into the top cross-modal encoder. Both approaches potentially restrict\nvision-language representation learning and limit model performance. In this\npaper, we propose BridgeTower, which introduces multiple bridge layers that\nbuild a connection between the top layers of uni-modal encoders and each layer\nof the cross-modal encoder. This enables effective bottom-up cross-modal\nalignment and fusion between visual and textual representations of different\nsemantic levels of pre-trained uni-modal encoders in the cross-modal encoder.\nPre-trained with only 4M images, BridgeTower achieves state-of-the-art\nperformance on various downstream vision-language tasks. In particular, on the\nVQAv2 test-std set, BridgeTower achieves an accuracy of 78.73%, outperforming\nthe previous state-of-the-art model METER by 1.09% with the same pre-training\ndata and almost negligible additional parameters and computational costs.\nNotably, when further scaling the model, BridgeTower achieves an accuracy of\n81.15%, surpassing models that are pre-trained on orders-of-magnitude larger\ndatasets. Code and checkpoints are available at\nhttps://github.com/microsoft/BridgeTower.\n","authors":["Xiao Xu","Chenfei Wu","Shachar Rosenman","Vasudev Lal","Wanxiang Che","Nan Duan"],"pdf_url":"https://arxiv.org/pdf/2206.08657v6.pdf","comment":"Accepted by AAAI 2023, Oral"},{"id":"http://arxiv.org/abs/2301.11104v4","updated":"2024-03-27T03:47:20Z","published":"2023-01-26T13:58:46Z","title":"Discovering and Mitigating Visual Biases through Keyword Explanation","summary":"  Addressing biases in computer vision models is crucial for real-world AI\ndeployments. However, mitigating visual biases is challenging due to their\nunexplainable nature, often identified indirectly through visualization or\nsample statistics, which necessitates additional human supervision for\ninterpretation. To tackle this issue, we propose the Bias-to-Text (B2T)\nframework, which interprets visual biases as keywords. Specifically, we extract\ncommon keywords from the captions of mispredicted images to identify potential\nbiases in the model. We then validate these keywords by measuring their\nsimilarity to the mispredicted images using a vision-language scoring model.\nThe keyword explanation form of visual bias offers several advantages, such as\na clear group naming for bias discovery and a natural extension for debiasing\nusing these group names. Our experiments demonstrate that B2T can identify\nknown biases, such as gender bias in CelebA, background bias in Waterbirds, and\ndistribution shifts in ImageNet-R/C. Additionally, B2T uncovers novel biases in\nlarger datasets, such as Dollar Street and ImageNet. For example, we discovered\na contextual bias between \"bee\" and \"flower\" in ImageNet. We also highlight\nvarious applications of B2T keywords, including debiased training, CLIP\nprompting, and model comparison.\n","authors":["Younghyun Kim","Sangwoo Mo","Minkyu Kim","Kyungmin Lee","Jaeho Lee","Jinwoo Shin"],"pdf_url":"https://arxiv.org/pdf/2301.11104v4.pdf","comment":"CVPR 2024. First two authors contributed equally"},{"id":"http://arxiv.org/abs/2403.18233v1","updated":"2024-03-27T03:39:57Z","published":"2024-03-27T03:39:57Z","title":"Benchmarking Image Transformers for Prostate Cancer Detection from\n  Ultrasound Data","summary":"  PURPOSE: Deep learning methods for classifying prostate cancer (PCa) in\nultrasound images typically employ convolutional networks (CNNs) to detect\ncancer in small regions of interest (ROI) along a needle trace region. However,\nthis approach suffers from weak labelling, since the ground-truth\nhistopathology labels do not describe the properties of individual ROIs.\nRecently, multi-scale approaches have sought to mitigate this issue by\ncombining the context awareness of transformers with a CNN feature extractor to\ndetect cancer from multiple ROIs using multiple-instance learning (MIL). In\nthis work, we present a detailed study of several image transformer\narchitectures for both ROI-scale and multi-scale classification, and a\ncomparison of the performance of CNNs and transformers for ultrasound-based\nprostate cancer classification. We also design a novel multi-objective learning\nstrategy that combines both ROI and core predictions to further mitigate label\nnoise. METHODS: We evaluate 3 image transformers on ROI-scale cancer\nclassification, then use the strongest model to tune a multi-scale classifier\nwith MIL. We train our MIL models using our novel multi-objective learning\nstrategy and compare our results to existing baselines. RESULTS: We find that\nfor both ROI-scale and multi-scale PCa detection, image transformer backbones\nlag behind their CNN counterparts. This deficit in performance is even more\nnoticeable for larger models. When using multi-objective learning, we can\nimprove performance of MIL, with a 77.9% AUROC, a sensitivity of 75.9%, and a\nspecificity of 66.3%. CONCLUSION: Convolutional networks are better suited for\nmodelling sparse datasets of prostate ultrasounds, producing more robust\nfeatures than transformers in PCa detection. Multi-scale methods remain the\nbest architecture for this task, with multi-objective learning presenting an\neffective way to improve performance.\n","authors":["Mohamed Harmanani","Paul F. R. Wilson","Fahimeh Fooladgar","Amoon Jamzad","Mahdi Gilany","Minh Nguyen Nhat To","Brian Wodlinger","Purang Abolmaesumi","Parvin Mousavi"],"pdf_url":"https://arxiv.org/pdf/2403.18233v1.pdf","comment":"early draft, 7 pages; Accepted to SPIE Medical Imaging 2024"},{"id":"http://arxiv.org/abs/2403.18228v1","updated":"2024-03-27T03:31:16Z","published":"2024-03-27T03:31:16Z","title":"Fourier or Wavelet bases as counterpart self-attention in spikformer for\n  efficient visual classification","summary":"  Energy-efficient spikformer has been proposed by integrating the biologically\nplausible spiking neural network (SNN) and artificial Transformer, whereby the\nSpiking Self-Attention (SSA) is used to achieve both higher accuracy and lower\ncomputational cost. However, it seems that self-attention is not always\nnecessary, especially in sparse spike-form calculation manners. In this paper,\nwe innovatively replace vanilla SSA (using dynamic bases calculating from Query\nand Key) with spike-form Fourier Transform, Wavelet Transform, and their\ncombinations (using fixed triangular or wavelets bases), based on a key\nhypothesis that both of them use a set of basis functions for information\ntransformation. Hence, the Fourier-or-Wavelet-based spikformer (FWformer) is\nproposed and verified in visual classification tasks, including both static\nimage and event-based video datasets. The FWformer can achieve comparable or\neven higher accuracies ($0.4\\%$-$1.5\\%$), higher running speed ($9\\%$-$51\\%$\nfor training and $19\\%$-$70\\%$ for inference), reduced theoretical energy\nconsumption ($20\\%$-$25\\%$), and reduced GPU memory usage ($4\\%$-$26\\%$),\ncompared to the standard spikformer. Our result indicates the continuous\nrefinement of new Transformers, that are inspired either by biological\ndiscovery (spike-form), or information theory (Fourier or Wavelet Transform),\nis promising.\n","authors":["Qingyu Wang","Duzhen Zhang","Tilelin Zhang","Bo Xu"],"pdf_url":"https://arxiv.org/pdf/2403.18228v1.pdf","comment":"18 pages, 2 figures. arXiv admin note: substantial text overlap with\n  arXiv:2308.02557"},{"id":"http://arxiv.org/abs/2403.18223v1","updated":"2024-03-27T03:25:45Z","published":"2024-03-27T03:25:45Z","title":"A Transformer-Based Framework for Payload Malware Detection and\n  Classification","summary":"  As malicious cyber threats become more sophisticated in breaching computer\nnetworks, the need for effective intrusion detection systems (IDSs) becomes\ncrucial. Techniques such as Deep Packet Inspection (DPI) have been introduced\nto allow IDSs analyze the content of network packets, providing more context\nfor identifying potential threats. IDSs traditionally rely on using\nanomaly-based and signature-based detection techniques to detect unrecognized\nand suspicious activity. Deep learning techniques have shown great potential in\nDPI for IDSs due to their efficiency in learning intricate patterns from the\npacket content being transmitted through the network. In this paper, we propose\na revolutionary DPI algorithm based on transformers adapted for the purpose of\ndetecting malicious traffic with a classifier head. Transformers learn the\ncomplex content of sequence data and generalize them well to similar scenarios\nthanks to their self-attention mechanism. Our proposed method uses the raw\npayload bytes that represent the packet contents and is deployed as\nman-in-the-middle. The payload bytes are used to detect malicious packets and\nclassify their types. Experimental results on the UNSW-NB15 and CIC-IOT23\ndatasets demonstrate that our transformer-based model is effective in\ndistinguishing malicious from benign traffic in the test dataset, attaining an\naverage accuracy of 79\\% using binary classification and 72\\% on the\nmulti-classification experiment, both using solely payload bytes.\n","authors":["Kyle Stein","Arash Mahyari","Guillermo Francia III","Eman El-Sheikh"],"pdf_url":"https://arxiv.org/pdf/2403.18223v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.18222v1","updated":"2024-03-27T03:19:36Z","published":"2024-03-27T03:19:36Z","title":"Uncertainty-Aware Deployment of Pre-trained Language-Conditioned\n  Imitation Learning Policies","summary":"  Large-scale robotic policies trained on data from diverse tasks and robotic\nplatforms hold great promise for enabling general-purpose robots; however,\nreliable generalization to new environment conditions remains a major\nchallenge. Toward addressing this challenge, we propose a novel approach for\nuncertainty-aware deployment of pre-trained language-conditioned imitation\nlearning agents. Specifically, we use temperature scaling to calibrate these\nmodels and exploit the calibrated model to make uncertainty-aware decisions by\naggregating the local information of candidate actions. We implement our\napproach in simulation using three such pre-trained models, and showcase its\npotential to significantly enhance task completion rates. The accompanying code\nis accessible at the link:\nhttps://github.com/BobWu1998/uncertainty_quant_all.git\n","authors":["Bo Wu","Bruce D. Lee","Kostas Daniilidis","Bernadette Bucher","Nikolai Matni"],"pdf_url":"https://arxiv.org/pdf/2403.18222v1.pdf","comment":"8 pages, 7 figures"},{"id":"http://arxiv.org/abs/2312.03256v2","updated":"2024-03-27T03:14:14Z","published":"2023-12-06T03:09:19Z","title":"CAFE: Towards Compact, Adaptive, and Fast Embedding for Large-scale\n  Recommendation Models","summary":"  Recently, the growing memory demands of embedding tables in Deep Learning\nRecommendation Models (DLRMs) pose great challenges for model training and\ndeployment. Existing embedding compression solutions cannot simultaneously meet\nthree key design requirements: memory efficiency, low latency, and adaptability\nto dynamic data distribution. This paper presents CAFE, a Compact, Adaptive,\nand Fast Embedding compression framework that addresses the above requirements.\nThe design philosophy of CAFE is to dynamically allocate more memory resources\nto important features (called hot features), and allocate less memory to\nunimportant ones. In CAFE, we propose a fast and lightweight sketch data\nstructure, named HotSketch, to capture feature importance and report hot\nfeatures in real time. For each reported hot feature, we assign it a unique\nembedding. For the non-hot features, we allow multiple features to share one\nembedding by using hash embedding technique. Guided by our design philosophy,\nwe further propose a multi-level hash embedding framework to optimize the\nembedding tables of non-hot features. We theoretically analyze the accuracy of\nHotSketch, and analyze the model convergence against deviation. Extensive\nexperiments show that CAFE significantly outperforms existing embedding\ncompression methods, yielding 3.92% and 3.68% superior testing AUC on Criteo\nKaggle dataset and CriteoTB dataset at a compression ratio of 10000x. The\nsource codes of CAFE are available at GitHub.\n","authors":["Hailin Zhang","Zirui Liu","Boxuan Chen","Yikai Zhao","Tong Zhao","Tong Yang","Bin Cui"],"pdf_url":"https://arxiv.org/pdf/2312.03256v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.18219v1","updated":"2024-03-27T03:07:18Z","published":"2024-03-27T03:07:18Z","title":"From Two-Dimensional to Three-Dimensional Environment with Q-Learning:\n  Modeling Autonomous Navigation with Reinforcement Learning and no Libraries","summary":"  Reinforcement learning (RL) algorithms have become indispensable tools in\nartificial intelligence, empowering agents to acquire optimal decision-making\npolicies through interactions with their environment and feedback mechanisms.\nThis study explores the performance of RL agents in both two-dimensional (2D)\nand three-dimensional (3D) environments, aiming to research the dynamics of\nlearning across different spatial dimensions. A key aspect of this\ninvestigation is the absence of pre-made libraries for learning, with the\nalgorithm developed exclusively through computational mathematics. The\nmethodological framework centers on RL principles, employing a Q-learning agent\nclass and distinct environment classes tailored to each spatial dimension. The\nresearch aims to address the question: How do reinforcement learning agents\nadapt and perform in environments of varying spatial dimensions, particularly\nin 2D and 3D settings? Through empirical analysis, the study evaluates agents'\nlearning trajectories and adaptation processes, revealing insights into the\nefficacy of RL algorithms in navigating complex, multi-dimensional spaces.\nReflections on the findings prompt considerations for future research,\nparticularly in understanding the dynamics of learning in higher-dimensional\nenvironments.\n","authors":["Ergon Cugler de Moraes Silva"],"pdf_url":"https://arxiv.org/pdf/2403.18219v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.18216v1","updated":"2024-03-27T02:59:04Z","published":"2024-03-27T02:59:04Z","title":"Minimax Optimal Fair Classification with Bounded Demographic Disparity","summary":"  Mitigating the disparate impact of statistical machine learning methods is\ncrucial for ensuring fairness. While extensive research aims to reduce\ndisparity, the effect of using a \\emph{finite dataset} -- as opposed to the\nentire population -- remains unclear. This paper explores the statistical\nfoundations of fair binary classification with two protected groups, focusing\non controlling demographic disparity, defined as the difference in acceptance\nrates between the groups. Although fairness may come at the cost of accuracy\neven with infinite data, we show that using a finite sample incurs additional\ncosts due to the need to estimate group-specific acceptance thresholds. We\nstudy the minimax optimal classification error while constraining demographic\ndisparity to a user-specified threshold. To quantify the impact of fairness\nconstraints, we introduce a novel measure called \\emph{fairness-aware excess\nrisk} and derive a minimax lower bound on this measure that all classifiers\nmust satisfy. Furthermore, we propose FairBayes-DDP+, a group-wise thresholding\nmethod with an offset that we show attains the minimax lower bound. Our lower\nbound proofs involve several innovations. Experiments support that\nFairBayes-DDP+ controls disparity at the user-specified level, while being\nfaster and having a more favorable fairness-accuracy tradeoff than several\nbaselines.\n","authors":["Xianli Zeng","Guang Cheng","Edgar Dobriban"],"pdf_url":"https://arxiv.org/pdf/2403.18216v1.pdf","comment":null}],"Multimedia":[{"id":"http://arxiv.org/abs/2403.18821v1","updated":"2024-03-27T17:59:56Z","published":"2024-03-27T17:59:56Z","title":"Real Acoustic Fields: An Audio-Visual Room Acoustics Dataset and\n  Benchmark","summary":"  We present a new dataset called Real Acoustic Fields (RAF) that captures real\nacoustic room data from multiple modalities. The dataset includes high-quality\nand densely captured room impulse response data paired with multi-view images,\nand precise 6DoF pose tracking data for sound emitters and listeners in the\nrooms. We used this dataset to evaluate existing methods for novel-view\nacoustic synthesis and impulse response generation which previously relied on\nsynthetic data. In our evaluation, we thoroughly assessed existing audio and\naudio-visual models against multiple criteria and proposed settings to enhance\ntheir performance on real-world data. We also conducted experiments to\ninvestigate the impact of incorporating visual data (i.e., images and depth)\ninto neural acoustic field models. Additionally, we demonstrated the\neffectiveness of a simple sim2real approach, where a model is pre-trained with\nsimulated data and fine-tuned with sparse real-world data, resulting in\nsignificant improvements in the few-shot learning approach. RAF is the first\ndataset to provide densely captured room acoustic data, making it an ideal\nresource for researchers working on audio and audio-visual neural acoustic\nfield modeling techniques. Demos and datasets are available on our project\npage: https://facebookresearch.github.io/real-acoustic-fields/\n","authors":["Ziyang Chen","Israel D. Gebru","Christian Richardt","Anurag Kumar","William Laney","Andrew Owens","Alexander Richard"],"pdf_url":"https://arxiv.org/pdf/2403.18821v1.pdf","comment":"Accepted to CVPR 2024. Project site:\n  https://facebookresearch.github.io/real-acoustic-fields/"},{"id":"http://arxiv.org/abs/2403.18715v1","updated":"2024-03-27T16:04:47Z","published":"2024-03-27T16:04:47Z","title":"Mitigating Hallucinations in Large Vision-Language Models with\n  Instruction Contrastive Decoding","summary":"  Large Vision-Language Models (LVLMs) are increasingly adept at generating\ncontextually detailed and coherent responses from visual inputs. However, their\napplication in multimodal decision-making and open-ended generation is hindered\nby a notable rate of hallucinations, where generated text inaccurately\nrepresents the visual contents. To address this issue, this paper introduces\nthe Instruction Contrastive Decoding (ICD) method, a novel approach designed to\nreduce hallucinations during LVLM inference. Our method is inspired by our\nobservation that what we call disturbance instructions significantly exacerbate\nhallucinations in multimodal fusion modules. ICD contrasts distributions from\nstandard and instruction disturbance, thereby increasing alignment uncertainty\nand effectively subtracting hallucinated concepts from the original\ndistribution. Through comprehensive experiments on discriminative benchmarks\n(POPE and MME) and a generative benchmark (LLaVa-Bench), we demonstrate that\nICD significantly mitigates both object-level and attribute-level\nhallucinations. Moreover, our method not only addresses hallucinations but also\nsignificantly enhances the general perception and recognition capabilities of\nLVLMs.\n","authors":["Xintong Wang","Jingheng Pan","Liang Ding","Chris Biemann"],"pdf_url":"https://arxiv.org/pdf/2403.18715v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.18714v1","updated":"2024-03-27T16:02:00Z","published":"2024-03-27T16:02:00Z","title":"Bringing Textual Prompt to AI-Generated Image Quality Assessment","summary":"  AI-Generated Images (AGIs) have inherent multimodal nature. Unlike\ntraditional image quality assessment (IQA) on natural scenarios, AGIs quality\nassessment (AGIQA) takes the correspondence of image and its textual prompt\ninto consideration. This is coupled in the ground truth score, which confuses\nthe unimodal IQA methods. To solve this problem, we introduce IP-IQA (AGIs\nQuality Assessment via Image and Prompt), a multimodal framework for AGIQA via\ncorresponding image and prompt incorporation. Specifically, we propose a novel\nincremental pretraining task named Image2Prompt for better understanding of\nAGIs and their corresponding textual prompts. An effective and efficient\nimage-prompt fusion module, along with a novel special [QA] token, are also\napplied. Both are plug-and-play and beneficial for the cooperation of image and\nits corresponding prompt. Experiments demonstrate that our IP-IQA achieves the\nstate-of-the-art on AGIQA-1k and AGIQA-3k datasets. Code will be available.\n","authors":["Bowen Qu","Haohui Li","Wei Gao"],"pdf_url":"https://arxiv.org/pdf/2403.18714v1.pdf","comment":"6 pages, 3 figures, accepted by ICME2024"},{"id":"http://arxiv.org/abs/2402.14326v2","updated":"2024-03-27T13:25:17Z","published":"2024-02-22T06:38:25Z","title":"Think before You Leap: Content-Aware Low-Cost Edge-Assisted Video\n  Semantic Segmentation","summary":"  Offloading computing to edge servers is a promising solution to support\ngrowing video understanding applications at resource-constrained IoT devices.\nRecent efforts have been made to enhance the scalability of such systems by\nreducing inference costs on edge servers. However, existing research is not\ndirectly applicable to pixel-level vision tasks such as video semantic\nsegmentation (VSS), partly due to the fluctuating VSS accuracy and segment\nbitrate caused by the dynamic video content. In response, we present Penance, a\nnew edge inference cost reduction framework. By exploiting softmax outputs of\nVSS models and the prediction mechanism of H.264/AVC codecs, Penance optimizes\nmodel selection and compression settings to minimize the inference cost while\nmeeting the required accuracy within the available bandwidth constraints. We\nimplement Penance in a commercial IoT device with only CPUs. Experimental\nresults show that Penance consumes a negligible 6.8% more computation resources\nthan the optimal strategy while satisfying accuracy and bandwidth constraints\nwith a low failure rate.\n","authors":["Mingxuan Yan","Yi Wang","Xuedou Xiao","Zhiqing Luo","Jianhua He","Wei Wang"],"pdf_url":"https://arxiv.org/pdf/2402.14326v2.pdf","comment":"Accepted by ACM Multimedia 2023"},{"id":"http://arxiv.org/abs/2403.18323v1","updated":"2024-03-27T07:52:51Z","published":"2024-03-27T07:52:51Z","title":"How to Cache Important Contents for Multi-modal Service in Dynamic\n  Networks: A DRL-based Caching Scheme","summary":"  With the continuous evolution of networking technologies, multi-modal\nservices that involve video, audio, and haptic contents are expected to become\nthe dominant multimedia service in the near future. Edge caching is a key\ntechnology that can significantly reduce network load and content transmission\nlatency, which is critical for the delivery of multi-modal contents. However,\nexisting caching approaches only rely on a limited number of factors, e.g.,\npopularity, to evaluate their importance for caching, which is inefficient for\ncaching multi-modal contents, especially in dynamic network environments. To\novercome this issue, we propose a content importance-based caching scheme which\nconsists of a content importance evaluation model and a caching model. By\nleveraging dueling double deep Q networks (D3QN) model, the content importance\nevaluation model can adaptively evaluate contents' importance in dynamic\nnetworks. Based on the evaluated contents' importance, the caching model can\neasily cache and evict proper contents to improve caching efficiency. The\nsimulation results show that the proposed content importance-based caching\nscheme outperforms existing caching schemes in terms of caching hit ratio (at\nleast 15% higher), reduced network load (up to 22% reduction), average number\nof hops (up to 27% lower), and unsatisfied requests ratio (more than 47%\nreduction).\n","authors":["Zhe Zhang","Marc St-Hilaire","Xin Wei","Haiwei Dong","Abdulmotaleb El Saddik"],"pdf_url":"https://arxiv.org/pdf/2403.18323v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.18252v1","updated":"2024-03-27T04:49:23Z","published":"2024-03-27T04:49:23Z","title":"Beyond Embeddings: The Promise of Visual Table in Multi-Modal Models","summary":"  Visual representation learning has been a cornerstone in computer vision,\nevolving from supervised learning with human-annotated labels to aligning\nimage-text pairs from the Internet. Despite recent advancements in multi-modal\nlarge language models (MLLMs), the visual representations they rely on, such as\nCLIP embeddings, often lack access to external world knowledge critical for\nreal-world visual reasoning. In this work, we propose Visual Table, a novel\nvisual representation tailored for MLLMs. It provides hierarchical text\ndescriptions of holistic visual scenes, consisting of a scene description and\nmultiple object-centric descriptions that encompass categories, attributes, and\nknowledge at instance level. We further develop a scalable generator for visual\ntable generation and train it on small-scale annotations from GPT4V. Extensive\nevaluations demonstrate that, with generated visual tables as additional visual\nrepresentations, our model can consistently outperform the state-of-the-art\n(SOTA) MLLMs across diverse benchmarks. When visual tables serve as standalone\nvisual representations, our model can closely match or even beat the SOTA MLLMs\nthat are built on CLIP visual embeddings. Our code is available at\nhttps://github.com/LaVi-Lab/Visual-Table.\n","authors":["Yiwu Zhong","Zi-Yuan Hu","Michael R. Lyu","Liwei Wang"],"pdf_url":"https://arxiv.org/pdf/2403.18252v1.pdf","comment":"Project page: https://github.com/LaVi-Lab/Visual-Table"},{"id":"http://arxiv.org/abs/2403.10066v3","updated":"2024-03-27T02:25:51Z","published":"2024-03-15T07:16:07Z","title":"Contrastive Pre-Training with Multi-View Fusion for No-Reference Point\n  Cloud Quality Assessment","summary":"  No-reference point cloud quality assessment (NR-PCQA) aims to automatically\nevaluate the perceptual quality of distorted point clouds without available\nreference, which have achieved tremendous improvements due to the utilization\nof deep neural networks. However, learning-based NR-PCQA methods suffer from\nthe scarcity of labeled data and usually perform suboptimally in terms of\ngeneralization. To solve the problem, we propose a novel contrastive\npre-training framework tailored for PCQA (CoPA), which enables the pre-trained\nmodel to learn quality-aware representations from unlabeled data. To obtain\nanchors in the representation space, we project point clouds with different\ndistortions into images and randomly mix their local patches to form mixed\nimages with multiple distortions. Utilizing the generated anchors, we constrain\nthe pre-training process via a quality-aware contrastive loss following the\nphilosophy that perceptual quality is closely related to both content and\ndistortion. Furthermore, in the model fine-tuning stage, we propose a\nsemantic-guided multi-view fusion module to effectively integrate the features\nof projected images from multiple perspectives. Extensive experiments show that\nour method outperforms the state-of-the-art PCQA methods on popular benchmarks.\nFurther investigations demonstrate that CoPA can also benefit existing\nlearning-based PCQA models.\n","authors":["Ziyu Shan","Yujie Zhang","Qi Yang","Haichen Yang","Yiling Xu","Jenq-Neng Hwang","Xiaozhong Xu","Shan Liu"],"pdf_url":"https://arxiv.org/pdf/2403.10066v3.pdf","comment":null}],"Machine Learning 2":[{"id":"http://arxiv.org/abs/2309.04381v2","updated":"2024-03-27T17:07:47Z","published":"2023-09-08T15:23:40Z","title":"Generalization Bounds: Perspectives from Information Theory and\n  PAC-Bayes","summary":"  A fundamental question in theoretical machine learning is generalization.\nOver the past decades, the PAC-Bayesian approach has been established as a\nflexible framework to address the generalization capabilities of machine\nlearning algorithms, and design new ones. Recently, it has garnered increased\ninterest due to its potential applicability for a variety of learning\nalgorithms, including deep neural networks. In parallel, an\ninformation-theoretic view of generalization has developed, wherein the\nrelation between generalization and various information measures has been\nestablished. This framework is intimately connected to the PAC-Bayesian\napproach, and a number of results have been independently discovered in both\nstrands. In this monograph, we highlight this strong connection and present a\nunified treatment of PAC-Bayesian and information-theoretic generalization\nbounds. We present techniques and results that the two perspectives have in\ncommon, and discuss the approaches and interpretations that differ. In\nparticular, we demonstrate how many proofs in the area share a modular\nstructure, through which the underlying ideas can be intuited. We pay special\nattention to the conditional mutual information (CMI) framework; analytical\nstudies of the information complexity of learning algorithms; and the\napplication of the proposed methods to deep learning. This monograph is\nintended to provide a comprehensive introduction to information-theoretic\ngeneralization bounds and their connection to PAC-Bayes, serving as a\nfoundation from which the most recent developments are accessible. It is aimed\nbroadly towards researchers with an interest in generalization and theoretical\nmachine learning.\n","authors":["Fredrik Hellstr√∂m","Giuseppe Durisi","Benjamin Guedj","Maxim Raginsky"],"pdf_url":"https://arxiv.org/pdf/2309.04381v2.pdf","comment":"228 pages"},{"id":"http://arxiv.org/abs/2403.18739v1","updated":"2024-03-27T16:32:32Z","published":"2024-03-27T16:32:32Z","title":"Usage-Specific Survival Modeling Based on Operational Data and Neural\n  Networks","summary":"  Accurate predictions of when a component will fail are crucial when planning\nmaintenance, and by modeling the distribution of these failure times, survival\nmodels have shown to be particularly useful in this context. The presented\nmethodology is based on conventional neural network-based survival models that\nare trained using data that is continuously gathered and stored at specific\ntimes, called snapshots. An important property of this type of training data is\nthat it can contain more than one snapshot from a specific individual which\nresults in that standard maximum likelihood training can not be directly\napplied since the data is not independent. However, the papers show that if the\ndata is in a specific format where all snapshot times are the same for all\nindividuals, called homogeneously sampled, maximum likelihood training can be\napplied and produce desirable results. In many cases, the data is not\nhomogeneously sampled and in this case, it is proposed to resample the data to\nmake it homogeneously sampled. How densely the dataset is sampled turns out to\nbe an important parameter; it should be chosen large enough to produce good\nresults, but this also increases the size of the dataset which makes training\nslow. To reduce the number of samples needed during training, the paper also\nproposes a technique to, instead of resampling the dataset once before the\ntraining starts, randomly resample the dataset at the start of each epoch\nduring the training. The proposed methodology is evaluated on both a simulated\ndataset and an experimental dataset of starter battery failures. The results\nshow that if the data is homogeneously sampled the methodology works as\nintended and produces accurate survival models. The results also show that\nrandomly resampling the dataset on each epoch is an effective way to reduce the\nsize of the training data.\n","authors":["Olov Holmer","Mattias Krysander","Erik Frisk"],"pdf_url":"https://arxiv.org/pdf/2403.18739v1.pdf","comment":"7 pages"},{"id":"http://arxiv.org/abs/2402.07868v2","updated":"2024-03-27T16:12:43Z","published":"2024-02-12T18:29:17Z","title":"Nesting Particle Filters for Experimental Design in Dynamical Systems","summary":"  In this paper, we propose a novel approach to Bayesian experimental design\nfor non-exchangeable data that formulates it as risk-sensitive policy\noptimization. We develop the Inside-Out SMC$^2$ algorithm, a nested sequential\nMonte Carlo technique to infer optimal designs, and embed it into a particle\nMarkov chain Monte Carlo framework to perform gradient-based policy\namortization. Our approach is distinct from other amortized experimental design\ntechniques, as it does not rely on contrastive estimators. Numerical validation\non a set of dynamical systems showcases the efficacy of our method in\ncomparison to other state-of-the-art strategies.\n","authors":["Sahel Iqbal","Adrien Corenflos","Simo S√§rkk√§","Hany Abdulsamad"],"pdf_url":"https://arxiv.org/pdf/2402.07868v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.18717v1","updated":"2024-03-27T16:06:37Z","published":"2024-03-27T16:06:37Z","title":"Semi-Supervised Learning for Deep Causal Generative Models","summary":"  Developing models that can answer questions of the form \"How would $x$ change\nif $y$ had been $z$?\" is fundamental for advancing medical image analysis.\nTraining causal generative models that address such counterfactual questions,\nthough, currently requires that all relevant variables have been observed and\nthat corresponding labels are available in training data. However, clinical\ndata may not have complete records for all patients and state of the art causal\ngenerative models are unable to take full advantage of this. We thus develop,\nfor the first time, a semi-supervised deep causal generative model that\nexploits the causal relationships between variables to maximise the use of all\navailable data. We explore this in the setting where each sample is either\nfully labelled or fully unlabelled, as well as the more clinically realistic\ncase of having different labels missing for each sample. We leverage techniques\nfrom causal inference to infer missing values and subsequently generate\nrealistic counterfactuals, even for samples with incomplete labels.\n","authors":["Yasin Ibrahim","Hermione Warr","Konstantinos Kamnitsas"],"pdf_url":"https://arxiv.org/pdf/2403.18717v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.18668v1","updated":"2024-03-27T15:11:07Z","published":"2024-03-27T15:11:07Z","title":"Aiming for Relevance","summary":"  Vital signs are crucial in intensive care units (ICUs). They are used to\ntrack the patient's state and to identify clinically significant changes.\nPredicting vital sign trajectories is valuable for early detection of adverse\nevents. However, conventional machine learning metrics like RMSE often fail to\ncapture the true clinical relevance of such predictions. We introduce novel\nvital sign prediction performance metrics that align with clinical contexts,\nfocusing on deviations from clinical norms, overall trends, and trend\ndeviations. These metrics are derived from empirical utility curves obtained in\na previous study through interviews with ICU clinicians. We validate the\nmetrics' usefulness using simulated and real clinical datasets (MIMIC and\neICU). Furthermore, we employ these metrics as loss functions for neural\nnetworks, resulting in models that excel in predicting clinically significant\nevents. This research paves the way for clinically relevant machine learning\nmodel evaluation and optimization, promising to improve ICU patient care. 10\npages, 9 figures.\n","authors":["Bar Eini Porat","Danny Eytan","Uri Shalit"],"pdf_url":"https://arxiv.org/pdf/2403.18668v1.pdf","comment":"10 pages, 9 figures, AMIA Informatics 2024"},{"id":"http://arxiv.org/abs/2403.18664v1","updated":"2024-03-27T15:08:00Z","published":"2024-03-27T15:08:00Z","title":"Neural Network-Based Piecewise Survival Models","summary":"  In this paper, a family of neural network-based survival models is presented.\nThe models are specified based on piecewise definitions of the hazard function\nand the density function on a partitioning of the time; both constant and\nlinear piecewise definitions are presented, resulting in a family of four\nmodels. The models can be seen as an extension of the commonly used\ndiscrete-time and piecewise exponential models and thereby add flexibility to\nthis set of standard models. Using a simulated dataset the models are shown to\nperform well compared to the highly expressive, state-of-the-art energy-based\nmodel, while only requiring a fraction of the computation time.\n","authors":["Olov Holmer","Erik Frisk","Mattias Krysander"],"pdf_url":"https://arxiv.org/pdf/2403.18664v1.pdf","comment":"7 pages"},{"id":"http://arxiv.org/abs/2403.18658v1","updated":"2024-03-27T15:03:29Z","published":"2024-03-27T15:03:29Z","title":"Theoretical Guarantees for the Subspace-Constrained Tyler's Estimator","summary":"  This work analyzes the subspace-constrained Tyler's estimator (STE) designed\nfor recovering a low-dimensional subspace within a dataset that may be highly\ncorrupted with outliers. It assumes a weak inlier-outlier model and allows the\nfraction of inliers to be smaller than a fraction that leads to computational\nhardness of the robust subspace recovery problem. It shows that in this\nsetting, if the initialization of STE, which is an iterative algorithm,\nsatisfies a certain condition, then STE can effectively recover the underlying\nsubspace. It further shows that under the generalized haystack model, STE\ninitialized by the Tyler's M-estimator (TME), can recover the subspace when the\nfraction of iniliers is too small for TME to handle.\n","authors":["Gilad Lerman","Feng Yu","Teng Zhang"],"pdf_url":"https://arxiv.org/pdf/2403.18658v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.18578v1","updated":"2024-03-27T13:59:05Z","published":"2024-03-27T13:59:05Z","title":"SteinGen: Generating Fidelitous and Diverse Graph Samples","summary":"  Generating graphs that preserve characteristic structures while promoting\nsample diversity can be challenging, especially when the number of graph\nobservations is small. Here, we tackle the problem of graph generation from\nonly one observed graph. The classical approach of graph generation from\nparametric models relies on the estimation of parameters, which can be\ninconsistent or expensive to compute due to intractable normalisation\nconstants. Generative modelling based on machine learning techniques to\ngenerate high-quality graph samples avoids parameter estimation but usually\nrequires abundant training samples. Our proposed generating procedure,\nSteinGen, which is phrased in the setting of graphs as realisations of\nexponential random graph models, combines ideas from Stein's method and MCMC by\nemploying Markovian dynamics which are based on a Stein operator for the target\nmodel. SteinGen uses the Glauber dynamics associated with an estimated Stein\noperator to generate a sample, and re-estimates the Stein operator from the\nsample after every sampling step. We show that on a class of exponential random\ngraph models this novel \"estimation and re-estimation\" generation strategy\nyields high distributional similarity (high fidelity) to the original data,\ncombined with high sample diversity.\n","authors":["Gesine Reinert","Wenkai Xu"],"pdf_url":"https://arxiv.org/pdf/2403.18578v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2310.16502v3","updated":"2024-03-27T13:40:27Z","published":"2023-10-25T09:44:16Z","title":"Assessing the overall and partial causal well-specification of nonlinear\n  additive noise models","summary":"  We propose a method to detect model misspecifications in nonlinear causal\nadditive and potentially heteroscedastic noise models. We aim to identify\npredictor variables for which we can infer the causal effect even in cases of\nsuch misspecification. We develop a general framework based on knowledge of the\nmultivariate observational data distribution. We then propose an algorithm for\nfinite sample data, discuss its asymptotic properties, and illustrate its\nperformance on simulated and real data.\n","authors":["Christoph Schultheiss","Peter B√ºhlmann"],"pdf_url":"https://arxiv.org/pdf/2310.16502v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.18540v1","updated":"2024-03-27T13:17:15Z","published":"2024-03-27T13:17:15Z","title":"skscope: Fast Sparsity-Constrained Optimization in Python","summary":"  Applying iterative solvers on sparsity-constrained optimization (SCO)\nrequires tedious mathematical deduction and careful programming/debugging that\nhinders these solvers' broad impact. In the paper, the library skscope is\nintroduced to overcome such an obstacle. With skscope, users can solve the SCO\nby just programming the objective function. The convenience of skscope is\ndemonstrated through two examples in the paper, where sparse linear regression\nand trend filtering are addressed with just four lines of code. More\nimportantly, skscope's efficient implementation allows state-of-the-art solvers\nto quickly attain the sparse solution regardless of the high dimensionality of\nparameter space. Numerical experiments reveal the available solvers in skscope\ncan achieve up to 80x speedup on the competing relaxation solutions obtained\nvia the benchmarked convex solver. skscope is published on the Python Package\nIndex (PyPI) and Conda, and its source code is available at:\nhttps://github.com/abess-team/skscope.\n","authors":["Zezhi Wang","Jin Zhu","Peng Chen","Huiyang Peng","Xiaoke Zhang","Anran Wang","Yu Zheng","Junxian Zhu","Xueqin Wang"],"pdf_url":"https://arxiv.org/pdf/2403.18540v1.pdf","comment":"4 pages"},{"id":"http://arxiv.org/abs/2403.17767v2","updated":"2024-03-27T08:49:19Z","published":"2024-03-26T14:54:35Z","title":"Asymptotic Bayes risk of semi-supervised learning with uncertain\n  labeling","summary":"  This article considers a semi-supervised classification setting on a Gaussian\nmixture model, where the data is not labeled strictly as usual, but instead\nwith uncertain labels. Our main aim is to compute the Bayes risk for this\nmodel. We compare the behavior of the Bayes risk and the best known algorithm\nfor this model. This comparison eventually gives new insights over the\nalgorithm.\n","authors":["Victor Leger","Romain Couillet"],"pdf_url":"https://arxiv.org/pdf/2403.17767v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.18355v1","updated":"2024-03-27T08:48:16Z","published":"2024-03-27T08:48:16Z","title":"Supervised Multiple Kernel Learning approaches for multi-omics data\n  integration","summary":"  Advances in high-throughput technologies have originated an ever-increasing\navailability of omics datasets. The integration of multiple heterogeneous data\nsources is currently an issue for biology and bioinformatics. Multiple kernel\nlearning (MKL) has shown to be a flexible and valid approach to consider the\ndiverse nature of multi-omics inputs, despite being an underused tool in\ngenomic data mining.We provide novel MKL approaches based on different kernel\nfusion strategies.To learn from the meta-kernel of input kernels, we\nadaptedunsupervised integration algorithms for supervised tasks with support\nvector machines.We also tested deep learning architectures for kernel fusion\nand classification.The results show that MKL-based models can compete with more\ncomplex, state-of-the-art, supervised multi-omics integrative approaches.\nMultiple kernel learning offers a natural framework for predictive models in\nmulti-omics genomic data. Our results offer a direction for bio-data mining\nresearch and further development of methods for heterogeneous data integration.\n","authors":["Mitja Briscik","Gabriele Tazza","Marie-Agnes Dillies","L√°szl√≥ Vid√°cs","S√©bastien Dejean"],"pdf_url":"https://arxiv.org/pdf/2403.18355v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2305.02158v4","updated":"2024-03-27T07:31:34Z","published":"2023-05-03T14:46:16Z","title":"Shotgun crystal structure prediction using machine-learned formation\n  energies","summary":"  Stable or metastable crystal structures of assembled atoms can be predicted\nby finding the global or local minima of the energy surface defined on the\nspace of the atomic configurations. Generally, this requires repeated\nfirst-principles energy calculations that are impractical for large systems,\nsuch as those containing more than 30 atoms in the unit cell. Here, we have\nmade significant progress in solving the crystal structure prediction problem\nwith a simple but powerful machine-learning workflow; using a machine-learning\nsurrogate for first-principles energy calculations, we performed non-iterative,\nsingle-shot screening using a large library of virtually created crystal\nstructures. The present method relies on two key technical components: transfer\nlearning, which enables a highly accurate energy prediction of pre-relaxed\ncrystalline states given only a small set of training samples from\nfirst-principles calculations, and generative models to create promising and\ndiverse crystal structures for screening. Here, first-principles calculations\nwere performed only to generate the training samples, and for the optimization\nof a dozen or fewer finally narrowed-down crystal structures. Our shotgun\nmethod proved to be computationally less demanding compared to conventional\nmethods, which heavily rely on iterations of first-principles calculations, and\nachieved an exceptional prediction accuracy, reaching 92.2% in a benchmark task\ninvolving the prediction of 90 different crystal structures.\n","authors":["Chang Liu","Hiromasa Tamaki","Tomoyasu Yokoyama","Kensuke Wakasugi","Satoshi Yotsuhashi","Minoru Kusaba","Ryo Yoshida"],"pdf_url":"https://arxiv.org/pdf/2305.02158v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.18301v1","updated":"2024-03-27T06:55:23Z","published":"2024-03-27T06:55:23Z","title":"Selective Mixup Fine-Tuning for Optimizing Non-Decomposable Objectives","summary":"  The rise in internet usage has led to the generation of massive amounts of\ndata, resulting in the adoption of various supervised and semi-supervised\nmachine learning algorithms, which can effectively utilize the colossal amount\nof data to train models. However, before deploying these models in the real\nworld, these must be strictly evaluated on performance measures like worst-case\nrecall and satisfy constraints such as fairness. We find that current\nstate-of-the-art empirical techniques offer sub-optimal performance on these\npractical, non-decomposable performance objectives. On the other hand, the\ntheoretical techniques necessitate training a new model from scratch for each\nperformance objective. To bridge the gap, we propose SelMix, a selective\nmixup-based inexpensive fine-tuning technique for pre-trained models, to\noptimize for the desired objective. The core idea of our framework is to\ndetermine a sampling distribution to perform a mixup of features between\nsamples from particular classes such that it optimizes the given objective. We\ncomprehensively evaluate our technique against the existing empirical and\ntheoretically principled methods on standard benchmark datasets for imbalanced\nclassification. We find that proposed SelMix fine-tuning significantly improves\nthe performance for various practical non-decomposable objectives across\nbenchmarks.\n","authors":["Shrinivas Ramasubramanian","Harsh Rangwani","Sho Takemori","Kunal Samanta","Yuhei Umeda","Venkatesh Babu Radhakrishnan"],"pdf_url":"https://arxiv.org/pdf/2403.18301v1.pdf","comment":"ICLR 2024 SpotLight"},{"id":"http://arxiv.org/abs/2403.18269v1","updated":"2024-03-27T05:50:23Z","published":"2024-03-27T05:50:23Z","title":"Clustering Change Sign Detection by Fusing Mixture Complexity","summary":"  This paper proposes an early detection method for cluster structural changes.\nCluster structure refers to discrete structural characteristics, such as the\nnumber of clusters, when data are represented using finite mixture models, such\nas Gaussian mixture models. We focused on scenarios in which the cluster\nstructure gradually changed over time. For finite mixture models, the concept\nof mixture complexity (MC) measures the continuous cluster size by considering\nthe cluster proportion bias and overlap between clusters. In this paper, we\npropose MC fusion as an extension of MC to handle situations in which multiple\nmixture numbers are possible in a finite mixture model. By incorporating the\nfusion of multiple models, our approach accurately captured the cluster\nstructure during transitional periods of gradual change. Moreover, we introduce\na method for detecting changes in the cluster structure by examining the\ntransition of MC fusion. We demonstrate the effectiveness of our method through\nempirical analysis using both artificial and real-world datasets.\n","authors":["Kento Urano","Ryo Yuki","Kenji Yamanishi"],"pdf_url":"https://arxiv.org/pdf/2403.18269v1.pdf","comment":"23 pages"},{"id":"http://arxiv.org/abs/2312.12558v2","updated":"2024-03-27T05:48:21Z","published":"2023-12-19T19:53:58Z","title":"Sample Efficient Reinforcement Learning with Partial Dynamics Knowledge","summary":"  The problem of sample complexity of online reinforcement learning is often\nstudied in the literature without taking into account any partial knowledge\nabout the system dynamics that could potentially accelerate the learning\nprocess. In this paper, we study the sample complexity of online Q-learning\nmethods when some prior knowledge about the dynamics is available or can be\nlearned efficiently. We focus on systems that evolve according to an additive\ndisturbance model of the form $S_{h+1} = f(S_h, A_h) + W_h$, where $f$\nrepresents the underlying system dynamics, and $W_h$ are unknown disturbances\nindependent of states and actions. In the setting of finite episodic Markov\ndecision processes with $S$ states, $A$ actions, and episode length $H$, we\npresent an optimistic Q-learning algorithm that achieves\n$\\tilde{\\mathcal{O}}(\\text{Poly}(H)\\sqrt{T})$ regret under perfect knowledge of\n$f$, where $T$ is the total number of interactions with the system. This is in\ncontrast to the typical $\\tilde{\\mathcal{O}}(\\text{Poly}(H)\\sqrt{SAT})$ regret\nfor existing Q-learning methods. Further, if only a noisy estimate $\\hat{f}$ of\n$f$ is available, our method can learn an approximately optimal policy in a\nnumber of samples that is independent of the cardinalities of state and action\nspaces. The sub-optimality gap depends on the approximation error $\\hat{f}-f$,\nas well as the Lipschitz constant of the corresponding optimal value function.\nOur approach does not require modeling of the transition probabilities and\nenjoys the same memory complexity as model-free methods.\n","authors":["Meshal Alharbi","Mardavij Roozbehani","Munther Dahleh"],"pdf_url":"https://arxiv.org/pdf/2312.12558v2.pdf","comment":"Published in the 38th Annual AAAI Conference on Artificial\n  Intelligence"},{"id":"http://arxiv.org/abs/2403.18248v1","updated":"2024-03-27T04:39:13Z","published":"2024-03-27T04:39:13Z","title":"Statistical Inference of Optimal Allocations I: Regularities and their\n  Implications","summary":"  In this paper, we develp a functional differentiability approach for solving\nstatistical optimal allocation problems. We first derive Hadamard\ndifferentiability of the value function through a detailed analysis of the\ngeneral properties of the sorting operator. Central to our framework are the\nconcept of Hausdorff measure and the area and coarea integration formulas from\ngeometric measure theory. Building on our Hadamard differentiability results,\nwe demonstrate how the functional delta method can be used to directly derive\nthe asymptotic properties of the value function process for binary constrained\noptimal allocation problems, as well as the two-step ROC curve estimator.\nMoreover, leveraging profound insights from geometric functional analysis on\nconvex and local Lipschitz functionals, we obtain additional generic Fr\\'echet\ndifferentiability results for the value functions of optimal allocation\nproblems. These compelling findings motivate us to study carefully the first\norder approximation of the optimal social welfare. In this paper, we then\npresent a double / debiased estimator for the value functions. Importantly, the\nconditions outlined in the Hadamard differentiability section validate the\nmargin assumption from the statistical classification literature employing\nplug-in methods that justifies a faster convergence rate.\n","authors":["Kai Feng","Han Hong"],"pdf_url":"https://arxiv.org/pdf/2403.18248v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.18216v1","updated":"2024-03-27T02:59:04Z","published":"2024-03-27T02:59:04Z","title":"Minimax Optimal Fair Classification with Bounded Demographic Disparity","summary":"  Mitigating the disparate impact of statistical machine learning methods is\ncrucial for ensuring fairness. While extensive research aims to reduce\ndisparity, the effect of using a \\emph{finite dataset} -- as opposed to the\nentire population -- remains unclear. This paper explores the statistical\nfoundations of fair binary classification with two protected groups, focusing\non controlling demographic disparity, defined as the difference in acceptance\nrates between the groups. Although fairness may come at the cost of accuracy\neven with infinite data, we show that using a finite sample incurs additional\ncosts due to the need to estimate group-specific acceptance thresholds. We\nstudy the minimax optimal classification error while constraining demographic\ndisparity to a user-specified threshold. To quantify the impact of fairness\nconstraints, we introduce a novel measure called \\emph{fairness-aware excess\nrisk} and derive a minimax lower bound on this measure that all classifiers\nmust satisfy. Furthermore, we propose FairBayes-DDP+, a group-wise thresholding\nmethod with an offset that we show attains the minimax lower bound. Our lower\nbound proofs involve several innovations. Experiments support that\nFairBayes-DDP+ controls disparity at the user-specified level, while being\nfaster and having a more favorable fairness-accuracy tradeoff than several\nbaselines.\n","authors":["Xianli Zeng","Guang Cheng","Edgar Dobriban"],"pdf_url":"https://arxiv.org/pdf/2403.18216v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.08214v2","updated":"2024-03-27T01:59:13Z","published":"2023-11-14T14:50:46Z","title":"Frequentist Guarantees of Distributed (Non)-Bayesian Inference","summary":"  Motivated by the need to analyze large, decentralized datasets, distributed\nBayesian inference has become a critical research area across multiple fields,\nincluding statistics, electrical engineering, and economics. This paper\nestablishes Frequentist properties, such as posterior consistency, asymptotic\nnormality, and posterior contraction rates, for the distributed (non-)Bayes\nInference problem among agents connected via a communication network. Our\nresults show that, under appropriate assumptions on the communication graph,\ndistributed Bayesian inference retains parametric efficiency while enhancing\nrobustness in uncertainty quantification. We also explore the trade-off between\nstatistical efficiency and communication efficiency by examining how the design\nand size of the communication graph impact the posterior contraction rate.\nFurthermore, We extend our analysis to time-varying graphs and apply our\nresults to exponential family models, distributed logistic regression, and\ndecentralized detection models.\n","authors":["Bohan Wu","C√©sar A. Uribe"],"pdf_url":"https://arxiv.org/pdf/2311.08214v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2308.11138v3","updated":"2024-03-27T00:29:33Z","published":"2023-08-22T02:39:42Z","title":"NLP-based detection of systematic anomalies among the narratives of\n  consumer complaints","summary":"  We develop an NLP-based procedure for detecting systematic nonmeritorious\nconsumer complaints, simply called systematic anomalies, among complaint\nnarratives. While classification algorithms are used to detect pronounced\nanomalies, in the case of smaller and frequent systematic anomalies, the\nalgorithms may falter due to a variety of reasons, including technical ones as\nwell as natural limitations of human analysts. Therefore, as the next step\nafter classification, we convert the complaint narratives into quantitative\ndata, which are then analyzed using an algorithm for detecting systematic\nanomalies. We illustrate the entire procedure using complaint narratives from\nthe Consumer Complaint Database of the Consumer Financial Protection Bureau.\n","authors":["Peiheng Gao","Ning Sun","Xuefeng Wang","Chen Yang","Riƒçardas Zitikis"],"pdf_url":"https://arxiv.org/pdf/2308.11138v3.pdf","comment":null}]},"2024-03-26T00:00:00Z":{"Multimedia":[{"id":"http://arxiv.org/abs/2403.18063v1","updated":"2024-03-26T19:29:21Z","published":"2024-03-26T19:29:21Z","title":"Spectral Convolutional Transformer: Harmonizing Real vs. Complex\n  Multi-View Spectral Operators for Vision Transformer","summary":"  Transformers used in vision have been investigated through diverse\narchitectures - ViT, PVT, and Swin. These have worked to improve the attention\nmechanism and make it more efficient. Differently, the need for including local\ninformation was felt, leading to incorporating convolutions in transformers\nsuch as CPVT and CvT. Global information is captured using a complex Fourier\nbasis to achieve global token mixing through various methods, such as AFNO,\nGFNet, and Spectformer. We advocate combining three diverse views of data -\nlocal, global, and long-range dependence. We also investigate the simplest\nglobal representation using only the real domain spectral representation -\nobtained through the Hartley transform. We use a convolutional operator in the\ninitial layers to capture local information. Through these two contributions,\nwe are able to optimize and obtain a spectral convolution transformer (SCT)\nthat provides improved performance over the state-of-the-art methods while\nreducing the number of parameters. Through extensive experiments, we show that\nSCT-C-small gives state-of-the-art performance on the ImageNet dataset and\nreaches 84.5\\% top-1 accuracy, while SCT-C-Large reaches 85.9\\% and SCT-C-Huge\nreaches 86.4\\%. We evaluate SCT on transfer learning on datasets such as\nCIFAR-10, CIFAR-100, Oxford Flower, and Stanford Car. We also evaluate SCT on\ndownstream tasks i.e. instance segmentation on the MSCOCO dataset. The project\npage is available on this webpage.\\url{https://github.com/badripatro/sct}\n","authors":["Badri N. Patro","Vinay P. Namboodiri","Vijay S. Agneeswaran"],"pdf_url":"https://arxiv.org/pdf/2403.18063v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.17870v1","updated":"2024-03-26T16:57:55Z","published":"2024-03-26T16:57:55Z","title":"Boosting Diffusion Models with Moving Average Sampling in Frequency\n  Domain","summary":"  Diffusion models have recently brought a powerful revolution in image\ngeneration. Despite showing impressive generative capabilities, most of these\nmodels rely on the current sample to denoise the next one, possibly resulting\nin denoising instability. In this paper, we reinterpret the iterative denoising\nprocess as model optimization and leverage a moving average mechanism to\nensemble all the prior samples. Instead of simply applying moving average to\nthe denoised samples at different timesteps, we first map the denoised samples\nto data space and then perform moving average to avoid distribution shift\nacross timesteps. In view that diffusion models evolve the recovery from\nlow-frequency components to high-frequency details, we further decompose the\nsamples into different frequency components and execute moving average\nseparately on each component. We name the complete approach \"Moving Average\nSampling in Frequency domain (MASF)\". MASF could be seamlessly integrated into\nmainstream pre-trained diffusion models and sampling schedules. Extensive\nexperiments on both unconditional and conditional diffusion models demonstrate\nthat our MASF leads to superior performances compared to the baselines, with\nalmost negligible additional complexity cost.\n","authors":["Yurui Qian","Qi Cai","Yingwei Pan","Yehao Li","Ting Yao","Qibin Sun","Tao Mei"],"pdf_url":"https://arxiv.org/pdf/2403.17870v1.pdf","comment":"CVPR 2024"},{"id":"http://arxiv.org/abs/2403.17837v1","updated":"2024-03-26T16:24:42Z","published":"2024-03-26T16:24:42Z","title":"GTA-HDR: A Large-Scale Synthetic Dataset for HDR Image Reconstruction","summary":"  High Dynamic Range (HDR) content (i.e., images and videos) has a broad range\nof applications. However, capturing HDR content from real-world scenes is\nexpensive and time-consuming. Therefore, the challenging task of reconstructing\nvisually accurate HDR images from their Low Dynamic Range (LDR) counterparts is\ngaining attention in the vision research community. A major challenge in this\nresearch problem is the lack of datasets, which capture diverse scene\nconditions (e.g., lighting, shadows, weather, locations, landscapes, objects,\nhumans, buildings) and various image features (e.g., color, contrast,\nsaturation, hue, luminance, brightness, radiance). To address this gap, in this\npaper, we introduce GTA-HDR, a large-scale synthetic dataset of photo-realistic\nHDR images sampled from the GTA-V video game. We perform thorough evaluation of\nthe proposed dataset, which demonstrates significant qualitative and\nquantitative improvements of the state-of-the-art HDR image reconstruction\nmethods. Furthermore, we demonstrate the effectiveness of the proposed dataset\nand its impact on additional computer vision tasks including 3D human pose\nestimation, human body part segmentation, and holistic scene segmentation. The\ndataset, data collection pipeline, and evaluation code are available at:\nhttps://github.com/HrishavBakulBarua/GTA-HDR.\n","authors":["Hrishav Bakul Barua","Kalin Stefanov","KokSheik Wong","Abhinav Dhall","Ganesh Krishnasamy"],"pdf_url":"https://arxiv.org/pdf/2403.17837v1.pdf","comment":"Submitted to IEEE"},{"id":"http://arxiv.org/abs/2403.17727v1","updated":"2024-03-26T14:16:56Z","published":"2024-03-26T14:16:56Z","title":"FastPerson: Enhancing Video Learning through Effective Video\n  Summarization that Preserves Linguistic and Visual Contexts","summary":"  Quickly understanding lengthy lecture videos is essential for learners with\nlimited time and interest in various topics to improve their learning\nefficiency. To this end, video summarization has been actively researched to\nenable users to view only important scenes from a video. However, these studies\nfocus on either the visual or audio information of a video and extract\nimportant segments in the video. Therefore, there is a risk of missing\nimportant information when both the teacher's speech and visual information on\nthe blackboard or slides are important, such as in a lecture video. To tackle\nthis issue, we propose FastPerson, a video summarization approach that\nconsiders both the visual and auditory information in lecture videos.\nFastPerson creates summary videos by utilizing audio transcriptions along with\non-screen images and text, minimizing the risk of overlooking crucial\ninformation for learners. Further, it provides a feature that allows learners\nto switch between the summary and original videos for each chapter of the\nvideo, enabling them to adjust the pace of learning based on their interests\nand level of understanding. We conducted an evaluation with 40 participants to\nassess the effectiveness of our method and confirmed that it reduced viewing\ntime by 53\\% at the same level of comprehension as that when using traditional\nvideo playback methods.\n","authors":["Kazuki Kawamura","Jun Rekimoto"],"pdf_url":"https://arxiv.org/pdf/2403.17727v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.17708v1","updated":"2024-03-26T13:54:52Z","published":"2024-03-26T13:54:52Z","title":"Panonut360: A Head and Eye Tracking Dataset for Panoramic Video","summary":"  With the rapid development and widespread application of VR/AR technology,\nmaximizing the quality of immersive panoramic video services that match users'\npersonal preferences and habits has become a long-standing challenge.\nUnderstanding the saliency region where users focus, based on data collected\nwith HMDs, can promote multimedia encoding, transmission, and quality\nassessment. At the same time, large-scale datasets are essential for\nresearchers and developers to explore short/long-term user behavior patterns\nand train AI models related to panoramic videos. However, existing panoramic\nvideo datasets often include low-frequency user head or eye movement data\nthrough short-term videos only, lacking sufficient data for analyzing users'\nField of View (FoV) and generating video saliency regions.\n  Driven by these practical factors, in this paper, we present a head and eye\ntracking dataset involving 50 users (25 males and 25 females) watching 15\npanoramic videos. The dataset provides details on the viewport and gaze\nattention locations of users. Besides, we present some statistics samples\nextracted from the dataset. For example, the deviation between head and eye\nmovements challenges the widely held assumption that gaze attention decreases\nfrom the center of the FoV following a Gaussian distribution. Our analysis\nreveals a consistent downward offset in gaze fixations relative to the FoV in\nexperimental settings involving multiple users and videos. That's why we name\nthe dataset Panonut, a saliency weighting shaped like a donut. Finally, we also\nprovide a script that generates saliency distributions based on given head or\neye coordinates and pre-generated saliency distribution map sets of each video\nfrom the collected eye tracking data.\n  The dataset is available on website: https://dianvrlab.github.io/Panonut360/.\n","authors":["Yutong Xu","Junhao Du","Jiahe Wang","Yuwei Ning","Sihan Zhou Yang Cao"],"pdf_url":"https://arxiv.org/pdf/2403.17708v1.pdf","comment":"7 pages,ACM MMSys'24 accepted"},{"id":"http://arxiv.org/abs/2312.02512v2","updated":"2024-03-26T13:21:28Z","published":"2023-12-05T05:36:44Z","title":"AV2AV: Direct Audio-Visual Speech to Audio-Visual Speech Translation\n  with Unified Audio-Visual Speech Representation","summary":"  This paper proposes a novel direct Audio-Visual Speech to Audio-Visual Speech\nTranslation (AV2AV) framework, where the input and output of the system are\nmultimodal (i.e., audio and visual speech). With the proposed AV2AV, two key\nadvantages can be brought: 1) We can perform real-like conversations with\nindividuals worldwide in a virtual meeting by utilizing our own primary\nlanguages. In contrast to Speech-to-Speech Translation (A2A), which solely\ntranslates between audio modalities, the proposed AV2AV directly translates\nbetween audio-visual speech. This capability enhances the dialogue experience\nby presenting synchronized lip movements along with the translated speech. 2)\nWe can improve the robustness of the spoken language translation system. By\nemploying the complementary information of audio-visual speech, the system can\neffectively translate spoken language even in the presence of acoustic noise,\nshowcasing robust performance. To mitigate the problem of the absence of a\nparallel AV2AV translation dataset, we propose to train our spoken language\ntranslation system with the audio-only dataset of A2A. This is done by learning\nunified audio-visual speech representations through self-supervised learning in\nadvance to train the translation system. Moreover, we propose an AV-Renderer\nthat can generate raw audio and video in parallel. It is designed with\nzero-shot speaker modeling, thus the speaker in source audio-visual speech can\nbe maintained at the target translated audio-visual speech. The effectiveness\nof AV2AV is evaluated with extensive experiments in a many-to-many language\ntranslation setting. Demo page is available on\nhttps://choijeongsoo.github.io/av2av.\n","authors":["Jeongsoo Choi","Se Jin Park","Minsu Kim","Yong Man Ro"],"pdf_url":"https://arxiv.org/pdf/2312.02512v2.pdf","comment":"CVPR 2024. Code & Demo: https://choijeongsoo.github.io/av2av"},{"id":"http://arxiv.org/abs/2403.17589v1","updated":"2024-03-26T10:54:07Z","published":"2024-03-26T10:54:07Z","title":"Dual Memory Networks: A Versatile Adaptation Approach for\n  Vision-Language Models","summary":"  With the emergence of pre-trained vision-language models like CLIP, how to\nadapt them to various downstream classification tasks has garnered significant\nattention in recent research. The adaptation strategies can be typically\ncategorized into three paradigms: zero-shot adaptation, few-shot adaptation,\nand the recently-proposed training-free few-shot adaptation. Most existing\napproaches are tailored for a specific setting and can only cater to one or two\nof these paradigms. In this paper, we introduce a versatile adaptation approach\nthat can effectively work under all three settings. Specifically, we propose\nthe dual memory networks that comprise dynamic and static memory components.\nThe static memory caches training data knowledge, enabling training-free\nfew-shot adaptation, while the dynamic memory preserves historical test\nfeatures online during the testing process, allowing for the exploration of\nadditional data insights beyond the training set. This novel capability\nenhances model performance in the few-shot setting and enables model usability\nin the absence of training data. The two memory networks employ the same\nflexible memory interactive strategy, which can operate in a training-free mode\nand can be further enhanced by incorporating learnable projection layers. Our\napproach is tested across 11 datasets under the three task settings.\nRemarkably, in the zero-shot scenario, it outperforms existing methods by over\n3\\% and even shows superior results against methods utilizing external training\ndata. Additionally, our method exhibits robust performance against natural\ndistribution shifts. Codes are available at \\url{https://github.com/YBZh/DMN}.\n","authors":["Yabin Zhang","Wenjie Zhu","Hui Tang","Zhiyuan Ma","Kaiyang Zhou","Lei Zhang"],"pdf_url":"https://arxiv.org/pdf/2403.17589v1.pdf","comment":"CVPR2024; Codes are available at \\url{https://github.com/YBZh/DMN}"},{"id":"http://arxiv.org/abs/2403.17420v1","updated":"2024-03-26T06:27:50Z","published":"2024-03-26T06:27:50Z","title":"Learning to Visually Localize Sound Sources from Mixtures without Prior\n  Source Knowledge","summary":"  The goal of the multi-sound source localization task is to localize sound\nsources from the mixture individually. While recent multi-sound source\nlocalization methods have shown improved performance, they face challenges due\nto their reliance on prior information about the number of objects to be\nseparated. In this paper, to overcome this limitation, we present a novel\nmulti-sound source localization method that can perform localization without\nprior knowledge of the number of sound sources. To achieve this goal, we\npropose an iterative object identification (IOI) module, which can recognize\nsound-making objects in an iterative manner. After finding the regions of\nsound-making objects, we devise object similarity-aware clustering (OSC) loss\nto guide the IOI module to effectively combine regions of the same object but\nalso distinguish between different objects and backgrounds. It enables our\nmethod to perform accurate localization of sound-making objects without any\nprior knowledge. Extensive experimental results on the MUSIC and VGGSound\nbenchmarks show the significant performance improvements of the proposed method\nover the existing methods for both single and multi-source. Our code is\navailable at: https://github.com/VisualAIKHU/NoPrior_MultiSSL\n","authors":["Dongjin Kim","Sung Jin Um","Sangmin Lee","Jung Uk Kim"],"pdf_url":"https://arxiv.org/pdf/2403.17420v1.pdf","comment":"Accepted at CVPR 2024"},{"id":"http://arxiv.org/abs/2402.19330v2","updated":"2024-03-26T04:15:53Z","published":"2024-02-29T16:33:12Z","title":"A Novel Approach to Industrial Defect Generation through Blended Latent\n  Diffusion Model with Online Adaptation","summary":"  Effectively addressing the challenge of industrial Anomaly Detection (AD)\nnecessitates an ample supply of defective samples, a constraint often hindered\nby their scarcity in industrial contexts. This paper introduces a novel\nalgorithm designed to augment defective samples, thereby enhancing AD\nperformance. The proposed method tailors the blended latent diffusion model for\ndefect sample generation, employing a diffusion model to generate defective\nsamples in the latent space. A feature editing process, controlled by a\n``trimap\" mask and text prompts, refines the generated samples. The image\ngeneration inference process is structured into three stages: a free diffusion\nstage, an editing diffusion stage, and an online decoder adaptation stage. This\nsophisticated inference strategy yields high-quality synthetic defective\nsamples with diverse pattern variations, leading to significantly improved AD\naccuracies based on the augmented training set. Specifically, on the widely\nrecognized MVTec AD dataset, the proposed method elevates the state-of-the-art\n(SOTA) performance of AD with augmented data by 1.5%, 1.9%, and 3.1% for AD\nmetrics AP, IAP, and IAP90, respectively. The implementation code of this work\ncan be found at the GitHub repository\nhttps://github.com/GrandpaXun242/AdaBLDM.git\n","authors":["Hanxi Li","Zhengxun Zhang","Hao Chen","Lin Wu","Bo Li","Deyin Liu","Mingwen Wang"],"pdf_url":"https://arxiv.org/pdf/2402.19330v2.pdf","comment":"13 pages,7 figures"}],"Machine Learning 2":[{"id":"http://arxiv.org/abs/2306.13829v3","updated":"2024-03-26T23:39:35Z","published":"2023-06-24T01:14:26Z","title":"Selective inference using randomized group lasso estimators for general\n  models","summary":"  Selective inference methods are developed for group lasso estimators for use\nwith a wide class of distributions and loss functions. The method includes the\nuse of exponential family distributions, as well as quasi-likelihood modeling\nfor overdispersed count data, for example, and allows for categorical or\ngrouped covariates as well as continuous covariates. A randomized\ngroup-regularized optimization problem is studied. The added randomization\nallows us to construct a post-selection likelihood which we show to be adequate\nfor selective inference when conditioning on the event of the selection of the\ngrouped covariates. This likelihood also provides a selective point estimator,\naccounting for the selection by the group lasso. Confidence regions for the\nregression parameters in the selected model take the form of Wald-type regions\nand are shown to have bounded volume. The selective inference method for\ngrouped lasso is illustrated on data from the national health and nutrition\nexamination survey while simulations showcase its behaviour and favorable\ncomparison with other methods.\n","authors":["Yiling Huang","Sarah Pirenne","Snigdha Panigrahi","Gerda Claeskens"],"pdf_url":"https://arxiv.org/pdf/2306.13829v3.pdf","comment":"64pages, 4 figures, 3 tables"},{"id":"http://arxiv.org/abs/2403.18127v1","updated":"2024-03-26T22:15:47Z","published":"2024-03-26T22:15:47Z","title":"A Correction of Pseudo Log-Likelihood Method","summary":"  Pseudo log-likelihood is a type of maximum likelihood estimation (MLE) method\nused in various fields including contextual bandits, influence maximization of\nsocial networks, and causal bandits. However, in previous literature\n\\citep{li2017provably, zhang2022online, xiong2022combinatorial,\nfeng2023combinatorial1, feng2023combinatorial2}, the log-likelihood function\nmay not be bounded, which may result in the algorithm they proposed not\nwell-defined. In this paper, we give a counterexample that the maximum pseudo\nlog-likelihood estimation fails and then provide a solution to correct the\nalgorithms in \\citep{li2017provably, zhang2022online, xiong2022combinatorial,\nfeng2023combinatorial1, feng2023combinatorial2}.\n","authors":["Shi Feng","Nuoya Xiong","Zhijie Zhang","Wei Chen"],"pdf_url":"https://arxiv.org/pdf/2403.18127v1.pdf","comment":"7 pages"},{"id":"http://arxiv.org/abs/2402.09654v2","updated":"2024-03-26T20:12:18Z","published":"2024-02-15T01:38:50Z","title":"GPT-4's assessment of its performance in a USMLE-based case study","summary":"  This study investigates GPT-4's assessment of its performance in healthcare\napplications. A simple prompting technique was used to prompt the LLM with\nquestions taken from the United States Medical Licensing Examination (USMLE)\nquestionnaire and it was tasked to evaluate its confidence score before posing\nthe question and after asking the question. The questionnaire was categorized\ninto two groups-questions with feedback (WF) and questions with no feedback(NF)\npost-question. The model was asked to provide absolute and relative confidence\nscores before and after each question. The experimental findings were analyzed\nusing statistical tools to study the variability of confidence in WF and NF\ngroups. Additionally, a sequential analysis was conducted to observe the\nperformance variation for the WF and NF groups. Results indicate that feedback\ninfluences relative confidence but doesn't consistently increase or decrease\nit. Understanding the performance of LLM is paramount in exploring its utility\nin sensitive areas like healthcare. This study contributes to the ongoing\ndiscourse on the reliability of AI, particularly of LLMs like GPT-4, within\nhealthcare, offering insights into how feedback mechanisms might be optimized\nto enhance AI-assisted medical education and decision support.\n","authors":["Uttam Dhakal","Aniket Kumar Singh","Suman Devkota","Yogesh Sapkota","Bishal Lamichhane","Suprinsa Paudyal","Chandra Dhakal"],"pdf_url":"https://arxiv.org/pdf/2402.09654v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.18072v1","updated":"2024-03-26T19:49:58Z","published":"2024-03-26T19:49:58Z","title":"Goal-Oriented Bayesian Optimal Experimental Design for Nonlinear Models\n  using Markov Chain Monte Carlo","summary":"  Optimal experimental design (OED) provides a systematic approach to quantify\nand maximize the value of experimental data. Under a Bayesian approach,\nconventional OED maximizes the expected information gain (EIG) on model\nparameters. However, we are often interested in not the parameters themselves,\nbut predictive quantities of interest (QoIs) that depend on the parameters in a\nnonlinear manner. We present a computational framework of predictive\ngoal-oriented OED (GO-OED) suitable for nonlinear observation and prediction\nmodels, which seeks the experimental design providing the greatest EIG on the\nQoIs. In particular, we propose a nested Monte Carlo estimator for the QoI EIG,\nfeaturing Markov chain Monte Carlo for posterior sampling and kernel density\nestimation for evaluating the posterior-predictive density and its\nKullback-Leibler divergence from the prior-predictive. The GO-OED design is\nthen found by maximizing the EIG over the design space using Bayesian\noptimization. We demonstrate the effectiveness of the overall nonlinear GO-OED\nmethod, and illustrate its differences versus conventional non-GO-OED, through\nvarious test problems and an application of sensor placement for source\ninversion in a convection-diffusion field.\n","authors":["Shijie Zhong","Wanggang Shen","Tommie Catanach","Xun Huan"],"pdf_url":"https://arxiv.org/pdf/2403.18072v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.15328v3","updated":"2024-03-26T18:19:54Z","published":"2023-06-27T09:34:32Z","title":"Simulating counterfactuals","summary":"  Counterfactual inference considers a hypothetical intervention in a parallel\nworld that shares some evidence with the factual world. If the evidence\nspecifies a conditional distribution on a manifold, counterfactuals may be\nanalytically intractable. We present an algorithm for simulating values from a\ncounterfactual distribution where conditions can be set on both discrete and\ncontinuous variables. We show that the proposed algorithm can be presented as a\nparticle filter leading to asymptotically valid inference. The algorithm is\napplied to fairness analysis in credit-scoring.\n","authors":["Juha Karvanen","Santtu Tikka","Matti Vihola"],"pdf_url":"https://arxiv.org/pdf/2306.15328v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2211.01364v3","updated":"2024-03-26T17:45:01Z","published":"2022-11-02T17:59:09Z","title":"An optimal control perspective on diffusion-based generative modeling","summary":"  We establish a connection between stochastic optimal control and generative\nmodels based on stochastic differential equations (SDEs), such as recently\ndeveloped diffusion probabilistic models. In particular, we derive a\nHamilton-Jacobi-Bellman equation that governs the evolution of the\nlog-densities of the underlying SDE marginals. This perspective allows to\ntransfer methods from optimal control theory to generative modeling. First, we\nshow that the evidence lower bound is a direct consequence of the well-known\nverification theorem from control theory. Further, we can formulate\ndiffusion-based generative modeling as a minimization of the Kullback-Leibler\ndivergence between suitable measures in path space. Finally, we develop a novel\ndiffusion-based method for sampling from unnormalized densities -- a problem\nfrequently occurring in statistics and computational sciences. We demonstrate\nthat our time-reversed diffusion sampler (DIS) can outperform other\ndiffusion-based sampling approaches on multiple numerical examples.\n","authors":["Julius Berner","Lorenz Richter","Karen Ullrich"],"pdf_url":"https://arxiv.org/pdf/2211.01364v3.pdf","comment":"Accepted for oral presentation at NeurIPS 2022 Workshop on\n  Score-Based Methods"},{"id":"http://arxiv.org/abs/2403.17887v1","updated":"2024-03-26T17:20:04Z","published":"2024-03-26T17:20:04Z","title":"The Unreasonable Ineffectiveness of the Deeper Layers","summary":"  We empirically study a simple layer-pruning strategy for popular families of\nopen-weight pretrained LLMs, finding minimal degradation of performance on\ndifferent question-answering benchmarks until after a large fraction (up to\nhalf) of the layers are removed. To prune these models, we identify the optimal\nblock of layers to prune by considering similarity across layers; then, to\n\"heal\" the damage, we perform a small amount of finetuning. In particular, we\nuse parameter-efficient finetuning (PEFT) methods, specifically quantization\nand Low Rank Adapters (QLoRA), such that each of our experiments can be\nperformed on a single A100 GPU. From a practical perspective, these results\nsuggest that layer pruning methods can complement other PEFT strategies to\nfurther reduce computational resources of finetuning on the one hand, and can\nimprove the memory and latency of inference on the other hand. From a\nscientific perspective, the robustness of these LLMs to the deletion of layers\nimplies either that current pretraining methods are not properly leveraging the\nparameters in the deeper layers of the network or that the shallow layers play\na critical role in storing knowledge.\n","authors":["Andrey Gromov","Kushal Tirumala","Hassan Shapourian","Paolo Glorioso","Daniel A. Roberts"],"pdf_url":"https://arxiv.org/pdf/2403.17887v1.pdf","comment":"12 + 10 pages, 5 + 4 figures"},{"id":"http://arxiv.org/abs/2210.06459v2","updated":"2024-03-26T16:49:11Z","published":"2022-10-12T17:56:04Z","title":"Differentially private multivariate medians","summary":"  Statistical tools which satisfy rigorous privacy guarantees are necessary for\nmodern data analysis. It is well-known that robustness against contamination is\nlinked to differential privacy. Despite this fact, using multivariate medians\nfor differentially private and robust multivariate location estimation has not\nbeen systematically studied. We develop novel finite-sample performance\nguarantees for differentially private multivariate depth-based medians, which\nare essentially sharp. Our results cover commonly used depth functions, such as\nthe halfspace (or Tukey) depth, spatial depth, and the integrated dual depth.\nWe show that under Cauchy marginals, the cost of heavy-tailed location\nestimation outweighs the cost of privacy. We demonstrate our results\nnumerically using a Gaussian contamination model in dimensions up to d = 100,\nand compare them to a state-of-the-art private mean estimation algorithm. As a\nby-product of our investigation, we prove concentration inequalities for the\noutput of the exponential mechanism about the maximizer of the population\nobjective function. This bound applies to objective functions that satisfy a\nmild regularity condition.\n","authors":["Kelly Ramsay","Aukosh Jagannath","Shoja'eddin Chenouri"],"pdf_url":"https://arxiv.org/pdf/2210.06459v2.pdf","comment":"42 pages, 3 figures, 2 tables"},{"id":"http://arxiv.org/abs/2403.17852v1","updated":"2024-03-26T16:40:08Z","published":"2024-03-26T16:40:08Z","title":"Counterfactual Fairness through Transforming Data Orthogonal to Bias","summary":"  Machine learning models have shown exceptional prowess in solving complex\nissues across various domains. Nonetheless, these models can sometimes exhibit\nbiased decision-making, leading to disparities in treatment across different\ngroups. Despite the extensive research on fairness, the nuanced effects of\nmultivariate and continuous sensitive variables on decision-making outcomes\nremain insufficiently studied. We introduce a novel data pre-processing\nalgorithm, Orthogonal to Bias (OB), designed to remove the influence of a group\nof continuous sensitive variables, thereby facilitating counterfactual fairness\nin machine learning applications. Our approach is grounded in the assumption of\na jointly normal distribution within a structural causal model (SCM), proving\nthat counterfactual fairness can be achieved by ensuring the data is\nuncorrelated with sensitive variables. The OB algorithm is model-agnostic,\ncatering to a wide array of machine learning models and tasks, and includes a\nsparse variant to enhance numerical stability through regularization. Through\nempirical evaluation on simulated and real-world datasets - including the adult\nincome and the COMPAS recidivism datasets - our methodology demonstrates its\ncapacity to enable fairer outcomes without compromising accuracy.\n","authors":["Shuyi Chen","Shixiang Zhu"],"pdf_url":"https://arxiv.org/pdf/2403.17852v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.17820v1","updated":"2024-03-26T15:55:54Z","published":"2024-03-26T15:55:54Z","title":"Towards Multilevel Modelling of Train Passing Events on the\n  Staffordshire Bridge","summary":"  We suggest a multilevel model, to represent aggregate train-passing events\nfrom the Staffordshire bridge monitoring system. We formulate a combined model\nfrom simple units, representing strain envelopes (of each train passing) for\ntwo types of commuter train. The measurements are treated as a longitudinal\ndataset and represented with a (low-rank approximation) hierarchical Gaussian\nprocess. For each unit in the combined model, we encode domain expertise as\nboundary condition constraints and work towards a general representation of the\nstrain response. Looking forward, this should allow for the simulation of train\ntypes that were previously unobserved in the training data. For example, trains\nwith more passengers or freights with a heavier payload. The strain event\nsimulations are valuable since they can inform further experiments (including\nFEM calibration, fatigue analysis, or design) to test the bridge in\nhypothesised scenarios.\n","authors":["Lawrence A. Bull","Chiho Jeon","Mark Girolami","Andrew Duncan","Jennifer Schooling","Miguel Bravo Haro"],"pdf_url":"https://arxiv.org/pdf/2403.17820v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2211.09557v2","updated":"2024-03-26T13:54:44Z","published":"2022-11-17T14:27:52Z","title":"Optimal Design of Volt/VAR Control Rules of Inverters using Deep\n  Learning","summary":"  Distribution grids are challenged by rapid voltage fluctuations induced by\nvariable power injections from distributed energy resources (DERs). To regulate\nvoltage, the IEEE Standard 1547 recommends each DER inject reactive power\naccording to piecewise-affine Volt/VAR control rules. Although the standard\nsuggests a default shape, the rule can be customized per bus. This task of\noptimal rule design (ORD) is challenging as Volt/VAR rules introduce nonlinear\ndynamics, and lurk trade-offs between stability and steady-state voltage\nprofiles. ORD is formulated as a mixed-integer nonlinear program (MINLP), but\nscales unfavorably with the problem size. Towards a more efficient solution, we\nreformulate ORD as a deep learning problem. The idea is to design a DNN that\nemulates Volt/VAR dynamics. The DNN takes grid scenarios as inputs, rule\nparameters as weights, and outputs equilibrium voltages. Optimal rule\nparameters can be found by training the DNN so its output approaches unity for\nvarious scenarios. The DNN is only used to optimize rules and is never employed\nin the field. While dealing with ORD, we also review and expand on stability\nconditions and convergence rates for Volt/VAR dynamics on single- and\nmulti-phase feeders. Tests showcase the merit of DNN-based ORD by benchmarking\nit against its MINLP counterpart.\n","authors":["Sarthak Gupta","Vassilis Kekatos","Spyros Chatzivasileiadis"],"pdf_url":"https://arxiv.org/pdf/2211.09557v2.pdf","comment":"Accepted in the IEEE Trans. on Smart Grid"},{"id":"http://arxiv.org/abs/2306.16378v2","updated":"2024-03-26T12:29:35Z","published":"2023-06-28T17:14:49Z","title":"Spatiotemporal Besov Priors for Bayesian Inverse Problems","summary":"  Fast development in science and technology has driven the need for proper\nstatistical tools to capture special data features such as abrupt changes or\nsharp contrast. Many inverse problems in data science require spatiotemporal\nsolutions derived from a sequence of time-dependent objects with these spatial\nfeatures, e.g., dynamic reconstruction of computerized tomography (CT) images\nwith edges. Conventional methods based on Gaussian processes (GP) often fall\nshort in providing satisfactory solutions since they tend to offer over-smooth\npriors. Recently, the Besov process (BP), defined by wavelet expansions with\nrandom coefficients, has emerged as a more suitable prior for Bayesian inverse\nproblems of this nature. While BP excels in handling spatial inhomogeneity, it\ndoes not automatically incorporate temporal correlation inherited in the\ndynamically changing objects. In this paper, we generalize BP to a novel\nspatiotemporal Besov process (STBP) by replacing the random coefficients in the\nseries expansion with stochastic time functions as Q-exponential process (Q-EP)\nwhich governs the temporal correlation structure. We thoroughly investigate the\nmathematical and statistical properties of STBP. A white-noise representation\nof STBP is also proposed to facilitate the inference. Simulations, two\nlimited-angle CT reconstruction examples and a highly non-linear inverse\nproblem involving Navier-Stokes equation are used to demonstrate the advantage\nof the proposed STBP in preserving spatial features while accounting for\ntemporal changes compared with the classic STGP and a time-uncorrelated\napproach.\n","authors":["Shiwei Lan","Mirjeta Pasha","Shuyi Li","Weining Shen"],"pdf_url":"https://arxiv.org/pdf/2306.16378v2.pdf","comment":"47 pages, 15 figures"},{"id":"http://arxiv.org/abs/2403.17592v1","updated":"2024-03-26T11:01:53Z","published":"2024-03-26T11:01:53Z","title":"On the Benefits of Over-parameterization for Out-of-Distribution\n  Generalization","summary":"  In recent years, machine learning models have achieved success based on the\nindependently and identically distributed assumption. However, this assumption\ncan be easily violated in real-world applications, leading to the\nOut-of-Distribution (OOD) problem. Understanding how modern over-parameterized\nDNNs behave under non-trivial natural distributional shifts is essential, as\ncurrent theoretical understanding is insufficient. Existing theoretical works\noften provide meaningless results for over-parameterized models in OOD\nscenarios or even contradict empirical findings. To this end, we are\ninvestigating the performance of the over-parameterized model in terms of OOD\ngeneralization under the general benign overfitting conditions. Our analysis\nfocuses on a random feature model and examines non-trivial natural\ndistributional shifts, where the benign overfitting estimators demonstrate a\nconstant excess OOD loss, despite achieving zero excess in-distribution (ID)\nloss. We demonstrate that in this scenario, further increasing the model's\nparameterization can significantly reduce the OOD loss. Intuitively, the\nvariance term of ID loss remains low due to orthogonality of long-tail\nfeatures, meaning overfitting noise during training generally doesn't raise\ntesting loss. However, in OOD cases, distributional shift increases the\nvariance term. Thankfully, the inherent shift is unrelated to individual x,\nmaintaining the orthogonality of long-tail features. Expanding the hidden\ndimension can additionally improve this orthogonality by mapping the features\ninto higher-dimensional spaces, thereby reducing the variance term. We further\nshow that model ensembles also improve OOD loss, akin to increasing model\ncapacity. These insights explain the empirical phenomenon of enhanced OOD\ngeneralization through model ensembles, supported by consistent simulations\nwith theoretical results.\n","authors":["Yifan Hao","Yong Lin","Difan Zou","Tong Zhang"],"pdf_url":"https://arxiv.org/pdf/2403.17592v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.01050v6","updated":"2024-03-26T09:48:49Z","published":"2023-07-03T14:28:36Z","title":"Transport meets Variational Inference: Controlled Monte Carlo Diffusions","summary":"  Connecting optimal transport and variational inference, we present a\nprincipled and systematic framework for sampling and generative modelling\ncentred around divergences on path space. Our work culminates in the\ndevelopment of the \\emph{Controlled Monte Carlo Diffusion} sampler (CMCD) for\nBayesian computation, a score-based annealing technique that crucially adapts\nboth forward and backward dynamics in a diffusion model. On the way, we clarify\nthe relationship between the EM-algorithm and iterative proportional fitting\n(IPF) for Schr{\\\"o}dinger bridges, deriving as well a regularised objective\nthat bypasses the iterative bottleneck of standard IPF-updates. Finally, we\nshow that CMCD has a strong foundation in the Jarzinsky and Crooks identities\nfrom statistical physics, and that it convincingly outperforms competing\napproaches across a wide array of experiments.\n","authors":["Francisco Vargas","Shreyas Padhy","Denis Blessing","Nikolas N√ºsken"],"pdf_url":"https://arxiv.org/pdf/2307.01050v6.pdf","comment":"Workshop on New Frontiers in Learning, Control, and Dynamical Systems\n  at the International Conference on Machine Learning (ICML), Honolulu, Hawaii,\n  USA, 2023"},{"id":"http://arxiv.org/abs/2204.00406v3","updated":"2024-03-26T08:48:53Z","published":"2022-04-01T13:08:49Z","title":"A Semismooth Newton Stochastic Proximal Point Algorithm with Variance\n  Reduction","summary":"  We develop an implementable stochastic proximal point (SPP) method for a\nclass of weakly convex, composite optimization problems. The proposed\nstochastic proximal point algorithm incorporates a variance reduction mechanism\nand the resulting SPP updates are solved using an inexact semismooth Newton\nframework. We establish detailed convergence results that take the inexactness\nof the SPP steps into account and that are in accordance with existing\nconvergence guarantees of (proximal) stochastic variance-reduced gradient\nmethods. Numerical experiments show that the proposed algorithm competes\nfavorably with other state-of-the-art methods and achieves higher robustness\nwith respect to the step size selection.\n","authors":["Andre Milzarek","Fabian Schaipp","Michael Ulbrich"],"pdf_url":"https://arxiv.org/pdf/2204.00406v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2102.01432v2","updated":"2024-03-26T08:21:24Z","published":"2021-02-02T11:05:34Z","title":"Bayesian data-driven discovery of partial differential equations with\n  variable coefficients","summary":"  The discovery of Partial Differential Equations (PDEs) is an essential task\nfor applied science and engineering. However, data-driven discovery of PDEs is\ngenerally challenging, primarily stemming from the sensitivity of the\ndiscovered equation to noise and the complexities of model selection. In this\nwork, we propose an advanced Bayesian sparse learning algorithm for PDE\ndiscovery with variable coefficients, predominantly when the coefficients are\nspatially or temporally dependent. Specifically, we apply threshold Bayesian\ngroup Lasso regression with a spike-and-slab prior (tBGL-SS) and leverage a\nGibbs sampler for Bayesian posterior estimation of PDE coefficients. This\napproach not only enhances the robustness of point estimation with valid\nuncertainty quantification but also relaxes the computational burden from\nBayesian inference through the integration of coefficient thresholds as an\napproximate MCMC method. Moreover, from the quantified uncertainties, we\npropose a Bayesian total error bar criteria for model selection, which\noutperforms classic metrics including the root mean square and the Akaike\ninformation criterion. The capability of this method is illustrated by the\ndiscovery of several classical benchmark PDEs with spatially or temporally\nvarying coefficients from solution data obtained from the reference\nsimulations. In the experiments, we show that the tBGL-SS method is more robust\nthan the baseline methods under noisy environments and provides better model\nselection criteria along the regularization path.\n","authors":["Aoxue Chen","Yifan Du","Liyao Mars Gao","Guang Lin"],"pdf_url":"https://arxiv.org/pdf/2102.01432v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.02766v3","updated":"2024-03-26T08:05:11Z","published":"2023-11-05T20:51:03Z","title":"Riemannian Laplace Approximation with the Fisher Metric","summary":"  Laplace's method approximates a target density with a Gaussian distribution\nat its mode. It is computationally efficient and asymptotically exact for\nBayesian inference due to the Bernstein-von Mises theorem, but for complex\ntargets and finite-data posteriors it is often too crude an approximation. A\nrecent generalization of the Laplace Approximation transforms the Gaussian\napproximation according to a chosen Riemannian geometry providing a richer\napproximation family, while still retaining computational efficiency. However,\nas shown here, its properties depend heavily on the chosen metric, indeed the\nmetric adopted in previous work results in approximations that are overly\nnarrow as well as being biased even at the limit of infinite data. We correct\nthis shortcoming by developing the approximation family further, deriving two\nalternative variants that are exact at the limit of infinite data, extending\nthe theoretical analysis of the method, and demonstrating practical\nimprovements in a range of experiments.\n","authors":["Hanlin Yu","Marcelo Hartmann","Bernardo Williams","Mark Girolami","Arto Klami"],"pdf_url":"https://arxiv.org/pdf/2311.02766v3.pdf","comment":"AISTATS 2024, with additional fixes"},{"id":"http://arxiv.org/abs/2403.17423v1","updated":"2024-03-26T06:40:03Z","published":"2024-03-26T06:40:03Z","title":"Test-time Adaptation Meets Image Enhancement: Improving Accuracy via\n  Uncertainty-aware Logit Switching","summary":"  Deep neural networks have achieved remarkable success in a variety of\ncomputer vision applications. However, there is a problem of degrading accuracy\nwhen the data distribution shifts between training and testing. As a solution\nof this problem, Test-time Adaptation~(TTA) has been well studied because of\nits practicality. Although TTA methods increase accuracy under distribution\nshift by updating the model at test time, using high-uncertainty predictions is\nknown to degrade accuracy. Since the input image is the root of the\ndistribution shift, we incorporate a new perspective on enhancing the input\nimage into TTA methods to reduce the prediction's uncertainty. We hypothesize\nthat enhancing the input image reduces prediction's uncertainty and increase\nthe accuracy of TTA methods. On the basis of our hypothesis, we propose a novel\nmethod: Test-time Enhancer and Classifier Adaptation~(TECA). In TECA, the\nclassification model is combined with the image enhancement model that\ntransforms input images into recognition-friendly ones, and these models are\nupdated by existing TTA methods. Furthermore, we found that the prediction from\nthe enhanced image does not always have lower uncertainty than the prediction\nfrom the original image. Thus, we propose logit switching, which compares the\nuncertainty measure of these predictions and outputs the lower one. In our\nexperiments, we evaluate TECA with various TTA methods and show that TECA\nreduces prediction's uncertainty and increases accuracy of TTA methods despite\nhaving no hyperparameters and little parameter overhead.\n","authors":["Shohei Enomoto","Naoya Hasegawa","Kazuki Adachi","Taku Sasaki","Shin'ya Yamaguchi","Satoshi Suzuki","Takeharu Eda"],"pdf_url":"https://arxiv.org/pdf/2403.17423v1.pdf","comment":"Accepted to IJCNN2024"},{"id":"http://arxiv.org/abs/2403.17410v1","updated":"2024-03-26T06:06:01Z","published":"2024-03-26T06:06:01Z","title":"On permutation-invariant neural networks","summary":"  Conventional machine learning algorithms have traditionally been designed\nunder the assumption that input data follows a vector-based format, with an\nemphasis on vector-centric paradigms. However, as the demand for tasks\ninvolving set-based inputs has grown, there has been a paradigm shift in the\nresearch community towards addressing these challenges. In recent years, the\nemergence of neural network architectures such as Deep Sets and Transformers\nhas presented a significant advancement in the treatment of set-based data.\nThese architectures are specifically engineered to naturally accommodate sets\nas input, enabling more effective representation and processing of set\nstructures. Consequently, there has been a surge of research endeavors\ndedicated to exploring and harnessing the capabilities of these architectures\nfor various tasks involving the approximation of set functions. This\ncomprehensive survey aims to provide an overview of the diverse problem\nsettings and ongoing research efforts pertaining to neural networks that\napproximate set functions. By delving into the intricacies of these approaches\nand elucidating the associated challenges, the survey aims to equip readers\nwith a comprehensive understanding of the field. Through this comprehensive\nperspective, we hope that researchers can gain valuable insights into the\npotential applications, inherent limitations, and future directions of\nset-based neural networks. Indeed, from this survey we gain two insights: i)\nDeep Sets and its variants can be generalized by differences in the aggregation\nfunction, and ii) the behavior of Deep Sets is sensitive to the choice of the\naggregation function. From these observations, we show that Deep Sets, one of\nthe well-known permutation-invariant neural networks, can be generalized in the\nsense of a quasi-arithmetic mean.\n","authors":["Masanari Kimura","Ryotaro Shimizu","Yuki Hirakawa","Ryosuke Goto","Yuki Saito"],"pdf_url":"https://arxiv.org/pdf/2403.17410v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2304.10025v3","updated":"2024-03-26T03:18:24Z","published":"2023-04-20T00:39:20Z","title":"Identification and multiply robust estimation in causal mediation\n  analysis across principal strata","summary":"  We consider assessing causal mediation in the presence of a post-treatment\nevent (examples include noncompliance, a clinical event, or a terminal event).\nWe identify natural mediation effects for the entire study population and for\neach principal stratum characterized by the joint potential values of the\npost-treatment event. We derive efficient influence functions for each\nmediation estimand, which motivate a set of multiply robust estimators for\ninference. The multiply robust estimators are consistent under four types of\nmisspecifications and are efficient when all nuisance models are correctly\nspecified. We illustrate our methods via simulations and two real data\nexamples.\n","authors":["Chao Cheng","Fan Li"],"pdf_url":"https://arxiv.org/pdf/2304.10025v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2309.00736v3","updated":"2024-03-26T02:33:12Z","published":"2023-09-01T21:16:02Z","title":"Prediction Error Estimation in Random Forests","summary":"  In this paper, error estimates of classification Random Forests are\nquantitatively assessed. Based on the initial theoretical framework built by\nBates et al. (2023), the true error rate and expected error rate are\ntheoretically and empirically investigated in the context of a variety of error\nestimation methods common to Random Forests. We show that in the classification\ncase, Random Forests' estimates of prediction error is closer on average to the\ntrue error rate instead of the average prediction error. This is opposite the\nfindings of Bates et al. (2023) which are given for logistic regression. We\nfurther show that our result holds across different error estimation strategies\nsuch as cross-validation, bagging, and data splitting.\n","authors":["Ian Krupkin","Johanna Hardin"],"pdf_url":"https://arxiv.org/pdf/2309.00736v3.pdf","comment":"arXiv admin note: text overlap with arXiv:2104.00673 by other authors"},{"id":"http://arxiv.org/abs/2403.09960v3","updated":"2024-03-26T02:01:22Z","published":"2024-03-15T01:50:41Z","title":"Multivariate Gaussian Approximation for Random Forest via Region-based\n  Stabilization","summary":"  We derive Gaussian approximation bounds for random forest predictions based\non a set of training points given by a Poisson process, under fairly mild\nregularity assumptions on the data generating process. Our approach is based on\nthe key observation that the random forest predictions satisfy a certain\ngeometric property called region-based stabilization. In the process of\ndeveloping our results for the random forest, we also establish a probabilistic\nresult, which might be of independent interest, on multivariate Gaussian\napproximation bounds for general functionals of Poisson process that are\nregion-based stabilizing. This general result makes use of the Malliavin-Stein\nmethod, and is potentially applicable to various related statistical problems.\n","authors":["Zhaoyang Shi","Chinmoy Bhattacharjee","Krishnakumar Balasubramanian","Wolfgang Polonik"],"pdf_url":"https://arxiv.org/pdf/2403.09960v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.01453v2","updated":"2024-03-26T01:44:52Z","published":"2023-11-02T17:59:04Z","title":"PPI++: Efficient Prediction-Powered Inference","summary":"  We present PPI++: a computationally lightweight methodology for estimation\nand inference based on a small labeled dataset and a typically much larger\ndataset of machine-learning predictions. The methods automatically adapt to the\nquality of available predictions, yielding easy-to-compute confidence sets --\nfor parameters of any dimensionality -- that always improve on classical\nintervals using only the labeled data. PPI++ builds on prediction-powered\ninference (PPI), which targets the same problem setting, improving its\ncomputational and statistical efficiency. Real and synthetic experiments\ndemonstrate the benefits of the proposed adaptations.\n","authors":["Anastasios N. Angelopoulos","John C. Duchi","Tijana Zrnic"],"pdf_url":"https://arxiv.org/pdf/2311.01453v2.pdf","comment":"Code available at https://github.com/aangelopoulos/ppi_py"},{"id":"http://arxiv.org/abs/2403.17285v1","updated":"2024-03-26T00:25:32Z","published":"2024-03-26T00:25:32Z","title":"An Analysis of Switchback Designs in Reinforcement Learning","summary":"  This paper offers a detailed investigation of switchback designs in A/B\ntesting, which alternate between baseline and new policies over time. Our aim\nis to thoroughly evaluate the effects of these designs on the accuracy of their\nresulting average treatment effect (ATE) estimators. We propose a novel \"weak\nsignal analysis\" framework, which substantially simplifies the calculations of\nthe mean squared errors (MSEs) of these ATEs in Markov decision process\nenvironments. Our findings suggest that (i) when the majority of reward errors\nare positively correlated, the switchback design is more efficient than the\nalternating-day design which switches policies in a daily basis. Additionally,\nincreasing the frequency of policy switches tends to reduce the MSE of the ATE\nestimator. (ii) When the errors are uncorrelated, however, all these designs\nbecome asymptotically equivalent. (iii) In cases where the majority of errors\nare negative correlated, the alternating-day design becomes the optimal choice.\nThese insights are crucial, offering guidelines for practitioners on designing\nexperiments in A/B testing. Our analysis accommodates a variety of policy value\nestimators, including model-based estimators, least squares temporal difference\nlearning estimators, and double reinforcement learning estimators, thereby\noffering a comprehensive understanding of optimal design strategies for policy\nevaluation in reinforcement learning.\n","authors":["Qianglin Wen","Chengchun Shi","Ying Yang","Niansheng Tang","Hongtu Zhu"],"pdf_url":"https://arxiv.org/pdf/2403.17285v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.07905v2","updated":"2024-03-26T00:21:41Z","published":"2023-06-13T16:56:13Z","title":"Omega: Optimistic EMA Gradients","summary":"  Stochastic min-max optimization has gained interest in the machine learning\ncommunity with the advancements in GANs and adversarial training. Although game\noptimization is fairly well understood in the deterministic setting, some\nissues persist in the stochastic regime. Recent work has shown that stochastic\ngradient descent-ascent methods such as the optimistic gradient are highly\nsensitive to noise or can fail to converge. Although alternative strategies\nexist, they can be prohibitively expensive. We introduce Omega, a method with\noptimistic-like updates that mitigates the impact of noise by incorporating an\nEMA of historic gradients in its update rule. We also explore a variation of\nthis algorithm that incorporates momentum. Although we do not provide\nconvergence guarantees, our experiments on stochastic games show that Omega\noutperforms the optimistic gradient method when applied to linear players.\n","authors":["Juan Ramirez","Rohan Sukumaran","Quentin Bertrand","Gauthier Gidel"],"pdf_url":"https://arxiv.org/pdf/2306.07905v2.pdf","comment":"Oral at the LatinX in AI workshop @ ICML 2023"}]},"2024-03-25T00:00:00Z":{"Multimedia":[{"id":"http://arxiv.org/abs/2403.17005v1","updated":"2024-03-25T17:59:40Z","published":"2024-03-25T17:59:40Z","title":"TRIP: Temporal Residual Learning with Image Noise Prior for\n  Image-to-Video Diffusion Models","summary":"  Recent advances in text-to-video generation have demonstrated the utility of\npowerful diffusion models. Nevertheless, the problem is not trivial when\nshaping diffusion models to animate static image (i.e., image-to-video\ngeneration). The difficulty originates from the aspect that the diffusion\nprocess of subsequent animated frames should not only preserve the faithful\nalignment with the given image but also pursue temporal coherence among\nadjacent frames. To alleviate this, we present TRIP, a new recipe of\nimage-to-video diffusion paradigm that pivots on image noise prior derived from\nstatic image to jointly trigger inter-frame relational reasoning and ease the\ncoherent temporal modeling via temporal residual learning. Technically, the\nimage noise prior is first attained through one-step backward diffusion process\nbased on both static image and noised video latent codes. Next, TRIP executes a\nresidual-like dual-path scheme for noise prediction: 1) a shortcut path that\ndirectly takes image noise prior as the reference noise of each frame to\namplify the alignment between the first frame and subsequent frames; 2) a\nresidual path that employs 3D-UNet over noised video and static image latent\ncodes to enable inter-frame relational reasoning, thereby easing the learning\nof the residual noise for each frame. Furthermore, both reference and residual\nnoise of each frame are dynamically merged via attention mechanism for final\nvideo generation. Extensive experiments on WebVid-10M, DTDB and MSR-VTT\ndatasets demonstrate the effectiveness of our TRIP for image-to-video\ngeneration. Please see our project page at https://trip-i2v.github.io/TRIP/.\n","authors":["Zhongwei Zhang","Fuchen Long","Yingwei Pan","Zhaofan Qiu","Ting Yao","Yang Cao","Tao Mei"],"pdf_url":"https://arxiv.org/pdf/2403.17005v1.pdf","comment":"CVPR 2024; Project page: https://trip-i2v.github.io/TRIP/"},{"id":"http://arxiv.org/abs/2403.17004v1","updated":"2024-03-25T17:59:35Z","published":"2024-03-25T17:59:35Z","title":"SD-DiT: Unleashing the Power of Self-supervised Discrimination in\n  Diffusion Transformer","summary":"  Diffusion Transformer (DiT) has emerged as the new trend of generative\ndiffusion models on image generation. In view of extremely slow convergence in\ntypical DiT, recent breakthroughs have been driven by mask strategy that\nsignificantly improves the training efficiency of DiT with additional\nintra-image contextual learning. Despite this progress, mask strategy still\nsuffers from two inherent limitations: (a) training-inference discrepancy and\n(b) fuzzy relations between mask reconstruction & generative diffusion process,\nresulting in sub-optimal training of DiT. In this work, we address these\nlimitations by novelly unleashing the self-supervised discrimination knowledge\nto boost DiT training. Technically, we frame our DiT in a teacher-student\nmanner. The teacher-student discriminative pairs are built on the diffusion\nnoises along the same Probability Flow Ordinary Differential Equation (PF-ODE).\nInstead of applying mask reconstruction loss over both DiT encoder and decoder,\nwe decouple DiT encoder and decoder to separately tackle discriminative and\ngenerative objectives. In particular, by encoding discriminative pairs with\nstudent and teacher DiT encoders, a new discriminative loss is designed to\nencourage the inter-image alignment in the self-supervised embedding space.\nAfter that, student samples are fed into student DiT decoder to perform the\ntypical generative diffusion task. Extensive experiments are conducted on\nImageNet dataset, and our method achieves a competitive balance between\ntraining cost and generative capacity.\n","authors":["Rui Zhu","Yingwei Pan","Yehao Li","Ting Yao","Zhenglong Sun","Tao Mei","Chang Wen Chen"],"pdf_url":"https://arxiv.org/pdf/2403.17004v1.pdf","comment":"CVPR 2024"},{"id":"http://arxiv.org/abs/2403.17001v1","updated":"2024-03-25T17:59:31Z","published":"2024-03-25T17:59:31Z","title":"VP3D: Unleashing 2D Visual Prompt for Text-to-3D Generation","summary":"  Recent innovations on text-to-3D generation have featured Score Distillation\nSampling (SDS), which enables the zero-shot learning of implicit 3D models\n(NeRF) by directly distilling prior knowledge from 2D diffusion models.\nHowever, current SDS-based models still struggle with intricate text prompts\nand commonly result in distorted 3D models with unrealistic textures or\ncross-view inconsistency issues. In this work, we introduce a novel Visual\nPrompt-guided text-to-3D diffusion model (VP3D) that explicitly unleashes the\nvisual appearance knowledge in 2D visual prompt to boost text-to-3D generation.\nInstead of solely supervising SDS with text prompt, VP3D first capitalizes on\n2D diffusion model to generate a high-quality image from input text, which\nsubsequently acts as visual prompt to strengthen SDS optimization with explicit\nvisual appearance. Meanwhile, we couple the SDS optimization with additional\ndifferentiable reward function that encourages rendering images of 3D models to\nbetter visually align with 2D visual prompt and semantically match with text\nprompt. Through extensive experiments, we show that the 2D Visual Prompt in our\nVP3D significantly eases the learning of visual appearance of 3D models and\nthus leads to higher visual fidelity with more detailed textures. It is also\nappealing in view that when replacing the self-generating visual prompt with a\ngiven reference image, VP3D is able to trigger a new task of stylized\ntext-to-3D generation. Our project page is available at\nhttps://vp3d-cvpr24.github.io.\n","authors":["Yang Chen","Yingwei Pan","Haibo Yang","Ting Yao","Tao Mei"],"pdf_url":"https://arxiv.org/pdf/2403.17001v1.pdf","comment":"CVPR 2024; Project page: https://vp3d-cvpr24.github.io"},{"id":"http://arxiv.org/abs/2403.17000v1","updated":"2024-03-25T17:59:26Z","published":"2024-03-25T17:59:26Z","title":"Learning Spatial Adaptation and Temporal Coherence in Diffusion Models\n  for Video Super-Resolution","summary":"  Diffusion models are just at a tipping point for image super-resolution task.\nNevertheless, it is not trivial to capitalize on diffusion models for video\nsuper-resolution which necessitates not only the preservation of visual\nappearance from low-resolution to high-resolution videos, but also the temporal\nconsistency across video frames. In this paper, we propose a novel approach,\npursuing Spatial Adaptation and Temporal Coherence (SATeCo), for video\nsuper-resolution. SATeCo pivots on learning spatial-temporal guidance from\nlow-resolution videos to calibrate both latent-space high-resolution video\ndenoising and pixel-space video reconstruction. Technically, SATeCo freezes all\nthe parameters of the pre-trained UNet and VAE, and only optimizes two\ndeliberately-designed spatial feature adaptation (SFA) and temporal feature\nalignment (TFA) modules, in the decoder of UNet and VAE. SFA modulates frame\nfeatures via adaptively estimating affine parameters for each pixel,\nguaranteeing pixel-wise guidance for high-resolution frame synthesis. TFA\ndelves into feature interaction within a 3D local window (tubelet) through\nself-attention, and executes cross-attention between tubelet and its\nlow-resolution counterpart to guide temporal feature alignment. Extensive\nexperiments conducted on the REDS4 and Vid4 datasets demonstrate the\neffectiveness of our approach.\n","authors":["Zhikai Chen","Fuchen Long","Zhaofan Qiu","Ting Yao","Wengang Zhou","Jiebo Luo","Tao Mei"],"pdf_url":"https://arxiv.org/pdf/2403.17000v1.pdf","comment":"CVPR 2024"},{"id":"http://arxiv.org/abs/2403.16985v1","updated":"2024-03-25T17:46:51Z","published":"2024-03-25T17:46:51Z","title":"Towards Low-Latency and Energy-Efficient Hybrid P2P-CDN Live Video\n  Streaming","summary":"  Streaming segmented videos over the Hypertext Transfer Protocol (HTTP) is an\nincreasingly popular approach in both live and video-on-demand (VoD)\napplications. However, designing a scalable and adaptable framework that\nreduces servers energy consumption and supports low latency and high quality\nservices, particularly for live video streaming scenarios, is still challenging\nfor Over-The-Top (OTT) service providers. To address such challenges, this\npaper introduces a new hybrid P2P-CDN framework that leverages new networking\nand computing paradigms, i.e., Network Function Virtualization (NFV) and edge\ncomputing for live video streaming. The proposed framework introduces a\nmulti-layer architecture and a tree of possible actions therein (an action\ntree), taking into account all available resources from peers, edge, and CDN\nservers to efficiently distribute video fetching and transcoding tasks across a\nhybrid P2P-CDN network, consequently enhancing the users latency and video\nquality. We also discuss our testbed designed to validate the framework and\ncompare it with baseline methods. The experimental results indicate that the\nproposed framework improves user Quality of Experience (QoE), reduces client\nserving latency, and improves edge server energy consumption compared to\nbaseline approaches.\n","authors":["Reza Farahani","Christian Timmerer","Hermann Hellwagner"],"pdf_url":"https://arxiv.org/pdf/2403.16985v1.pdf","comment":"6 pages, 3 figures, Special Issue on Sustainable Multimedia\n  Communications and Services, IEEE MMTC Communications"},{"id":"http://arxiv.org/abs/2403.16951v1","updated":"2024-03-25T17:12:43Z","published":"2024-03-25T17:12:43Z","title":"Network-Assisted Delivery of Adaptive Video Streaming Services through\n  CDN, SDN, and MEC","summary":"  Multimedia applications, mainly video streaming services, are currently the\ndominant source of network load worldwide. In recent Video-on-Demand (VoD) and\nlive video streaming services, traditional streaming delivery techniques have\nbeen replaced by adaptive solutions based on the HTTP protocol. Current trends\ntoward high-resolution (e.g., 8K) and/or low-latency VoD and live video\nstreaming pose new challenges to end-to-end (E2E) bandwidth demand and have\nstringent delay requirements. To do this, video providers typically rely on\nContent Delivery Networks (CDNs) to ensure that they provide scalable video\nstreaming services. To support future streaming scenarios involving millions of\nusers, it is necessary to increase the CDNs' efficiency. It is widely agreed\nthat these requirements may be satisfied by adopting emerging networking\ntechniques to present Network-Assisted Video Streaming (NAVS) methods.\nMotivated by this, this thesis goes one step beyond traditional pure\nclient-based HAS algorithms by incorporating (an) in-network component(s) with\na broader view of the network to present completely transparent NAVS solutions\nfor HAS clients.\n","authors":["Reza Farahani"],"pdf_url":"https://arxiv.org/pdf/2403.16951v1.pdf","comment":"PhD thesis defended in 22.08.2023\n  (https://netlibrary.aau.at/obvuklhs/content/titleinfo/9173622)"},{"id":"http://arxiv.org/abs/2304.02970v5","updated":"2024-03-25T08:50:42Z","published":"2023-04-06T09:54:06Z","title":"Unraveling Instance Associations: A Closer Look for Audio-Visual\n  Segmentation","summary":"  Audio-visual segmentation (AVS) is a challenging task that involves\naccurately segmenting sounding objects based on audio-visual cues. The\neffectiveness of audio-visual learning critically depends on achieving accurate\ncross-modal alignment between sound and visual objects. Successful audio-visual\nlearning requires two essential components: 1) a challenging dataset with\nhigh-quality pixel-level multi-class annotated images associated with audio\nfiles, and 2) a model that can establish strong links between audio information\nand its corresponding visual object. However, these requirements are only\npartially addressed by current methods, with training sets containing biased\naudio-visual data, and models that generalise poorly beyond this biased\ntraining set. In this work, we propose a new cost-effective strategy to build\nchallenging and relatively unbiased high-quality audio-visual segmentation\nbenchmarks. We also propose a new informative sample mining method for\naudio-visual supervised contrastive learning to leverage discriminative\ncontrastive samples to enforce cross-modal understanding. We show empirical\nresults that demonstrate the effectiveness of our benchmark. Furthermore,\nexperiments conducted on existing AVS datasets and on our new benchmark show\nthat our method achieves state-of-the-art (SOTA) segmentation accuracy.\n","authors":["Yuanhong Chen","Yuyuan Liu","Hu Wang","Fengbei Liu","Chong Wang","Helen Frazer","Gustavo Carneiro"],"pdf_url":"https://arxiv.org/pdf/2304.02970v5.pdf","comment":"Code is available at https://github.com/cyh-0/CAVP"},{"id":"http://arxiv.org/abs/2402.18107v2","updated":"2024-03-25T05:28:20Z","published":"2024-02-28T06:54:35Z","title":"Multimodal Interaction Modeling via Self-Supervised Multi-Task Learning\n  for Review Helpfulness Prediction","summary":"  In line with the latest research, the task of identifying helpful reviews\nfrom a vast pool of user-generated textual and visual data has become a\nprominent area of study. Effective modal representations are expected to\npossess two key attributes: consistency and differentiation. Current methods\ndesigned for Multimodal Review Helpfulness Prediction (MRHP) face limitations\nin capturing distinctive information due to their reliance on uniform\nmultimodal annotation. The process of adding varied multimodal annotations is\nnot only time-consuming but also labor-intensive. To tackle these challenges,\nwe propose an auto-generated scheme based on multi-task learning to generate\npseudo labels. This approach allows us to simultaneously train for the global\nmultimodal interaction task and the separate cross-modal interaction subtasks,\nenabling us to learn and leverage both consistency and differentiation\neffectively. Subsequently, experimental results validate the effectiveness of\npseudo labels, and our approach surpasses previous textual and multimodal\nbaseline models on two widely accessible benchmark datasets, providing a\nsolution to the MRHP problem.\n","authors":["HongLin Gong","Mengzhao Jia","Liqiang Jing"],"pdf_url":"https://arxiv.org/pdf/2402.18107v2.pdf","comment":"10 pages,4 figures, 4 tables"},{"id":"http://arxiv.org/abs/2403.15048v2","updated":"2024-03-25T02:08:01Z","published":"2024-03-22T09:13:09Z","title":"Cartoon Hallucinations Detection: Pose-aware In Context Visual Learning","summary":"  Large-scale Text-to-Image (TTI) models have become a common approach for\ngenerating training data in various generative fields. However, visual\nhallucinations, which contain perceptually critical defects, remain a concern,\nespecially in non-photorealistic styles like cartoon characters. We propose a\nnovel visual hallucination detection system for cartoon character images\ngenerated by TTI models. Our approach leverages pose-aware in-context visual\nlearning (PA-ICVL) with Vision-Language Models (VLMs), utilizing both RGB\nimages and pose information. By incorporating pose guidance from a fine-tuned\npose estimator, we enable VLMs to make more accurate decisions. Experimental\nresults demonstrate significant improvements in identifying visual\nhallucinations compared to baseline methods relying solely on RGB images. This\nresearch advances TTI models by mitigating visual hallucinations, expanding\ntheir potential in non-photorealistic domains.\n","authors":["Bumsoo Kim","Wonseop Shin","Kyuchul Lee","Sanghyun Seo"],"pdf_url":"https://arxiv.org/pdf/2403.15048v2.pdf","comment":"11 pages, 12 figures, 1 table, Project page:\n  https://gh-bumsookim.github.io/Cartoon-Hallucinations-Detection/"},{"id":"http://arxiv.org/abs/2308.09911v2","updated":"2024-03-25T01:54:41Z","published":"2023-08-19T05:34:13Z","title":"Noisy-Correspondence Learning for Text-to-Image Person Re-identification","summary":"  Text-to-image person re-identification (TIReID) is a compelling topic in the\ncross-modal community, which aims to retrieve the target person based on a\ntextual query. Although numerous TIReID methods have been proposed and achieved\npromising performance, they implicitly assume the training image-text pairs are\ncorrectly aligned, which is not always the case in real-world scenarios. In\npractice, the image-text pairs inevitably exist under-correlated or even\nfalse-correlated, a.k.a noisy correspondence (NC), due to the low quality of\nthe images and annotation errors. To address this problem, we propose a novel\nRobust Dual Embedding method (RDE) that can learn robust visual-semantic\nassociations even with NC. Specifically, RDE consists of two main components:\n1) A Confident Consensus Division (CCD) module that leverages the dual-grained\ndecisions of dual embedding modules to obtain a consensus set of clean training\ndata, which enables the model to learn correct and reliable visual-semantic\nassociations. 2) A Triplet Alignment Loss (TAL) relaxes the conventional\nTriplet Ranking loss with the hardest negative samples to a log-exponential\nupper bound over all negative ones, thus preventing the model collapse under NC\nand can also focus on hard-negative samples for promising performance. We\nconduct extensive experiments on three public benchmarks, namely CUHK-PEDES,\nICFG-PEDES, and RSTPReID, to evaluate the performance and robustness of our\nRDE. Our method achieves state-of-the-art results both with and without\nsynthetic noisy correspondences on all three datasets. Code is available at\nhttps://github.com/QinYang79/RDE.\n","authors":["Yang Qin","Yingke Chen","Dezhong Peng","Xi Peng","Joey Tianyi Zhou","Peng Hu"],"pdf_url":"https://arxiv.org/pdf/2308.09911v2.pdf","comment":null}],"Machine Learning 2":[{"id":"http://arxiv.org/abs/2311.15404v2","updated":"2024-03-25T22:55:43Z","published":"2023-11-26T20:00:53Z","title":"Applying statistical learning theory to deep learning","summary":"  Although statistical learning theory provides a robust framework to\nunderstand supervised learning, many theoretical aspects of deep learning\nremain unclear, in particular how different architectures may lead to inductive\nbias when trained using gradient based methods. The goal of these lectures is\nto provide an overview of some of the main questions that arise when attempting\nto understand deep learning from a learning theory perspective. After a brief\nreminder on statistical learning theory and stochastic optimization, we discuss\nimplicit bias in the context of benign overfitting. We then move to a general\ndescription of the mirror descent algorithm, showing how we may go back and\nforth between a parameter space and the corresponding function space for a\ngiven learning problem, as well as how the geometry of the learning problem may\nbe represented by a metric tensor. Building on this framework, we provide a\ndetailed study of the implicit bias of gradient descent on linear diagonal\nnetworks for various regression tasks, showing how the loss function, scale of\nparameters at initialization and depth of the network may lead to various forms\nof implicit bias, in particular transitioning between kernel or feature\nlearning.\n","authors":["C√©dric Gerbelot","Avetik Karagulyan","Stefani Karp","Kavya Ravichandran","Menachem Stern","Nathan Srebro"],"pdf_url":"https://arxiv.org/pdf/2311.15404v2.pdf","comment":"66 pages, 20 figures"},{"id":"http://arxiv.org/abs/2403.17247v1","updated":"2024-03-25T22:49:56Z","published":"2024-03-25T22:49:56Z","title":"DASA: Delay-Adaptive Multi-Agent Stochastic Approximation","summary":"  We consider a setting in which $N$ agents aim to speedup a common Stochastic\nApproximation (SA) problem by acting in parallel and communicating with a\ncentral server. We assume that the up-link transmissions to the server are\nsubject to asynchronous and potentially unbounded time-varying delays. To\nmitigate the effect of delays and stragglers while reaping the benefits of\ndistributed computation, we propose \\texttt{DASA}, a Delay-Adaptive algorithm\nfor multi-agent Stochastic Approximation. We provide a finite-time analysis of\n\\texttt{DASA} assuming that the agents' stochastic observation processes are\nindependent Markov chains. Significantly advancing existing results,\n\\texttt{DASA} is the first algorithm whose convergence rate depends only on the\nmixing time $\\tmix$ and on the average delay $\\tau_{avg}$ while jointly\nachieving an $N$-fold convergence speedup under Markovian sampling. Our work is\nrelevant for various SA applications, including multi-agent and distributed\ntemporal difference (TD) learning, Q-learning and stochastic optimization with\ncorrelated data.\n","authors":["Nicolo Dal Fabbro","Arman Adibi","H. Vincent Poor","Sanjeev R. Kulkarni","Aritra Mitra","George J. Pappas"],"pdf_url":"https://arxiv.org/pdf/2403.17247v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.17091v1","updated":"2024-03-25T18:28:45Z","published":"2024-03-25T18:28:45Z","title":"Offline Reinforcement Learning: Role of State Aggregation and Trajectory\n  Data","summary":"  We revisit the problem of offline reinforcement learning with value function\nrealizability but without Bellman completeness. Previous work by Xie and Jiang\n(2021) and Foster et al. (2022) left open the question whether a bounded\nconcentrability coefficient along with trajectory-based offline data admits a\npolynomial sample complexity. In this work, we provide a negative answer to\nthis question for the task of offline policy evaluation. In addition to\naddressing this question, we provide a rather complete picture for offline\npolicy evaluation with only value function realizability. Our primary findings\nare threefold: 1) The sample complexity of offline policy evaluation is\ngoverned by the concentrability coefficient in an aggregated Markov Transition\nModel jointly determined by the function class and the offline data\ndistribution, rather than that in the original MDP. This unifies and\ngeneralizes the ideas of Xie and Jiang (2021) and Foster et al. (2022), 2) The\nconcentrability coefficient in the aggregated Markov Transition Model may grow\nexponentially with the horizon length, even when the concentrability\ncoefficient in the original MDP is small and the offline data is admissible\n(i.e., the data distribution equals the occupancy measure of some policy), 3)\nUnder value function realizability, there is a generic reduction that can\nconvert any hard instance with admissible data to a hard instance with\ntrajectory data, implying that trajectory data offers no extra benefits over\nadmissible data. These three pieces jointly resolve the open problem, though\neach of them could be of independent interest.\n","authors":["Zeyu Jia","Alexander Rakhlin","Ayush Sekhari","Chen-Yu Wei"],"pdf_url":"https://arxiv.org/pdf/2403.17091v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.03157v2","updated":"2024-03-25T18:14:54Z","published":"2023-02-06T23:34:51Z","title":"A distribution-free mixed-integer optimization approach to hierarchical\n  modelling of clustered and longitudinal data","summary":"  Recent advancements in Mixed Integer Optimization (MIO) algorithms, paired\nwith hardware enhancements, have led to significant speedups in resolving MIO\nproblems. These strategies have been utilized for optimal subset selection,\nspecifically for choosing $k$ features out of $p$ in linear regression given\n$n$ observations. In this paper, we broaden this method to facilitate\ncluster-aware regression, where selection aims to choose $\\lambda$ out of $K$\nclusters in a linear mixed effects (LMM) model with $n_k$ observations for each\ncluster. Through comprehensive testing on a multitude of synthetic and real\ndatasets, we exhibit that our method efficiently solves problems within\nminutes. Through numerical experiments, we also show that the MIO approach\noutperforms both Gaussian- and Laplace-distributed LMMs in terms of generating\nsparse solutions with high predictive power. Traditional LMMs typically assume\nthat clustering effects are independent of individual features. However, we\nintroduce an innovative algorithm that evaluates cluster effects for new data\npoints, thereby increasing the robustness and precision of this model. The\ninferential and predictive efficacy of this approach is further illustrated\nthrough its application in student scoring and protein expression.\n","authors":["Madhav Sankaranarayanan","Intekhab Hossain","Tom Chen"],"pdf_url":"https://arxiv.org/pdf/2302.03157v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2310.05401v5","updated":"2024-03-25T18:07:22Z","published":"2023-10-09T04:40:20Z","title":"Entropy-MCMC: Sampling from Flat Basins with Ease","summary":"  Bayesian deep learning counts on the quality of posterior distribution\nestimation. However, the posterior of deep neural networks is highly\nmulti-modal in nature, with local modes exhibiting varying generalization\nperformance. Given a practical budget, targeting at the original posterior can\nlead to suboptimal performance, as some samples may become trapped in \"bad\"\nmodes and suffer from overfitting. Leveraging the observation that \"good\" modes\nwith low generalization error often reside in flat basins of the energy\nlandscape, we propose to bias sampling on the posterior toward these flat\nregions. Specifically, we introduce an auxiliary guiding variable, the\nstationary distribution of which resembles a smoothed posterior free from sharp\nmodes, to lead the MCMC sampler to flat basins. By integrating this guiding\nvariable with the model parameter, we create a simple joint distribution that\nenables efficient sampling with minimal computational overhead. We prove the\nconvergence of our method and further show that it converges faster than\nseveral existing flatness-aware methods in the strongly convex setting.\nEmpirical results demonstrate that our method can successfully sample from flat\nbasins of the posterior, and outperforms all compared baselines on multiple\nbenchmarks including classification, calibration, and out-of-distribution\ndetection.\n","authors":["Bolian Li","Ruqi Zhang"],"pdf_url":"https://arxiv.org/pdf/2310.05401v5.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.16995v1","updated":"2024-03-25T17:58:22Z","published":"2024-03-25T17:58:22Z","title":"Language Rectified Flow: Advancing Diffusion Language Generation with\n  Probabilistic Flows","summary":"  Recent works have demonstrated success in controlling sentence attributes\n($e.g.$, sentiment) and structure ($e.g.$, syntactic structure) based on the\ndiffusion language model. A key component that drives theimpressive performance\nfor generating high-quality samples from noise is iteratively denoise for\nthousands of steps. While beneficial, the complexity of starting from the noise\nand the learning steps has limited its implementation to many NLP real-world\napplications. This paper proposes Language Rectified Flow ({\\ours}). Our method\nis based on the reformulation of the standard probabilistic flow models.\nLanguage rectified flow learns (neural) ordinary differential equation models\nto transport between the source distribution and the target distribution, hence\nproviding a unified and effective solution to generative modeling and domain\ntransfer. From the source distribution, our language rectified flow yields fast\nsimulation and effectively decreases the inference time. Experiments on three\nchallenging fine-grained control tasks and multiple high-quality text editing\nshow that our method consistently outperforms its baselines. Extensive\nexperiments and ablation studies demonstrate that our method can be general,\neffective, and beneficial for many NLP tasks.\n","authors":["Shujian Zhang","Lemeng Wu","Chengyue Gong","Xingchao Liu"],"pdf_url":"https://arxiv.org/pdf/2403.16995v1.pdf","comment":"Accepted to NAACL 2024"},{"id":"http://arxiv.org/abs/2403.16981v1","updated":"2024-03-25T17:42:32Z","published":"2024-03-25T17:42:32Z","title":"The Sample Complexity of Simple Binary Hypothesis Testing","summary":"  The sample complexity of simple binary hypothesis testing is the smallest\nnumber of i.i.d. samples required to distinguish between two distributions $p$\nand $q$ in either: (i) the prior-free setting, with type-I error at most\n$\\alpha$ and type-II error at most $\\beta$; or (ii) the Bayesian setting, with\nBayes error at most $\\delta$ and prior distribution $(\\alpha, 1-\\alpha)$. This\nproblem has only been studied when $\\alpha = \\beta$ (prior-free) or $\\alpha =\n1/2$ (Bayesian), and the sample complexity is known to be characterized by the\nHellinger divergence between $p$ and $q$, up to multiplicative constants. In\nthis paper, we derive a formula that characterizes the sample complexity (up to\nmultiplicative constants that are independent of $p$, $q$, and all error\nparameters) for: (i) all $0 \\le \\alpha, \\beta \\le 1/8$ in the prior-free\nsetting; and (ii) all $\\delta \\le \\alpha/4$ in the Bayesian setting. In\nparticular, the formula admits equivalent expressions in terms of certain\ndivergences from the Jensen--Shannon and Hellinger families. The main technical\nresult concerns an $f$-divergence inequality between members of the\nJensen--Shannon and Hellinger families, which is proved by a combination of\ninformation-theoretic tools and case-by-case analyses. We explore applications\nof our results to robust and distributed (locally-private and\ncommunication-constrained) hypothesis testing.\n","authors":["Ankit Pensia","Varun Jog","Po-Ling Loh"],"pdf_url":"https://arxiv.org/pdf/2403.16981v1.pdf","comment":"Comments welcome"},{"id":"http://arxiv.org/abs/2403.16916v1","updated":"2024-03-25T16:36:13Z","published":"2024-03-25T16:36:13Z","title":"SCOD: From Heuristics to Theory","summary":"  This paper addresses the problem of designing reliable prediction models that\nabstain from predictions when faced with uncertain or out-of-distribution\nsamples - a recently proposed problem known as Selective Classification in the\npresence of Out-of-Distribution data (SCOD). We make three key contributions to\nSCOD. Firstly, we demonstrate that the optimal SCOD strategy involves a Bayes\nclassifier for in-distribution (ID) data and a selector represented as a\nstochastic linear classifier in a 2D space, using i) the conditional risk of\nthe ID classifier, and ii) the likelihood ratio of ID and out-of-distribution\n(OOD) data as input. This contrasts with suboptimal strategies from current OOD\ndetection methods and the Softmax Information Retaining Combination (SIRC),\nspecifically developed for SCOD. Secondly, we establish that in a\ndistribution-free setting, the SCOD problem is not Probably Approximately\nCorrect learnable when relying solely on an ID data sample. Third, we introduce\nPOSCOD, a simple method for learning a plugin estimate of the optimal SCOD\nstrategy from both an ID data sample and an unlabeled mixture of ID and OOD\ndata. Our empirical results confirm the theoretical findings and demonstrate\nthat our proposed method, POSCOD, out performs existing OOD methods in\neffectively addressing the SCOD problem.\n","authors":["Vojtech Franc","Jakub Paplham","Daniel Prusa"],"pdf_url":"https://arxiv.org/pdf/2403.16916v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.09962v3","updated":"2024-03-25T16:07:31Z","published":"2022-12-20T02:30:13Z","title":"Distributional Robustness Bounds Generalization Errors","summary":"  Bayesian methods, distributionally robust optimization methods, and\nregularization methods are three pillars of trustworthy machine learning\ncombating distributional uncertainty, e.g., the uncertainty of an empirical\ndistribution compared to the true underlying distribution. This paper\ninvestigates the connections among the three frameworks and, in particular,\nexplores why these frameworks tend to have smaller generalization errors.\nSpecifically, first, we suggest a quantitative definition for \"distributional\nrobustness\", propose the concept of \"robustness measure\", and formalize several\nphilosophical concepts in distributionally robust optimization. Second, we show\nthat Bayesian methods are distributionally robust in the probably approximately\ncorrect (PAC) sense; in addition, by constructing a Dirichlet-process-like\nprior in Bayesian nonparametrics, it can be proven that any regularized\nempirical risk minimization method is equivalent to a Bayesian method. Third,\nwe show that generalization errors of machine learning models can be\ncharacterized using the distributional uncertainty of the nominal distribution\nand the robustness measures of these machine learning models, which is a new\nperspective to bound generalization errors, and therefore, explain the reason\nwhy distributionally robust machine learning models, Bayesian models, and\nregularization models tend to have smaller generalization errors in a unified\nmanner.\n","authors":["Shixiong Wang","Haowei Wang"],"pdf_url":"https://arxiv.org/pdf/2212.09962v3.pdf","comment":"Updated Version"},{"id":"http://arxiv.org/abs/2311.10610v2","updated":"2024-03-25T16:05:04Z","published":"2023-11-17T16:04:31Z","title":"A Poincar√© Inequality and Consistency Results for Signal Sampling on\n  Large Graphs","summary":"  Large-scale graph machine learning is challenging as the complexity of\nlearning models scales with the graph size. Subsampling the graph is a viable\nalternative, but sampling on graphs is nontrivial as graphs are non-Euclidean.\nExisting graph sampling techniques require not only computing the spectra of\nlarge matrices but also repeating these computations when the graph changes,\ne.g., grows. In this paper, we introduce a signal sampling theory for a type of\ngraph limit -- the graphon. We prove a Poincar\\'e inequality for graphon\nsignals and show that complements of node subsets satisfying this inequality\nare unique sampling sets for Paley-Wiener spaces of graphon signals. Exploiting\nconnections with spectral clustering and Gaussian elimination, we prove that\nsuch sampling sets are consistent in the sense that unique sampling sets on a\nconvergent graph sequence converge to unique sampling sets on the graphon. We\nthen propose a related graphon signal sampling algorithm for large graphs, and\ndemonstrate its good empirical performance on graph machine learning tasks.\n","authors":["Thien Le","Luana Ruiz","Stefanie Jegelka"],"pdf_url":"https://arxiv.org/pdf/2311.10610v2.pdf","comment":"23 pages"},{"id":"http://arxiv.org/abs/2403.17042v1","updated":"2024-03-25T15:58:26Z","published":"2024-03-25T15:58:26Z","title":"Provably Robust Score-Based Diffusion Posterior Sampling for\n  Plug-and-Play Image Reconstruction","summary":"  In a great number of tasks in science and engineering, the goal is to infer\nan unknown image from a small number of measurements collected from a known\nforward model describing certain sensing or imaging modality. Due to resource\nconstraints, this task is often extremely ill-posed, which necessitates the\nadoption of expressive prior information to regularize the solution space.\nScore-based diffusion models, due to its impressive empirical success, have\nemerged as an appealing candidate of an expressive prior in image\nreconstruction. In order to accommodate diverse tasks at once, it is of great\ninterest to develop efficient, consistent and robust algorithms that\nincorporate {\\em unconditional} score functions of an image prior distribution\nin conjunction with flexible choices of forward models.\n  This work develops an algorithmic framework for employing score-based\ndiffusion models as an expressive data prior in general nonlinear inverse\nproblems. Motivated by the plug-and-play framework in the imaging community, we\nintroduce a diffusion plug-and-play method (\\textsf{DPnP}) that alternatively\ncalls two samplers, a proximal consistency sampler based solely on the\nlikelihood function of the forward model, and a denoising diffusion sampler\nbased solely on the score functions of the image prior. The key insight is that\ndenoising under white Gaussian noise can be solved {\\em rigorously} via both\nstochastic (i.e., DDPM-type) and deterministic (i.e., DDIM-type) samplers using\nthe unconditional score functions. We establish both asymptotic and\nnon-asymptotic performance guarantees of \\textsf{DPnP}, and provide numerical\nexperiments to illustrate its promise in solving both linear and nonlinear\nimage reconstruction tasks. To the best of our knowledge, \\textsf{DPnP} is the\nfirst provably-robust posterior sampling method for nonlinear inverse problems\nusing unconditional diffusion priors.\n","authors":["Xingyu Xu","Yuejie Chi"],"pdf_url":"https://arxiv.org/pdf/2403.17042v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2310.01327v2","updated":"2024-03-25T15:55:22Z","published":"2023-10-02T16:45:19Z","title":"TACTiS-2: Better, Faster, Simpler Attentional Copulas for Multivariate\n  Time Series","summary":"  We introduce a new model for multivariate probabilistic time series\nprediction, designed to flexibly address a range of tasks including\nforecasting, interpolation, and their combinations. Building on copula theory,\nwe propose a simplified objective for the recently-introduced transformer-based\nattentional copulas (TACTiS), wherein the number of distributional parameters\nnow scales linearly with the number of variables instead of factorially. The\nnew objective requires the introduction of a training curriculum, which goes\nhand-in-hand with necessary changes to the original architecture. We show that\nthe resulting model has significantly better training dynamics and achieves\nstate-of-the-art performance across diverse real-world forecasting tasks, while\nmaintaining the flexibility of prior work, such as seamless handling of\nunaligned and unevenly-sampled time series. Code is made available at\nhttps://github.com/ServiceNow/TACTiS.\n","authors":["Arjun Ashok","√âtienne Marcotte","Valentina Zantedeschi","Nicolas Chapados","Alexandre Drouin"],"pdf_url":"https://arxiv.org/pdf/2310.01327v2.pdf","comment":"28 pages, 15 figures, The Twelfth International Conference on\n  Learning Representations (ICLR 2024)"},{"id":"http://arxiv.org/abs/2403.16883v1","updated":"2024-03-25T15:53:32Z","published":"2024-03-25T15:53:32Z","title":"Discrete Latent Graph Generative Modeling with Diffusion Bridges","summary":"  Learning graph generative models over latent spaces has received less\nattention compared to models that operate on the original data space and has so\nfar demonstrated lacklustre performance. We present GLAD a latent space graph\ngenerative model. Unlike most previous latent space graph generative models,\nGLAD operates on a discrete latent space that preserves to a significant extent\nthe discrete nature of the graph structures making no unnatural assumptions\nsuch as latent space continuity. We learn the prior of our discrete latent\nspace by adapting diffusion bridges to its structure. By operating over an\nappropriately constructed latent space we avoid relying on decompositions that\nare often used in models that operate in the original data space. We present\nexperiments on a series of graph benchmark datasets which clearly show the\nsuperiority of the discrete latent space and obtain state of the art graph\ngenerative performance, making GLAD the first latent space graph generative\nmodel with competitive performance. Our source code is published at:\n\\url{https://github.com/v18nguye/GLAD}.\n","authors":["Van Khoa Nguyen","Yoann Boget","Frantzeska Lavda","Alexandros Kalousis"],"pdf_url":"https://arxiv.org/pdf/2403.16883v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.16871v1","updated":"2024-03-25T15:37:43Z","published":"2024-03-25T15:37:43Z","title":"Conformal Off-Policy Prediction for Multi-Agent Systems","summary":"  Off-Policy Prediction (OPP), i.e., predicting the outcomes of a target policy\nusing only data collected under a nominal (behavioural) policy, is a paramount\nproblem in data-driven analysis of safety-critical systems where the deployment\nof a new policy may be unsafe. To achieve dependable off-policy predictions,\nrecent work on Conformal Off-Policy Prediction (COPP) leverage the conformal\nprediction framework to derive prediction regions with probabilistic guarantees\nunder the target process. Existing COPP methods can account for the\ndistribution shifts induced by policy switching, but are limited to\nsingle-agent systems and scalar outcomes (e.g., rewards). In this work, we\nintroduce MA-COPP, the first conformal prediction method to solve OPP problems\ninvolving multi-agent systems, deriving joint prediction regions for all\nagents' trajectories when one or more \"ego\" agents change their policies.\nUnlike the single-agent scenario, this setting introduces higher complexity as\nthe distribution shifts affect predictions for all agents, not just the ego\nagents, and the prediction task involves full multi-dimensional trajectories,\nnot just reward values. A key contribution of MA-COPP is to avoid enumeration\nor exhaustive search of the output space of agent trajectories, which is\ninstead required by existing COPP methods to construct the prediction region.\nWe achieve this by showing that an over-approximation of the true JPR can be\nconstructed, without enumeration, from the maximum density ratio of the JPR\ntrajectories. We evaluate the effectiveness of MA-COPP in multi-agent systems\nfrom the PettingZoo library and the F1TENTH autonomous racing environment,\nachieving nominal coverage in higher dimensions and various shift settings.\n","authors":["Tom Kuipers","Renukanandan Tumu","Shuo Yang","Milad Kazemi","Rahul Mangharam","Nicola Paoletti"],"pdf_url":"https://arxiv.org/pdf/2403.16871v1.pdf","comment":"Submitted to the 63rd IEEE Conference on Decision and Control (CDC)"},{"id":"http://arxiv.org/abs/2403.16825v1","updated":"2024-03-25T14:49:01Z","published":"2024-03-25T14:49:01Z","title":"Weak Convergence Analysis of Online Neural Actor-Critic Algorithms","summary":"  We prove that a single-layer neural network trained with the online actor\ncritic algorithm converges in distribution to a random ordinary differential\nequation (ODE) as the number of hidden units and the number of training steps\n$\\rightarrow \\infty$. In the online actor-critic algorithm, the distribution of\nthe data samples dynamically changes as the model is updated, which is a key\nchallenge for any convergence analysis. We establish the geometric ergodicity\nof the data samples under a fixed actor policy. Then, using a Poisson equation,\nwe prove that the fluctuations of the model updates around the limit\ndistribution due to the randomly-arriving data samples vanish as the number of\nparameter updates $\\rightarrow \\infty$. Using the Poisson equation and weak\nconvergence techniques, we prove that the actor neural network and critic\nneural network converge to the solutions of a system of ODEs with random\ninitial conditions. Analysis of the limit ODE shows that the limit critic\nnetwork will converge to the true value function, which will provide the actor\nan asymptotically unbiased estimate of the policy gradient. We then prove that\nthe limit actor network will converge to a stationary point.\n","authors":["Samuel Chun-Hei Lam","Justin Sirignano","Ziheng Wang"],"pdf_url":"https://arxiv.org/pdf/2403.16825v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.08347v3","updated":"2024-03-25T13:18:39Z","published":"2023-02-16T15:05:37Z","title":"The autoregressive neural network architecture of the Boltzmann\n  distribution of pairwise interacting spins systems","summary":"  Generative Autoregressive Neural Networks (ARNNs) have recently demonstrated\nexceptional results in image and language generation tasks, contributing to the\ngrowing popularity of generative models in both scientific and commercial\napplications. This work presents an exact mapping of the Boltzmann distribution\nof binary pairwise interacting systems into autoregressive form. The resulting\nARNN architecture has weights and biases of its first layer corresponding to\nthe Hamiltonian's couplings and external fields, featuring widely used\nstructures such as the residual connections and a recurrent architecture with\nclear physical meanings. Moreover, its architecture's explicit formulation\nenables the use of statistical physics techniques to derive new ARNNs for\nspecific systems. As examples, new effective ARNN architectures are derived\nfrom two well-known mean-field systems, the Curie-Weiss and\nSherrington-Kirkpatrick models, showing superior performance in approximating\nthe Boltzmann distributions of the corresponding physics model compared to\nother commonly used architectures. The connection established between the\nphysics of the system and the neural network architecture provides a means to\nderive new architectures for different interacting systems and interpret\nexisting ones from a physical perspective.\n","authors":["Indaco Biazzo"],"pdf_url":"https://arxiv.org/pdf/2302.08347v3.pdf","comment":"20 pages, 10 figure plus the Supplementary Information"},{"id":"http://arxiv.org/abs/2306.10180v3","updated":"2024-03-25T13:02:27Z","published":"2023-06-16T21:20:49Z","title":"Samplet basis pursuit: Multiresolution scattered data approximation with\n  sparsity constraints","summary":"  We consider scattered data approximation in samplet coordinates with\n$\\ell_1$-regularization. The application of an $\\ell_1$-regularization term\nenforces sparsity of the coefficients with respect to the samplet basis.\nSamplets are wavelet-type signed measures, which are tailored to scattered\ndata. They provide similar properties as wavelets in terms of localization,\nmultiresolution analysis, and data compression. By using the Riesz isometry, we\nembed samplets into reproducing kernel Hilbert spaces and discuss the\nproperties of the resulting functions. We argue that the class of signals that\nare sparse with respect to the embedded samplet basis is considerably larger\nthan the class of signals that are sparse with respect to the basis of kernel\ntranslates. Vice versa, every signal that is a linear combination of only a few\nkernel translates is sparse in samplet coordinates. Therefore, samplets enable\nthe use of well-established multiresolution techniques on general scattered\ndata sets.\n  We propose the rapid solution of the problem under consideration by combining\nsoft-shrinkage with the semi-smooth Newton method. Leveraging on the sparse\nrepresentation of kernel matrices in samplet coordinates, this approach\nconverges faster than the fast iterative shrinkage thresholding algorithm and\nis feasible for large-scale data. Numerical benchmarks are presented and\ndemonstrate the superiority of the multiresolution approach over the\nsingle-scale approach. As large-scale applications, the surface reconstruction\nfrom scattered data and the reconstruction of scattered temperature data using\na dictionary of multiple kernels are considered.\n","authors":["Davide Baroli","Helmut Harbrecht","Michael Multerer"],"pdf_url":"https://arxiv.org/pdf/2306.10180v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.16688v1","updated":"2024-03-25T12:23:19Z","published":"2024-03-25T12:23:19Z","title":"Optimal convex $M$-estimation via score matching","summary":"  In the context of linear regression, we construct a data-driven convex loss\nfunction with respect to which empirical risk minimisation yields optimal\nasymptotic variance in the downstream estimation of the regression\ncoefficients. Our semiparametric approach targets the best decreasing\napproximation of the derivative of the log-density of the noise distribution.\nAt the population level, this fitting process is a nonparametric extension of\nscore matching, corresponding to a log-concave projection of the noise\ndistribution with respect to the Fisher divergence. The procedure is\ncomputationally efficient, and we prove that our procedure attains the minimal\nasymptotic covariance among all convex $M$-estimators. As an example of a\nnon-log-concave setting, for Cauchy errors, the optimal convex loss function is\nHuber-like, and our procedure yields an asymptotic efficiency greater than 0.87\nrelative to the oracle maximum likelihood estimator of the regression\ncoefficients that uses knowledge of this error distribution; in this sense, we\nobtain robustness without sacrificing much efficiency. Numerical experiments\nconfirm the practical merits of our proposal.\n","authors":["Oliver Y. Feng","Yu-Chun Kao","Min Xu","Richard J. Samworth"],"pdf_url":"https://arxiv.org/pdf/2403.16688v1.pdf","comment":"69 pages, 12 figures and 4 tables"},{"id":"http://arxiv.org/abs/2403.16681v1","updated":"2024-03-25T12:15:55Z","published":"2024-03-25T12:15:55Z","title":"A note on generalization bounds for losses with finite moments","summary":"  This paper studies the truncation method from Alquier [1] to derive\nhigh-probability PAC-Bayes bounds for unbounded losses with heavy tails.\nAssuming that the $p$-th moment is bounded, the resulting bounds interpolate\nbetween a slow rate $1 / \\sqrt{n}$ when $p=2$, and a fast rate $1 / n$ when $p\n\\to \\infty$ and the loss is essentially bounded. Moreover, the paper derives a\nhigh-probability PAC-Bayes bound for losses with a bounded variance. This bound\nhas an exponentially better dependence on the confidence parameter and the\ndependency measure than previous bounds in the literature. Finally, the paper\nextends all results to guarantees in expectation and single-draw PAC-Bayes. In\norder to so, it obtains analogues of the PAC-Bayes fast rate bound for bounded\nlosses from [2] in these settings.\n","authors":["Borja Rodr√≠guez-G√°lvez","Omar Rivasplata","Ragnar Thobaben","Mikael Skoglund"],"pdf_url":"https://arxiv.org/pdf/2403.16681v1.pdf","comment":"9 pages: 5 of main text, 1 of references, and 3 of appendices"},{"id":"http://arxiv.org/abs/2311.17744v2","updated":"2024-03-25T11:04:17Z","published":"2023-11-29T15:49:31Z","title":"Variational Bayes image restoration with compressive autoencoders","summary":"  Regularization of inverse problems is of paramount importance in\ncomputational imaging. The ability of neural networks to learn efficient image\nrepresentations has been recently exploited to design powerful data-driven\nregularizers. While state-of-the-art plug-and-play methods rely on an implicit\nregularization provided by neural denoisers, alternative Bayesian approaches\nconsider Maximum A Posteriori (MAP) estimation in the latent space of a\ngenerative model, thus with an explicit regularization. However,\nstate-of-the-art deep generative models require a huge amount of training data\ncompared to denoisers. Besides, their complexity hampers the optimization\ninvolved in latent MAP derivation. In this work, we first propose to use\ncompressive autoencoders instead. These networks, which can be seen as\nvariational autoencoders with a flexible latent prior, are smaller and easier\nto train than state-of-the-art generative models. As a second contribution, we\nintroduce the Variational Bayes Latent Estimation (VBLE) algorithm, which\nperforms latent estimation within the framework of variational inference.\nThanks to a simple yet efficient parameterization of the variational posterior,\nVBLE allows for fast and easy (approximate) posterior sampling. Experimental\nresults on image datasets BSD and FFHQ demonstrate that VBLE reaches similar\nperformance than state-of-the-art plug-and-play methods, while being able to\nquantify uncertainties faster than other existing posterior sampling\ntechniques.\n","authors":["Maud Biquard","Marie Chabert","Thomas Oberlin"],"pdf_url":"https://arxiv.org/pdf/2311.17744v2.pdf","comment":null},{"id":"http://arxiv.org/abs/1902.05605v4","updated":"2024-03-25T10:20:18Z","published":"2019-02-14T21:05:50Z","title":"CrossQ: Batch Normalization in Deep Reinforcement Learning for Greater\n  Sample Efficiency and Simplicity","summary":"  Sample efficiency is a crucial problem in deep reinforcement learning. Recent\nalgorithms, such as REDQ and DroQ, found a way to improve the sample efficiency\nby increasing the update-to-data (UTD) ratio to 20 gradient update steps on the\ncritic per environment sample. However, this comes at the expense of a greatly\nincreased computational cost. To reduce this computational burden, we introduce\nCrossQ: A lightweight algorithm for continuous control tasks that makes careful\nuse of Batch Normalization and removes target networks to surpass the current\nstate-of-the-art in sample efficiency while maintaining a low UTD ratio of 1.\nNotably, CrossQ does not rely on advanced bias-reduction schemes used in\ncurrent methods. CrossQ's contributions are threefold: (1) it matches or\nsurpasses current state-of-the-art methods in terms of sample efficiency, (2)\nit substantially reduces the computational cost compared to REDQ and DroQ, (3)\nit is easy to implement, requiring just a few lines of code on top of SAC.\n","authors":["Aditya Bhatt","Daniel Palenicek","Boris Belousov","Max Argus","Artemij Amiranashvili","Thomas Brox","Jan Peters"],"pdf_url":"https://arxiv.org/pdf/1902.05605v4.pdf","comment":"Published at ICLR 2024. Project page at\n  http://aditya.bhatts.org/CrossQ and code release at\n  https://github.com/adityab/CrossQ"},{"id":"http://arxiv.org/abs/2403.16523v1","updated":"2024-03-25T08:06:08Z","published":"2024-03-25T08:06:08Z","title":"Causal Discovery from Poisson Branching Structural Causal Model Using\n  High-Order Cumulant with Path Analysis","summary":"  Count data naturally arise in many fields, such as finance, neuroscience, and\nepidemiology, and discovering causal structure among count data is a crucial\ntask in various scientific and industrial scenarios. One of the most common\ncharacteristics of count data is the inherent branching structure described by\na binomial thinning operator and an independent Poisson distribution that\ncaptures both branching and noise. For instance, in a population count\nscenario, mortality and immigration contribute to the count, where survival\nfollows a Bernoulli distribution, and immigration follows a Poisson\ndistribution. However, causal discovery from such data is challenging due to\nthe non-identifiability issue: a single causal pair is Markov equivalent, i.e.,\n$X\\rightarrow Y$ and $Y\\rightarrow X$ are distributed equivalent. Fortunately,\nin this work, we found that the causal order from $X$ to its child $Y$ is\nidentifiable if $X$ is a root vertex and has at least two directed paths to\n$Y$, or the ancestor of $X$ with the most directed path to $X$ has a directed\npath to $Y$ without passing $X$. Specifically, we propose a Poisson Branching\nStructure Causal Model (PB-SCM) and perform a path analysis on PB-SCM using\nhigh-order cumulants. Theoretical results establish the connection between the\npath and cumulant and demonstrate that the path information can be obtained\nfrom the cumulant. With the path information, causal order is identifiable\nunder some graphical conditions. A practical algorithm for learning causal\nstructure under PB-SCM is proposed and the experiments demonstrate and verify\nthe effectiveness of the proposed method.\n","authors":["Jie Qiao","Yu Xiang","Zhengming Chen","Ruichu Cai","Zhifeng Hao"],"pdf_url":"https://arxiv.org/pdf/2403.16523v1.pdf","comment":"Accepted by AAAI-2024"},{"id":"http://arxiv.org/abs/2305.00979v2","updated":"2024-03-25T07:47:57Z","published":"2023-04-29T23:56:55Z","title":"Spectral clustering in the Gaussian mixture block model","summary":"  Gaussian mixture block models are distributions over graphs that strive to\nmodel modern networks: to generate a graph from such a model, we associate each\nvertex $i$ with a latent feature vector $u_i \\in \\mathbb{R}^d$ sampled from a\nmixture of Gaussians, and we add edge $(i,j)$ if and only if the feature\nvectors are sufficiently similar, in that $\\langle u_i,u_j \\rangle \\ge \\tau$\nfor a pre-specified threshold $\\tau$. The different components of the Gaussian\nmixture represent the fact that there may be different types of nodes with\ndifferent distributions over features -- for example, in a social network each\ncomponent represents the different attributes of a distinct community. Natural\nalgorithmic tasks associated with these networks are embedding (recovering the\nlatent feature vectors) and clustering (grouping nodes by their mixture\ncomponent).\n  In this paper we initiate the study of clustering and embedding graphs\nsampled from high-dimensional Gaussian mixture block models, where the\ndimension of the latent feature vectors $d\\to \\infty$ as the size of the\nnetwork $n \\to \\infty$. This high-dimensional setting is most appropriate in\nthe context of modern networks, in which we think of the latent feature space\nas being high-dimensional. We analyze the performance of canonical spectral\nclustering and embedding algorithms for such graphs in the case of 2-component\nspherical Gaussian mixtures, and begin to sketch out the\ninformation-computation landscape for clustering and embedding in these models.\n","authors":["Shuangping Li","Tselil Schramm"],"pdf_url":"https://arxiv.org/pdf/2305.00979v2.pdf","comment":"48 pages"},{"id":"http://arxiv.org/abs/2403.16459v1","updated":"2024-03-25T06:42:02Z","published":"2024-03-25T06:42:02Z","title":"On the rates of convergence for learning with convolutional neural\n  networks","summary":"  We study the approximation and learning capacities of convolutional neural\nnetworks (CNNs). Our first result proves a new approximation bound for CNNs\nwith certain constraint on the weights. Our second result gives a new analysis\non the covering number of feed-forward neural networks, which include CNNs as\nspecial cases. The analysis carefully takes into account the size of the\nweights and hence gives better bounds than existing literature in some\nsituations. Using these two results, we are able to derive rates of convergence\nfor estimators based on CNNs in many learning problems. In particular, we\nestablish minimax optimal convergence rates of the least squares based on CNNs\nfor learning smooth functions in the nonparametric regression setting. For\nbinary classification, we derive convergence rates for CNN classifiers with\nhinge loss and logistic loss. It is also shown that the obtained rates are\nminimax optimal in several settings.\n","authors":["Yunfei Yang","Han Feng","Ding-Xuan Zhou"],"pdf_url":"https://arxiv.org/pdf/2403.16459v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.16377v1","updated":"2024-03-25T02:47:29Z","published":"2024-03-25T02:47:29Z","title":"Real-time Adaptation for Condition Monitoring Signal Prediction using\n  Label-aware Neural Processes","summary":"  Building a predictive model that rapidly adapts to real-time condition\nmonitoring (CM) signals is critical for engineering systems/units.\nUnfortunately, many current methods suffer from a trade-off between\nrepresentation power and agility in online settings. For instance, parametric\nmethods that assume an underlying functional form for CM signals facilitate\nefficient online prediction updates. However, this simplification leads to\nvulnerability to model specifications and an inability to capture complex\nsignals. On the other hand, approaches based on over-parameterized or\nnon-parametric models can excel at explaining complex nonlinear signals, but\nreal-time updates for such models pose a challenging task. In this paper, we\npropose a neural process-based approach that addresses this trade-off. It\nencodes available observations within a CM signal into a representation space\nand then reconstructs the signal's history and evolution for prediction. Once\ntrained, the model can encode an arbitrary number of observations without\nrequiring retraining, enabling on-the-spot real-time predictions along with\nquantified uncertainty and can be readily updated as more online data is\ngathered. Furthermore, our model is designed to incorporate qualitative\ninformation (i.e., labels) from individual units. This integration not only\nenhances individualized predictions for each unit but also enables joint\ninference for both signals and their associated labels. Numerical studies on\nboth synthetic and real-world data in reliability engineering highlight the\nadvantageous features of our model in real-time adaptation, enhanced signal\nprediction with uncertainty quantification, and joint prediction for labels and\nsignals.\n","authors":["Seokhyun Chung","Raed Al Kontar"],"pdf_url":"https://arxiv.org/pdf/2403.16377v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.16369v1","updated":"2024-03-25T02:17:54Z","published":"2024-03-25T02:17:54Z","title":"Learning Action-based Representations Using Invariance","summary":"  Robust reinforcement learning agents using high-dimensional observations must\nbe able to identify relevant state features amidst many exogeneous distractors.\nA representation that captures controllability identifies these state elements\nby determining what affects agent control. While methods such as inverse\ndynamics and mutual information capture controllability for a limited number of\ntimesteps, capturing long-horizon elements remains a challenging problem.\nMyopic controllability can capture the moment right before an agent crashes\ninto a wall, but not the control-relevance of the wall while the agent is still\nsome distance away. To address this we introduce action-bisimulation encoding,\na method inspired by the bisimulation invariance pseudometric, that extends\nsingle-step controllability with a recursive invariance constraint. By doing\nthis, action-bisimulation learns a multi-step controllability metric that\nsmoothly discounts distant state features that are relevant for control. We\ndemonstrate that action-bisimulation pretraining on reward-free, uniformly\nrandom data improves sample efficiency in several environments, including a\nphotorealistic 3D simulation domain, Habitat. Additionally, we provide\ntheoretical analysis and qualitative results demonstrating the information\ncaptured by action-bisimulation.\n","authors":["Max Rudolph","Caleb Chuck","Kevin Black","Misha Lvovsky","Scott Niekum","Amy Zhang"],"pdf_url":"https://arxiv.org/pdf/2403.16369v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.16336v1","updated":"2024-03-25T00:21:34Z","published":"2024-03-25T00:21:34Z","title":"Predictive Inference in Multi-environment Scenarios","summary":"  We address the challenge of constructing valid confidence intervals and sets\nin problems of prediction across multiple environments. We investigate two\ntypes of coverage suitable for these problems, extending the jackknife and\nsplit-conformal methods to show how to obtain distribution-free coverage in\nsuch non-traditional, hierarchical data-generating scenarios. Our contributions\nalso include extensions for settings with non-real-valued responses and a\ntheory of consistency for predictive inference in these general problems. We\ndemonstrate a novel resizing method to adapt to problem difficulty, which\napplies both to existing approaches for predictive inference with hierarchical\ndata and the methods we develop; this reduces prediction set sizes using\nlimited information from the test environment, a key to the methods' practical\nperformance, which we evaluate through neurochemical sensing and species\nclassification datasets.\n","authors":["John C. Duchi","Suyash Gupta","Kuanhao Jiang","Pragya Sur"],"pdf_url":"https://arxiv.org/pdf/2403.16336v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2310.08774v2","updated":"2024-03-25T00:18:35Z","published":"2023-10-12T23:46:08Z","title":"PhyloGFN: Phylogenetic inference with generative flow networks","summary":"  Phylogenetics is a branch of computational biology that studies the\nevolutionary relationships among biological entities. Its long history and\nnumerous applications notwithstanding, inference of phylogenetic trees from\nsequence data remains challenging: the high complexity of tree space poses a\nsignificant obstacle for the current combinatorial and probabilistic\ntechniques. In this paper, we adopt the framework of generative flow networks\n(GFlowNets) to tackle two core problems in phylogenetics: parsimony-based and\nBayesian phylogenetic inference. Because GFlowNets are well-suited for sampling\ncomplex combinatorial structures, they are a natural choice for exploring and\nsampling from the multimodal posterior distribution over tree topologies and\nevolutionary distances. We demonstrate that our amortized posterior sampler,\nPhyloGFN, produces diverse and high-quality evolutionary hypotheses on real\nbenchmark datasets. PhyloGFN is competitive with prior works in marginal\nlikelihood estimation and achieves a closer fit to the target distribution than\nstate-of-the-art variational inference methods. Our code is available at\nhttps://github.com/zmy1116/phylogfn.\n","authors":["Mingyang Zhou","Zichao Yan","Elliot Layne","Nikolay Malkin","Dinghuai Zhang","Moksh Jain","Mathieu Blanchette","Yoshua Bengio"],"pdf_url":"https://arxiv.org/pdf/2310.08774v2.pdf","comment":null}]},"2024-03-24T00:00:00Z":{"Multimedia":[{"id":"http://arxiv.org/abs/2403.16143v1","updated":"2024-03-24T13:31:31Z","published":"2024-03-24T13:31:31Z","title":"CFAT: Unleashing TriangularWindows for Image Super-resolution","summary":"  Transformer-based models have revolutionized the field of image\nsuper-resolution (SR) by harnessing their inherent ability to capture complex\ncontextual features. The overlapping rectangular shifted window technique used\nin transformer architecture nowadays is a common practice in super-resolution\nmodels to improve the quality and robustness of image upscaling. However, it\nsuffers from distortion at the boundaries and has limited unique shifting\nmodes. To overcome these weaknesses, we propose a non-overlapping triangular\nwindow technique that synchronously works with the rectangular one to mitigate\nboundary-level distortion and allows the model to access more unique sifting\nmodes. In this paper, we propose a Composite Fusion Attention Transformer\n(CFAT) that incorporates triangular-rectangular window-based local attention\nwith a channel-based global attention technique in image super-resolution. As a\nresult, CFAT enables attention mechanisms to be activated on more image pixels\nand captures long-range, multi-scale features to improve SR performance. The\nextensive experimental results and ablation study demonstrate the effectiveness\nof CFAT in the SR domain. Our proposed model shows a significant 0.7 dB\nperformance improvement over other state-of-the-art SR architectures.\n","authors":["Abhisek Ray","Gaurav Kumar","Maheshkumar H. Kolekar"],"pdf_url":"https://arxiv.org/pdf/2403.16143v1.pdf","comment":"Accepted to CVPR 2024"},{"id":"http://arxiv.org/abs/2403.16071v1","updated":"2024-03-24T09:18:21Z","published":"2024-03-24T09:18:21Z","title":"Landmark-Guided Cross-Speaker Lip Reading with Mutual Information\n  Regularization","summary":"  Lip reading, the process of interpreting silent speech from visual lip\nmovements, has gained rising attention for its wide range of realistic\napplications. Deep learning approaches greatly improve current lip reading\nsystems. However, lip reading in cross-speaker scenarios where the speaker\nidentity changes, poses a challenging problem due to inter-speaker variability.\nA well-trained lip reading system may perform poorly when handling a brand new\nspeaker. To learn a speaker-robust lip reading model, a key insight is to\nreduce visual variations across speakers, avoiding the model overfitting to\nspecific speakers. In this work, in view of both input visual clues and latent\nrepresentations based on a hybrid CTC/attention architecture, we propose to\nexploit the lip landmark-guided fine-grained visual clues instead of\nfrequently-used mouth-cropped images as input features, diminishing\nspeaker-specific appearance characteristics. Furthermore, a max-min mutual\ninformation regularization approach is proposed to capture speaker-insensitive\nlatent representations. Experimental evaluations on public lip reading datasets\ndemonstrate the effectiveness of the proposed approach under the intra-speaker\nand inter-speaker conditions.\n","authors":["Linzhi Wu","Xingyu Zhang","Yakun Zhang","Changyan Zheng","Tiejun Liu","Liang Xie","Ye Yan","Erwei Yin"],"pdf_url":"https://arxiv.org/pdf/2403.16071v1.pdf","comment":"To appear in LREC-COLING 2024"},{"id":"http://arxiv.org/abs/2403.11311v2","updated":"2024-03-24T06:21:27Z","published":"2024-03-17T19:12:26Z","title":"Mixture-of-Prompt-Experts for Multi-modal Semantic Understanding","summary":"  Deep multimodal semantic understanding that goes beyond the mere superficial\ncontent relation mining has received increasing attention in the realm of\nartificial intelligence. The challenges of collecting and annotating\nhigh-quality multi-modal data have underscored the significance of few-shot\nlearning. In this paper, we focus on two critical tasks under this context:\nfew-shot multi-modal sarcasm detection (MSD) and multi-modal sentiment analysis\n(MSA). To address them, we propose Mixture-of-Prompt-Experts with Block-Aware\nPrompt Fusion (MoPE-BAF), a novel multi-modal soft prompt framework based on\nthe unified vision-language model (VLM). Specifically, we design three experts\nof soft prompts: a text prompt and an image prompt that extract\nmodality-specific features to enrich the single-modal representation, and a\nunified prompt to assist multi-modal interaction. Additionally, we reorganize\nTransformer layers into several blocks and introduce cross-modal prompt\nattention between adjacent blocks, which smoothens the transition from\nsingle-modal representation to multi-modal fusion. On both MSD and MSA datasets\nin few-shot setting, our proposed model not only surpasses the 8.2B model\nInstructBLIP with merely 2% parameters (150M), but also significantly\noutperforms other widely-used prompt methods on VLMs or task-specific methods.\n","authors":["Zichen Wu","Hsiu-Yuan Huang","Fanyi Qu","Yunfang Wu"],"pdf_url":"https://arxiv.org/pdf/2403.11311v2.pdf","comment":"LREC-COLING 2024, Long Paper"}],"Machine Learning 2":[{"id":"http://arxiv.org/abs/2402.11858v2","updated":"2024-03-24T21:33:21Z","published":"2024-02-19T06:00:35Z","title":"Stochastic Hessian Fittings on Lie Groups","summary":"  This paper studies the fitting of Hessian or its inverse for stochastic\noptimizations using a Hessian fitting criterion from the preconditioned\nstochastic gradient descent (PSGD) method, which is intimately related to many\ncommonly used second order and adaptive gradient optimizers, e.g., BFGS,\nGaussian-Newton and natural gradient descent, AdaGrad, etc. Our analyses reveal\nthe efficiency and reliability differences among a wide range of preconditioner\nfitting methods, from closed-form to iterative solutions, using Hessian-vector\nproducts or stochastic gradients only, with Hessian fittings in the Euclidean\nspace, the manifold of symmetric positive definite (SPL) matrices, or a variety\nof Lie groups. The most intriguing discovery is that the Hessian fitting itself\nas an optimization problem is strongly convex under mild conditions on a\nspecific yet general enough Lie group. This discovery turns Hessian fitting\ninto a well behaved optimization problem, and facilitates the designs of highly\nefficient and elegant Lie group sparse preconditioner fitting methods for large\nscale stochastic optimizations.\n","authors":["Xi-Lin Li"],"pdf_url":"https://arxiv.org/pdf/2402.11858v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.16260v1","updated":"2024-03-24T18:43:04Z","published":"2024-03-24T18:43:04Z","title":"Out-of-Distribution Detection via Deep Multi-Comprehension Ensemble","summary":"  Recent research underscores the pivotal role of the Out-of-Distribution (OOD)\nfeature representation field scale in determining the efficacy of models in OOD\ndetection. Consequently, the adoption of model ensembles has emerged as a\nprominent strategy to augment this feature representation field, capitalizing\non anticipated model diversity.\n  However, our introduction of novel qualitative and quantitative model\nensemble evaluation methods, specifically Loss Basin/Barrier Visualization and\nthe Self-Coupling Index, reveals a critical drawback in existing ensemble\nmethods. We find that these methods incorporate weights that are\naffine-transformable, exhibiting limited variability and thus failing to\nachieve the desired diversity in feature representation.\n  To address this limitation, we elevate the dimensions of traditional model\nensembles, incorporating various factors such as different weight\ninitializations, data holdout, etc., into distinct supervision tasks. This\ninnovative approach, termed Multi-Comprehension (MC) Ensemble, leverages\ndiverse training tasks to generate distinct comprehensions of the data and\nlabels, thereby extending the feature representation field.\n  Our experimental results demonstrate the superior performance of the MC\nEnsemble strategy in OOD detection compared to both the naive Deep Ensemble\nmethod and a standalone model of comparable size. This underscores the\neffectiveness of our proposed approach in enhancing the model's capability to\ndetect instances outside its training distribution.\n","authors":["Chenhui Xu","Fuxun Yu","Zirui Xu","Nathan Inkawhich","Xiang Chen"],"pdf_url":"https://arxiv.org/pdf/2403.16260v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.09961v2","updated":"2024-03-24T18:11:41Z","published":"2022-12-20T02:28:27Z","title":"Uncertainty Quantification of MLE for Entity Ranking with Covariates","summary":"  This paper concerns with statistical estimation and inference for the ranking\nproblems based on pairwise comparisons with additional covariate information\nsuch as the attributes of the compared items. Despite extensive studies, few\nprior literatures investigate this problem under the more realistic setting\nwhere covariate information exists. To tackle this issue, we propose a novel\nmodel, Covariate-Assisted Ranking Estimation (CARE) model, that extends the\nwell-known Bradley-Terry-Luce (BTL) model, by incorporating the covariate\ninformation. Specifically, instead of assuming every compared item has a fixed\nlatent score $\\{\\theta_i^*\\}_{i=1}^n$, we assume the underlying scores are\ngiven by $\\{\\alpha_i^*+{x}_i^\\top\\beta^*\\}_{i=1}^n$, where $\\alpha_i^*$ and\n${x}_i^\\top\\beta^*$ represent latent baseline and covariate score of the $i$-th\nitem, respectively. We impose natural identifiability conditions and derive the\n$\\ell_{\\infty}$- and $\\ell_2$-optimal rates for the maximum likelihood\nestimator of $\\{\\alpha_i^*\\}_{i=1}^{n}$ and $\\beta^*$ under a sparse comparison\ngraph, using a novel `leave-one-out' technique (Chen et al., 2019) . To conduct\nstatistical inferences, we further derive asymptotic distributions for the MLE\nof $\\{\\alpha_i^*\\}_{i=1}^n$ and $\\beta^*$ with minimal sample complexity. This\nallows us to answer the question whether some covariates have any explanation\npower for latent scores and to threshold some sparse parameters to improve the\nranking performance. We improve the approximation method used in (Gao et al.,\n2021) for the BLT model and generalize it to the CARE model. Moreover, we\nvalidate our theoretical results through large-scale numerical studies and an\napplication to the mutual fund stock holding dataset.\n","authors":["Jianqing Fan","Jikai Hou","Mengxin Yu"],"pdf_url":"https://arxiv.org/pdf/2212.09961v2.pdf","comment":"81 pages, 3 figures"},{"id":"http://arxiv.org/abs/2303.16971v3","updated":"2024-03-24T17:10:42Z","published":"2023-03-29T19:10:24Z","title":"Sparse joint shift in multinomial classification","summary":"  Sparse joint shift (SJS) was recently proposed as a tractable model for\ngeneral dataset shift which may cause changes to the marginal distributions of\nfeatures and labels as well as the posterior probabilities and the\nclass-conditional feature distributions. Fitting SJS for a target dataset\nwithout label observations may produce valid predictions of labels and\nestimates of class prior probabilities. We present new results on the\ntransmission of SJS from sets of features to larger sets of features, a\nconditional correction formula for the class posterior probabilities under the\ntarget distribution, identifiability of SJS, and the relationship between SJS\nand covariate shift. In addition, we point out inconsistencies in the\nalgorithms which were proposed for estimating the characteristics of SJS, as\nthey could hamper the search for optimal solutions, and suggest potential\nimprovements.\n","authors":["Dirk Tasche"],"pdf_url":"https://arxiv.org/pdf/2303.16971v3.pdf","comment":"27 pages"},{"id":"http://arxiv.org/abs/2312.09146v3","updated":"2024-03-24T16:32:13Z","published":"2023-12-14T17:17:16Z","title":"Featurizing Koopman Mode Decomposition","summary":"  This article introduces an advanced Koopman mode decomposition (KMD)\ntechnique -- coined Featurized Koopman Mode Decomposition (FKMD) -- that uses\ntime embedding and Mahalanobis scaling to enhance analysis and prediction of\nhigh dimensional dynamical systems. The time embedding expands the observation\nspace to better capture underlying manifold structure, while the Mahalanobis\nscaling, applied to kernel or random Fourier features, adjusts observations\nbased on the system's dynamics. This aids in featurizing KMD in cases where\ngood features are not a priori known. We find that the Mahalanobis scaling from\nFKMD can be used for effective dimensionality reduction of alanine dipeptide\ndata. We also show that FKMD improves predictions for a high-dimensional Lorenz\nattractor and a cell signaling problem from cancer research.\n","authors":["David Aristoff","Jeremy Copperman","Nathan Mankovich","Alexander Davies"],"pdf_url":"https://arxiv.org/pdf/2312.09146v3.pdf","comment":"10 pages, 5 figures"},{"id":"http://arxiv.org/abs/2306.14693v2","updated":"2024-03-24T15:43:32Z","published":"2023-06-26T13:38:49Z","title":"Conformal link prediction for false discovery rate control","summary":"  Most link prediction methods return estimates of the connection probability\nof missing edges in a graph. Such output can be used to rank the missing edges\nfrom most to least likely to be a true edge, but does not directly provide a\nclassification into true and non-existent. In this work, we consider the\nproblem of identifying a set of true edges with a control of the false\ndiscovery rate (FDR). We propose a novel method based on high-level ideas from\nthe literature on conformal inference. The graph structure induces intricate\ndependence in the data, which we carefully take into account, as this makes the\nsetup different from the usual setup in conformal inference, where data\nexchangeability is assumed. The FDR control is empirically demonstrated for\nboth simulated and real data.\n","authors":["Ariane Marandon"],"pdf_url":"https://arxiv.org/pdf/2306.14693v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.16163v1","updated":"2024-03-24T14:08:24Z","published":"2024-03-24T14:08:24Z","title":"An Analytic Solution to Covariance Propagation in Neural Networks","summary":"  Uncertainty quantification of neural networks is critical to measuring the\nreliability and robustness of deep learning systems. However, this often\ninvolves costly or inaccurate sampling methods and approximations. This paper\npresents a sample-free moment propagation technique that propagates mean\nvectors and covariance matrices across a network to accurately characterize the\ninput-output distributions of neural networks. A key enabler of our technique\nis an analytic solution for the covariance of random variables passed through\nnonlinear activation functions, such as Heaviside, ReLU, and GELU. The wide\napplicability and merits of the proposed technique are shown in experiments\nanalyzing the input-output distributions of trained neural networks and\ntraining Bayesian neural networks.\n","authors":["Oren Wright","Yorie Nakahira","Jos√© M. F. Moura"],"pdf_url":"https://arxiv.org/pdf/2403.16163v1.pdf","comment":"Accepted to AISTATS 2024"},{"id":"http://arxiv.org/abs/2402.15585v2","updated":"2024-03-24T12:36:03Z","published":"2024-02-23T19:52:09Z","title":"Inference for Regression with Variables Generated from Unstructured Data","summary":"  The leading strategy for analyzing unstructured data uses two steps. First,\nlatent variables of economic interest are estimated with an upstream\ninformation retrieval model. Second, the estimates are treated as \"data\" in a\ndownstream econometric model. We establish theoretical arguments for why this\ntwo-step strategy leads to biased inference in empirically plausible settings.\nMore constructively, we propose a one-step strategy for valid inference that\nuses the upstream and downstream models jointly. The one-step strategy (i)\nsubstantially reduces bias in simulations; (ii) has quantitatively important\neffects in a leading application using CEO time-use data; and (iii) can be\nreadily adapted by applied researchers.\n","authors":["Laura Battaglia","Timothy Christensen","Stephen Hansen","Szymon Sacher"],"pdf_url":"https://arxiv.org/pdf/2402.15585v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.11782v2","updated":"2024-03-24T10:12:42Z","published":"2024-03-18T13:40:48Z","title":"A tutorial on learning from preferences and choices with Gaussian\n  Processes","summary":"  Preference modelling lies at the intersection of economics, decision theory,\nmachine learning and statistics. By understanding individuals' preferences and\nhow they make choices, we can build products that closely match their\nexpectations, paving the way for more efficient and personalised applications\nacross a wide range of domains. The objective of this tutorial is to present a\ncohesive and comprehensive framework for preference learning with Gaussian\nProcesses (GPs), demonstrating how to seamlessly incorporate rationality\nprinciples (from economics and decision theory) into the learning process. By\nsuitably tailoring the likelihood function, this framework enables the\nconstruction of preference learning models that encompass random utility\nmodels, limits of discernment, and scenarios with multiple conflicting\nutilities for both object- and label-preference. This tutorial builds upon\nestablished research while simultaneously introducing some novel GP-based\nmodels to address specific gaps in the existing literature.\n","authors":["Alessio Benavoli","Dario Azzimonti"],"pdf_url":"https://arxiv.org/pdf/2403.11782v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.16059v1","updated":"2024-03-24T08:06:34Z","published":"2024-03-24T08:06:34Z","title":"Manifold Regularization Classification Model Based On Improved Diffusion\n  Map","summary":"  Manifold regularization model is a semi-supervised learning model that\nleverages the geometric structure of a dataset, comprising a small number of\nlabeled samples and a large number of unlabeled samples, to generate\nclassifiers. However, the original manifold norm limits the performance of\nmodels to local regions. To address this limitation, this paper proposes an\napproach to improve manifold regularization based on a label propagation model.\nWe initially enhance the probability transition matrix of the diffusion map\nalgorithm, which can be used to estimate the Neumann heat kernel, enabling it\nto accurately depict the label propagation process on the manifold. Using this\nmatrix, we establish a label propagation function on the dataset to describe\nthe distribution of labels at different time steps. Subsequently, we extend the\nlabel propagation function to the entire data manifold. We prove that the\nextended label propagation function converges to a stable distribution after a\nsufficiently long time and can be considered as a classifier. Building upon\nthis concept, we propose a viable improvement to the manifold regularization\nmodel and validate its superiority through experiments.\n","authors":["Hongfu Guo","Wencheng Zou","Zeyu Zhang","Shuishan Zhang","Ruitong Wang","Jintao Zhang"],"pdf_url":"https://arxiv.org/pdf/2403.16059v1.pdf","comment":"20 pages, 24figures"},{"id":"http://arxiv.org/abs/2208.07243v4","updated":"2024-03-24T07:48:18Z","published":"2022-08-15T14:57:26Z","title":"Exponential Concentration in Stochastic Approximation","summary":"  We analyze the behavior of stochastic approximation algorithms where\niterates, in expectation, progress towards an objective at each step. When\nprogress is proportional to the step size of the algorithm, we prove\nexponential concentration bounds. These tail-bounds contrast asymptotic\nnormality results, which are more frequently associated with stochastic\napproximation. The methods that we develop rely on a geometric ergodicity\nproof. This extends a result on Markov chains due to Hajek (1982) to the area\nof stochastic approximation algorithms. We apply our results to several\ndifferent Stochastic Approximation algorithms, specifically Projected\nStochastic Gradient Descent, Kiefer-Wolfowitz and Stochastic Frank-Wolfe\nalgorithms. When applicable, our results prove faster $O(1/t)$ and linear\nconvergence rates for Projected Stochastic Gradient Descent with a\nnon-vanishing gradient.\n","authors":["Kody Law","Neil Walton","Shangda Yang"],"pdf_url":"https://arxiv.org/pdf/2208.07243v4.pdf","comment":"35 pages, 11 Figures"},{"id":"http://arxiv.org/abs/2309.05153v3","updated":"2024-03-24T07:31:23Z","published":"2023-09-10T22:05:24Z","title":"Learning Energy-Based Models by Cooperative Diffusion Recovery\n  Likelihood","summary":"  Training energy-based models (EBMs) on high-dimensional data can be both\nchallenging and time-consuming, and there exists a noticeable gap in sample\nquality between EBMs and other generative frameworks like GANs and diffusion\nmodels. To close this gap, inspired by the recent efforts of learning EBMs by\nmaximizing diffusion recovery likelihood (DRL), we propose cooperative\ndiffusion recovery likelihood (CDRL), an effective approach to tractably learn\nand sample from a series of EBMs defined on increasingly noisy versions of a\ndataset, paired with an initializer model for each EBM. At each noise level,\nthe two models are jointly estimated within a cooperative training framework:\nsamples from the initializer serve as starting points that are refined by a few\nMCMC sampling steps from the EBM. The EBM is then optimized by maximizing\nrecovery likelihood, while the initializer model is optimized by learning from\nthe difference between the refined samples and the initial samples. In\naddition, we made several practical designs for EBM training to further improve\nthe sample quality. Combining these advances, our approach significantly boost\nthe generation performance compared to existing EBM methods on CIFAR-10 and\nImageNet datasets. We also demonstrate the effectiveness of our models for\nseveral downstream tasks, including classifier-free guided generation,\ncompositional generation, image inpainting and out-of-distribution detection.\n","authors":["Yaxuan Zhu","Jianwen Xie","Yingnian Wu","Ruiqi Gao"],"pdf_url":"https://arxiv.org/pdf/2309.05153v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.16031v1","updated":"2024-03-24T06:14:50Z","published":"2024-03-24T06:14:50Z","title":"Learning Directed Acyclic Graphs from Partial Orderings","summary":"  Directed acyclic graphs (DAGs) are commonly used to model causal\nrelationships among random variables. In general, learning the DAG structure is\nboth computationally and statistically challenging. Moreover, without\nadditional information, the direction of edges may not be estimable from\nobservational data. In contrast, given a complete causal ordering of the\nvariables, the problem can be solved efficiently, even in high dimensions. In\nthis paper, we consider the intermediate problem of learning DAGs when a\npartial causal ordering of variables is available. We propose a general\nestimation framework for leveraging the partial ordering and present efficient\nestimation algorithms for low- and high-dimensional problems. The advantages of\nthe proposed framework are illustrated via numerical studies.\n","authors":["Ali Shojaie","Wenyu Chen"],"pdf_url":"https://arxiv.org/pdf/2403.16031v1.pdf","comment":"29 pages, 5 figures"},{"id":"http://arxiv.org/abs/2403.03868v2","updated":"2024-03-24T04:07:37Z","published":"2024-03-06T17:18:24Z","title":"Confidence on the Focal: Conformal Prediction with Selection-Conditional\n  Coverage","summary":"  Conformal prediction builds marginally valid prediction intervals that cover\nthe unknown outcome of a randomly drawn new test point with a prescribed\nprobability. However, a common scenario in practice is that, after seeing the\ndata, practitioners decide which test unit(s) to focus on in a data-driven\nmanner and seek for uncertainty quantification of the focal unit(s). In such\ncases, marginally valid conformal prediction intervals may not provide valid\ncoverage for the focal unit(s) due to selection bias. This paper presents a\ngeneral framework for constructing a prediction set with finite-sample exact\ncoverage conditional on the unit being selected by a given procedure. The\ngeneral form of our method works for arbitrary selection rules that are\ninvariant to the permutation of the calibration units, and generalizes Mondrian\nConformal Prediction to multiple test units and non-equivariant classifiers. We\nthen work out the computationally efficient implementation of our framework for\na number of realistic selection rules, including top-K selection,\noptimization-based selection, selection based on conformal p-values, and\nselection based on properties of preliminary conformal prediction sets. The\nperformance of our methods is demonstrated via applications in drug discovery\nand health risk prediction.\n","authors":["Ying Jin","Zhimei Ren"],"pdf_url":"https://arxiv.org/pdf/2403.03868v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.15999v1","updated":"2024-03-24T03:57:21Z","published":"2024-03-24T03:57:21Z","title":"Near-Optimal differentially private low-rank trace regression with\n  guaranteed private initialization","summary":"  We study differentially private (DP) estimation of a rank-$r$ matrix $M \\in\n\\mathbb{R}^{d_1\\times d_2}$ under the trace regression model with Gaussian\nmeasurement matrices. Theoretically, the sensitivity of non-private spectral\ninitialization is precisely characterized, and the\ndifferential-privacy-constrained minimax lower bound for estimating $M$ under\nthe Schatten-$q$ norm is established. Methodologically, the paper introduces a\ncomputationally efficient algorithm for DP-initialization with a sample size of\n$n \\geq \\widetilde O (r^2 (d_1\\vee d_2))$. Under certain regularity conditions,\nthe DP-initialization falls within a local ball surrounding $M$. We also\npropose a differentially private algorithm for estimating $M$ based on\nRiemannian optimization (DP-RGrad), which achieves a near-optimal convergence\nrate with the DP-initialization and sample size of $n \\geq \\widetilde O(r (d_1\n+ d_2))$. Finally, the paper discusses the non-trivial gap between the minimax\nlower bound and the upper bound of low-rank matrix estimation under the trace\nregression model. It is shown that the estimator given by DP-RGrad attains the\noptimal convergence rate in a weaker notion of differential privacy. Our\npowerful technique for analyzing the sensitivity of initialization requires no\neigengap condition between $r$ non-zero singular values.\n","authors":["Mengyue Zha"],"pdf_url":"https://arxiv.org/pdf/2403.15999v1.pdf","comment":null}]},"2024-03-23T00:00:00Z":{"Multimedia":[{"id":"http://arxiv.org/abs/2309.11093v3","updated":"2024-03-23T13:33:06Z","published":"2023-09-20T06:54:55Z","title":"K-pop Lyric Translation: Dataset, Analysis, and Neural-Modelling","summary":"  Lyric translation, a field studied for over a century, is now attracting\ncomputational linguistics researchers. We identified two limitations in\nprevious studies. Firstly, lyric translation studies have predominantly focused\non Western genres and languages, with no previous study centering on K-pop\ndespite its popularity. Second, the field of lyric translation suffers from a\nlack of publicly available datasets; to the best of our knowledge, no such\ndataset exists. To broaden the scope of genres and languages in lyric\ntranslation studies, we introduce a novel singable lyric translation dataset,\napproximately 89\\% of which consists of K-pop song lyrics. This dataset aligns\nKorean and English lyrics line-by-line and section-by-section. We leveraged\nthis dataset to unveil unique characteristics of K-pop lyric translation,\ndistinguishing it from other extensively studied genres, and to construct a\nneural lyric translation model, thereby underscoring the importance of a\ndedicated dataset for singable lyric translations.\n","authors":["Haven Kim","Jongmin Jung","Dasaem Jeong","Juhan Nam"],"pdf_url":"https://arxiv.org/pdf/2309.11093v3.pdf","comment":"LREC-COLING 2024"},{"id":"http://arxiv.org/abs/2403.15694v1","updated":"2024-03-23T03:06:19Z","published":"2024-03-23T03:06:19Z","title":"Group Benefits Instances Selection for Data Purification","summary":"  Manually annotating datasets for training deep models is very labor-intensive\nand time-consuming. To overcome such inferiority, directly leveraging web\nimages to conduct training data becomes a natural choice. Nevertheless, the\npresence of label noise in web data usually degrades the model performance.\nExisting methods for combating label noise are typically designed and tested on\nsynthetic noisy datasets. However, they tend to fail to achieve satisfying\nresults on real-world noisy datasets. To this end, we propose a method named\nGRIP to alleviate the noisy label problem for both synthetic and real-world\ndatasets. Specifically, GRIP utilizes a group regularization strategy that\nestimates class soft labels to improve noise robustness. Soft label supervision\nreduces overfitting on noisy labels and learns inter-class similarities to\nbenefit classification. Furthermore, an instance purification operation\nglobally identifies noisy labels by measuring the difference between each\ntraining sample and its class soft label. Through operations at both group and\ninstance levels, our approach integrates the advantages of noise-robust and\nnoise-cleaning methods and remarkably alleviates the performance degradation\ncaused by noisy labels. Comprehensive experimental results on synthetic and\nreal-world datasets demonstrate the superiority of GRIP over the existing\nstate-of-the-art methods.\n","authors":["Zhenhuang Cai","Chuanyi Zhang","Dan Huang","Yuanbo Chen","Xiuyun Guan","Yazhou Yao"],"pdf_url":"https://arxiv.org/pdf/2403.15694v1.pdf","comment":"accepted by IEEE Intelligent Systems"},{"id":"http://arxiv.org/abs/2403.15679v1","updated":"2024-03-23T02:09:23Z","published":"2024-03-23T02:09:23Z","title":"DS-NeRV: Implicit Neural Video Representation with Decomposed Static and\n  Dynamic Codes","summary":"  Implicit neural representations for video (NeRV) have recently become a novel\nway for high-quality video representation. However, existing works employ a\nsingle network to represent the entire video, which implicitly confuse static\nand dynamic information. This leads to an inability to effectively compress the\nredundant static information and lack the explicitly modeling of global\ntemporal-coherent dynamic details. To solve above problems, we propose DS-NeRV,\nwhich decomposes videos into sparse learnable static codes and dynamic codes\nwithout the need for explicit optical flow or residual supervision. By setting\ndifferent sampling rates for two codes and applying weighted sum and\ninterpolation sampling methods, DS-NeRV efficiently utilizes redundant static\ninformation while maintaining high-frequency details. Additionally, we design a\ncross-channel attention-based (CCA) fusion module to efficiently fuse these two\ncodes for frame decoding. Our approach achieves a high quality reconstruction\nof 31.2 PSNR with only 0.35M parameters thanks to separate static and dynamic\ncodes representation and outperforms existing NeRV methods in many downstream\ntasks. Our project website is at https://haoyan14.github.io/DS-NeRV.\n","authors":["Hao Yan","Zhihui Ke","Xiaobo Zhou","Tie Qiu","Xidong Shi","Dadong Jiang"],"pdf_url":"https://arxiv.org/pdf/2403.15679v1.pdf","comment":"CVPR 2024. Project page at https://haoyan14.github.io/DS-NeRV"}],"Machine Learning 2":[{"id":"http://arxiv.org/abs/2403.15908v1","updated":"2024-03-23T18:42:22Z","published":"2024-03-23T18:42:22Z","title":"Deep Gaussian Covariance Network with Trajectory Sampling for\n  Data-Efficient Policy Search","summary":"  Probabilistic world models increase data efficiency of model-based\nreinforcement learning (MBRL) by guiding the policy with their epistemic\nuncertainty to improve exploration and acquire new samples. Moreover, the\nuncertainty-aware learning procedures in probabilistic approaches lead to\nrobust policies that are less sensitive to noisy observations compared to\nuncertainty unaware solutions. We propose to combine trajectory sampling and\ndeep Gaussian covariance network (DGCN) for a data-efficient solution to MBRL\nproblems in an optimal control setting. We compare trajectory sampling with\ndensity-based approximation for uncertainty propagation using three different\nprobabilistic world models; Gaussian processes, Bayesian neural networks, and\nDGCNs. We provide empirical evidence using four different well-known test\nenvironments, that our method improves the sample-efficiency over other\ncombinations of uncertainty propagation methods and probabilistic models.\nDuring our tests, we place particular emphasis on the robustness of the learned\npolicies with respect to noisy initial states.\n","authors":["Can Bogoclu","Robert Vosshall","Kevin Cremanns","Dirk Roos"],"pdf_url":"https://arxiv.org/pdf/2403.15908v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.15881v1","updated":"2024-03-23T16:21:22Z","published":"2024-03-23T16:21:22Z","title":"Fast and Unified Path Gradient Estimators for Normalizing Flows","summary":"  Recent work shows that path gradient estimators for normalizing flows have\nlower variance compared to standard estimators for variational inference,\nresulting in improved training. However, they are often prohibitively more\nexpensive from a computational point of view and cannot be applied to maximum\nlikelihood training in a scalable manner, which severely hinders their\nwidespread adoption. In this work, we overcome these crucial limitations.\nSpecifically, we propose a fast path gradient estimator which improves\ncomputational efficiency significantly and works for all normalizing flow\narchitectures of practical relevance. We then show that this estimator can also\nbe applied to maximum likelihood training for which it has a regularizing\neffect as it can take the form of a given target energy function into account.\nWe empirically establish its superior performance and reduced variance for\nseveral natural sciences applications.\n","authors":["Lorenz Vaitl","Ludwig Winkler","Lorenz Richter","Pan Kessel"],"pdf_url":"https://arxiv.org/pdf/2403.15881v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.15877v1","updated":"2024-03-23T15:55:52Z","published":"2024-03-23T15:55:52Z","title":"Integrated path stability selection","summary":"  Stability selection is a widely used method for improving the performance of\nfeature selection algorithms. However, stability selection has been found to be\nhighly conservative, resulting in low sensitivity. Further, the theoretical\nbound on the expected number of false positives, E(FP), is relatively loose,\nmaking it difficult to know how many false positives to expect in practice. In\nthis paper, we introduce a novel method for stability selection based on\nintegrating the stability paths rather than maximizing over them. This yields a\ntighter bound on E(FP), resulting in a feature selection criterion that has\nhigher sensitivity in practice and is better calibrated in terms of matching\nthe target E(FP). Our proposed method requires the same amount of computation\nas the original stability selection algorithm, and only requires the user to\nspecify one input parameter, a target value for E(FP). We provide theoretical\nbounds on performance, and demonstrate the method on simulations and real data\nfrom cancer gene expression studies.\n","authors":["Omar Melikechi","Jeffrey W. Miller"],"pdf_url":"https://arxiv.org/pdf/2403.15877v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.17978v1","updated":"2024-03-23T15:49:13Z","published":"2024-03-23T15:49:13Z","title":"Holographic Global Convolutional Networks for Long-Range Prediction\n  Tasks in Malware Detection","summary":"  Malware detection is an interesting and valuable domain to work in because it\nhas significant real-world impact and unique machine-learning challenges. We\ninvestigate existing long-range techniques and benchmarks and find that they're\nnot very suitable in this problem area. In this paper, we introduce Holographic\nGlobal Convolutional Networks (HGConv) that utilize the properties of\nHolographic Reduced Representations (HRR) to encode and decode features from\nsequence elements. Unlike other global convolutional methods, our method does\nnot require any intricate kernel computation or crafted kernel design. HGConv\nkernels are defined as simple parameters learned through backpropagation. The\nproposed method has achieved new SOTA results on Microsoft Malware\nClassification Challenge, Drebin, and EMBER malware benchmarks. With log-linear\ncomplexity in sequence length, the empirical results demonstrate substantially\nfaster run-time by HGConv compared to other methods achieving far more\nefficient scaling even with sequence length $\\geq 100,000$.\n","authors":["Mohammad Mahmudul Alam","Edward Raff","Stella Biderman","Tim Oates","James Holt"],"pdf_url":"https://arxiv.org/pdf/2403.17978v1.pdf","comment":"To appear in Proceedings of the 27th International Conference on\n  Artificial Intelligence and Statistics (AISTATS) 2024, Valencia, Spain"},{"id":"http://arxiv.org/abs/2009.13961v4","updated":"2024-03-23T15:01:03Z","published":"2020-09-29T12:25:05Z","title":"Online Action Learning in High Dimensions: A Conservative Perspective","summary":"  Sequential learning problems are common in several fields of research and\npractical applications. Examples include dynamic pricing and assortment, design\nof auctions and incentives and permeate a large number of sequential treatment\nexperiments. In this paper, we extend one of the most popular learning\nsolutions, the $\\epsilon_t$-greedy heuristics, to high-dimensional contexts\nconsidering a conservative directive. We do this by allocating part of the time\nthe original rule uses to adopt completely new actions to a more focused search\nin a restrictive set of promising actions. The resulting rule might be useful\nfor practical applications that still values surprises, although at a\ndecreasing rate, while also has restrictions on the adoption of unusual\nactions. With high probability, we find reasonable bounds for the cumulative\nregret of a conservative high-dimensional decaying $\\epsilon_t$-greedy rule.\nAlso, we provide a lower bound for the cardinality of the set of viable actions\nthat implies in an improved regret bound for the conservative version when\ncompared to its non-conservative counterpart. Additionally, we show that\nend-users have sufficient flexibility when establishing how much safety they\nwant, since it can be tuned without impacting theoretical properties. We\nillustrate our proposal both in a simulation exercise and using a real dataset.\n","authors":["Claudio Cardoso Flores","Marcelo Cunha Medeiros"],"pdf_url":"https://arxiv.org/pdf/2009.13961v4.pdf","comment":"We found an error in the proof of the main theorem which cannot be\n  fixed without completely changing the results in the paper"},{"id":"http://arxiv.org/abs/2303.10599v2","updated":"2024-03-23T13:26:31Z","published":"2023-03-19T08:29:49Z","title":"Convergence Analysis of Stochastic Gradient Descent with MCMC Estimators","summary":"  Understanding stochastic gradient descent (SGD) and its variants is essential\nfor machine learning. However, most of the preceding analyses are conducted\nunder amenable conditions such as unbiased gradient estimator and bounded\nobjective functions, which does not encompass many sophisticated applications,\nsuch as variational Monte Carlo, entropy-regularized reinforcement learning and\nvariational inference. In this paper, we consider the SGD algorithm that employ\nthe Markov Chain Monte Carlo (MCMC) estimator to compute the gradient, called\nMCMC-SGD. Since MCMC reduces the sampling complexity significantly, it is an\nasymptotically convergent biased estimator in practice. Moreover, by\nincorporating a general class of unbounded functions, it is much more difficult\nto analyze the MCMC sampling error. Therefore, we assume that the function is\nsub-exponential and use the Bernstein inequality for non-stationary Markov\nchains to derive error bounds of the MCMC estimator. Consequently, MCMC-SGD is\nproven to have a first order convergence rate $O(\\log K/\\sqrt{n K})$ with $K$\niterations and a sample size $n$. It partially explains how MCMC influences the\nbehavior of SGD. Furthermore, we verify the correlated negative curvature\ncondition under reasonable assumptions. It is shown that MCMC-SGD escapes from\nsaddle points and reaches $(\\epsilon,\\epsilon^{1/4})$ approximate second order\nstationary points or $\\epsilon^{1/2}$-variance points at least\n$O(\\epsilon^{-11/2}\\log^{2}(1/\\epsilon) )$ steps with high probability. Our\nanalysis unveils the convergence pattern of MCMC-SGD across a broad class of\nstochastic optimization problems, and interprets the convergence phenomena\nobserved in practical applications.\n","authors":["Tianyou Li","Fan Chen","Huajie Chen","Zaiwen Wen"],"pdf_url":"https://arxiv.org/pdf/2303.10599v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.15822v1","updated":"2024-03-23T12:19:49Z","published":"2024-03-23T12:19:49Z","title":"Computational Sentence-level Metrics Predicting Human Sentence\n  Comprehension","summary":"  The majority of research in computational psycholinguistics has concentrated\non the processing of words. This study introduces innovative methods for\ncomputing sentence-level metrics using multilingual large language models. The\nmetrics developed sentence surprisal and sentence relevance and then are tested\nand compared to validate whether they can predict how humans comprehend\nsentences as a whole across languages. These metrics offer significant\ninterpretability and achieve high accuracy in predicting human sentence reading\nspeeds. Our results indicate that these computational sentence-level metrics\nare exceptionally effective at predicting and elucidating the processing\ndifficulties encountered by readers in comprehending sentences as a whole\nacross a variety of languages. Their impressive performance and generalization\ncapabilities provide a promising avenue for future research in integrating LLMs\nand cognitive science.\n","authors":["Kun Sun","Rong Wang"],"pdf_url":"https://arxiv.org/pdf/2403.15822v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.03967v2","updated":"2024-03-23T11:22:00Z","published":"2024-03-06T15:41:21Z","title":"Effect of Ambient-Intrinsic Dimension Gap on Adversarial Vulnerability","summary":"  The existence of adversarial attacks on machine learning models imperceptible\nto a human is still quite a mystery from a theoretical perspective. In this\nwork, we introduce two notions of adversarial attacks: natural or on-manifold\nattacks, which are perceptible by a human/oracle, and unnatural or off-manifold\nattacks, which are not. We argue that the existence of the off-manifold attacks\nis a natural consequence of the dimension gap between the intrinsic and ambient\ndimensions of the data. For 2-layer ReLU networks, we prove that even though\nthe dimension gap does not affect generalization performance on samples drawn\nfrom the observed data space, it makes the clean-trained model more vulnerable\nto adversarial perturbations in the off-manifold direction of the data space.\nOur main results provide an explicit relationship between the\n$\\ell_2,\\ell_{\\infty}$ attack strength of the on/off-manifold attack and the\ndimension gap.\n","authors":["Rajdeep Haldar","Yue Xing","Qifan Song"],"pdf_url":"https://arxiv.org/pdf/2403.03967v2.pdf","comment":"AISTATS 2024"},{"id":"http://arxiv.org/abs/2403.15790v1","updated":"2024-03-23T10:37:22Z","published":"2024-03-23T10:37:22Z","title":"Boarding for ISS: Imbalanced Self-Supervised: Discovery of a Scaled\n  Autoencoder for Mixed Tabular Datasets","summary":"  The field of imbalanced self-supervised learning, especially in the context\nof tabular data, has not been extensively studied. Existing research has\npredominantly focused on image datasets. This paper aims to fill this gap by\nexamining the specific challenges posed by data imbalance in self-supervised\nlearning in the domain of tabular data, with a primary focus on autoencoders.\nAutoencoders are widely employed for learning and constructing a new\nrepresentation of a dataset, particularly for dimensionality reduction. They\nare also often used for generative model learning, as seen in variational\nautoencoders. When dealing with mixed tabular data, qualitative variables are\noften encoded using a one-hot encoder with a standard loss function (MSE or\nCross Entropy). In this paper, we analyze the drawbacks of this approach,\nespecially when categorical variables are imbalanced. We propose a novel metric\nto balance learning: a Multi-Supervised Balanced MSE. This approach reduces the\nreconstruction error by balancing the influence of variables. Finally, we\nempirically demonstrate that this new metric, compared to the standard MSE: i)\noutperforms when the dataset is imbalanced, especially when the learning\nprocess is insufficient, and ii) provides similar results in the opposite case.\n","authors":["Samuel Stocksieker","Denys Pommeret","Arthur Charpentier"],"pdf_url":"https://arxiv.org/pdf/2403.15790v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.15778v1","updated":"2024-03-23T09:24:29Z","published":"2024-03-23T09:24:29Z","title":"Supervised Learning via Ensembles of Diverse Functional Representations:\n  the Functional Voting Classifier","summary":"  Many conventional statistical and machine learning methods face challenges\nwhen applied directly to high dimensional temporal observations. In recent\ndecades, Functional Data Analysis (FDA) has gained widespread popularity as a\nframework for modeling and analyzing data that are, by their nature, functions\nin the domain of time. Although supervised classification has been extensively\nexplored in recent decades within the FDA literature, ensemble learning of\nfunctional classifiers has only recently emerged as a topic of significant\ninterest. Thus, the latter subject presents unexplored facets and challenges\nfrom various statistical perspectives. The focal point of this paper lies in\nthe realm of ensemble learning for functional data and aims to show how\ndifferent functional data representations can be used to train ensemble members\nand how base model predictions can be combined through majority voting. The\nso-called Functional Voting Classifier (FVC) is proposed to demonstrate how\ndifferent functional representations leading to augmented diversity can\nincrease predictive accuracy. Many real-world datasets from several domains are\nused to display that the FVC can significantly enhance performance compared to\nindividual models. The framework presented provides a foundation for voting\nensembles with functional data and can stimulate a highly encouraging line of\nresearch in the FDA context.\n","authors":["Donato Riccio","Fabrizio Maturo","Elvira Romano"],"pdf_url":"https://arxiv.org/pdf/2403.15778v1.pdf","comment":"35 pages, 20 figures"},{"id":"http://arxiv.org/abs/2403.15711v1","updated":"2024-03-23T04:13:55Z","published":"2024-03-23T04:13:55Z","title":"Identifiable Latent Neural Causal Models","summary":"  Causal representation learning seeks to uncover latent, high-level causal\nrepresentations from low-level observed data. It is particularly good at\npredictions under unseen distribution shifts, because these shifts can\ngenerally be interpreted as consequences of interventions. Hence leveraging\n{seen} distribution shifts becomes a natural strategy to help identifying\ncausal representations, which in turn benefits predictions where distributions\nare previously {unseen}. Determining the types (or conditions) of such\ndistribution shifts that do contribute to the identifiability of causal\nrepresentations is critical. This work establishes a {sufficient} and\n{necessary} condition characterizing the types of distribution shifts for\nidentifiability in the context of latent additive noise models. Furthermore, we\npresent partial identifiability results when only a portion of distribution\nshifts meets the condition. In addition, we extend our findings to latent\npost-nonlinear causal models. We translate our findings into a practical\nalgorithm, allowing for the acquisition of reliable latent causal\nrepresentations. Our algorithm, guided by our underlying theory, has\ndemonstrated outstanding performance across a diverse range of synthetic and\nreal-world datasets. The empirical observations align closely with the\ntheoretical findings, affirming the robustness and effectiveness of our\napproach.\n","authors":["Yuhang Liu","Zhen Zhang","Dong Gong","Mingming Gong","Biwei Huang","Anton van den Hengel","Kun Zhang","Javen Qinfeng Shi"],"pdf_url":"https://arxiv.org/pdf/2403.15711v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.15707v1","updated":"2024-03-23T03:57:28Z","published":"2024-03-23T03:57:28Z","title":"Role of Locality and Weight Sharing in Image-Based Tasks: A Sample\n  Complexity Separation between CNNs, LCNs, and FCNs","summary":"  Vision tasks are characterized by the properties of locality and translation\ninvariance. The superior performance of convolutional neural networks (CNNs) on\nthese tasks is widely attributed to the inductive bias of locality and weight\nsharing baked into their architecture. Existing attempts to quantify the\nstatistical benefits of these biases in CNNs over locally connected\nconvolutional neural networks (LCNs) and fully connected neural networks (FCNs)\nfall into one of the following categories: either they disregard the optimizer\nand only provide uniform convergence upper bounds with no separating lower\nbounds, or they consider simplistic tasks that do not truly mirror the locality\nand translation invariance as found in real-world vision tasks. To address\nthese deficiencies, we introduce the Dynamic Signal Distribution (DSD)\nclassification task that models an image as consisting of $k$ patches, each of\ndimension $d$, and the label is determined by a $d$-sparse signal vector that\ncan freely appear in any one of the $k$ patches. On this task, for any\northogonally equivariant algorithm like gradient descent, we prove that CNNs\nrequire $\\tilde{O}(k+d)$ samples, whereas LCNs require $\\Omega(kd)$ samples,\nestablishing the statistical advantages of weight sharing in translation\ninvariant tasks. Furthermore, LCNs need $\\tilde{O}(k(k+d))$ samples, compared\nto $\\Omega(k^2d)$ samples for FCNs, showcasing the benefits of locality in\nlocal tasks. Additionally, we develop information theoretic tools for analyzing\nrandomized algorithms, which may be of interest for statistical research.\n","authors":["Aakash Lahoti","Stefani Karp","Ezra Winston","Aarti Singh","Yuanzhi Li"],"pdf_url":"https://arxiv.org/pdf/2403.15707v1.pdf","comment":"40 pages, 4 figures, Accepted to ICLR 2024, Spotlight"}]},"2024-03-22T00:00:00Z":{"Multimedia":[{"id":"http://arxiv.org/abs/2403.15336v1","updated":"2024-03-22T16:41:45Z","published":"2024-03-22T16:41:45Z","title":"Dialogue Understandability: Why are we streaming movies with subtitles?","summary":"  Watching movies and TV shows with subtitles enabled is not simply down to\naudibility or speech intelligibility. A variety of evolving factors related to\ntechnological advances, cinema production and social behaviour challenge our\nperception and understanding. This study seeks to formalise and give context to\nthese influential factors under a wider and novel term referred to as Dialogue\nUnderstandability. We propose a working definition for Dialogue\nUnderstandability being a listener's capacity to follow the story without undue\ncognitive effort or concentration being required that impacts their Quality of\nExperience (QoE). The paper identifies, describes and categorises the factors\nthat influence Dialogue Understandability mapping them over the QoE framework,\na media streaming lifecycle, and the stakeholders involved. We then explore\navailable measurement tools in the literature and link them to the factors they\ncould potentially be used for. The maturity and suitability of these tools is\nevaluated over a set of pilot experiments. Finally, we reflect on the gaps that\nstill need to be filled, what we can measure and what not, future subjective\nexperiments, and new research trends that could help us to fully characterise\nDialogue Understandability.\n","authors":["Helard Becerra Martinez","Alessandro Ragano","Diptasree Debnath","Asad Ullah","Crisron Rudolf Lucas","Martin Walsh","Andrew Hines"],"pdf_url":"https://arxiv.org/pdf/2403.15336v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.15256v1","updated":"2024-03-22T14:57:12Z","published":"2024-03-22T14:57:12Z","title":"Experimental Studies of Metaverse Streaming","summary":"  Metaverse aims to construct a large, unified, immersive, and shared digital\nrealm by combining various technologies, namely XR (extended reality),\nblockchain, and digital twin, among others. This article explores the Metaverse\nfrom the perspective of multimedia communication by conducting and analyzing\nreal-world experiments on four different Metaverse platforms: VR (virtual\nreality) Vircadia, VR Mozilla Hubs, VRChat, and MR (mixed reality) Virtual\nCity. We first investigate the traffic patterns and network performance in the\nthree VR platforms. After raising the challenges of the Metaverse streaming and\ninvestigating the potential methods to enhance Metaverse performance, we\npropose a remote rendering architecture and verify its advantages through a\nprototype involving the campus network and MR multimodal interaction by\ncomparison with local rendering.\n","authors":["Haopeng Wang","Roberto Martinez-Velazquez","Haiwei Dong","Abdulmotaleb El Saddik"],"pdf_url":"https://arxiv.org/pdf/2403.15256v1.pdf","comment":"Accepted by IEEE Consumer Electronics Magazine"},{"id":"http://arxiv.org/abs/2308.04025v3","updated":"2024-03-22T14:49:31Z","published":"2023-08-08T03:43:24Z","title":"MSAC: Multiple Speech Attribute Control Method for Reliable Speech\n  Emotion Recognition","summary":"  Despite notable progress, speech emotion recognition (SER) remains\nchallenging due to the intricate and ambiguous nature of speech emotion,\nparticularly in wild world. While current studies primarily focus on\nrecognition and generalization abilities, our research pioneers an\ninvestigation into the reliability of SER methods in the presence of semantic\ndata shifts and explores how to exert fine-grained control over various\nattributes inherent in speech signals to enhance speech emotion modeling. In\nthis paper, we first introduce MSAC-SERNet, a novel unified SER framework\ncapable of simultaneously handling both single-corpus and cross-corpus SER.\nSpecifically, concentrating exclusively on the speech emotion attribute, a\nnovel CNN-based SER model is presented to extract discriminative emotional\nrepresentations, guided by additive margin softmax loss. Considering\ninformation overlap between various speech attributes, we propose a novel\nlearning paradigm based on correlations of different speech attributes, termed\nMultiple Speech Attribute Control (MSAC), which empowers the proposed SER model\nto simultaneously capture fine-grained emotion-related features while\nmitigating the negative impact of emotion-agnostic representations.\nFurthermore, we make a first attempt to examine the reliability of the\nMSAC-SERNet framework using out-of-distribution detection methods. Experiments\non both single-corpus and cross-corpus SER scenarios indicate that MSAC-SERNet\nnot only consistently outperforms the baseline in all aspects, but achieves\nsuperior performance compared to state-of-the-art SER approaches.\n","authors":["Yu Pan","Yuguang Yang","Yuheng Huang","Jixun Yao","Jingjing Yin","Yanni Hu","Heng Lu","Lei Ma","Jianjun Zhao"],"pdf_url":"https://arxiv.org/pdf/2308.04025v3.pdf","comment":"12 pages"},{"id":"http://arxiv.org/abs/2403.15226v1","updated":"2024-03-22T14:20:34Z","published":"2024-03-22T14:20:34Z","title":"Not All Attention is Needed: Parameter and Computation Efficient\n  Transfer Learning for Multi-modal Large Language Models","summary":"  In this paper, we propose a novel parameter and computation efficient tuning\nmethod for Multi-modal Large Language Models (MLLMs), termed Efficient\nAttention Skipping (EAS). Concretely, we first reveal that multi-head\nattentions (MHAs), the main computational overhead of MLLMs, are often\nredundant to downstream tasks. Based on this observation, EAS evaluates the\nattention redundancy and skips the less important MHAs to speed up inference.\nBesides, we also propose a novel propagation-of-information adapter (PIA) to\nserve the attention skipping of EAS and keep parameter efficiency, which can be\nfurther re-parameterized into feed-forward networks (FFNs) for zero-extra\nlatency. To validate EAS, we apply it to a recently proposed MLLM called LaVIN\nand a classic VL pre-trained model called METER, and conduct extensive\nexperiments on a set of benchmarks. The experiments show that EAS not only\nretains high performance and parameter efficiency, but also greatly speeds up\ninference speed. For instance, LaVIN-EAS can obtain 89.98\\% accuracy on\nScineceQA while speeding up inference by 2.2 times to LaVIN\n","authors":["Qiong Wu","Weihao Ye","Yiyi Zhou","Xiaoshuai Sun","Rongrong Ji"],"pdf_url":"https://arxiv.org/pdf/2403.15226v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.14899v2","updated":"2024-03-22T13:24:35Z","published":"2023-06-26T17:59:55Z","title":"FunQA: Towards Surprising Video Comprehension","summary":"  Surprising videos, such as funny clips, creative performances, or visual\nillusions, attract significant attention. Enjoyment of these videos is not\nsimply a response to visual stimuli; rather, it hinges on the human capacity to\nunderstand (and appreciate) commonsense violations depicted in these videos. We\nintroduce FunQA, a challenging video question-answering (QA) dataset\nspecifically designed to evaluate and enhance the depth of video reasoning\nbased on counter-intuitive and fun videos. Unlike most video QA benchmarks\nwhich focus on less surprising contexts, e.g., cooking or instructional videos,\nFunQA covers three previously unexplored types of surprising videos: 1)\nHumorQA, 2) CreativeQA, and 3) MagicQA. For each subset, we establish rigorous\nQA tasks designed to assess the model's capability in counter-intuitive\ntimestamp localization, detailed video description, and reasoning around\ncounter-intuitiveness. We also pose higher-level tasks, such as attributing a\nfitting and vivid title to the video and scoring the video creativity. In\ntotal, the FunQA benchmark consists of 312K free-text QA pairs derived from\n4.3K video clips, spanning a total of 24 video hours. Moreover, we propose\nFunMentor, an agent designed for Vision-Language Models (VLMs) that uses\nmulti-turn dialogues to enhance models' understanding of counter-intuitiveness.\nExtensive experiments with existing VLMs demonstrate the effectiveness of\nFunMentor and reveal significant performance gaps for the FunQA videos across\nspatial-temporal reasoning, visual-centered reasoning, and free-text\ngeneration.\n","authors":["Binzhu Xie","Sicheng Zhang","Zitang Zhou","Bo Li","Yuanhan Zhang","Jack Hessel","Jingkang Yang","Ziwei Liu"],"pdf_url":"https://arxiv.org/pdf/2306.14899v2.pdf","comment":"Project Page: https://funqa-benchmark.github.io/ Codebase:\n  https://github.com/Jingkang50/FunQA"},{"id":"http://arxiv.org/abs/2402.02733v3","updated":"2024-03-22T09:17:24Z","published":"2024-02-05T05:25:33Z","title":"ToonAging: Face Re-Aging upon Artistic Portrait Style Transfer","summary":"  Face re-aging is a prominent field in computer vision and graphics, with\nsignificant applications in photorealistic domains such as movies, advertising,\nand live streaming. Recently, the need to apply face re-aging to\nnon-photorealistic images, like comics, illustrations, and animations, has\nemerged as an extension in various entertainment sectors. However, the lack of\na network that can seamlessly edit the apparent age in NPR images has limited\nthese tasks to a naive, sequential approach. This often results in unpleasant\nartifacts and a loss of facial attributes due to domain discrepancies. In this\npaper, we introduce a novel one-stage method for face re-aging combined with\nportrait style transfer, executed in a single generative step. We leverage\nexisting face re-aging and style transfer networks, both trained within the\nsame PR domain. Our method uniquely fuses distinct latent vectors, each\nresponsible for managing aging-related attributes and NPR appearance. By\nadopting an exemplar-based approach, our method offers greater flexibility\ncompared to domain-level fine-tuning approaches, which typically require\nseparate training or fine-tuning for each domain. This effectively addresses\nthe limitation of requiring paired datasets for re-aging and domain-level,\ndata-driven approaches for stylization. Our experiments show that our model can\neffortlessly generate re-aged images while simultaneously transferring the\nstyle of examples, maintaining both natural appearance and controllability.\n","authors":["Bumsoo Kim","Abdul Muqeet","Kyuchul Lee","Sanghyun Seo"],"pdf_url":"https://arxiv.org/pdf/2402.02733v3.pdf","comment":"14 pages, 15 figures, 1 table"},{"id":"http://arxiv.org/abs/2403.11700v2","updated":"2024-03-22T08:13:11Z","published":"2024-03-18T11:56:35Z","title":"Virbo: Multimodal Multilingual Avatar Video Generation in Digital\n  Marketing","summary":"  With the widespread popularity of internet celebrity marketing all over the\nworld, short video production has gradually become a popular way of presenting\nproducts information. However, the traditional video production industry\nusually includes series of procedures as script writing, video filming in a\nprofessional studio, video clipping, special effects rendering, customized\npost-processing, and so forth. Not to mention that multilingual videos is not\naccessible for those who could not speak multilingual languages. These\ncomplicated procedures usually needs a professional team to complete, and this\nmade short video production costly in both time and money. This paper presents\nan intelligent system that supports the automatic generation of talking avatar\nvideos, namely Virbo. With simply a user-specified script, Virbo could use a\ndeep generative model to generate a target talking videos. Meanwhile, the\nsystem also supports multimodal inputs to customize the video with specified\nface, specified voice and special effects. This system also integrated a\nmultilingual customization module that supports generate multilingual talking\navatar videos in a batch with hundreds of delicate templates and creative\nspecial effects. Through a series of user studies and demo tests, we found that\nVirbo can generate talking avatar videos that maintained a high quality of\nvideos as those from a professional team while reducing the entire production\ncosts significantly. This intelligent system will effectively promote the video\nproduction industry and facilitate the internet marketing neglecting of\nlanguage barriers and cost challenges.\n","authors":["Juan Zhang","Jiahao Chen","Cheng Wang","Zhiwang Yu","Tangquan Qi","Can Liu","Di Wu"],"pdf_url":"https://arxiv.org/pdf/2403.11700v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.14972v1","updated":"2024-03-22T06:03:07Z","published":"2024-03-22T06:03:07Z","title":"A Picture Is Worth a Graph: Blueprint Debate on Graph for Multimodal\n  Reasoning","summary":"  This paper presents a pilot study aimed at introducing multi-agent debate\ninto multimodal reasoning. The study addresses two key challenges: the\ntrivialization of opinions resulting from excessive summarization and the\ndiversion of focus caused by distractor concepts introduced from images. These\nchallenges stem from the inductive (bottom-up) nature of existing debating\nschemes. To address the issue, we propose a deductive (top-down) debating\napproach called Blueprint Debate on Graphs (BDoG). In BDoG, debates are\nconfined to a blueprint graph to prevent opinion trivialization through\nworld-level summarization. Moreover, by storing evidence in branches within the\ngraph, BDoG mitigates distractions caused by frequent but irrelevant concepts.\nExtensive experiments validate BDoG, achieving state-of-the-art results in\nScience QA and MMBench with significant improvements over previous methods.\n","authors":["Changmeng Zheng","Dayong Liang","Wengyu Zhang","Xiao-Yong Wei","Tat-Seng Chua","Qing Li"],"pdf_url":"https://arxiv.org/pdf/2403.14972v1.pdf","comment":"Work in progress"},{"id":"http://arxiv.org/abs/2403.14468v2","updated":"2024-03-22T02:16:40Z","published":"2024-03-21T15:15:00Z","title":"AnyV2V: A Plug-and-Play Framework For Any Video-to-Video Editing Tasks","summary":"  Video-to-video editing involves editing a source video along with additional\ncontrol (such as text prompts, subjects, or styles) to generate a new video\nthat aligns with the source video and the provided control. Traditional methods\nhave been constrained to certain editing types, limiting their ability to meet\nthe wide range of user demands. In this paper, we introduce AnyV2V, a novel\ntraining-free framework designed to simplify video editing into two primary\nsteps: (1) employing an off-the-shelf image editing model (e.g.\nInstructPix2Pix, InstantID, etc) to modify the first frame, (2) utilizing an\nexisting image-to-video generation model (e.g. I2VGen-XL) for DDIM inversion\nand feature injection. In the first stage, AnyV2V can plug in any existing\nimage editing tools to support an extensive array of video editing tasks.\nBeyond the traditional prompt-based editing methods, AnyV2V also can support\nnovel video editing tasks, including reference-based style transfer,\nsubject-driven editing, and identity manipulation, which were unattainable by\nprevious methods. In the second stage, AnyV2V can plug in any existing\nimage-to-video models to perform DDIM inversion and intermediate feature\ninjection to maintain the appearance and motion consistency with the source\nvideo. On the prompt-based editing, we show that AnyV2V can outperform the\nprevious best approach by 35\\% on prompt alignment, and 25\\% on human\npreference. On the three novel tasks, we show that AnyV2V also achieves a high\nsuccess rate. We believe AnyV2V will continue to thrive due to its ability to\nseamlessly integrate the fast-evolving image editing methods. Such\ncompatibility can help AnyV2V to increase its versatility to cater to diverse\nuser demands.\n","authors":["Max Ku","Cong Wei","Weiming Ren","Harry Yang","Wenhu Chen"],"pdf_url":"https://arxiv.org/pdf/2403.14468v2.pdf","comment":"preprint"}],"Machine Learning 2":[{"id":"http://arxiv.org/abs/2401.11565v2","updated":"2024-03-22T21:33:47Z","published":"2024-01-21T18:57:38Z","title":"Thompson Sampling for Stochastic Bandits with Noisy Contexts: An\n  Information-Theoretic Regret Analysis","summary":"  We explore a stochastic contextual linear bandit problem where the agent\nobserves a noisy, corrupted version of the true context through a noise channel\nwith an unknown noise parameter. Our objective is to design an action policy\nthat can approximate\" that of an oracle, which has access to the reward model,\nthe channel parameter, and the predictive distribution of the true context from\nthe observed noisy context. In a Bayesian framework, we introduce a Thompson\nsampling algorithm for Gaussian bandits with Gaussian context noise. Adopting\nan information-theoretic analysis, we demonstrate the Bayesian regret of our\nalgorithm concerning the oracle's action policy. We also extend this problem to\na scenario where the agent observes the true context with some delay after\nreceiving the reward and show that delayed true contexts lead to lower Bayesian\nregret. Finally, we empirically demonstrate the performance of the proposed\nalgorithms against baselines.\n","authors":["Sharu Theresa Jose","Shana Moothedath"],"pdf_url":"https://arxiv.org/pdf/2401.11565v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.06721v3","updated":"2024-03-22T19:40:59Z","published":"2023-06-11T16:46:00Z","title":"Differentially Private Conditional Independence Testing","summary":"  Conditional independence (CI) tests are widely used in statistical data\nanalysis, e.g., they are the building block of many algorithms for causal graph\ndiscovery. The goal of a CI test is to accept or reject the null hypothesis\nthat $X \\perp \\!\\!\\! \\perp Y \\mid Z$, where $X \\in \\mathbb{R}, Y \\in\n\\mathbb{R}, Z \\in \\mathbb{R}^d$. In this work, we investigate conditional\nindependence testing under the constraint of differential privacy. We design\ntwo private CI testing procedures: one based on the generalized covariance\nmeasure of Shah and Peters (2020) and another based on the conditional\nrandomization test of Cand\\`es et al. (2016) (under the model-X assumption). We\nprovide theoretical guarantees on the performance of our tests and validate\nthem empirically. These are the first private CI tests with rigorous\ntheoretical guarantees that work for the general case when $Z$ is continuous.\n","authors":["Iden Kalemaj","Shiva Prasad Kasiviswanathan","Aaditya Ramdas"],"pdf_url":"https://arxiv.org/pdf/2306.06721v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2310.02710v2","updated":"2024-03-22T18:49:46Z","published":"2023-10-04T10:27:17Z","title":"Local Search GFlowNets","summary":"  Generative Flow Networks (GFlowNets) are amortized sampling methods that\nlearn a distribution over discrete objects proportional to their rewards.\nGFlowNets exhibit a remarkable ability to generate diverse samples, yet\noccasionally struggle to consistently produce samples with high rewards due to\nover-exploration on wide sample space. This paper proposes to train GFlowNets\nwith local search, which focuses on exploiting high-rewarded sample space to\nresolve this issue. Our main idea is to explore the local neighborhood via\nbacktracking and reconstruction guided by backward and forward policies,\nrespectively. This allows biasing the samples toward high-reward solutions,\nwhich is not possible for a typical GFlowNet solution generation scheme, which\nuses the forward policy to generate the solution from scratch. Extensive\nexperiments demonstrate a remarkable performance improvement in several\nbiochemical tasks. Source code is available:\n\\url{https://github.com/dbsxodud-11/ls_gfn}.\n","authors":["Minsu Kim","Taeyoung Yun","Emmanuel Bengio","Dinghuai Zhang","Yoshua Bengio","Sungsoo Ahn","Jinkyoo Park"],"pdf_url":"https://arxiv.org/pdf/2310.02710v2.pdf","comment":"ICLR 2024 (Spotlight paper), 18 pages, 17 figures"},{"id":"http://arxiv.org/abs/2306.03111v2","updated":"2024-03-22T18:43:38Z","published":"2023-06-05T08:23:46Z","title":"Bootstrapped Training of Score-Conditioned Generator for Offline Design\n  of Biological Sequences","summary":"  We study the problem of optimizing biological sequences, e.g., proteins, DNA,\nand RNA, to maximize a black-box score function that is only evaluated in an\noffline dataset. We propose a novel solution, bootstrapped training of\nscore-conditioned generator (BootGen) algorithm. Our algorithm repeats a\ntwo-stage process. In the first stage, our algorithm trains the biological\nsequence generator with rank-based weights to enhance the accuracy of sequence\ngeneration based on high scores. The subsequent stage involves bootstrapping,\nwhich augments the training dataset with self-generated data labeled by a proxy\nscore function. Our key idea is to align the score-based generation with a\nproxy score function, which distills the knowledge of the proxy score function\nto the generator. After training, we aggregate samples from multiple\nbootstrapped generators and proxies to produce a diverse design. Extensive\nexperiments show that our method outperforms competitive baselines on\nbiological sequential design tasks. We provide reproducible source code:\n\\href{https://github.com/kaist-silab/bootgen}{https://github.com/kaist-silab/bootgen}.\n","authors":["Minsu Kim","Federico Berto","Sungsoo Ahn","Jinkyoo Park"],"pdf_url":"https://arxiv.org/pdf/2306.03111v2.pdf","comment":"NeurIPS 2023, 19 pages, 5 figures"},{"id":"http://arxiv.org/abs/2309.16512v4","updated":"2024-03-22T17:26:53Z","published":"2023-09-28T15:19:30Z","title":"From Complexity to Clarity: Analytical Expressions of Deep Neural\n  Network Weights via Clifford's Geometric Algebra and Convexity","summary":"  In this paper, we introduce a novel analysis of neural networks based on\ngeometric (Clifford) algebra and convex optimization. We show that optimal\nweights of deep ReLU neural networks are given by the wedge product of training\nsamples when trained with standard regularized loss. Furthermore, the training\nproblem reduces to convex optimization over wedge product features, which\nencode the geometric structure of the training dataset. This structure is given\nin terms of signed volumes of triangles and parallelotopes generated by data\nvectors. The convex problem finds a small subset of samples via $\\ell_1$\nregularization to discover only relevant wedge product features. Our analysis\nprovides a novel perspective on the inner workings of deep neural networks and\nsheds light on the role of the hidden layers.\n","authors":["Mert Pilanci"],"pdf_url":"https://arxiv.org/pdf/2309.16512v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.02695v2","updated":"2024-03-22T17:00:40Z","published":"2023-11-05T16:05:00Z","title":"Identifying Linearly-Mixed Causal Representations from Multi-Node\n  Interventions","summary":"  The task of inferring high-level causal variables from low-level\nobservations, commonly referred to as causal representation learning, is\nfundamentally underconstrained. As such, recent works to address this problem\nfocus on various assumptions that lead to identifiability of the underlying\nlatent causal variables. A large corpus of these preceding approaches consider\nmulti-environment data collected under different interventions on the causal\nmodel. What is common to virtually all of these works is the restrictive\nassumption that in each environment, only a single variable is intervened on.\nIn this work, we relax this assumption and provide the first identifiability\nresult for causal representation learning that allows for multiple variables to\nbe targeted by an intervention within one environment. Our approach hinges on a\ngeneral assumption on the coverage and diversity of interventions across\nenvironments, which also includes the shared assumption of single-node\ninterventions of previous works. The main idea behind our approach is to\nexploit the trace that interventions leave on the variance of the ground truth\ncausal variables and regularizing for a specific notion of sparsity with\nrespect to this trace. In addition to and inspired by our theoretical\ncontributions, we present a practical algorithm to learn causal representations\nfrom multi-node interventional data and provide empirical evidence that\nvalidates our identifiability results.\n","authors":["Simon Bing","Urmi Ninad","Jonas Wahl","Jakob Runge"],"pdf_url":"https://arxiv.org/pdf/2311.02695v2.pdf","comment":"Accepted for publication at CLeaR 2024"},{"id":"http://arxiv.org/abs/2403.15312v1","updated":"2024-03-22T16:04:26Z","published":"2024-03-22T16:04:26Z","title":"A Wasserstein perspective of Vanilla GANs","summary":"  The empirical success of Generative Adversarial Networks (GANs) caused an\nincreasing interest in theoretical research. The statistical literature is\nmainly focused on Wasserstein GANs and generalizations thereof, which\nespecially allow for good dimension reduction properties. Statistical results\nfor Vanilla GANs, the original optimization problem, are still rather limited\nand require assumptions such as smooth activation functions and equal\ndimensions of the latent space and the ambient space. To bridge this gap, we\ndraw a connection from Vanilla GANs to the Wasserstein distance. By doing so,\nexisting results for Wasserstein GANs can be extended to Vanilla GANs. In\nparticular, we obtain an oracle inequality for Vanilla GANs in Wasserstein\ndistance. The assumptions of this oracle inequality are designed to be\nsatisfied by network architectures commonly used in practice, such as\nfeedforward ReLU networks. By providing a quantitative result for the\napproximation of a Lipschitz function by a feedforward ReLU network with\nbounded H\\\"older norm, we conclude a rate of convergence for Vanilla GANs as\nwell as Wasserstein GANs as estimators of the unknown probability distribution.\n","authors":["Lea Kunkel","Mathias Trabs"],"pdf_url":"https://arxiv.org/pdf/2403.15312v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.15527v1","updated":"2024-03-22T15:40:06Z","published":"2024-03-22T15:40:06Z","title":"Conformal online model aggregation","summary":"  Conformal prediction equips machine learning models with a reasonable notion\nof uncertainty quantification without making strong distributional assumptions.\nIt wraps around any black-box prediction model and converts point predictions\ninto set predictions that have a predefined marginal coverage guarantee.\nHowever, conformal prediction only works if we fix the underlying machine\nlearning model in advance. A relatively unaddressed issue in conformal\nprediction is that of model selection and/or aggregation: for a given problem,\nwhich of the plethora of prediction methods (random forests, neural nets,\nregularized linear models, etc.) should we conformalize? This paper proposes a\nnew approach towards conformal model aggregation in online settings that is\nbased on combining the prediction sets from several algorithms by voting, where\nweights on the models are adapted over time based on past performance.\n","authors":["Matteo Gasparin","Aaditya Ramdas"],"pdf_url":"https://arxiv.org/pdf/2403.15527v1.pdf","comment":"15 pages, 8 figures. arXiv admin note: substantial text overlap with\n  arXiv:2401.09379"},{"id":"http://arxiv.org/abs/2403.15263v1","updated":"2024-03-22T15:02:24Z","published":"2024-03-22T15:02:24Z","title":"Federated Bayesian Deep Learning: The Application of Statistical\n  Aggregation Methods to Bayesian Models","summary":"  Federated learning (FL) is an approach to training machine learning models\nthat takes advantage of multiple distributed datasets while maintaining data\nprivacy and reducing communication costs associated with sharing local\ndatasets. Aggregation strategies have been developed to pool or fuse the\nweights and biases of distributed deterministic models; however, modern\ndeterministic deep learning (DL) models are often poorly calibrated and lack\nthe ability to communicate a measure of epistemic uncertainty in prediction,\nwhich is desirable for remote sensing platforms and safety-critical\napplications. Conversely, Bayesian DL models are often well calibrated and\ncapable of quantifying and communicating a measure of epistemic uncertainty\nalong with a competitive prediction accuracy. Unfortunately, because the\nweights and biases in Bayesian DL models are defined by a probability\ndistribution, simple application of the aggregation methods associated with FL\nschemes for deterministic models is either impossible or results in sub-optimal\nperformance. In this work, we use independent and identically distributed (IID)\nand non-IID partitions of the CIFAR-10 dataset and a fully variational\nResNet-20 architecture to analyze six different aggregation strategies for\nBayesian DL models. Additionally, we analyze the traditional federated\naveraging approach applied to an approximate Bayesian Monte Carlo dropout model\nas a lightweight alternative to more complex variational inference methods in\nFL. We show that aggregation strategy is a key hyperparameter in the design of\na Bayesian FL system with downstream effects on accuracy, calibration,\nuncertainty quantification, training stability, and client compute\nrequirements.\n","authors":["John Fischer","Marko Orescanin","Justin Loomis","Patrick McClure"],"pdf_url":"https://arxiv.org/pdf/2403.15263v1.pdf","comment":"22 pages, 9 figures"},{"id":"http://arxiv.org/abs/2403.15175v1","updated":"2024-03-22T12:59:03Z","published":"2024-03-22T12:59:03Z","title":"Double Cross-fit Doubly Robust Estimators: Beyond Series Regression","summary":"  Doubly robust estimators with cross-fitting have gained popularity in causal\ninference due to their favorable structure-agnostic error guarantees. However,\nwhen additional structure, such as H\\\"{o}lder smoothness, is available then\nmore accurate \"double cross-fit doubly robust\" (DCDR) estimators can be\nconstructed by splitting the training data and undersmoothing nuisance function\nestimators on independent samples. We study a DCDR estimator of the Expected\nConditional Covariance, a functional of interest in causal inference and\nconditional independence testing, and derive a series of increasingly powerful\nresults with progressively stronger assumptions. We first provide a\nstructure-agnostic error analysis for the DCDR estimator with no assumptions on\nthe nuisance functions or their estimators. Then, assuming the nuisance\nfunctions are H\\\"{o}lder smooth, but without assuming knowledge of the true\nsmoothness level or the covariate density, we establish that DCDR estimators\nwith several linear smoothers are semiparametric efficient under minimal\nconditions and achieve fast convergence rates in the non-$\\sqrt{n}$ regime.\nWhen the covariate density and smoothnesses are known, we propose a minimax\nrate-optimal DCDR estimator based on undersmoothed kernel regression. Moreover,\nwe show an undersmoothed DCDR estimator satisfies a slower-than-$\\sqrt{n}$\ncentral limit theorem, and that inference is possible even in the\nnon-$\\sqrt{n}$ regime. Finally, we support our theoretical results with\nsimulations, providing intuition for double cross-fitting and undersmoothing,\ndemonstrating where our estimator achieves semiparametric efficiency while the\nusual \"single cross-fit\" estimator fails, and illustrating asymptotic normality\nfor the undersmoothed DCDR estimator.\n","authors":["Alec McClean","Sivaraman Balakrishnan","Edward H. Kennedy","Larry Wasserman"],"pdf_url":"https://arxiv.org/pdf/2403.15175v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.13185v2","updated":"2024-03-22T12:20:30Z","published":"2023-06-22T20:03:05Z","title":"An Agnostic View on the Cost of Overfitting in (Kernel) Ridge Regression","summary":"  We study the cost of overfitting in noisy kernel ridge regression (KRR),\nwhich we define as the ratio between the test error of the interpolating\nridgeless model and the test error of the optimally-tuned model. We take an\n\"agnostic\" view in the following sense: we consider the cost as a function of\nsample size for any target function, even if the sample size is not large\nenough for consistency or the target is outside the RKHS. We analyze the cost\nof overfitting under a Gaussian universality ansatz using recently derived\n(non-rigorous) risk estimates in terms of the task eigenstructure. Our analysis\nprovides a more refined characterization of benign, tempered and catastrophic\noverfitting (cf. Mallinar et al. 2022).\n","authors":["Lijia Zhou","James B. Simon","Gal Vardi","Nathan Srebro"],"pdf_url":"https://arxiv.org/pdf/2306.13185v2.pdf","comment":"This is the ICLR CR version"},{"id":"http://arxiv.org/abs/2312.16427v3","updated":"2024-03-22T12:05:02Z","published":"2023-12-27T06:23:29Z","title":"Learning to Embed Time Series Patches Independently","summary":"  Masked time series modeling has recently gained much attention as a\nself-supervised representation learning strategy for time series. Inspired by\nmasked image modeling in computer vision, recent works first patchify and\npartially mask out time series, and then train Transformers to capture the\ndependencies between patches by predicting masked patches from unmasked\npatches. However, we argue that capturing such patch dependencies might not be\nan optimal strategy for time series representation learning; rather, learning\nto embed patches independently results in better time series representations.\nSpecifically, we propose to use 1) the simple patch reconstruction task, which\nautoencode each patch without looking at other patches, and 2) the simple\npatch-wise MLP that embeds each patch independently. In addition, we introduce\ncomplementary contrastive learning to hierarchically capture adjacent time\nseries information efficiently. Our proposed method improves time series\nforecasting and classification performance compared to state-of-the-art\nTransformer-based models, while it is more efficient in terms of the number of\nparameters and training/inference time. Code is available at this repository:\nhttps://github.com/seunghan96/pits.\n","authors":["Seunghan Lee","Taeyoung Park","Kibok Lee"],"pdf_url":"https://arxiv.org/pdf/2312.16427v3.pdf","comment":"ICLR 2024"},{"id":"http://arxiv.org/abs/2312.16424v3","updated":"2024-03-22T12:02:42Z","published":"2023-12-27T06:15:00Z","title":"Soft Contrastive Learning for Time Series","summary":"  Contrastive learning has shown to be effective to learn representations from\ntime series in a self-supervised way. However, contrasting similar time series\ninstances or values from adjacent timestamps within a time series leads to\nignore their inherent correlations, which results in deteriorating the quality\nof learned representations. To address this issue, we propose SoftCLT, a simple\nyet effective soft contrastive learning strategy for time series. This is\nachieved by introducing instance-wise and temporal contrastive loss with soft\nassignments ranging from zero to one. Specifically, we define soft assignments\nfor 1) instance-wise contrastive loss by the distance between time series on\nthe data space, and 2) temporal contrastive loss by the difference of\ntimestamps. SoftCLT is a plug-and-play method for time series contrastive\nlearning that improves the quality of learned representations without bells and\nwhistles. In experiments, we demonstrate that SoftCLT consistently improves the\nperformance in various downstream tasks including classification,\nsemi-supervised learning, transfer learning, and anomaly detection, showing\nstate-of-the-art performance. Code is available at this repository:\nhttps://github.com/seunghan96/softclt.\n","authors":["Seunghan Lee","Taeyoung Park","Kibok Lee"],"pdf_url":"https://arxiv.org/pdf/2312.16424v3.pdf","comment":"ICLR 2024 Spotlight"},{"id":"http://arxiv.org/abs/2403.15123v1","updated":"2024-03-22T11:25:38Z","published":"2024-03-22T11:25:38Z","title":"Quantification using Permutation-Invariant Networks based on Histograms","summary":"  Quantification, also known as class prevalence estimation, is the supervised\nlearning task in which a model is trained to predict the prevalence of each\nclass in a given bag of examples. This paper investigates the application of\ndeep neural networks to tasks of quantification in scenarios where it is\npossible to apply a symmetric supervised approach that eliminates the need for\nclassification as an intermediary step, directly addressing the quantification\nproblem. Additionally, it discusses existing permutation-invariant layers\ndesigned for set processing and assesses their suitability for quantification.\nIn light of our analysis, we propose HistNetQ, a novel neural architecture that\nrelies on a permutation-invariant representation based on histograms that is\nspecially suited for quantification problems. Our experiments carried out in\nthe only quantification competition held to date, show that HistNetQ\noutperforms other deep neural architectures devised for set processing, as well\nas the state-of-the-art quantification methods. Furthermore, HistNetQ offers\ntwo significant advantages over traditional quantification methods: i) it does\nnot require the labels of the training examples but only the prevalence values\nof a collection of training bags, making it applicable to new scenarios; and\nii) it is able to optimize any custom quantification-oriented loss function.\n","authors":["Olaya P√©rez-Mon","Alejandro Moreo","Juan Jos√© del Coz","Pablo Gonz√°lez"],"pdf_url":"https://arxiv.org/pdf/2403.15123v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2210.06015v4","updated":"2024-03-22T10:59:43Z","published":"2022-10-12T08:39:35Z","title":"EC-NAS: Energy Consumption Aware Tabular Benchmarks for Neural\n  Architecture Search","summary":"  Energy consumption from the selection, training, and deployment of deep\nlearning models has seen a significant uptick recently. This work aims to\nfacilitate the design of energy-efficient deep learning models that require\nless computational resources and prioritize environmental sustainability by\nfocusing on the energy consumption. Neural architecture search (NAS) benefits\nfrom tabular benchmarks, which evaluate NAS strategies cost-effectively through\nprecomputed performance statistics. We advocate for including energy efficiency\nas an additional performance criterion in NAS. To this end, we introduce an\nenhanced tabular benchmark encompassing data on energy consumption for varied\narchitectures. The benchmark, designated as EC-NAS, has been made available in\nan open-source format to advance research in energy-conscious NAS. EC-NAS\nincorporates a surrogate model to predict energy consumption, aiding in\ndiminishing the energy expenditure of the dataset creation. Our findings\nemphasize the potential of EC-NAS by leveraging multi-objective optimization\nalgorithms, revealing a balance between energy usage and accuracy. This\nsuggests the feasibility of identifying energy-lean architectures with little\nor no compromise in performance.\n","authors":["Pedram Bakhtiarifard","Christian Igel","Raghavendra Selvan"],"pdf_url":"https://arxiv.org/pdf/2210.06015v4.pdf","comment":"Accepted to be presented at the International Conference on\n  Acoustics, Speech and Signal Processing (ICASSP-2024). Source code at\n  https://github.com/saintslab/EC-NAS-Bench"},{"id":"http://arxiv.org/abs/2403.15108v1","updated":"2024-03-22T10:51:55Z","published":"2024-03-22T10:51:55Z","title":"Active Learning for Regression based on Wasserstein distance and\n  GroupSort Neural Networks","summary":"  This paper addresses a new active learning strategy for regression problems.\nThe presented Wasserstein active regression model is based on the principles of\ndistribution-matching to measure the representativeness of the labeled dataset.\nThe Wasserstein distance is computed using GroupSort Neural Networks. The use\nof such networks provides theoretical foundations giving a way to quantify\nerrors with explicit bounds for their size and depth. This solution is combined\nwith another uncertainty-based approach that is more outlier-tolerant to\ncomplete the query strategy. Finally, this method is compared with other\nclassical and recent solutions. The study empirically shows the pertinence of\nsuch a representativity-uncertainty approach, which provides good estimation\nall along the query procedure. Moreover, the Wasserstein active regression\noften achieves more precise estimations and tends to improve accuracy faster\nthan other models.\n","authors":["Benjamin Bobbia","Matthias Picard"],"pdf_url":"https://arxiv.org/pdf/2403.15108v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.15038v1","updated":"2024-03-22T08:42:41Z","published":"2024-03-22T08:42:41Z","title":"Estimation of multiple mean vectors in high dimension","summary":"  We endeavour to estimate numerous multi-dimensional means of various\nprobability distributions on a common space based on independent samples. Our\napproach involves forming estimators through convex combinations of empirical\nmeans derived from these samples. We introduce two strategies to find\nappropriate data-dependent convex combination weights: a first one employing a\ntesting procedure to identify neighbouring means with low variance, which\nresults in a closed-form plug-in formula for the weights, and a second one\ndetermining weights via minimization of an upper confidence bound on the\nquadratic risk.Through theoretical analysis, we evaluate the improvement in\nquadratic risk offered by our methods compared to the empirical means. Our\nanalysis focuses on a dimensional asymptotics perspective, showing that our\nmethods asymptotically approach an oracle (minimax) improvement as the\neffective dimension of the data increases.We demonstrate the efficacy of our\nmethods in estimating multiple kernel mean embeddings through experiments on\nboth simulated and real-world datasets.\n","authors":["Gilles Blanchard","Jean-Baptiste Fermanian","Hannah Marienwald"],"pdf_url":"https://arxiv.org/pdf/2403.15038v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2308.11838v6","updated":"2024-03-22T08:42:14Z","published":"2023-08-23T00:10:29Z","title":"A Benchmark Study on Calibration","summary":"  Deep neural networks are increasingly utilized in various machine learning\ntasks. However, as these models grow in complexity, they often face calibration\nissues, despite enhanced prediction accuracy. Many studies have endeavored to\nimprove calibration performance through the use of specific loss functions,\ndata preprocessing and training frameworks. Yet, investigations into\ncalibration properties have been somewhat overlooked. Our study leverages the\nNeural Architecture Search (NAS) search space, offering an exhaustive model\narchitecture space for thorough calibration properties exploration. We\nspecifically create a model calibration dataset. This dataset evaluates 90\nbin-based and 12 additional calibration measurements across 117,702 unique\nneural networks within the widely employed NATS-Bench search space. Our\nanalysis aims to answer several longstanding questions in the field, using our\nproposed dataset: (i) Can model calibration be generalized across different\ndatasets? (ii) Can robustness be used as a calibration measurement? (iii) How\nreliable are calibration metrics? (iv) Does a post-hoc calibration method\naffect all models uniformly? (v) How does calibration interact with accuracy?\n(vi) What is the impact of bin size on calibration measurement? (vii) Which\narchitectural designs are beneficial for calibration? Additionally, our study\nbridges an existing gap by exploring calibration within NAS. By providing this\ndataset, we enable further research into NAS calibration. As far as we are\naware, our research represents the first large-scale investigation into\ncalibration properties and the premier study of calibration issues within NAS.\nThe project page can be found at https://www.taolinwei.com/calibration-study\n","authors":["Linwei Tao","Younan Zhu","Haolan Guo","Minjing Dong","Chang Xu"],"pdf_url":"https://arxiv.org/pdf/2308.11838v6.pdf","comment":"ICLR 2024 poster"},{"id":"http://arxiv.org/abs/2403.15025v1","updated":"2024-03-22T08:13:33Z","published":"2024-03-22T08:13:33Z","title":"Robust Conformal Prediction under Distribution Shift via\n  Physics-Informed Structural Causal Model","summary":"  Uncertainty is critical to reliable decision-making with machine learning.\nConformal prediction (CP) handles uncertainty by predicting a set on a test\ninput, hoping the set to cover the true label with at least $(1-\\alpha)$\nconfidence. This coverage can be guaranteed on test data even if the marginal\ndistributions $P_X$ differ between calibration and test datasets. However, as\nit is common in practice, when the conditional distribution $P_{Y|X}$ is\ndifferent on calibration and test data, the coverage is not guaranteed and it\nis essential to measure and minimize the coverage loss under distributional\nshift at \\textit{all} possible confidence levels. To address these issues, we\nupper bound the coverage difference at all levels using the cumulative density\nfunctions of calibration and test conformal scores and Wasserstein distance.\nInspired by the invariance of physics across data distributions, we propose a\nphysics-informed structural causal model (PI-SCM) to reduce the upper bound. We\nvalidated that PI-SCM can improve coverage robustness along confidence level\nand test domain on a traffic speed prediction task and an epidemic spread task\nwith multiple real-world datasets.\n","authors":["Rui Xu","Yue Sun","Chao Chen","Parv Venkitasubramaniam","Sihong Xie"],"pdf_url":"https://arxiv.org/pdf/2403.15025v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.15012v1","updated":"2024-03-22T07:56:31Z","published":"2024-03-22T07:56:31Z","title":"Empirical investigation of multi-source cross-validation in clinical\n  machine learning","summary":"  Traditionally, machine learning-based clinical prediction models have been\ntrained and evaluated on patient data from a single source, such as a hospital.\nCross-validation methods can be used to estimate the accuracy of such models on\nnew patients originating from the same source, by repeated random splitting of\nthe data. However, such estimates tend to be highly overoptimistic when\ncompared to accuracy obtained from deploying models to sources not represented\nin the dataset, such as a new hospital. The increasing availability of\nmulti-source medical datasets provides new opportunities for obtaining more\ncomprehensive and realistic evaluations of expected accuracy through\nsource-level cross-validation designs.\n  In this study, we present a systematic empirical evaluation of standard\nK-fold cross-validation and leave-source-out cross-validation methods in a\nmulti-source setting. We consider the task of electrocardiogram based\ncardiovascular disease classification, combining and harmonizing the openly\navailable PhysioNet CinC Challenge 2021 and the Shandong Provincial Hospital\ndatasets for our study.\n  Our results show that K-fold cross-validation, both on single-source and\nmulti-source data, systemically overestimates prediction performance when the\nend goal is to generalize to new sources. Leave-source-out cross-validation\nprovides more reliable performance estimates, having close to zero bias though\nlarger variability. The evaluation highlights the dangers of obtaining\nmisleading cross-validation results on medical data and demonstrates how these\nissues can be mitigated when having access to multi-source data.\n","authors":["Tuija Leinonen","David Wong","Ali Wahab","Ramesh Nadarajah","Matti Kaisti","Antti Airola"],"pdf_url":"https://arxiv.org/pdf/2403.15012v1.pdf","comment":"14 pages, 3 figures"},{"id":"http://arxiv.org/abs/1808.07840v2","updated":"2024-03-22T07:27:29Z","published":"2018-08-23T16:55:53Z","title":"Learning to Importance Sample in Primary Sample Space","summary":"  Importance sampling is one of the most widely used variance reduction\nstrategies in Monte Carlo rendering. In this paper, we propose a novel\nimportance sampling technique that uses a neural network to learn how to sample\nfrom a desired density represented by a set of samples. Our approach considers\nan existing Monte Carlo rendering algorithm as a black box. During a\nscene-dependent training phase, we learn to generate samples with a desired\ndensity in the primary sample space of the rendering algorithm using maximum\nlikelihood estimation. We leverage a recent neural network architecture that\nwas designed to represent real-valued non-volume preserving ('Real NVP')\ntransformations in high dimensional spaces. We use Real NVP to non-linearly\nwarp primary sample space and obtain desired densities. In addition, Real NVP\nefficiently computes the determinant of the Jacobian of the warp, which is\nrequired to implement the change of integration variables implied by the warp.\nA main advantage of our approach is that it is agnostic of underlying light\ntransport effects, and can be combined with many existing rendering techniques\nby treating them as a black box. We show that our approach leads to effective\nvariance reduction in several practical scenarios.\n","authors":["Quan Zheng","Matthias Zwicker"],"pdf_url":"https://arxiv.org/pdf/1808.07840v2.pdf","comment":"11 pages, 14 figure; authors' version, the definitive version of\n  record is available at https://onlinelibrary.wiley.com/doi/10.1111/cgf.13628"},{"id":"http://arxiv.org/abs/2402.15213v2","updated":"2024-03-22T07:26:48Z","published":"2024-02-23T09:19:26Z","title":"Statistical Agnostic Regression: a machine learning method to validate\n  regression models","summary":"  Regression analysis is a central topic in statistical modeling, aiming to\nestimate the relationships between a dependent variable, commonly referred to\nas the response variable, and one or more independent variables, i.e.,\nexplanatory variables. Linear regression is by far the most popular method for\nperforming this task in several fields of research, such as prediction,\nforecasting, or causal inference. Beyond various classical methods to solve\nlinear regression problems, such as Ordinary Least Squares, Ridge, or Lasso\nregressions - which are often the foundation for more advanced machine learning\n(ML) techniques - the latter have been successfully applied in this scenario\nwithout a formal definition of statistical significance. At most, permutation\nor classical analyses based on empirical measures (e.g., residuals or accuracy)\nhave been conducted to reflect the greater ability of ML estimations for\ndetection. In this paper, we introduce a method, named Statistical Agnostic\nRegression (SAR), for evaluating the statistical significance of an ML-based\nlinear regression based on concentration inequalities of the actual risk using\nthe analysis of the worst case. To achieve this goal, similar to the\nclassification problem, we define a threshold to establish that there is\nsufficient evidence with a probability of at least 1-eta to conclude that there\nis a linear relationship in the population between the explanatory (feature)\nand the response (label) variables. Simulations in only two dimensions\ndemonstrate the ability of the proposed agnostic test to provide a similar\nanalysis of variance given by the classical $F$ test for the slope parameter.\n","authors":["Juan M Gorriz","J. Ramirez","F. Segovia","F. J. Martinez-Murcia","C. Jim√©nez-Mesa","J. Suckling"],"pdf_url":"https://arxiv.org/pdf/2402.15213v2.pdf","comment":"17 pages, 15 figures"},{"id":"http://arxiv.org/abs/2309.06985v2","updated":"2024-03-22T06:37:39Z","published":"2023-09-13T14:20:22Z","title":"CARE: Large Precision Matrix Estimation for Compositional Data","summary":"  High-dimensional compositional data are prevalent in many applications. The\nsimplex constraint poses intrinsic challenges to inferring the conditional\ndependence relationships among the components forming a composition, as encoded\nby a large precision matrix. We introduce a precise specification of the\ncompositional precision matrix and relate it to its basis counterpart, which is\nshown to be asymptotically identifiable under suitable sparsity assumptions. By\nexploiting this connection, we propose a composition adaptive regularized\nestimation (CARE) method for estimating the sparse basis precision matrix. We\nderive rates of convergence for the estimator and provide theoretical\nguarantees on support recovery and data-driven parameter tuning. Our theory\nreveals an intriguing trade-off between identification and estimation, thereby\nhighlighting the blessing of dimensionality in compositional data analysis. In\nparticular, in sufficiently high dimensions, the CARE estimator achieves\nminimax optimality and performs as well as if the basis were observed. We\nfurther discuss how our framework can be extended to handle data containing\nzeros, including sampling zeros and structural zeros. The advantages of CARE\nover existing methods are illustrated by simulation studies and an application\nto inferring microbial ecological networks in the human gut.\n","authors":["Shucong Zhang","Huiyuan Wang","Wei Lin"],"pdf_url":"https://arxiv.org/pdf/2309.06985v2.pdf","comment":"67 pages, 7 figures, to appear in Journal of the American Statistical\n  Association (http://www.tandfonline.com/r/JASA)"},{"id":"http://arxiv.org/abs/2312.09016v2","updated":"2024-03-22T04:12:08Z","published":"2023-12-14T15:06:48Z","title":"Symmetry Breaking and Equivariant Neural Networks","summary":"  Using symmetry as an inductive bias in deep learning has been proven to be a\nprincipled approach for sample-efficient model design. However, the\nrelationship between symmetry and the imperative for equivariance in neural\nnetworks is not always obvious. Here, we analyze a key limitation that arises\nin equivariant functions: their incapacity to break symmetry at the level of\nindividual data samples. In response, we introduce a novel notion of 'relaxed\nequivariance' that circumvents this limitation. We further demonstrate how to\nincorporate this relaxation into equivariant multilayer perceptrons (E-MLPs),\noffering an alternative to the noise-injection method. The relevance of\nsymmetry breaking is then discussed in various application domains: physics,\ngraph representation learning, combinatorial optimization and equivariant\ndecoding.\n","authors":["S√©kou-Oumar Kaba","Siamak Ravanbakhsh"],"pdf_url":"https://arxiv.org/pdf/2312.09016v2.pdf","comment":"14 pages, 2 figures, Symmetry and Geometry in Neural Representations"},{"id":"http://arxiv.org/abs/2403.14926v1","updated":"2024-03-22T03:01:42Z","published":"2024-03-22T03:01:42Z","title":"Contrastive Learning on Multimodal Analysis of Electronic Health Records","summary":"  Electronic health record (EHR) systems contain a wealth of multimodal\nclinical data including structured data like clinical codes and unstructured\ndata such as clinical notes. However, many existing EHR-focused studies has\ntraditionally either concentrated on an individual modality or merged different\nmodalities in a rather rudimentary fashion. This approach often results in the\nperception of structured and unstructured data as separate entities, neglecting\nthe inherent synergy between them. Specifically, the two important modalities\ncontain clinically relevant, inextricably linked and complementary health\ninformation. A more complete picture of a patient's medical history is captured\nby the joint analysis of the two modalities of data. Despite the great success\nof multimodal contrastive learning on vision-language, its potential remains\nunder-explored in the realm of multimodal EHR, particularly in terms of its\ntheoretical understanding. To accommodate the statistical analysis of\nmultimodal EHR data, in this paper, we propose a novel multimodal feature\nembedding generative model and design a multimodal contrastive loss to obtain\nthe multimodal EHR feature representation. Our theoretical analysis\ndemonstrates the effectiveness of multimodal learning compared to\nsingle-modality learning and connects the solution of the loss function to the\nsingular value decomposition of a pointwise mutual information matrix. This\nconnection paves the way for a privacy-preserving algorithm tailored for\nmultimodal EHR feature representation learning. Simulation studies show that\nthe proposed algorithm performs well under a variety of configurations. We\nfurther validate the clinical utility of the proposed algorithm in real-world\nEHR data.\n","authors":["Tianxi Cai","Feiqing Huang","Ryumei Nakada","Linjun Zhang","Doudou Zhou"],"pdf_url":"https://arxiv.org/pdf/2403.14926v1.pdf","comment":"34 pages"},{"id":"http://arxiv.org/abs/2403.14917v1","updated":"2024-03-22T02:41:57Z","published":"2024-03-22T02:41:57Z","title":"Mean-field Analysis on Two-layer Neural Networks from a Kernel\n  Perspective","summary":"  In this paper, we study the feature learning ability of two-layer neural\nnetworks in the mean-field regime through the lens of kernel methods. To focus\non the dynamics of the kernel induced by the first layer, we utilize a\ntwo-timescale limit, where the second layer moves much faster than the first\nlayer. In this limit, the learning problem is reduced to the minimization\nproblem over the intrinsic kernel. Then, we show the global convergence of the\nmean-field Langevin dynamics and derive time and particle discretization error.\nWe also demonstrate that two-layer neural networks can learn a union of\nmultiple reproducing kernel Hilbert spaces more efficiently than any kernel\nmethods, and neural networks acquire data-dependent kernel which aligns with\nthe target function. In addition, we develop a label noise procedure, which\nconverges to the global optimum and show that the degrees of freedom appears as\nan implicit regularization.\n","authors":["Shokichi Takakura","Taiji Suzuki"],"pdf_url":"https://arxiv.org/pdf/2403.14917v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.06370v4","updated":"2024-03-22T02:30:02Z","published":"2022-12-13T05:03:16Z","title":"Dual Accuracy-Quality-Driven Neural Network for Prediction Interval\n  Generation","summary":"  Accurate uncertainty quantification is necessary to enhance the reliability\nof deep learning models in real-world applications. In the case of regression\ntasks, prediction intervals (PIs) should be provided along with the\ndeterministic predictions of deep learning models. Such PIs are useful or\n\"high-quality\" as long as they are sufficiently narrow and capture most of the\nprobability density. In this paper, we present a method to learn prediction\nintervals for regression-based neural networks automatically in addition to the\nconventional target predictions. In particular, we train two companion neural\nnetworks: one that uses one output, the target estimate, and another that uses\ntwo outputs, the upper and lower bounds of the corresponding PI. Our main\ncontribution is the design of a novel loss function for the PI-generation\nnetwork that takes into account the output of the target-estimation network and\nhas two optimization objectives: minimizing the mean prediction interval width\nand ensuring the PI integrity using constraints that maximize the prediction\ninterval probability coverage implicitly. Furthermore, we introduce a\nself-adaptive coefficient that balances both objectives within the loss\nfunction, which alleviates the task of fine-tuning. Experiments using a\nsynthetic dataset, eight benchmark datasets, and a real-world crop yield\nprediction dataset showed that our method was able to maintain a nominal\nprobability coverage and produce significantly narrower PIs without detriment\nto its target estimation accuracy when compared to those PIs generated by three\nstate-of-the-art neural-network-based methods. In other words, our method was\nshown to produce higher-quality PIs.\n","authors":["Giorgio Morales","John W. Sheppard"],"pdf_url":"https://arxiv.org/pdf/2212.06370v4.pdf","comment":"Accepted at the IEEE Transactions on Neural Networks and Learning\n  Systems"},{"id":"http://arxiv.org/abs/2401.14591v6","updated":"2024-03-22T01:51:51Z","published":"2024-01-26T01:36:48Z","title":"Ricci flow-guided autoencoders in learning time-dependent dynamics","summary":"  We present a manifold-based autoencoder method for learning nonlinear\ndynamics in time, notably partial differential equations (PDEs), in which the\nmanifold latent space evolves according to Ricci flow. This can be accomplished\nby simulating Ricci flow in a physics-informed setting, and manifold quantities\ncan be matched so that Ricci flow is empirically achieved. With our\nmethodology, the manifold is learned as part of the training procedure, so\nideal geometries may be discerned, while the evolution simultaneously induces a\nmore accommodating latent representation over static methods. We present our\nmethod on a range of numerical experiments consisting of PDEs that encompass\ndesirable characteristics such as periodicity and randomness, remarking error\non in-distribution and extrapolation scenarios.\n","authors":["Andrew Gracyk"],"pdf_url":"https://arxiv.org/pdf/2401.14591v6.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.14899v1","updated":"2024-03-22T01:06:36Z","published":"2024-03-22T01:06:36Z","title":"Statistical Inference For Noisy Matrix Completion Incorporating\n  Auxiliary Information","summary":"  This paper investigates statistical inference for noisy matrix completion in\na semi-supervised model when auxiliary covariates are available. The model\nconsists of two parts. One part is a low-rank matrix induced by unobserved\nlatent factors; the other part models the effects of the observed covariates\nthrough a coefficient matrix which is composed of high-dimensional column\nvectors. We model the observational pattern of the responses through a logistic\nregression of the covariates, and allow its probability to go to zero as the\nsample size increases. We apply an iterative least squares (LS) estimation\napproach in our considered context. The iterative LS methods in general enjoy a\nlow computational cost, but deriving the statistical properties of the\nresulting estimators is a challenging task. We show that our method only needs\na few iterations, and the resulting entry-wise estimators of the low-rank\nmatrix and the coefficient matrix are guaranteed to have asymptotic normal\ndistributions. As a result, individual inference can be conducted for each\nentry of the unknown matrices. We also propose a simultaneous testing procedure\nwith multiplier bootstrap for the high-dimensional coefficient matrix. This\nsimultaneous inferential tool can help us further investigate the effects of\ncovariates for the prediction of missing entries.\n","authors":["Shujie Ma","Po-Yao Niu","Yichong Zhang","Yinchu Zhu"],"pdf_url":"https://arxiv.org/pdf/2403.14899v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.10270v2","updated":"2024-03-22T00:08:51Z","published":"2023-11-17T01:30:43Z","title":"Multiscale Hodge Scattering Networks for Data Analysis","summary":"  We propose new scattering networks for signals measured on simplicial\ncomplexes, which we call \\emph{Multiscale Hodge Scattering Networks} (MHSNs).\nOur construction is based on multiscale basis dictionaries on simplicial\ncomplexes, i.e., the $\\kappa$-GHWT and $\\kappa$-HGLET, which we recently\ndeveloped for simplices of dimension $\\kappa \\in \\mathbb{N}$ in a given\nsimplicial complex by generalizing the node-based Generalized Haar-Walsh\nTransform (GHWT) and Hierarchical Graph Laplacian Eigen Transform (HGLET). The\n$\\kappa$-GHWT and the $\\kappa$-HGLET both form redundant sets (i.e.,\ndictionaries) of multiscale basis vectors and the corresponding expansion\ncoefficients of a given signal. Our MHSNs use a layered structure analogous to\na convolutional neural network (CNN) to cascade the moments of the modulus of\nthe dictionary coefficients. The resulting features are invariant to reordering\nof the simplices (i.e., node permutation of the underlying graphs).\nImportantly, the use of multiscale basis dictionaries in our MHSNs admits a\nnatural pooling operation that is akin to local pooling in CNNs, and which may\nbe performed either locally or per-scale. These pooling operations are harder\nto define in both traditional scattering networks based on Morlet wavelets, and\ngeometric scattering networks based on Diffusion Wavelets. As a result, we are\nable to extract a rich set of descriptive yet robust features that can be used\nalong with very simple machine learning methods (i.e., logistic regression or\nsupport vector machines) to achieve high-accuracy classification systems with\nfar fewer parameters to train than most modern graph neural networks. Finally,\nwe demonstrate the usefulness of our MHSNs in three distinct types of problems:\nsignal classification, domain (i.e., graph/simplex) classification, and\nmolecular dynamics prediction.\n","authors":["Naoki Saito","Stefan C. Schonsheck","Eugene Shvarts"],"pdf_url":"https://arxiv.org/pdf/2311.10270v2.pdf","comment":"20 Pages, Comments Welcome"}]},"2024-03-21T00:00:00Z":{"Multimedia":[{"id":"http://arxiv.org/abs/2403.14773v1","updated":"2024-03-21T18:27:29Z","published":"2024-03-21T18:27:29Z","title":"StreamingT2V: Consistent, Dynamic, and Extendable Long Video Generation\n  from Text","summary":"  Text-to-video diffusion models enable the generation of high-quality videos\nthat follow text instructions, making it easy to create diverse and individual\ncontent. However, existing approaches mostly focus on high-quality short video\ngeneration (typically 16 or 24 frames), ending up with hard-cuts when naively\nextended to the case of long video synthesis. To overcome these limitations, we\nintroduce StreamingT2V, an autoregressive approach for long video generation of\n80, 240, 600, 1200 or more frames with smooth transitions. The key components\nare:(i) a short-term memory block called conditional attention module (CAM),\nwhich conditions the current generation on the features extracted from the\nprevious chunk via an attentional mechanism, leading to consistent chunk\ntransitions, (ii) a long-term memory block called appearance preservation\nmodule, which extracts high-level scene and object features from the first\nvideo chunk to prevent the model from forgetting the initial scene, and (iii) a\nrandomized blending approach that enables to apply a video enhancer\nautoregressively for infinitely long videos without inconsistencies between\nchunks. Experiments show that StreamingT2V generates high motion amount. In\ncontrast, all competing image-to-video methods are prone to video stagnation\nwhen applied naively in an autoregressive manner. Thus, we propose with\nStreamingT2V a high-quality seamless text-to-long video generator that\noutperforms competitors with consistency and motion. Our code will be available\nat: https://github.com/Picsart-AI-Research/StreamingT2V\n","authors":["Roberto Henschel","Levon Khachatryan","Daniil Hayrapetyan","Hayk Poghosyan","Vahram Tadevosyan","Zhangyang Wang","Shant Navasardyan","Humphrey Shi"],"pdf_url":"https://arxiv.org/pdf/2403.14773v1.pdf","comment":"https://github.com/Picsart-AI-Research/StreamingT2V"},{"id":"http://arxiv.org/abs/2403.14449v1","updated":"2024-03-21T14:56:46Z","published":"2024-03-21T14:56:46Z","title":"Bringing Robots Home: The Rise of AI Robots in Consumer Electronics","summary":"  On March 18, 2024, NVIDIA unveiled Project GR00T, a general-purpose\nmultimodal generative AI model designed specifically for training humanoid\nrobots. Preceding this event, Tesla's unveiling of the Optimus Gen 2 humanoid\nrobot on December 12, 2023, underscored the profound impact robotics is poised\nto have on reshaping various facets of our daily lives. While robots have long\ndominated industrial settings, their presence within our homes is a burgeoning\nphenomenon. This can be attributed, in part, to the complexities of domestic\nenvironments and the challenges of creating robots that can seamlessly\nintegrate into our daily routines.\n","authors":["Haiwei Dong","Yang Liu","Ted Chu","Abdulmotaleb El Saddik"],"pdf_url":"https://arxiv.org/pdf/2403.14449v1.pdf","comment":"Accepted by IEEE Consumer Electronics Magazine"},{"id":"http://arxiv.org/abs/2301.12831v3","updated":"2024-03-21T05:39:44Z","published":"2023-01-30T12:37:04Z","title":"M3FAS: An Accurate and Robust MultiModal Mobile Face Anti-Spoofing\n  System","summary":"  Face presentation attacks (FPA), also known as face spoofing, have brought\nincreasing concerns to the public through various malicious applications, such\nas financial fraud and privacy leakage. Therefore, safeguarding face\nrecognition systems against FPA is of utmost importance. Although existing\nlearning-based face anti-spoofing (FAS) models can achieve outstanding\ndetection performance, they lack generalization capability and suffer\nsignificant performance drops in unforeseen environments. Many methodologies\nseek to use auxiliary modality data (e.g., depth and infrared maps) during the\npresentation attack detection (PAD) to address this limitation. However, these\nmethods can be limited since (1) they require specific sensors such as depth\nand infrared cameras for data capture, which are rarely available on commodity\nmobile devices, and (2) they cannot work properly in practical scenarios when\neither modality is missing or of poor quality. In this paper, we devise an\naccurate and robust MultiModal Mobile Face Anti-Spoofing system named M3FAS to\novercome the issues above. The primary innovation of this work lies in the\nfollowing aspects: (1) To achieve robust PAD, our system combines visual and\nauditory modalities using three commonly available sensors: camera, speaker,\nand microphone; (2) We design a novel two-branch neural network with three\nhierarchical feature aggregation modules to perform cross-modal feature fusion;\n(3). We propose a multi-head training strategy, allowing the model to output\npredictions from the vision, acoustic, and fusion heads, resulting in a more\nflexible PAD. Extensive experiments have demonstrated the accuracy, robustness,\nand flexibility of M3FAS under various challenging experimental settings. The\nsource code and dataset are available at: https://github.com/ChenqiKONG/M3FAS/\n","authors":["Chenqi Kong","Kexin Zheng","Yibing Liu","Shiqi Wang","Anderson Rocha","Haoliang Li"],"pdf_url":"https://arxiv.org/pdf/2301.12831v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2309.06255v3","updated":"2024-03-21T03:21:24Z","published":"2023-09-12T14:16:34Z","title":"Enhancing Multimodal Cooperation via Fine-grained Modality Valuation","summary":"  One primary topic of multimodal learning is to jointly incorporate\nheterogeneous information from different modalities. However, most models often\nsuffer from unsatisfactory multimodal cooperation, which cannot jointly utilize\nall modalities well. Some methods are proposed to identify and enhance the\nworse learnt modality, but they are often hard to provide the fine-grained\nobservation of multimodal cooperation at sample-level with theoretical support.\nHence, it is essential to reasonably observe and improve the fine-grained\ncooperation between modalities, especially when facing realistic scenarios\nwhere the modality discrepancy could vary across different samples. To this\nend, we introduce a sample-level modality valuation metric to evaluate the\ncontribution of each modality for each sample. Via modality valuation, we\nobserve that modality discrepancy indeed could be different at sample-level,\nbeyond the global contribution discrepancy at dataset-level. We further analyze\nthis issue and improve cooperation between modalities at sample-level by\nenhancing the discriminative ability of low-contributing modalities in a\ntargeted manner. Overall, our methods reasonably observe the fine-grained\nuni-modal contribution and achieve considerable improvement. The source code\nand dataset are available at\n\\url{https://github.com/GeWu-Lab/Valuate-and-Enhance-Multimodal-Cooperation}.\n","authors":["Yake Wei","Ruoxuan Feng","Zihe Wang","Di Hu"],"pdf_url":"https://arxiv.org/pdf/2309.06255v3.pdf","comment":"Accepted by CVPR 2024"},{"id":"http://arxiv.org/abs/2403.10406v2","updated":"2024-03-21T01:45:43Z","published":"2024-03-15T15:38:30Z","title":"Deep Bi-directional Attention Network for Image Super-Resolution Quality\n  Assessment","summary":"  There has emerged a growing interest in exploring efficient quality\nassessment algorithms for image super-resolution (SR). However, employing deep\nlearning techniques, especially dual-branch algorithms, to automatically\nevaluate the visual quality of SR images remains challenging. Existing SR image\nquality assessment (IQA) metrics based on two-stream networks lack interactions\nbetween branches. To address this, we propose a novel full-reference IQA\n(FR-IQA) method for SR images. Specifically, producing SR images and evaluating\nhow close the SR images are to the corresponding HR references are separate\nprocesses. Based on this consideration, we construct a deep Bi-directional\nAttention Network (BiAtten-Net) that dynamically deepens visual attention to\ndistortions in both processes, which aligns well with the human visual system\n(HVS). Experiments on public SR quality databases demonstrate the superiority\nof our proposed BiAtten-Net over state-of-the-art quality assessment methods.\nIn addition, the visualization results and ablation study show the\neffectiveness of bi-directional attention.\n","authors":["Yixiao Li","Xiaoyuan Yang","Jun Fu","Guanghui Yue","Wei Zhou"],"pdf_url":"https://arxiv.org/pdf/2403.10406v2.pdf","comment":"7 pages, 3 figures, published to 2024 IEEE International Conference\n  on Multimedia and Expo (ICME)"}],"Machine Learning 2":[{"id":"http://arxiv.org/abs/2403.14830v1","updated":"2024-03-21T20:43:44Z","published":"2024-03-21T20:43:44Z","title":"Deep Clustering Evaluation: How to Validate Internal Clustering\n  Validation Measures","summary":"  Deep clustering, a method for partitioning complex, high-dimensional data\nusing deep neural networks, presents unique evaluation challenges. Traditional\nclustering validation measures, designed for low-dimensional spaces, are\nproblematic for deep clustering, which involves projecting data into\nlower-dimensional embeddings before partitioning. Two key issues are\nidentified: 1) the curse of dimensionality when applying these measures to raw\ndata, and 2) the unreliable comparison of clustering results across different\nembedding spaces stemming from variations in training procedures and parameter\nsettings in different clustering models. This paper addresses these challenges\nin evaluating clustering quality in deep learning. We present a theoretical\nframework to highlight ineffectiveness arising from using internal validation\nmeasures on raw and embedded data and propose a systematic approach to applying\nclustering validity indices in deep clustering contexts. Experiments show that\nthis framework aligns better with external validation measures, effectively\nreducing the misguidance from the improper use of clustering validity indices\nin deep learning.\n","authors":["Zeya Wang","Chenglong Ye"],"pdf_url":"https://arxiv.org/pdf/2403.14830v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.14829v1","updated":"2024-03-21T20:43:34Z","published":"2024-03-21T20:43:34Z","title":"Hyperbolic Secant representation of the logistic function: Application\n  to probabilistic Multiple Instance Learning for CT intracranial hemorrhage\n  detection","summary":"  Multiple Instance Learning (MIL) is a weakly supervised paradigm that has\nbeen successfully applied to many different scientific areas and is\nparticularly well suited to medical imaging. Probabilistic MIL methods, and\nmore specifically Gaussian Processes (GPs), have achieved excellent results due\nto their high expressiveness and uncertainty quantification capabilities. One\nof the most successful GP-based MIL methods, VGPMIL, resorts to a variational\nbound to handle the intractability of the logistic function. Here, we formulate\nVGPMIL using P\\'olya-Gamma random variables. This approach yields the same\nvariational posterior approximations as the original VGPMIL, which is a\nconsequence of the two representations that the Hyperbolic Secant distribution\nadmits. This leads us to propose a general GP-based MIL method that takes\ndifferent forms by simply leveraging distributions other than the Hyperbolic\nSecant one. Using the Gamma distribution we arrive at a new approach that\nobtains competitive or superior predictive performance and efficiency. This is\nvalidated in a comprehensive experimental study including one synthetic MIL\ndataset, two well-known MIL benchmarks, and a real-world medical problem. We\nexpect that this work provides useful ideas beyond MIL that can foster further\nresearch in the field.\n","authors":["F. M. Castro-Mac√≠as","P. Morales-√Ålvarez","Y. Wu","R. Molina","A. K. Katsaggelos"],"pdf_url":"https://arxiv.org/pdf/2403.14829v1.pdf","comment":"48 pages, 12 figures, published in Artificial Intelligence Journal"},{"id":"http://arxiv.org/abs/2403.14822v1","updated":"2024-03-21T20:29:43Z","published":"2024-03-21T20:29:43Z","title":"Non-Convex Robust Hypothesis Testing using Sinkhorn Uncertainty Sets","summary":"  We present a new framework to address the non-convex robust hypothesis\ntesting problem, wherein the goal is to seek the optimal detector that\nminimizes the maximum of worst-case type-I and type-II risk functions. The\ndistributional uncertainty sets are constructed to center around the empirical\ndistribution derived from samples based on Sinkhorn discrepancy. Given that the\nobjective involves non-convex, non-smooth probabilistic functions that are\noften intractable to optimize, existing methods resort to approximations rather\nthan exact solutions. To tackle the challenge, we introduce an exact\nmixed-integer exponential conic reformulation of the problem, which can be\nsolved into a global optimum with a moderate amount of input data.\nSubsequently, we propose a convex approximation, demonstrating its superiority\nover current state-of-the-art methodologies in literature. Furthermore, we\nestablish connections between robust hypothesis testing and regularized\nformulations of non-robust risk functions, offering insightful interpretations.\nOur numerical study highlights the satisfactory testing performance and\ncomputational efficiency of the proposed framework.\n","authors":["Jie Wang","Rui Gao","Yao Xie"],"pdf_url":"https://arxiv.org/pdf/2403.14822v1.pdf","comment":"26 pages, 2 figures"},{"id":"http://arxiv.org/abs/2403.14813v1","updated":"2024-03-21T19:59:07Z","published":"2024-03-21T19:59:07Z","title":"Curvature Augmented Manifold Embedding and Learning","summary":"  A new dimensional reduction (DR) and data visualization method,\nCurvature-Augmented Manifold Embedding and Learning (CAMEL), is proposed. The\nkey novel contribution is to formulate the DR problem as a mechanistic/physics\nmodel, where the force field among nodes (data points) is used to find an\nn-dimensional manifold representation of the data sets. Compared with many\nexisting attractive-repulsive force-based methods, one unique contribution of\nthe proposed method is to include a non-pairwise force. A new force field model\nis introduced and discussed, inspired by the multi-body potential in\nlattice-particle physics and Riemann curvature in topology. A\ncurvature-augmented force is included in CAMEL. Following this, CAMEL\nformulation for unsupervised learning, supervised learning, semi-supervised\nlearning/metric learning, and inverse learning are provided. Next, CAMEL is\napplied to many benchmark datasets by comparing existing models, such as tSNE,\nUMAP, TRIMAP, and PacMap. Both visual comparison and metrics-based evaluation\nare performed. 14 open literature and self-proposed metrics are employed for a\ncomprehensive comparison. Conclusions and future work are suggested based on\nthe current investigation. Related code and demonstration are available on\nhttps://github.com/ymlasu/CAMEL for interested readers to reproduce the results\nand other applications.\n","authors":["Yongming Liu"],"pdf_url":"https://arxiv.org/pdf/2403.14813v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.14593v1","updated":"2024-03-21T17:48:38Z","published":"2024-03-21T17:48:38Z","title":"Rethinking Adversarial Inverse Reinforcement Learning: From the Angles\n  of Policy Imitation and Transferable Reward Recovery","summary":"  Adversarial inverse reinforcement learning (AIRL) stands as a cornerstone\napproach in imitation learning. This paper rethinks the two different angles of\nAIRL: policy imitation and transferable reward recovery. We begin with\nsubstituting the built-in algorithm in AIRL with soft actor-critic (SAC) during\nthe policy optimization process to enhance sample efficiency, thanks to the\noff-policy formulation of SAC and identifiable Markov decision process (MDP)\nmodels with respect to AIRL. It indeed exhibits a significant improvement in\npolicy imitation but accidentally brings drawbacks to transferable reward\nrecovery. To learn this issue, we illustrate that the SAC algorithm itself is\nnot feasible to disentangle the reward function comprehensively during the AIRL\ntraining process, and propose a hybrid framework, PPO-AIRL + SAC, for\nsatisfactory transfer effect. Additionally, we analyze the capability of\nenvironments to extract disentangled rewards from an algebraic theory\nperspective.\n","authors":["Yangchun Zhang","Yirui Zhou"],"pdf_url":"https://arxiv.org/pdf/2403.14593v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.14573v1","updated":"2024-03-21T17:20:23Z","published":"2024-03-21T17:20:23Z","title":"A Transfer Learning Causal Approach to Evaluate Racial/Ethnic and\n  Geographic Variation in Outcomes Following Congenital Heart Surgery","summary":"  Congenital heart defects (CHD) are the most prevalent birth defects in the\nUnited States and surgical outcomes vary considerably across the country. The\noutcomes of treatment for CHD differ for specific patient subgroups, with\nnon-Hispanic Black and Hispanic populations experiencing higher rates of\nmortality and morbidity. A valid comparison of outcomes within racial/ethnic\nsubgroups is difficult given large differences in case-mix and small subgroup\nsizes. We propose a causal inference framework for outcome assessment and\nleverage advances in transfer learning to incorporate data from both target and\nsource populations to help estimate causal effects while accounting for\ndifferent sources of risk factor and outcome differences across populations.\nUsing the Society of Thoracic Surgeons' Congenital Heart Surgery Database\n(STS-CHSD), we focus on a national cohort of patients undergoing the Norwood\noperation from 2016-2022 to assess operative mortality and morbidity outcomes\nacross U.S. geographic regions by race/ethnicity. We find racial and ethnic\noutcome differences after controlling for potential confounding factors. While\ngeography does not have a causal effect on outcomes for non-Hispanic Caucasian\npatients, non-Hispanic Black patients experience wide variability in outcomes\nwith estimated 30-day mortality ranging from 5.9% (standard error 2.2%) to\n21.6% (4.4%) across U.S. regions.\n","authors":["Larry Han","Yi Zhang","Meena Nathan","John E. Mayer, Jr.","Sara K. Pasquali","Katya Zelevinsky","Rui Duan","Sharon-Lise T. Normand"],"pdf_url":"https://arxiv.org/pdf/2403.14573v1.pdf","comment":"26 pages"},{"id":"http://arxiv.org/abs/2312.09234v3","updated":"2024-03-21T16:26:09Z","published":"2023-12-14T18:57:16Z","title":"Let's do the time-warp-attend: Learning topological invariants of\n  dynamical systems","summary":"  Dynamical systems across the sciences, from electrical circuits to ecological\nnetworks, undergo qualitative and often catastrophic changes in behavior,\ncalled bifurcations, when their underlying parameters cross a threshold.\nExisting methods predict oncoming catastrophes in individual systems but are\nprimarily time-series-based and struggle both to categorize qualitative\ndynamical regimes across diverse systems and to generalize to real data. To\naddress this challenge, we propose a data-driven, physically-informed\ndeep-learning framework for classifying dynamical regimes and characterizing\nbifurcation boundaries based on the extraction of topologically invariant\nfeatures. We focus on the paradigmatic case of the supercritical Hopf\nbifurcation, which is used to model periodic dynamics across a wide range of\napplications. Our convolutional attention method is trained with data\naugmentations that encourage the learning of topological invariants which can\nbe used to detect bifurcation boundaries in unseen systems and to design models\nof biological systems like oscillatory gene regulatory networks. We further\ndemonstrate our method's use in analyzing real data by recovering distinct\nproliferation and differentiation dynamics along pancreatic endocrinogenesis\ntrajectory in gene expression space based on single-cell data. Our method\nprovides valuable insights into the qualitative, long-term behavior of a wide\nrange of dynamical systems, and can detect bifurcations or catastrophic\ntransitions in large-scale physical and biological systems.\n","authors":["Noa Moriel","Matthew Ricci","Mor Nitzan"],"pdf_url":"https://arxiv.org/pdf/2312.09234v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2310.12032v2","updated":"2024-03-21T14:36:26Z","published":"2023-10-18T15:16:24Z","title":"Exact and general decoupled solutions of the LMC Multitask Gaussian\n  Process model","summary":"  The Linear Model of Co-regionalization (LMC) is a very general model of\nmultitask gaussian process for regression or classification. While its\nexpressivity and conceptual simplicity are appealing, naive implementations\nhave cubic complexity in the number of datapoints and number of tasks, making\napproximations mandatory for most applications. However, recent work has shown\nthat under some conditions the latent processes of the model can be decoupled,\nleading to a complexity that is only linear in the number of said processes. We\nhere extend these results, showing from the most general assumptions that the\nonly condition necessary to an efficient exact computation of the LMC is a mild\nhypothesis on the noise model. We introduce a full parametrization of the\nresulting \\emph{projected LMC} model, and an expression of the marginal\nlikelihood enabling efficient optimization. We perform a parametric study on\nsynthetic data to show the excellent performance of our approach, compared to\nan unrestricted exact LMC and approximations of the latter. Overall, the\nprojected LMC appears as a credible and simpler alternative to state-of-the art\nmodels, which greatly facilitates some computations such as leave-one-out\ncross-validation and fantasization.\n","authors":["Olivier Truffinet","Karim Ammar","Jean-Philippe Argaud","Bertrand Bouriquet"],"pdf_url":"https://arxiv.org/pdf/2310.12032v2.pdf","comment":"29 pages, 10 figures, submitted to UAI"},{"id":"http://arxiv.org/abs/2209.10053v5","updated":"2024-03-21T14:12:15Z","published":"2022-09-21T00:44:20Z","title":"Instance-dependent uniform tail bounds for empirical processes","summary":"  We formulate a uniform tail bound for empirical processes indexed by a class\nof functions, in terms of the individual deviations of the functions rather\nthan the worst-case deviation in the considered class. The tail bound is\nestablished by introducing an initial \"deflation\" step to the standard generic\nchaining argument. The resulting tail bound is the sum of the complexity of the\n\"deflated function class\" in terms of a generalization of Talagrand's $\\gamma$\nfunctional, and the deviation of the function instance, both of which are\nformulated based on the natural seminorm induced by the corresponding\nCram\\'{e}r functions. We also provide certain approximations for the mentioned\nseminorm when the function class lies in a given (exponential type) Orlicz\nspace, that can be used to make the complexity term and the deviation term more\nexplicit.\n","authors":["Sohail Bahmani"],"pdf_url":"https://arxiv.org/pdf/2209.10053v5.pdf","comment":"25 pages. Revised and extended one of the examples for a more clear,\n  detailed, and accurate description"},{"id":"http://arxiv.org/abs/2403.14385v1","updated":"2024-03-21T13:21:33Z","published":"2024-03-21T13:21:33Z","title":"Estimating Causal Effects with Double Machine Learning -- A Method\n  Evaluation","summary":"  The estimation of causal effects with observational data continues to be a\nvery active research area. In recent years, researchers have developed new\nframeworks which use machine learning to relax classical assumptions necessary\nfor the estimation of causal effects. In this paper, we review one of the most\nprominent methods - \"double/debiased machine learning\" (DML) - and empirically\nevaluate it by comparing its performance on simulated data relative to more\ntraditional statistical methods, before applying it to real-world data. Our\nfindings indicate that the application of a suitably flexible machine learning\nalgorithm within DML improves the adjustment for various nonlinear confounding\nrelationships. This advantage enables a departure from traditional functional\nform assumptions typically necessary in causal effect estimation. However, we\ndemonstrate that the method continues to critically depend on standard\nassumptions about causal structure and identification. When estimating the\neffects of air pollution on housing prices in our application, we find that DML\nestimates are consistently larger than estimates of less flexible methods. From\nour overall results, we provide actionable recommendations for specific choices\nresearchers must make when applying DML in practice.\n","authors":["Jonathan Fuhr","Philipp Berens","Dominik Papies"],"pdf_url":"https://arxiv.org/pdf/2403.14385v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.10326v2","updated":"2024-03-21T12:54:04Z","published":"2024-02-15T21:01:29Z","title":"Mathematical Opportunities in Digital Twins (MATH-DT)","summary":"  The report describes the discussions from the Workshop on Mathematical\nOpportunities in Digital Twins (MATH-DT) from December 11-13, 2023, George\nMason University.\n  It illustrates that foundational Mathematical advances are required for\nDigital Twins (DTs) that are different from traditional approaches. A\ntraditional model, in biology, physics, engineering or medicine, starts with a\ngeneric physical law (e.g., equations) and is often a simplification of\nreality. A DT starts with a specific ecosystem, object or person (e.g.,\npersonalized care) representing reality, requiring multi -scale, -physics\nmodeling and coupling. Thus, these processes begin at opposite ends of the\nsimulation and modeling pipeline, requiring different reliability criteria and\nuncertainty assessments. Additionally, unlike existing approaches, a DT assists\nhumans to make decisions for the physical system, which (via sensors) in turn\nfeeds data into the DT, and operates for the life of the physical system.\n  While some of the foundational mathematical research can be done without a\nspecific application context, one must also keep specific applications in mind\nfor DTs. E.g., modeling a bridge or a biological system (a patient), or a\nsocio-technical system (a city) is very different. The models range from\ndifferential equations (deterministic/uncertain) in engineering, to stochastic\nin biology, including agent-based. These are multi-scale hybrid models or large\nscale (multi-objective) optimization problems under uncertainty. There are no\nuniversal models or approaches. For e.g., Kalman filters for forecasting might\nwork in engineering, but can fail in biomedical domain. Ad hoc studies, with\nlimited systematic work, have shown that AI/ML methods can fail for simple\nengineering systems and can work well for biomedical problems.\n  A list of `Mathematical Opportunities and Challenges' concludes the report.\n","authors":["Harbir Antil"],"pdf_url":"https://arxiv.org/pdf/2402.10326v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2310.03054v3","updated":"2024-03-21T12:43:34Z","published":"2023-10-04T11:40:02Z","title":"Posterior Sampling Based on Gradient Flows of the MMD with Negative\n  Distance Kernel","summary":"  We propose conditional flows of the maximum mean discrepancy (MMD) with the\nnegative distance kernel for posterior sampling and conditional generative\nmodeling. This MMD, which is also known as energy distance, has several\nadvantageous properties like efficient computation via slicing and sorting. We\napproximate the joint distribution of the ground truth and the observations\nusing discrete Wasserstein gradient flows and establish an error bound for the\nposterior distributions. Further, we prove that our particle flow is indeed a\nWasserstein gradient flow of an appropriate functional. The power of our method\nis demonstrated by numerical examples including conditional image generation\nand inverse problems like superresolution, inpainting and computed tomography\nin low-dose and limited-angle settings.\n","authors":["Paul Hagemann","Johannes Hertrich","Fabian Altekr√ºger","Robert Beinert","Jannis Chemseddine","Gabriele Steidl"],"pdf_url":"https://arxiv.org/pdf/2310.03054v3.pdf","comment":"Published as a conference paper at ICLR 2024"},{"id":"http://arxiv.org/abs/2303.10712v2","updated":"2024-03-21T12:19:24Z","published":"2023-03-19T16:43:17Z","title":"Mixture of segmentation for heterogeneous functional data","summary":"  In this paper we consider functional data with heterogeneity in time and in\npopulation. We propose a mixture model with segmentation of time to represent\nthis heterogeneity while keeping the functional structure. Maximum likelihood\nestimator is considered, proved to be identifiable and consistent. In practice,\nan EM algorithm is used, combined with dynamic programming for the maximization\nstep, to approximate the maximum likelihood estimator. The method is\nillustrated on a simulated dataset, and used on a real dataset of electricity\nconsumption.\n","authors":["Vincent Brault","√âmilie Devijver","Charlotte Laclau"],"pdf_url":"https://arxiv.org/pdf/2303.10712v2.pdf","comment":"45 pages, 13 figures"},{"id":"http://arxiv.org/abs/2305.15141v3","updated":"2024-03-21T10:15:19Z","published":"2023-05-24T13:36:06Z","title":"From Tempered to Benign Overfitting in ReLU Neural Networks","summary":"  Overparameterized neural networks (NNs) are observed to generalize well even\nwhen trained to perfectly fit noisy data. This phenomenon motivated a large\nbody of work on \"benign overfitting\", where interpolating predictors achieve\nnear-optimal performance. Recently, it was conjectured and empirically observed\nthat the behavior of NNs is often better described as \"tempered overfitting\",\nwhere the performance is non-optimal yet also non-trivial, and degrades as a\nfunction of the noise level. However, a theoretical justification of this claim\nfor non-linear NNs has been lacking so far. In this work, we provide several\nresults that aim at bridging these complementing views. We study a simple\nclassification setting with 2-layer ReLU NNs, and prove that under various\nassumptions, the type of overfitting transitions from tempered in the extreme\ncase of one-dimensional data, to benign in high dimensions. Thus, we show that\nthe input dimension has a crucial role on the type of overfitting in this\nsetting, which we also validate empirically for intermediate dimensions.\nOverall, our results shed light on the intricate connections between the\ndimension, sample size, architecture and training algorithm on the one hand,\nand the type of resulting overfitting on the other hand.\n","authors":["Guy Kornowski","Gilad Yehudai","Ohad Shamir"],"pdf_url":"https://arxiv.org/pdf/2305.15141v3.pdf","comment":"NeurIPS 2023; fixed bug"},{"id":"http://arxiv.org/abs/2308.03574v2","updated":"2024-03-21T09:13:17Z","published":"2023-08-07T13:25:48Z","title":"Generalized Early Stopping in Evolutionary Direct Policy Search","summary":"  Lengthy evaluation times are common in many optimization problems such as\ndirect policy search tasks, especially when they involve conducting evaluations\nin the physical world, e.g. in robotics applications. Often when evaluating\nsolution over a fixed time period it becomes clear that the objective value\nwill not increase with additional computation time (for example when a two\nwheeled robot continuously spins on the spot). In such cases, it makes sense to\nstop the evaluation early to save computation time. However, most approaches to\nstop the evaluation are problem specific and need to be specifically designed\nfor the task at hand. Therefore, we propose an early stopping method for direct\npolicy search. The proposed method only looks at the objective value at each\ntime step and requires no problem specific knowledge. We test the introduced\nstopping criterion in five direct policy search environments drawn from games,\nrobotics and classic control domains, and show that it can save up to 75% of\nthe computation time. We also compare it with problem specific stopping\ncriteria and show that it performs comparably, while being more generally\napplicable.\n","authors":["Etor Arza","Leni K. Le Goff","Emma Hart"],"pdf_url":"https://arxiv.org/pdf/2308.03574v2.pdf","comment":null},{"id":"http://arxiv.org/abs/1902.06931v5","updated":"2024-03-21T09:01:19Z","published":"2019-02-19T07:27:19Z","title":"On the consistency of supervised learning with missing values","summary":"  In many application settings, the data have missing entries which make\nanalysis challenging. An abundant literature addresses missing values in an\ninferential framework: estimating parameters and their variance from incomplete\ntables. Here, we consider supervised-learning settings: predicting a target\nwhen missing values appear in both training and testing data. We show the\nconsistency of two approaches in prediction. A striking result is that the\nwidely-used method of imputing with a constant, such as the mean prior to\nlearning is consistent when missing values are not informative. This contrasts\nwith inferential settings where mean imputation is pointed at for distorting\nthe distribution of the data. That such a simple approach can be consistent is\nimportant in practice. We also show that a predictor suited for complete\nobservations can predict optimally on incomplete data, through multiple\nimputation. Finally, to compare imputation with learning directly with a model\nthat accounts for missing values, we analyze further decision trees. These can\nnaturally tackle empirical risk minimization with missing values, due to their\nability to handle the half-discrete nature of incomplete variables. After\ncomparing theoretically and empirically different missing values strategies in\ntrees, we recommend using the \"missing incorporated in attribute\" method as it\ncan handle both non-informative and informative missing values.\n","authors":["Julie Josse","Jacob M. Chen","Nicolas Prost","Erwan Scornet","Ga√´l Varoquaux"],"pdf_url":"https://arxiv.org/pdf/1902.06931v5.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.14228v1","updated":"2024-03-21T08:39:13Z","published":"2024-03-21T08:39:13Z","title":"Recovering Latent Confounders from High-dimensional Proxy Variables","summary":"  Detecting latent confounders from proxy variables is an essential problem in\ncausal effect estimation. Previous approaches are limited to low-dimensional\nproxies, sorted proxies, and binary treatments. We remove these assumptions and\npresent a novel Proxy Confounder Factorization (PCF) framework for continuous\ntreatment effect estimation when latent confounders manifest through\nhigh-dimensional, mixed proxy variables. For specific sample sizes, our\ntwo-step PCF implementation, using Independent Component Analysis (ICA-PCF),\nand the end-to-end implementation, using Gradient Descent (GD-PCF), achieve\nhigh correlation with the latent confounder and low absolute error in causal\neffect estimation with synthetic datasets in the high sample size regime. Even\nwhen faced with climate data, ICA-PCF recovers four components that explain\n$75.9\\%$ of the variance in the North Atlantic Oscillation, a known confounder\nof precipitation patterns in Europe. Code for our PCF implementations and\nexperiments can be found here: https://github.com/IPL-UV/confound_it. The\nproposed methodology constitutes a stepping stone towards discovering latent\nconfounders and can be applied to many problems in disciplines dealing with\nhigh-dimensional observed proxies, e.g., spatiotemporal fields.\n","authors":["Nathan Mankovich","Homer Durand","Emiliano Diaz","Gherardo Varando","Gustau Camps-Valls"],"pdf_url":"https://arxiv.org/pdf/2403.14228v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.14225v1","updated":"2024-03-21T08:31:36Z","published":"2024-03-21T08:31:36Z","title":"Posterior concentrations of fully-connected Bayesian neural networks\n  with general priors on the weights","summary":"  Bayesian approaches for training deep neural networks (BNNs) have received\nsignificant interest and have been effectively utilized in a wide range of\napplications. There have been several studies on the properties of posterior\nconcentrations of BNNs. However, most of these studies only demonstrate results\nin BNN models with sparse or heavy-tailed priors. Surprisingly, no theoretical\nresults currently exist for BNNs using Gaussian priors, which are the most\ncommonly used one. The lack of theory arises from the absence of approximation\nresults of Deep Neural Networks (DNNs) that are non-sparse and have bounded\nparameters. In this paper, we present a new approximation theory for non-sparse\nDNNs with bounded parameters. Additionally, based on the approximation theory,\nwe show that BNNs with non-sparse general priors can achieve near-minimax\noptimal posterior concentration rates to the true model.\n","authors":["Insung Kong","Yongdai Kim"],"pdf_url":"https://arxiv.org/pdf/2403.14225v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2310.02712v2","updated":"2024-03-21T07:20:35Z","published":"2023-10-04T10:28:38Z","title":"ED-NeRF: Efficient Text-Guided Editing of 3D Scene with Latent Space\n  NeRF","summary":"  Recently, there has been a significant advancement in text-to-image diffusion\nmodels, leading to groundbreaking performance in 2D image generation. These\nadvancements have been extended to 3D models, enabling the generation of novel\n3D objects from textual descriptions. This has evolved into NeRF editing\nmethods, which allow the manipulation of existing 3D objects through textual\nconditioning. However, existing NeRF editing techniques have faced limitations\nin their performance due to slow training speeds and the use of loss functions\nthat do not adequately consider editing. To address this, here we present a\nnovel 3D NeRF editing approach dubbed ED-NeRF by successfully embedding\nreal-world scenes into the latent space of the latent diffusion model (LDM)\nthrough a unique refinement layer. This approach enables us to obtain a NeRF\nbackbone that is not only faster but also more amenable to editing compared to\ntraditional image space NeRF editing. Furthermore, we propose an improved loss\nfunction tailored for editing by migrating the delta denoising score (DDS)\ndistillation loss, originally used in 2D image editing to the three-dimensional\ndomain. This novel loss function surpasses the well-known score distillation\nsampling (SDS) loss in terms of suitability for editing purposes. Our\nexperimental results demonstrate that ED-NeRF achieves faster editing speed\nwhile producing improved output quality compared to state-of-the-art 3D editing\nmodels.\n","authors":["Jangho Park","Gihyun Kwon","Jong Chul Ye"],"pdf_url":"https://arxiv.org/pdf/2310.02712v2.pdf","comment":"ICLR 2024; Project Page: https://jhq1234.github.io/ed-nerf.github.io/"},{"id":"http://arxiv.org/abs/2403.14183v1","updated":"2024-03-21T07:15:37Z","published":"2024-03-21T07:15:37Z","title":"OTSeg: Multi-prompt Sinkhorn Attention for Zero-Shot Semantic\n  Segmentation","summary":"  The recent success of CLIP has demonstrated promising results in zero-shot\nsemantic segmentation by transferring muiltimodal knowledge to pixel-level\nclassification. However, leveraging pre-trained CLIP knowledge to closely align\ntext embeddings with pixel embeddings still has limitations in existing\napproaches. To address this issue, we propose OTSeg, a novel multimodal\nattention mechanism aimed at enhancing the potential of multiple text prompts\nfor matching associated pixel embeddings. We first propose Multi-Prompts\nSinkhorn (MPS) based on the Optimal Transport (OT) algorithm, which leads\nmultiple text prompts to selectively focus on various semantic features within\nimage pixels. Moreover, inspired by the success of Sinkformers in unimodal\nsettings, we introduce the extension of MPS, called Multi-Prompts Sinkhorn\nAttention (MPSA), which effectively replaces cross-attention mechanisms within\nTransformer framework in multimodal settings. Through extensive experiments, we\ndemonstrate that OTSeg achieves state-of-the-art (SOTA) performance with\nsignificant gains on Zero-Shot Semantic Segmentation (ZS3) tasks across three\nbenchmark datasets.\n","authors":["Kwanyoung Kim","Yujin Oh","Jong Chul Ye"],"pdf_url":"https://arxiv.org/pdf/2403.14183v1.pdf","comment":"22 pages, 7 figures"}]},"2024-03-20T00:00:00Z":{"Multimedia":[{"id":"http://arxiv.org/abs/2403.13667v1","updated":"2024-03-20T15:24:57Z","published":"2024-03-20T15:24:57Z","title":"DanceCamera3D: 3D Camera Movement Synthesis with Music and Dance","summary":"  Choreographers determine what the dances look like, while cameramen determine\nthe final presentation of dances. Recently, various methods and datasets have\nshowcased the feasibility of dance synthesis. However, camera movement\nsynthesis with music and dance remains an unsolved challenging problem due to\nthe scarcity of paired data. Thus, we present DCM, a new multi-modal 3D\ndataset, which for the first time combines camera movement with dance motion\nand music audio. This dataset encompasses 108 dance sequences (3.2 hours) of\npaired dance-camera-music data from the anime community, covering 4 music\ngenres. With this dataset, we uncover that dance camera movement is\nmultifaceted and human-centric, and possesses multiple influencing factors,\nmaking dance camera synthesis a more challenging task compared to camera or\ndance synthesis alone. To overcome these difficulties, we propose\nDanceCamera3D, a transformer-based diffusion model that incorporates a novel\nbody attention loss and a condition separation strategy. For evaluation, we\ndevise new metrics measuring camera movement quality, diversity, and dancer\nfidelity. Utilizing these metrics, we conduct extensive experiments on our DCM\ndataset, providing both quantitative and qualitative evidence showcasing the\neffectiveness of our DanceCamera3D model. Code and video demos are available at\nhttps://github.com/Carmenw1203/DanceCamera3D-Official.\n","authors":["Zixuan Wang","Jia Jia","Shikun Sun","Haozhe Wu","Rong Han","Zhenyu Li","Di Tang","Jiaqing Zhou","Jiebo Luo"],"pdf_url":"https://arxiv.org/pdf/2403.13667v1.pdf","comment":"Accept to CVPR 2024"},{"id":"http://arxiv.org/abs/2403.11959v2","updated":"2024-03-20T11:58:23Z","published":"2024-03-18T16:56:47Z","title":"IVAC-P2L: Leveraging Irregular Repetition Priors for Improving Video\n  Action Counting","summary":"  Video Action Counting (VAC) is crucial in analyzing sports, fitness, and\neveryday activities by quantifying repetitive actions in videos. However,\ntraditional VAC methods have overlooked the complexity of action repetitions,\nsuch as interruptions and the variability in cycle duration. Our research\naddresses the shortfall by introducing a novel approach to VAC, called\nIrregular Video Action Counting (IVAC). IVAC prioritizes modeling irregular\nrepetition patterns in videos, which we define through two primary aspects:\nInter-cycle Consistency and Cycle-interval Inconsistency. Inter-cycle\nConsistency ensures homogeneity in the spatial-temporal representations of\ncycle segments, signifying action uniformity within cycles. Cycle-interval\ninconsistency highlights the importance of distinguishing between cycle\nsegments and intervals based on their inherent content differences. To\nencapsulate these principles, we propose a new methodology that includes\nconsistency and inconsistency modules, supported by a unique pull-push loss\n(P2L) mechanism. The IVAC-P2L model applies a pull loss to promote coherence\namong cycle segment features and a push loss to clearly distinguish features of\ncycle segments from interval segments. Empirical evaluations conducted on the\nRepCount dataset demonstrate that the IVAC-P2L model sets a new benchmark in\nVAC task performance. Furthermore, the model demonstrates exceptional\nadaptability and generalization across various video contents, outperforming\nexisting models on two additional datasets, UCFRep and Countix, without the\nneed for dataset-specific optimization. These results confirm the efficacy of\nour approach in addressing irregular repetitions in videos and pave the way for\nfurther advancements in video analysis and understanding.\n","authors":["Hang Wang","Zhi-Qi Cheng","Youtian Du","Lei Zhang"],"pdf_url":"https://arxiv.org/pdf/2403.11959v2.pdf","comment":"Source code: https://github.com/hwang-cs-ime/IVAC-P2L"},{"id":"http://arxiv.org/abs/2403.13501v1","updated":"2024-03-20T10:58:58Z","published":"2024-03-20T10:58:58Z","title":"VSTAR: Generative Temporal Nursing for Longer Dynamic Video Synthesis","summary":"  Despite tremendous progress in the field of text-to-video (T2V) synthesis,\nopen-sourced T2V diffusion models struggle to generate longer videos with\ndynamically varying and evolving content. They tend to synthesize quasi-static\nvideos, ignoring the necessary visual change-over-time implied in the text\nprompt. At the same time, scaling these models to enable longer, more dynamic\nvideo synthesis often remains computationally intractable. To address this\nchallenge, we introduce the concept of Generative Temporal Nursing (GTN), where\nwe aim to alter the generative process on the fly during inference to improve\ncontrol over the temporal dynamics and enable generation of longer videos. We\npropose a method for GTN, dubbed VSTAR, which consists of two key ingredients:\n1) Video Synopsis Prompting (VSP) - automatic generation of a video synopsis\nbased on the original single prompt leveraging LLMs, which gives accurate\ntextual guidance to different visual states of longer videos, and 2) Temporal\nAttention Regularization (TAR) - a regularization technique to refine the\ntemporal attention units of the pre-trained T2V diffusion models, which enables\ncontrol over the video dynamics. We experimentally showcase the superiority of\nthe proposed approach in generating longer, visually appealing videos over\nexisting open-sourced T2V models. We additionally analyze the temporal\nattention maps realized with and without VSTAR, demonstrating the importance of\napplying our method to mitigate neglect of the desired visual change over time.\n","authors":["Yumeng Li","William Beluch","Margret Keuper","Dan Zhang","Anna Khoreva"],"pdf_url":"https://arxiv.org/pdf/2403.13501v1.pdf","comment":"Project page: https://yumengli007.github.io/VSTAR"},{"id":"http://arxiv.org/abs/2403.13480v1","updated":"2024-03-20T10:34:40Z","published":"2024-03-20T10:34:40Z","title":"A Unified Optimal Transport Framework for Cross-Modal Retrieval with\n  Noisy Labels","summary":"  Cross-modal retrieval (CMR) aims to establish interaction between different\nmodalities, among which supervised CMR is emerging due to its flexibility in\nlearning semantic category discrimination. Despite the remarkable performance\nof previous supervised CMR methods, much of their success can be attributed to\nthe well-annotated data. However, even for unimodal data, precise annotation is\nexpensive and time-consuming, and it becomes more challenging with the\nmultimodal scenario. In practice, massive multimodal data are collected from\nthe Internet with coarse annotation, which inevitably introduces noisy labels.\nTraining with such misleading labels would bring two key challenges --\nenforcing the multimodal samples to \\emph{align incorrect semantics} and\n\\emph{widen the heterogeneous gap}, resulting in poor retrieval performance. To\ntackle these challenges, this work proposes UOT-RCL, a Unified framework based\non Optimal Transport (OT) for Robust Cross-modal Retrieval. First, we propose a\nsemantic alignment based on partial OT to progressively correct the noisy\nlabels, where a novel cross-modal consistent cost function is designed to blend\ndifferent modalities and provide precise transport cost. Second, to narrow the\ndiscrepancy in multi-modal data, an OT-based relation alignment is proposed to\ninfer the semantic-level cross-modal matching. Both of these two components\nleverage the inherent correlation among multi-modal data to facilitate\neffective cost function. The experiments on three widely-used cross-modal\nretrieval datasets demonstrate that our UOT-RCL surpasses the state-of-the-art\napproaches and significantly improves the robustness against noisy labels.\n","authors":["Haochen Han","Minnan Luo","Huan Liu","Fang Nan"],"pdf_url":"https://arxiv.org/pdf/2403.13480v1.pdf","comment":"This work has been submitted to the IEEE for possible publication.\n  Copyright may be transferred without notice, after which this version may no\n  longer be accessible"},{"id":"http://arxiv.org/abs/2403.12053v2","updated":"2024-03-20T03:45:34Z","published":"2024-01-04T12:02:15Z","title":"PiGW: A Plug-in Generative Watermarking Framework","summary":"  Integrating watermarks into generative images is a critical strategy for\nprotecting intellectual property and enhancing artificial intelligence\nsecurity. This paper proposes Plug-in Generative Watermarking (PiGW) as a\ngeneral framework for integrating watermarks into generative images. More\nspecifically, PiGW embeds watermark information into the initial noise using a\nlearnable watermark embedding network and an adaptive frequency spectrum mask.\nFurthermore, it optimizes training costs by gradually increasing timesteps.\nExtensive experiments demonstrate that PiGW enables embedding watermarks into\nthe generated image with negligible quality loss while achieving true\ninvisibility and high resistance to noise attacks. Moreover, PiGW can serve as\na plugin for various commonly used generative structures and multimodal\ngenerative content types. Finally, we demonstrate how PiGW can also be utilized\nfor detecting generated images, contributing to the promotion of secure AI\ndevelopment. The project code will be made available on GitHub.\n","authors":["Rui Ma","Mengxi Guo","Li Yuming","Hengyuan Zhang","Cong Ma","Yuan Li","Xiaodong Xie","Shanghang Zhang"],"pdf_url":"https://arxiv.org/pdf/2403.12053v2.pdf","comment":"Improve experimental content"},{"id":"http://arxiv.org/abs/2403.12667v2","updated":"2024-03-20T03:15:31Z","published":"2024-03-19T12:05:09Z","title":"ICE: Interactive 3D Game Character Editing via Dialogue","summary":"  Text-driven in-game 3D character auto-customization systems eliminate the\ncomplicated process of manipulating intricate character control parameters.\nHowever, current methods are limited by their single-round generation,\nincapable of further editing and fine-grained modification. In this paper, we\npropose an Interactive Character Editing framework (ICE) to achieve a\nmulti-round dialogue-based refinement process. In a nutshell, our ICE offers a\nmore user-friendly way to enable players to convey creative ideas iteratively\nwhile ensuring that created characters align with the expectations of players.\nSpecifically, we propose an Instruction Parsing Module (IPM) that utilizes\nlarge language models (LLMs) to parse multi-round dialogues into clear editing\ninstruction prompts in each round. To reliably and swiftly modify character\ncontrol parameters at a fine-grained level, we propose a Semantic-guided\nLow-dimension Parameter Solver (SLPS) that edits character control parameters\naccording to prompts in a zero-shot manner. Our SLPS first localizes the\ncharacter control parameters related to the fine-grained modification, and then\noptimizes the corresponding parameters in a low-dimension space to avoid\nunrealistic results. Extensive experimental results demonstrate the\neffectiveness of our proposed ICE for in-game character creation and the\nsuperior editing performance of ICE. Project page: https://iceedit.github.io/.\n","authors":["Haoqian Wu","Yunjie Wu","Zhipeng Hu","Lincheng Li","Weijie Chen","Rui Zhao","Changjie Fan","Xin Yu"],"pdf_url":"https://arxiv.org/pdf/2403.12667v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.10943v2","updated":"2024-03-20T02:52:42Z","published":"2024-03-16T15:14:15Z","title":"MIntRec2.0: A Large-scale Benchmark Dataset for Multimodal Intent\n  Recognition and Out-of-scope Detection in Conversations","summary":"  Multimodal intent recognition poses significant challenges, requiring the\nincorporation of non-verbal modalities from real-world contexts to enhance the\ncomprehension of human intentions. Existing benchmark datasets are limited in\nscale and suffer from difficulties in handling out-of-scope samples that arise\nin multi-turn conversational interactions. We introduce MIntRec2.0, a\nlarge-scale benchmark dataset for multimodal intent recognition in multi-party\nconversations. It contains 1,245 dialogues with 15,040 samples, each annotated\nwithin a new intent taxonomy of 30 fine-grained classes. Besides 9,304 in-scope\nsamples, it also includes 5,736 out-of-scope samples appearing in multi-turn\ncontexts, which naturally occur in real-world scenarios. Furthermore, we\nprovide comprehensive information on the speakers in each utterance, enriching\nits utility for multi-party conversational research. We establish a general\nframework supporting the organization of single-turn and multi-turn dialogue\ndata, modality feature extraction, multimodal fusion, as well as in-scope\nclassification and out-of-scope detection. Evaluation benchmarks are built\nusing classic multimodal fusion methods, ChatGPT, and human evaluators. While\nexisting methods incorporating nonverbal information yield improvements,\neffectively leveraging context information and detecting out-of-scope samples\nremains a substantial challenge. Notably, large language models exhibit a\nsignificant performance gap compared to humans, highlighting the limitations of\nmachine learning methods in the cognitive intent understanding task. We believe\nthat MIntRec2.0 will serve as a valuable resource, providing a pioneering\nfoundation for research in human-machine conversational interactions, and\nsignificantly facilitating related applications. The full dataset and codes are\navailable at https://github.com/thuiar/MIntRec2.0.\n","authors":["Hanlei Zhang","Xin Wang","Hua Xu","Qianrui Zhou","Kai Gao","Jianhua Su","jinyue Zhao","Wenrui Li","Yanting Chen"],"pdf_url":"https://arxiv.org/pdf/2403.10943v2.pdf","comment":"Published in ICLR 2024; The abstract is slightly modified due to the\n  length limitation"},{"id":"http://arxiv.org/abs/2403.08505v2","updated":"2024-03-20T02:35:57Z","published":"2024-03-13T13:12:57Z","title":"Content-aware Masked Image Modeling Transformer for Stereo Image\n  Compression","summary":"  Existing learning-based stereo image codec adopt sophisticated transformation\nwith simple entropy models derived from single image codecs to encode latent\nrepresentations. However, those entropy models struggle to effectively capture\nthe spatial-disparity characteristics inherent in stereo images, which leads to\nsuboptimal rate-distortion results. In this paper, we propose a stereo image\ncompression framework, named CAMSIC. CAMSIC independently transforms each image\nto latent representation and employs a powerful decoder-free Transformer\nentropy model to capture both spatial and disparity dependencies, by\nintroducing a novel content-aware masked image modeling (MIM) technique. Our\ncontent-aware MIM facilitates efficient bidirectional interaction between prior\ninformation and estimated tokens, which naturally obviates the need for an\nextra Transformer decoder. Experiments show that our stereo image codec\nachieves state-of-the-art rate-distortion performance on two stereo image\ndatasets Cityscapes and InStereo2K with fast encoding and decoding speed.\n","authors":["Xinjie Zhang","Shenyuan Gao","Zhening Liu","Jiawei Shao","Xingtong Ge","Dailan He","Tongda Xu","Yan Wang","Jun Zhang"],"pdf_url":"https://arxiv.org/pdf/2403.08505v2.pdf","comment":null}]}}